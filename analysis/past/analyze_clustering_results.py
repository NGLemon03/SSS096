# -*- coding: utf-8 -*-
'''
åˆ†æåˆ†ç¾¤çµæœçš„è…³æœ¬
'''
import pandas as pd
import numpy as np
import json
from pathlib import Path

def analyze_clustering_results():
    """åˆ†æä¸åŒåˆ†ç¾¤æ–¹æ³•çš„æ•ˆæœ"""
    
    # è®€å–æœ€æ–°çš„å…©å€‹çµæœæª”æ¡ˆ
    results_dir = Path("results")
    
    # æª”æ¡ˆ1: æ©Ÿå™¨å­¸ç¿’åˆ†ç¾¤çµæœ (20250701_093224)
    file1 = results_dir / "optuna_results_single_20250701_093224.csv"
    file1_final = results_dir / "optuna_results_single_dtw_final_20250701_093224.csv"
    
    # æª”æ¡ˆ2: ä¹‹å‰çš„åˆ†ç¾¤çµæœ (20250701_090755) 
    file2 = results_dir / "optuna_results_single_20250701_090755.csv"
    file2_final = results_dir / "optuna_results_single_dtw_final_20250701_090755.csv"
    
    print("=== åˆ†æåˆ†ç¾¤çµæœ ===\n")
    
    # åˆ†ææª”æ¡ˆ1 (æ©Ÿå™¨å­¸ç¿’åˆ†ç¾¤)
    if file1.exists() and file1_final.exists():
        print("ğŸ“Š æª”æ¡ˆ1: æ©Ÿå™¨å­¸ç¿’åˆ†ç¾¤çµæœ (20250701_093224)")
        df1 = pd.read_csv(file1)
        df1_final = pd.read_csv(file1_final)
        
        print(f"ç¸½ç­–ç•¥æ•¸: {len(df1)}")
        print(f"åˆ†ç¾¤æ•¸: {len(df1_final)}")
        
        # åˆ†ææ¯å€‹åˆ†ç¾¤çš„ç­–ç•¥æ•¸é‡å’Œç‰¹å¾µ
        cluster_stats = df1.groupby('dtw_cluster').agg({
            'score': ['count', 'mean', 'std'],
            'total_return': ['mean', 'std'],
            'sharpe_ratio': ['mean', 'std'],
            'max_drawdown': ['mean', 'std'],
            'profit_factor': ['mean', 'std']
        }).round(3)
        
        print("\nå„åˆ†ç¾¤çµ±è¨ˆ:")
        print(cluster_stats)
        
        # åˆ†æåˆ†ç¾¤ä»£è¡¨ç­–ç•¥
        print(f"\nåˆ†ç¾¤ä»£è¡¨ç­–ç•¥:")
        for _, row in df1_final.iterrows():
            cluster = row['dtw_cluster']
            score = row['score']
            total_ret = row['total_return']
            sharpe = row['sharpe_ratio']
            params = json.loads(row['parameters'])
            
            print(f"åˆ†ç¾¤ {cluster}: è©¦é©—{row['trial_number']} (åˆ†æ•¸: {score:.2f}, å ±é…¬: {total_ret:.1f}%, å¤æ™®: {sharpe:.2f})")
            print(f"  åƒæ•¸: linlen={params['linlen']}, smaalen={params['smaalen']}, devwin={params['devwin']}")
            print(f"  buy_mult={params['buy_mult']}, sell_mult={params['sell_mult']}, stop_loss={params['stop_loss']}")
        
        print("\n" + "="*50 + "\n")
    
    # åˆ†ææª”æ¡ˆ2 (ä¹‹å‰çš„åˆ†ç¾¤)
    if file2.exists() and file2_final.exists():
        print("ğŸ“Š æª”æ¡ˆ2: ä¹‹å‰çš„åˆ†ç¾¤çµæœ (20250701_090755)")
        df2 = pd.read_csv(file2)
        df2_final = pd.read_csv(file2_final)
        
        print(f"ç¸½ç­–ç•¥æ•¸: {len(df2)}")
        print(f"åˆ†ç¾¤æ•¸: {len(df2_final)}")
        
        # åˆ†ææ¯å€‹åˆ†ç¾¤çš„ç­–ç•¥æ•¸é‡å’Œç‰¹å¾µ
        cluster_stats2 = df2.groupby('dtw_cluster').agg({
            'score': ['count', 'mean', 'std'],
            'total_return': ['mean', 'std'],
            'sharpe_ratio': ['mean', 'std'],
            'max_drawdown': ['mean', 'std'],
            'profit_factor': ['mean', 'std']
        }).round(3)
        
        print("\nå„åˆ†ç¾¤çµ±è¨ˆ:")
        print(cluster_stats2)
        
        # åˆ†æåˆ†ç¾¤ä»£è¡¨ç­–ç•¥
        print(f"\nåˆ†ç¾¤ä»£è¡¨ç­–ç•¥:")
        for _, row in df2_final.iterrows():
            cluster = row['dtw_cluster']
            score = row['score']
            total_ret = row['total_return']
            sharpe = row['sharpe_ratio']
            params = json.loads(row['parameters'])
            
            print(f"åˆ†ç¾¤ {cluster}: è©¦é©—{row['trial_number']} (åˆ†æ•¸: {score:.2f}, å ±é…¬: {total_ret:.1f}%, å¤æ™®: {sharpe:.2f})")
            print(f"  åƒæ•¸: linlen={params['linlen']}, smaalen={params['smaalen']}, devwin={params['devwin']}")
            print(f"  buy_mult={params['buy_mult']}, sell_mult={params['sell_mult']}, stop_loss={params['stop_loss']}")
    
    # æ¯”è¼ƒåˆ†æ
    print("\n" + "="*50)
    print("ğŸ” æ¯”è¼ƒåˆ†æ")
    print("="*50)
    
    if file1.exists() and file2.exists():
        df1 = pd.read_csv(file1)
        df2 = pd.read_csv(file2)
        
        print(f"æª”æ¡ˆ1 (æ©Ÿå™¨å­¸ç¿’): {len(df1)} ç­–ç•¥ â†’ {df1['dtw_cluster'].nunique()} åˆ†ç¾¤")
        print(f"æª”æ¡ˆ2 (ä¹‹å‰): {len(df2)} ç­–ç•¥ â†’ {df2['dtw_cluster'].nunique()} åˆ†ç¾¤")
        
        print(f"\næª”æ¡ˆ1å¹³å‡æ¯ç¾¤ç­–ç•¥æ•¸: {len(df1)/df1['dtw_cluster'].nunique():.1f}")
        print(f"æª”æ¡ˆ2å¹³å‡æ¯ç¾¤ç­–ç•¥æ•¸: {len(df2)/df2['dtw_cluster'].nunique():.1f}")
        
        # åˆ†æåˆ†ç¾¤å“è³ª
        print(f"\nåˆ†ç¾¤å“è³ªè©•ä¼°:")
        print(f"æª”æ¡ˆ1: æ¯ç¾¤ç­–ç•¥æ•¸ç¯„åœ {df1.groupby('dtw_cluster').size().min()}-{df1.groupby('dtw_cluster').size().max()}")
        print(f"æª”æ¡ˆ2: æ¯ç¾¤ç­–ç•¥æ•¸ç¯„åœ {df2.groupby('dtw_cluster').size().min()}-{df2.groupby('dtw_cluster').size().max()}")
        
        # è©•ä¼°åˆ†ç¾¤æ•ˆæœ
        print(f"\nåˆ†ç¾¤æ•ˆæœè©•ä¼°:")
        if len(df1)/df1['dtw_cluster'].nunique() < 20:
            print("âœ… æª”æ¡ˆ1: åˆ†ç¾¤æ•¸é‡åˆç†ï¼Œèƒ½æœ‰æ•ˆæ’é™¤éåº¦ç›¸ä¼¼")
        else:
            print("âš ï¸  æª”æ¡ˆ1: æ¯ç¾¤ç­–ç•¥æ•¸éå¤šï¼Œå¯èƒ½ç„¡æ³•æœ‰æ•ˆæ’é™¤éåº¦ç›¸ä¼¼")
            
        if len(df2)/df2['dtw_cluster'].nunique() < 20:
            print("âœ… æª”æ¡ˆ2: åˆ†ç¾¤æ•¸é‡åˆç†ï¼Œèƒ½æœ‰æ•ˆæ’é™¤éåº¦ç›¸ä¼¼")
        else:
            print("âš ï¸  æª”æ¡ˆ2: æ¯ç¾¤ç­–ç•¥æ•¸éå¤šï¼Œå¯èƒ½ç„¡æ³•æœ‰æ•ˆæ’é™¤éåº¦ç›¸ä¼¼")

if __name__ == "__main__":
    analyze_clustering_results() 