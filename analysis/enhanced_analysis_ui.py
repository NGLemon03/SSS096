# -*- coding: utf-8 -*-
"""
å¢å¼·åˆ†æUIæ•´åˆæ¨¡çµ„ - 2025-08-18 04:45
æä¾›Dashçµ„ä»¶å’Œå›èª¿å‡½æ•¸ï¼Œå°‡å¢å¼·åˆ†æåŠŸèƒ½æ•´åˆåˆ°ç¾æœ‰UIä¸­

ä½œè€…ï¼šAI Assistant
è·¯å¾‘ï¼š#analysis/enhanced_analysis_ui.py
"""

import dash
from dash import dcc, html, dash_table, Input, Output, State, ctx
import dash_bootstrap_components as dbc
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime
import warnings
import logging
warnings.filterwarnings('ignore')

# è¨­å®š logger
logger = logging.getLogger(__name__)

def safe_to_datetime(col):
    """
    å°å„ç¨®å¥‡æ€ªæƒ…å½¢åšé˜²å®ˆï¼š
    - è‹¥å‚³å…¥çš„æ˜¯ DataFrameï¼ˆå¯èƒ½æ˜¯é‡è¤‡æ¬„ä½é¸å–æˆ– pack è§£åŒ…ä¸ä¸€è‡´ï¼‰ï¼Œå…ˆå˜—è©¦ direct to_datetimeï¼Œ
      å¤±æ•—æ™‚æŠŠæ¬„ä½åˆä½µæˆå­—ä¸²å† parseã€‚
    - è‹¥ Series å…§å« dict-like ç‰©ä»¶ï¼Œæœƒå…ˆè½‰æˆ DataFrameï¼Œå†å˜—è©¦ parseï¼ˆè‹¥å¤±æ•—å‰‡åˆä½µå­—ä¸² parseï¼‰ã€‚
    - å…¶ä»–æƒ…æ³ç›´æ¥å‘¼å« pd.to_datetime(..., errors='coerce')ã€‚
    å›å‚³ä¸€æ”¯ pd.Series(datetime64[ns])ï¼ˆNaT è¡¨ç¤º parse å¤±æ•—ï¼‰ã€‚
    """
    # è‹¥æ˜¯ç›´æ¥å‚³å…¥ DataFrame -> å˜—è©¦è™•ç†
    if isinstance(col, pd.DataFrame):
        try:
            return pd.to_datetime(col, errors='coerce')
        except Exception:
            # åˆä½µæ‰€æœ‰æ¬„ç‚ºå­—ä¸²ï¼Œä½œç‚ºå¾Œå‚™
            return pd.to_datetime(col.astype(str).agg(' '.join, axis=1), errors='coerce')

    # è‹¥æ˜¯ Seriesï¼Œä½†å…ƒç´ å¯èƒ½ç‚º dict / DataFrame / list ç­‰
    if isinstance(col, pd.Series):
        # è‹¥æœ‰ä»»ä½•å…ƒç´ æ˜¯ dict-like
        is_dict_like = col.dropna().apply(lambda x: isinstance(x, dict)).any()
        is_df_like = col.dropna().apply(lambda x: isinstance(x, (pd.DataFrame, np.ndarray, list))).any()

        if is_dict_like:
            # å°‡ list of dict -> DataFrameï¼ˆè‹¥ keys ä¸ä¸€è‡´ï¼Œpandas æœƒä»¥ NaN è£œé½Šï¼‰
            try:
                df = pd.DataFrame(list(col))
                try:
                    return pd.to_datetime(df, errors='coerce')
                except Exception:
                    # fallback: é€åˆ—åˆæˆå­—ä¸²å† parse
                    return pd.to_datetime(df.astype(str).agg(' '.join, axis=1), errors='coerce')
            except Exception:
                # å¦‚æœç„¡æ³•è½‰ï¼ˆæ¥µç«¯æƒ…å½¢ï¼‰ï¼Œé€€å›å­—ä¸²è™•ç†
                return pd.to_datetime(col.astype(str), errors='coerce')

        if is_df_like:
            # å¦‚æœ Series è£¡é¢æ˜¯ list/ndarray/dataframe ç­‰ï¼Œå…ˆæŠŠå…§å®¹ stringify
            return pd.to_datetime(col.astype(str).map(lambda x: ' '.join(map(str, x)) if isinstance(x, (list, np.ndarray)) else str(x)),
                                   errors='coerce')

        # æ­£å¸¸æƒ…æ³ï¼šç›´æ¥ parse
        return pd.to_datetime(col, errors='coerce')

    # å…¶ä»–ä¸å¯é æœŸé¡å‹ï¼Œå˜—è©¦ str parse
    return pd.to_datetime(pd.Series(col).astype(str), errors='coerce')

try:
    from analysis.enhanced_trade_analysis import EnhancedTradeAnalyzer
    ENHANCED_ANALYSIS_AVAILABLE = True
except ImportError:
    ENHANCED_ANALYSIS_AVAILABLE = False
    print("è­¦å‘Šï¼šç„¡æ³•å°å…¥ EnhancedTradeAnalyzerï¼Œå¢å¼·åˆ†æåŠŸèƒ½å°‡ä¸å¯ç”¨")

class EnhancedAnalysisUI:
    """å¢å¼·åˆ†æUIæ•´åˆå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–UIæ•´åˆå™¨"""
        self.enhanced_analyzer = None
        self.analysis_results = {}
        
    def create_enhanced_analysis_tab(self):
        """å‰µå»ºå¢å¼·åˆ†ææ¨™ç±¤é """
        from dash import dcc
        
        if not ENHANCED_ANALYSIS_AVAILABLE:
            return dcc.Tab(
                label="âŒ å¢å¼·åˆ†æ (ä¸å¯ç”¨)", 
                value="enhanced_analysis",
                disabled=True
            )
            
        return dcc.Tab(
            label="ğŸ” å¢å¼·åˆ†æ", 
            value="enhanced_analysis",
            children=[
                self._create_enhanced_analysis_layout()
            ]
        )
        
    def _create_enhanced_analysis_layout(self):
        """å‰µå»ºå¢å¼·åˆ†æé é¢ä½ˆå±€"""
        from dash import html, dcc
        import dash_bootstrap_components as dbc
        
        return html.Div([
            # é é¢æ¨™é¡Œ
            html.H3("ğŸ” å¢å¼·äº¤æ˜“åˆ†æ", className="mb-4"),
            
            # æ•¸æ“šé¸æ“‡å€åŸŸ
            dbc.Card([
                dbc.CardHeader("ğŸ“Š æ•¸æ“šé¸æ“‡"),
                dbc.CardBody([
                    dbc.Row([
                        dbc.Col([
                            html.Label("é¸æ“‡ç­–ç•¥å›æ¸¬çµæœ"),
                            dcc.Dropdown(
                                id='strategy-selector',
                                options=[
                                    {'label': 'ä½¿ç”¨ç•¶å‰å›æ¸¬çµæœ', 'value': 'current'},
                                    {'label': 'é¸æ“‡ç‰¹å®šç­–ç•¥', 'value': 'specific'}
                                ],
                                value='current',
                                clearable=False
                            ),
                            html.Div(id='strategy-options', style={'marginTop': '10px'}),
                        ], width=6),
                        dbc.Col([
                            html.Label("åŸºæº–æ•¸æ“šé¸æ“‡"),
                            dcc.Dropdown(
                                id='benchmark-selector',
                                options=[
                                    {'label': 'TWII (å°ç£åŠ æ¬ŠæŒ‡æ•¸)', 'value': 'TWII'},
                                    {'label': '2330.TW (å°ç©é›»)', 'value': '2330.TW'},
                                    {'label': '2412.TW (ä¸­è¯é›»)', 'value': '2412.TW'},
                                    {'label': '2414.TW (ç²¾æŠ€)', 'value': '2414.TW'},
                                    {'label': 'è‡ªå®šç¾©è‚¡åƒ¹æª”æ¡ˆ', 'value': 'custom'}
                                ],
                                value='TWII',
                                clearable=False
                            ),
                            html.Div(id='custom-benchmark-upload', style={'display': 'none', 'marginTop': '10px'}),
                        ], width=6)
                    ]),
                    html.Br(),
                    
                    # å¾å›æ¸¬çµæœè¼‰å…¥åŠŸèƒ½
                    dbc.Card([
                        dbc.CardHeader("ğŸ§  è‡ªå‹•å¿«å–æœ€ä½³ç­–ç•¥æ•¸æ“š"),
                        dbc.CardBody([
                            html.Div("èªªæ˜ï¼šç³»çµ±æœƒè‡ªå‹•å¾ä¸»é ç±¤çš„å›æ¸¬çµæœä¸­é¸æ“‡æœ€ä½³ç­–ç•¥ä¸¦å¿«å–åˆ° enhanced-trades-cacheã€‚", className="text-muted mb-2"),
                            dcc.Dropdown(id="enhanced-strategy-selector", placeholder="è‡ªå‹•é¸æ“‡æœ€ä½³ç­–ç•¥ï¼ˆç„¡éœ€æ‰‹å‹•æ“ä½œï¼‰"),
                            html.Div("âœ… å›æ¸¬å®Œæˆå¾Œæœƒè‡ªå‹•å¿«å–æœ€ä½³ç­–ç•¥æ•¸æ“š", className="text-success mt-2"),
                            dcc.Store(id="enhanced-trades-cache")  # å­˜æ”¾ç”± backtest-store è§£æå‡ºçš„ trade_df
                        ])
                    ], className="mb-3"),
                    
                    dbc.Button(
                         "â³ ç­‰å¾…å›æ¸¬å®Œæˆ", 
                         id="run-enhanced-analysis-btn", 
                         color="primary",
                         className="me-2",
                         disabled=True
                     ),
                    dbc.Button(
                        "ğŸ“Š ç”Ÿæˆå ±å‘Š", 
                        id="generate-enhanced-report-btn", 
                        color="success",
                        className="me-2",
                        disabled=True
                    ),
                    dbc.Button(
                        "ğŸ”„ é‡ç½®", 
                        id="reset-enhanced-analysis-btn", 
                        color="secondary"
                    )
                ])
            ], className="mb-4"),
            
            # åˆ†æçµæœé¡¯ç¤ºå€åŸŸ
            html.Div(id="enhanced-analysis-results", children=[
                # åˆ†ææ‘˜è¦å¡ç‰‡
                dbc.Card([
                    dbc.CardHeader("ğŸ“‹ åˆ†ææ‘˜è¦"),
                    dbc.CardBody(id="enhanced-analysis-summary")
                ], className="mb-4"),
                
                # é¢¨éšªé–¥é–€åˆ†æ
                dbc.Card([
                    dbc.CardHeader("âš ï¸ é¢¨éšªé–¥é–€åˆ†æ"),
                    dbc.CardBody(id="risk-valve-analysis-content")
                ], className="mb-4"),
                
                # äº¤æ˜“éšæ®µåˆ†æ
                dbc.Card([
                    dbc.CardHeader("ğŸ”„ äº¤æ˜“éšæ®µåˆ†æ"),
                    dbc.CardBody(id="phase-analysis-content")
                ], className="mb-4"),
                
                # åŠ ç¢¼æ¢¯åº¦å„ªåŒ–
                dbc.Card([
                    dbc.CardHeader("ğŸ“ˆ åŠ ç¢¼æ¢¯åº¦å„ªåŒ–"),
                    dbc.CardBody(id="gradient-optimization-content")
                ], className="mb-4"),
                
                # åœ–è¡¨é¡¯ç¤ºå€åŸŸ
                html.Div(id="enhanced-analysis-charts")
            ], style={'display': 'none'})
        ])
        
    def create_enhanced_analysis_callbacks(self, app):
        """å‰µå»ºå¢å¼·åˆ†æçš„å›èª¿å‡½æ•¸"""
        from dash import html, Input, Output, State
        
        # é˜²æ­¢é‡è¤‡è¨»å†Š
        if getattr(app, "_enhanced_callbacks_registered", False):
            return
        app._enhanced_callbacks_registered = True
        
        if not ENHANCED_ANALYSIS_AVAILABLE:
            return
            
        # ç­–ç•¥é¸æ“‡å™¨å›èª¿
        @app.callback(
            Output('strategy-options', 'children'),
            Input('strategy-selector', 'value'),
            State('backtest-store', 'data')
        )
        def update_strategy_options(selector_value, backtest_data):
            if selector_value == 'specific' and backtest_data and 'results' in backtest_data:
                strategies = list(backtest_data.get('results', {}).keys())
                if strategies:
                    return dcc.Dropdown(
                        id='specific-strategy',
                        options=[{'label': s, 'value': s} for s in strategies],
                        value=strategies[0] if strategies else None,
                        placeholder='é¸æ“‡ç­–ç•¥'
                    )
            return html.Div("å°‡ä½¿ç”¨ç•¶å‰é¸ä¸­çš„ç­–ç•¥")
        
        # æª¢æŸ¥å›æ¸¬ç‹€æ…‹ä¸¦æ›´æ–°åŸ·è¡ŒæŒ‰éˆ•ç‹€æ…‹
        @app.callback(
            Output('run-enhanced-analysis-btn', 'disabled'),
            Output('run-enhanced-analysis-btn', 'children'),
            Input('backtest-store', 'data'),
            State('strategy-selector', 'value')
        )
        def update_analysis_button_state(backtest_data, strategy_selector):
            if not backtest_data or 'results' not in backtest_data:
                return True, "â³ ç­‰å¾…å›æ¸¬å®Œæˆ"
            
            results = backtest_data.get('results', {})
            if not results:
                return True, "â³ ç­‰å¾…å›æ¸¬å®Œæˆ"
            
            # æª¢æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„äº¤æ˜“æ•¸æ“š
            has_trades = False
            for strategy_name, result in results.items():
                if ('trade_ledger' in result and result['trade_ledger']) or \
                   ('trade_df' in result and result['trade_df']):
                    has_trades = True
                    break
            
            if not has_trades:
                return True, "âš ï¸ å›æ¸¬å®Œæˆä½†ç„¡äº¤æ˜“æ•¸æ“š"
            
            return False, "ğŸš€ åŸ·è¡Œå¢å¼·åˆ†æ"
        
        # åŸºæº–é¸æ“‡å™¨å›èª¿
        @app.callback(
            Output('custom-benchmark-upload', 'children'),
            Output('custom-benchmark-upload', 'style'),
            Input('benchmark-selector', 'value')
        )
        def update_benchmark_upload(benchmark_value):
            if benchmark_value == 'custom':
                return dcc.Upload(
                    id='custom-benchmark-upload-input',
                    children=html.Div([
                        'æ‹–æ‹½æˆ–é»æ“Šä¸Šå‚³è‡ªå®šç¾©è‚¡åƒ¹æ•¸æ“š',
                        html.Br(),
                        html.A('é¸æ“‡æ–‡ä»¶')
                    ]),
                    style={
                        'width': '100%',
                        'height': '60px',
                        'lineHeight': '60px',
                        'borderWidth': '1px',
                        'borderStyle': 'dashed',
                        'borderRadius': '5px',
                        'textAlign': 'center',
                        'margin': '10px'
                    },
                    multiple=False
                ), {'display': 'block', 'marginTop': '10px'}
            else:
                return "", {'display': 'none'}
        
        # ä¾ backtest-store æ›´æ–°ç­–ç•¥ä¸‹æ‹‰é¸å–®
        @app.callback(
            Output("enhanced-strategy-selector", "options"),
            Input("backtest-store", "data"),
            prevent_initial_call=False
        )
        def _fill_strategy_options(backtest_data):
            if not backtest_data or "results" not in backtest_data:
                return []
            strategies = list(backtest_data["results"].keys())
            return [{"label": s, "value": s} for s in strategies]
        
        # åŸ·è¡Œå¢å¼·åˆ†æå›èª¿
        @app.callback(
            Output("enhanced-analysis-results", "style"),
            Output("enhanced-analysis-summary", "children"),
            Output("risk-valve-analysis-content", "children"),
            Output("phase-analysis-content", "children"),
            Output("gradient-optimization-content", "children"),
            Output("enhanced-analysis-charts", "children"),
            Output("generate-enhanced-report-btn", "disabled"),
            Input("run-enhanced-analysis-btn", "n_clicks"),
            State("strategy-selector", "value"),
            State("benchmark-selector", "value"),
            State("backtest-store", "data"),
            # æ–°å¢ â†“â†“â†“
            State("enhanced-trades-cache", "data"),
            prevent_initial_call=True
        )
        def run_enhanced_analysis(n_clicks, strategy_selector, benchmark_selector, backtest_data, trades_from_store):
            if n_clicks is None:
                from dash import no_update
                return (no_update, no_update, no_update, no_update, no_update, no_update, no_update)

            try:
                # 1) å…ˆè§£æäº¤æ˜“è³‡æ–™ï¼šå„ªå…ˆé †åº = enhanced-trades-cache â†’ åŸæœ‰é‚è¼¯ â†’ ç„¡
                trades_df = None
                if trades_from_store:
                    # ç”¨ _df_from_pack é‚„åŸ
                    import io
                    try:
                        trades_df = pd.read_json(io.StringIO(trades_from_store), orient="split")
                        print(f"å¾ enhanced-trades-cache è¼‰å…¥äº¤æ˜“æ•¸æ“šæˆåŠŸï¼Œå½¢ç‹€ï¼š{trades_df.shape}")
                        
                        # æ–°å¢ï¼ˆç¢ºä¿æ—¥æœŸæ˜¯ datetime64ï¼Œé¿å… object é€ æˆæ¯”è¼ƒ/ç¯©é¸èª¤å·®ï¼‰
                        if 'äº¤æ˜“æ—¥æœŸ' in trades_df.columns:
                            trades_df['äº¤æ˜“æ—¥æœŸ'] = pd.to_datetime(trades_df['äº¤æ˜“æ—¥æœŸ'], errors='coerce')
                            trades_df = trades_df.dropna(subset=['äº¤æ˜“æ—¥æœŸ']).sort_values('äº¤æ˜“æ—¥æœŸ').reset_index(drop=True)
                    except Exception as e:
                        print(f"è§£æ enhanced-trades-cache å¤±æ•—ï¼š{e}")
                        trades_df = None
                
                # å¦‚æœæ²’æœ‰å¾ enhanced-trades-cache è¼‰å…¥ï¼Œä½¿ç”¨åŸæœ‰é‚è¼¯
                if trades_df is None or trades_df.empty:
                    # æª¢æŸ¥å›æ¸¬ç‹€æ…‹
                    if not backtest_data or 'results' not in backtest_data:
                        return self._error_outputs("âŒ è«‹å…ˆåŸ·è¡Œç­–ç•¥å›æ¸¬")
                    
                    results = backtest_data.get('results', {})
                    if not results:
                        return self._error_outputs("âŒ å›æ¸¬å°šæœªå®Œæˆï¼Œè«‹ç­‰å¾…å›æ¸¬è¨ˆç®—å®Œæˆ")
                    
                    # ç²å–äº¤æ˜“æ•¸æ“š
                    trades_df = self._get_trades_data(strategy_selector, None, backtest_data)
                    if trades_df is None or trades_df.empty:
                        return self._error_outputs("âŒ ç„¡æ³•ç²å–äº¤æ˜“æ•¸æ“šï¼ˆå›æ¸¬å¯èƒ½å°šæœªå®Œæˆæˆ–æ•¸æ“šæ ¼å¼ä¸æ­£ç¢ºï¼‰")
                
                if trades_df is None or trades_df.empty:
                    return self._error_outputs("æ‰¾ä¸åˆ°äº¤æ˜“è³‡æ–™ï¼ˆè«‹ä¸Šå‚³æª”æ¡ˆæˆ–å…ˆç”¨ã€å¾å›æ¸¬çµæœè¼‰å…¥ã€ï¼‰")

                # 2) è§£æåŸºæº–ï¼šå„ªå…ˆé †åº = backtest-store çš„ df_raw â†’ æœ¬åœ°æ•¸æ“š â†’ ç„¡
                benchmark_df = None
                
                if backtest_data and "df_raw" in backtest_data:
                    try:
                        # ä½¿ç”¨èˆ‡ app_dash åŒåçš„å·¥å…·å‡½æ•¸
                        df_raw = self._df_from_pack(backtest_data["df_raw"])
                        if df_raw is not None and not df_raw.empty:
                            # è½‰æˆå¢å¼·åˆ†æé æœŸæ¬„ä½ï¼ˆä¸­æ–‡ï¼‰
                            b = pd.DataFrame({
                                "æ—¥æœŸ": pd.to_datetime(df_raw.index),
                                "æ”¶ç›¤åƒ¹": pd.to_numeric(df_raw["close"], errors="coerce")
                            })
                            # âœ… ä¸è¦å† set_indexï¼›ç¶­æŒä¸€èˆ¬æ•´æ•¸ç´¢å¼•ï¼Œé¿å…ç´¢å¼•åèˆ‡æ¬„ä½åé‡è¤‡
                            # b = b.set_index("æ—¥æœŸ", drop=False)   # â† åˆªæ‰é€™è¡Œ
                            
                            # è‹¥ç„¡é«˜ä½åƒ¹ï¼Œenhanced_trade_analysis.py å·²æœ‰å›é€€
                            if "high" in df_raw.columns and "low" in df_raw.columns:
                                b["æœ€é«˜åƒ¹"] = pd.to_numeric(df_raw["high"], errors="coerce")
                                b["æœ€ä½åƒ¹"] = pd.to_numeric(df_raw["low"], errors="coerce")
                            benchmark_df = b
                            print(f"å¾ backtest-store.df_raw è½‰æ›åŸºæº–æ•¸æ“šæˆåŠŸï¼Œå½¢ç‹€ï¼š{benchmark_df.shape}")
                            print(f"åŸºæº–æ•¸æ“šæ¬„ä½ï¼š{list(benchmark_df.columns)}")
                            print(f"åŸºæº–æ•¸æ“šç´¢å¼•é¡å‹ï¼š{type(benchmark_df.index)}")
                    except Exception as e:
                        print(f"å¾ backtest-store.df_raw è½‰æ›åŸºæº–æ•¸æ“šå¤±æ•—ï¼š{e}")
                
                # å¦‚æœé‚„æ˜¯æ²’æœ‰åŸºæº–æ•¸æ“šï¼Œä½¿ç”¨æœ¬åœ°æ•¸æ“š
                if benchmark_df is None or benchmark_df.empty:
                    benchmark_df = self._get_benchmark_data(benchmark_selector, None)

                # debug: benchmark æª¢æŸ¥
                try:
                    from debug_enhanced_data import diag_df
                    diag_df("benchmark", benchmark_df)
                except Exception as e:
                    logger.exception("diag_df(benchmark) fail: %s", e)
                    print(f"è¨ºæ–·å¤±æ•—ï¼š{e}")

                # debug: before analysis
                try:
                    logger.info("DEBUG: entering analyzer with trade rows=%s, benchmark rows=%s", len(trades_df), len(benchmark_df))
                    diag_df("trades_before_analysis", trades_df)
                    diag_df("benchmark_before_analysis", benchmark_df)
                except Exception as e:
                    logger.exception("diag_df(before_analysis) fail: %s", e)
                    print(f"è¨ºæ–·å¤±æ•—ï¼š{e}")

                # === è©³ç´°è¨ºæ–·ï¼šå¯¦éš›å‚³åˆ°åˆ†æå™¨çš„æ•¸æ“š ===
                print("\n" + "="*60)
                print("è©³ç´°è¨ºæ–·ï¼šå¯¦éš›å‚³åˆ°åˆ†æå™¨çš„æ•¸æ“š")
                print("="*60)
                
                # 1) æª¢æŸ¥ trades DataFrame
                print("\n--- 1) æª¢æŸ¥ trades DataFrame ---")
                print("columns:", trades_df.columns.tolist())
                print("dtypes:\n", trades_df.dtypes)
                print("trades_df.head(10):")
                print(trades_df.head(10).to_string())
                
                # é—œéµæª¢æŸ¥ï¼š'ç›ˆè™§%' æ¬„
                if 'ç›ˆè™§%' in trades_df.columns:
                    s = pd.to_numeric(trades_df['ç›ˆè™§%'], errors='coerce')
                    print("\n'ç›ˆè™§%' æ¬„è©³ç´°æª¢æŸ¥:")
                    print("to_numeric NaN count:", s.isna().sum(), "/", len(s))
                    print("sample values:", trades_df['ç›ˆè™§%'].head(10).tolist())
                    print("stats: min/max/mean/absmax:", s.min(), s.max(), s.mean(), s.abs().max())
                else:
                    print("\nWARNING: trades_df ä¸­æ²’æœ‰ 'ç›ˆè™§%' æ¬„ï¼Œè«‹ç¢ºèªé è™•ç†æµç¨‹æ˜¯å¦æ­£ç¢ºç”¢ç”Ÿè©²æ¬„")
                
                # 2) æª¢æŸ¥åŸºæº–èˆ‡ trades çš„æ—¥æœŸå‹æ…‹ã€é‡ç–Šå€é–“èˆ‡åŒ¹é…æ•¸
                print("\n--- 2) æª¢æŸ¥åŸºæº–èˆ‡ trades çš„æ—¥æœŸåŒ¹é… ---")
                print("benchmark columns:", benchmark_df.columns.tolist())
                print("benchmark date dtype:", benchmark_df['æ—¥æœŸ'].dtype if 'æ—¥æœŸ' in benchmark_df.columns else type(benchmark_df.index))
                print("trades date dtype:", trades_df['äº¤æ˜“æ—¥æœŸ'].dtype)
                
                # å¼·åˆ¶ parse ä¸¦æ¯”è¼ƒ
                benchmark_dates = pd.to_datetime(benchmark_df['æ—¥æœŸ'] if 'æ—¥æœŸ' in benchmark_df.columns else benchmark_df.index)
                trades_dates = pd.to_datetime(trades_df['äº¤æ˜“æ—¥æœŸ'])
                print("benchmark min/max:", benchmark_dates.min(), benchmark_dates.max())
                print("trades min/max:", trades_dates.min(), trades_dates.max())
                
                # æª¢æŸ¥åŒ¹é…
                risk_periods = benchmark_dates[benchmark_df.get('risk_valve_triggered', pd.Series(False, index=benchmark_dates.index))]
                print("risk_periods count:", len(risk_periods))
                print("trade dates in risk_periods:", trades_dates.isin(risk_periods).sum(), "/", len(trades_dates))
                
                print("="*60 + "\n")

                # åŸ·è¡Œå¢å¼·åˆ†æ
                self.enhanced_analyzer = EnhancedTradeAnalyzer(trades_df, benchmark_df)

                risk_results = self.enhanced_analyzer.risk_valve_backtest()
                phase_results = self.enhanced_analyzer.trade_contribution_analysis()
                gradient_results = self.enhanced_analyzer.position_gradient_optimization()

                comprehensive_report = self.enhanced_analyzer.generate_comprehensive_report()
                self.analysis_results = comprehensive_report

                summary_content = self._create_summary_content(comprehensive_report)
                risk_content = self._create_risk_valve_content(risk_results)
                phase_content = self._create_phase_analysis_content(phase_results)
                gradient_content = self._create_gradient_optimization_content(gradient_results)
                charts_content = self._create_charts_content()

                return (
                    {'display': 'block'},
                    summary_content, risk_content, phase_content, gradient_content, charts_content,
                    False  # enable å ±å‘ŠæŒ‰éˆ•
                )

            except Exception as e:
                return self._error_outputs(f"åˆ†æåŸ·è¡Œå¤±æ•—ï¼š{str(e)}")
                
        # ç”Ÿæˆå ±å‘Šå›èª¿
        @app.callback(
            Output("generate-enhanced-report-btn", "children"),
            Input("generate-enhanced-report-btn", "n_clicks"),
            prevent_initial_call=True
        )
        def generate_enhanced_report(n_clicks):
            if n_clicks is None:
                from dash import no_update
                return no_update
                
            try:
                if self.enhanced_analyzer and self.analysis_results:
                    # ç”ŸæˆExcelå ±å‘Š
                    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                    filename = f"enhanced_analysis_report_{timestamp}.xlsx"
                    
                    # é€™è£¡å¯ä»¥èª¿ç”¨å ±å‘Šç”Ÿæˆå‡½æ•¸
                    # self.enhanced_analyzer.generate_comprehensive_report()
                    
                    return f"âœ… å ±å‘Šå·²ç”Ÿæˆ ({filename})"
                else:
                    return "âŒ è«‹å…ˆåŸ·è¡Œåˆ†æ"
            except Exception as e:
                return f"âŒ ç”Ÿæˆå ±å‘Šå¤±æ•—ï¼š{str(e)}"
                
        # é‡ç½®åˆ†æå›èª¿
        @app.callback(
            Output("enhanced-analysis-results", "style", allow_duplicate=True),
            Output("enhanced-analysis-summary", "children", allow_duplicate=True),
            Output("risk-valve-analysis-content", "children", allow_duplicate=True),
            Output("phase-analysis-content", "children", allow_duplicate=True),
            Output("gradient-optimization-content", "children", allow_duplicate=True),
            Output("enhanced-analysis-charts", "children", allow_duplicate=True),
            Output("generate-enhanced-report-btn", "disabled", allow_duplicate=True),
            Input("reset-enhanced-analysis-btn", "n_clicks"),
            prevent_initial_call=True
        )
        def reset_enhanced_analysis(n_clicks):
            if n_clicks is None:
                from dash import no_update
                return no_update
                
            self.enhanced_analyzer = None
            self.analysis_results = {}
            
            return (
                {'display': 'none'},  # éš±è—çµæœå€åŸŸ
                html.P("è«‹é¸æ“‡æ•¸æ“šä¸¦åŸ·è¡Œåˆ†æ"),
                html.P("è«‹é¸æ“‡æ•¸æ“šä¸¦åŸ·è¡Œåˆ†æ"),
                html.P("è«‹é¸æ“‡æ•¸æ“šä¸¦åŸ·è¡Œåˆ†æ"),
                html.P("è«‹é¸æ“‡æ•¸æ“šä¸¦åŸ·è¡Œåˆ†æ"),
                html.P("è«‹é¸æ“‡æ•¸æ“šä¸¦åŸ·è¡Œåˆ†æ"),
                True  # ç¦ç”¨ç”Ÿæˆå ±å‘ŠæŒ‰éˆ•
            )
            
    def _parse_uploaded_data(self, content, data_type):
        """è§£æä¸Šå‚³çš„æ•¸æ“š"""
        if content is None:
            print(f"è­¦å‘Šï¼š{data_type} æ•¸æ“šç‚ºç©º")
            return None
            
        import base64
        import io
        
        try:
            print(f"é–‹å§‹è§£æ {data_type} æ•¸æ“š...")
            print(f"Content é¡å‹: {type(content)}")
            print(f"Content é•·åº¦: {len(str(content)) if content else 0}")
            
            # æª¢æŸ¥ content æ ¼å¼
            if not isinstance(content, str):
                print(f"éŒ¯èª¤ï¼šcontent ä¸æ˜¯å­—ä¸²ï¼Œè€Œæ˜¯ {type(content)}")
                return None
                
            if ',' not in content:
                print(f"éŒ¯èª¤ï¼šcontent æ ¼å¼ä¸æ­£ç¢ºï¼Œç¼ºå°‘é€—è™Ÿåˆ†éš”ç¬¦")
                print(f"Content å‰100å­—ç¬¦: {content[:100] if content else 'None'}")
                return None
            
            # è§£ç¢¼base64å…§å®¹
            content_type, content_string = content.split(',', 1)
            print(f"Content type: {content_type}")
            print(f"Content string é•·åº¦: {len(content_string)}")
            
            try:
                decoded = base64.b64decode(content_string)
                print(f"è§£ç¢¼å¾Œæ•¸æ“šé•·åº¦: {len(decoded)} bytes")
            except Exception as decode_error:
                print(f"Base64 è§£ç¢¼å¤±æ•—: {decode_error}")
                return None
            
            df = None
            if 'csv' in content_type:
                print("å˜—è©¦è§£æ CSV æ ¼å¼...")
                try:
                    df = pd.read_csv(io.StringIO(decoded.decode('utf-8')))
                    print(f"CSV è§£ææˆåŠŸï¼Œæ¬„ä½: {list(df.columns)}")
                except UnicodeDecodeError:
                    # å˜—è©¦å…¶ä»–ç·¨ç¢¼
                    try:
                        df = pd.read_csv(io.StringIO(decoded.decode('big5')))
                        print(f"CSV è§£ææˆåŠŸ (big5ç·¨ç¢¼)ï¼Œæ¬„ä½: {list(df.columns)}")
                    except:
                        df = pd.read_csv(io.StringIO(decoded.decode('utf-8', errors='ignore')))
                        print(f"CSV è§£ææˆåŠŸ (å¿½ç•¥éŒ¯èª¤)ï¼Œæ¬„ä½: {list(df.columns)}")
            elif 'excel' in content_type:
                print("å˜—è©¦è§£æ Excel æ ¼å¼...")
                df = pd.read_excel(io.BytesIO(decoded))
                print(f"Excel è§£ææˆåŠŸï¼Œæ¬„ä½: {list(df.columns)}")
            else:
                print(f"ä¸æ”¯æ´çš„æª”æ¡ˆé¡å‹: {content_type}")
                return None
            
            if df is None or df.empty:
                print(f"è­¦å‘Šï¼šè§£æå¾Œçš„ DataFrame ç‚ºç©º")
                return None
                
            print(f"åŸå§‹æ•¸æ“šå½¢ç‹€: {df.shape}")
            print(f"åŸå§‹æ¬„ä½: {list(df.columns)}")
            
            # æ ¹æ“šæ•¸æ“šé¡å‹é€²è¡Œé è™•ç†
            if data_type == "trades":
                df = self._preprocess_trades_data(df)
            elif data_type == "benchmark":
                df = self._preprocess_benchmark_data(df)
            
            print(f"é è™•ç†å¾Œæ•¸æ“šå½¢ç‹€: {df.shape}")
            print(f"é è™•ç†å¾Œæ¬„ä½: {list(df.columns)}")
                
            return df
            
        except Exception as e:
            print(f"è§£æ{data_type}æ•¸æ“šå¤±æ•—ï¼š{e}")
            import traceback
            traceback.print_exc()
            return None
            
    def _ensure_trade_returns(self, df):
        """ç¢ºä¿äº¤æ˜“æ•¸æ“šæœ‰ç›ˆè™§%æ¬„ä½ï¼Œè‹¥ç„¡å‰‡ç”¨è²·è³£é…å°å¾åƒ¹æ ¼æ¨ç®—"""
        # å·²æœ‰å°±ä¸å‹•
        if 'ç›ˆè™§%' in df.columns:
            return df

        df = df.copy()
        
        # ç¢ºä¿æœ‰å¿…è¦çš„æ¬„ä½
        if 'äº¤æ˜“æ—¥æœŸ' not in df.columns or 'äº¤æ˜“é¡å‹' not in df.columns:
            print("ç¼ºå°‘å¿…è¦æ¬„ä½ï¼Œç„¡æ³•æ¨ç®—ç›ˆè™§%")
            df['ç›ˆè™§%'] = 0.0
            return df
            
        df.sort_values('äº¤æ˜“æ—¥æœŸ', inplace=True)

        # ç”¨ç°¡å–®è²·è³£é…å°ï¼šé‡åˆ° sellï¼Œä½¿ç”¨ä¸Šä¸€ç­† buy çš„åƒ¹æ ¼ç®—å ±é…¬
        last_buy_price = None
        returns = []
        for _, row in df.iterrows():
            t = str(row.get('äº¤æ˜“é¡å‹') or row.get('type') or '').lower()
            px = row.get('åƒ¹æ ¼', row.get('price'))
            ret = None
            if t == 'buy':
                last_buy_price = px
            elif t == 'sell' and last_buy_price and last_buy_price > 0:
                ret = (px - last_buy_price) / last_buy_price
                last_buy_price = None
            returns.append(ret)

        df['ç›ˆè™§%'] = pd.Series(returns, index=df.index)
        print("å·²å¾è²·è³£é…å°æ¨ç®—ç›ˆè™§%æ¬„ä½")
        return df

    def _preprocess_trades_data(self, df):
        """é è™•ç†äº¤æ˜“æ•¸æ“š"""
        print(f"é–‹å§‹é è™•ç†äº¤æ˜“æ•¸æ“š...")
        print(f"è¼¸å…¥æ¬„ä½: {list(df.columns)}")
        
        # æ¨™æº–åŒ–æ¬„ä½åç¨±
        column_mapping = {
            'Date': 'äº¤æ˜“æ—¥æœŸ',
            'date': 'äº¤æ˜“æ—¥æœŸ',
            'Weight_Change': 'æ¬Šé‡è®ŠåŒ–',
            'weight_change': 'æ¬Šé‡è®ŠåŒ–',
            'Pnl_Pct': 'ç›ˆè™§%',
            'pnl_pct': 'ç›ˆè™§%',
            'Pnl': 'ç›ˆè™§%',
            'pnl': 'ç›ˆè™§%',
            'pnl_pct': 'ç›ˆè™§%',
            'pnl_pct': 'ç›ˆè™§%',
            'return': 'ç›ˆè™§%',
            'Return': 'ç›ˆè™§%',
            'weight': 'æ¬Šé‡è®ŠåŒ–',
            'Weight': 'æ¬Šé‡è®ŠåŒ–',
            'trade_date': 'äº¤æ˜“æ—¥æœŸ',
            'Trade_Date': 'äº¤æ˜“æ—¥æœŸ'
        }
        
        # æª¢æŸ¥åŸå§‹æ¬„ä½
        original_columns = list(df.columns)
        print(f"åŸå§‹æ¬„ä½: {original_columns}")
        
        # é‡å‘½åæ¬„ä½
        df = df.rename(columns=column_mapping)
        print(f"é‡å‘½åå¾Œæ¬„ä½: {list(df.columns)}")
        
        # æª¢æŸ¥å¿…è¦æ¬„ä½
        required_columns = ['äº¤æ˜“æ—¥æœŸ', 'æ¬Šé‡è®ŠåŒ–', 'ç›ˆè™§%']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            print(f"è­¦å‘Šï¼šç¼ºå°‘å¿…è¦æ¬„ä½ï¼š{missing_columns}")
            print(f"å¯ç”¨æ¬„ä½: {list(df.columns)}")
            
            # å˜—è©¦å¾å…¶ä»–æ¬„ä½æ¨å°
            if 'ç›ˆè™§%' not in df.columns:
                print("å˜—è©¦æ¨å°ç›ˆè™§%æ¬„ä½...")
                if 'æ¯ç­†ç›ˆè™§%' in df.columns:
                    df['ç›ˆè™§%'] = df['æ¯ç­†ç›ˆè™§%']
                    print("ä½¿ç”¨ 'æ¯ç­†ç›ˆè™§%' ä½œç‚º 'ç›ˆè™§%'")
                elif 'ç¸½è³‡ç”¢' in df.columns and 'äº¤æ˜“æ—¥æœŸ' in df.columns:
                    df = df.sort_values('äº¤æ˜“æ—¥æœŸ').reset_index(drop=True)
                    df['ç›ˆè™§%'] = df['ç¸½è³‡ç”¢'].pct_change().fillna(0) * 100.0
                    print("å¾ 'ç¸½è³‡ç”¢' æ¨å° 'ç›ˆè™§%'")
                else:
                    print("å˜—è©¦ç”¨è²·è³£é…å°æ¨ç®—ç›ˆè™§%...")
                    df = self._ensure_trade_returns(df)
            
            if 'æ¬Šé‡è®ŠåŒ–' not in df.columns:
                print("å˜—è©¦æ¨å°æ¬Šé‡è®ŠåŒ–æ¬„ä½...")
                if 'weight' in df.columns:
                    df['æ¬Šé‡è®ŠåŒ–'] = df['weight']
                    print("ä½¿ç”¨ 'weight' ä½œç‚º 'æ¬Šé‡è®ŠåŒ–'")
                elif 'w' in df.columns:
                    df['æ¬Šé‡è®ŠåŒ–'] = df['w']
                    print("ä½¿ç”¨ 'w' ä½œç‚º 'æ¬Šé‡è®ŠåŒ–'")
                else:
                    print("ç„¡æ³•æ¨å°æ¬Šé‡è®ŠåŒ–ï¼Œè¨­å®šç‚º0")
                    df['æ¬Šé‡è®ŠåŒ–'] = 0.0
            
            if 'äº¤æ˜“æ—¥æœŸ' not in df.columns:
                print("å˜—è©¦æ¨å°äº¤æ˜“æ—¥æœŸæ¬„ä½...")
                if 'date' in df.columns:
                    df['äº¤æ˜“æ—¥æœŸ'] = df['date']
                    print("ä½¿ç”¨ 'date' ä½œç‚º 'äº¤æ˜“æ—¥æœŸ'")
                elif 'trade_date' in df.columns:
                    df['äº¤æ˜“æ—¥æœŸ'] = df['trade_date']
                    print("ä½¿ç”¨ 'trade_date' ä½œç‚º 'äº¤æ˜“æ—¥æœŸ'")
                else:
                    print("ç„¡æ³•æ¨å°äº¤æ˜“æ—¥æœŸ")
                    return df
        
        # è½‰æ›æ—¥æœŸæ ¼å¼
        if 'äº¤æ˜“æ—¥æœŸ' in df.columns:
            try:
                df['äº¤æ˜“æ—¥æœŸ'] = pd.to_datetime(df['äº¤æ˜“æ—¥æœŸ'])
                print("æ—¥æœŸæ ¼å¼è½‰æ›æˆåŠŸ")
            except Exception as e:
                print(f"æ—¥æœŸæ ¼å¼è½‰æ›å¤±æ•—: {e}")
                # å˜—è©¦å…¶ä»–æ—¥æœŸæ ¼å¼
                try:
                    df['äº¤æ˜“æ—¥æœŸ'] = pd.to_datetime(df['äº¤æ˜“æ—¥æœŸ'], format='%Y/%m/%d')
                    print("ä½¿ç”¨ %Y/%m/%d æ ¼å¼è½‰æ›æˆåŠŸ")
                except:
                    try:
                        df['äº¤æ˜“æ—¥æœŸ'] = pd.to_datetime(df['äº¤æ˜“æ—¥æœŸ'], format='%Y-%m-%d')
                        print("ä½¿ç”¨ %Y-%m-%d æ ¼å¼è½‰æ›æˆåŠŸ")
                    except:
                        print("æ‰€æœ‰æ—¥æœŸæ ¼å¼éƒ½è½‰æ›å¤±æ•—")
        
        print(f"é è™•ç†å®Œæˆï¼Œæœ€çµ‚æ¬„ä½: {list(df.columns)}")
        print(f"æœ€çµ‚æ•¸æ“šå½¢ç‹€: {df.shape}")
        
        return df
        
    def _preprocess_benchmark_data(self, df):
        """é è™•ç†åŸºæº–æ•¸æ“š"""
        print(f"é–‹å§‹é è™•ç†åŸºæº–æ•¸æ“š...")
        print(f"è¼¸å…¥æ¬„ä½: {list(df.columns)}")
        
        # æ¨™æº–åŒ–æ¬„ä½åç¨±
        column_mapping = {
            'Date': 'æ—¥æœŸ',
            'date': 'æ—¥æœŸ',
            'Close': 'æ”¶ç›¤åƒ¹',
            'close': 'æ”¶ç›¤åƒ¹',
            'High': 'æœ€é«˜åƒ¹',
            'high': 'æœ€é«˜åƒ¹',
            'Low': 'æœ€ä½åƒ¹',
            'low': 'æœ€ä½åƒ¹',
            'trade_date': 'æ—¥æœŸ',
            'Trade_Date': 'æ—¥æœŸ',
            'price': 'æ”¶ç›¤åƒ¹',
            'Price': 'æ”¶ç›¤åƒ¹'
        }
        
        # æª¢æŸ¥åŸå§‹æ¬„ä½
        original_columns = list(df.columns)
        print(f"åŸå§‹æ¬„ä½: {original_columns}")
        
        # é‡å‘½åæ¬„ä½
        df = df.rename(columns=column_mapping)
        print(f"é‡å‘½åå¾Œæ¬„ä½: {list(df.columns)}")
        
        # æª¢æŸ¥å¿…è¦æ¬„ä½
        required_columns = ['æ—¥æœŸ', 'æ”¶ç›¤åƒ¹']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            print(f"è­¦å‘Šï¼šç¼ºå°‘å¿…è¦æ¬„ä½ï¼š{missing_columns}")
            print(f"å¯ç”¨æ¬„ä½: {list(df.columns)}")
            
            # å˜—è©¦å¾å…¶ä»–æ¬„ä½æ¨å°
            if 'æ—¥æœŸ' not in df.columns:
                print("å˜—è©¦æ¨å°æ—¥æœŸæ¬„ä½...")
                if 'trade_date' in df.columns:
                    df['æ—¥æœŸ'] = df['trade_date']
                    print("ä½¿ç”¨ 'trade_date' ä½œç‚º 'æ—¥æœŸ'")
                elif 'index' in df.columns:
                    df['æ—¥æœŸ'] = df['index']
                    print("ä½¿ç”¨ 'index' ä½œç‚º 'æ—¥æœŸ'")
                elif df.index.name is not None and df.index.dtype == 'datetime64[ns]':
                    # å¦‚æœç´¢å¼•æ˜¯æ—¥æœŸé¡å‹ï¼Œå¾ç´¢å¼•å‰µå»ºæ—¥æœŸæ¬„ä½
                    df['æ—¥æœŸ'] = df.index
                    print("å¾ç´¢å¼•å‰µå»º 'æ—¥æœŸ' æ¬„ä½")
                else:
                    print("ç„¡æ³•æ¨å°æ—¥æœŸæ¬„ä½")
                    return df
            
            if 'æ”¶ç›¤åƒ¹' not in df.columns:
                print("å˜—è©¦æ¨å°æ”¶ç›¤åƒ¹æ¬„ä½...")
                if 'price' in df.columns:
                    df['æ”¶ç›¤åƒ¹'] = df['price']
                    print("ä½¿ç”¨ 'price' ä½œç‚º 'æ”¶ç›¤åƒ¹'")
                elif 'open' in df.columns:
                    df['æ”¶ç›¤åƒ¹'] = df['open']
                    print("ä½¿ç”¨ 'open' ä½œç‚º 'æ”¶ç›¤åƒ¹'")
                else:
                    print("ç„¡æ³•æ¨å°æ”¶ç›¤åƒ¹æ¬„ä½")
                    return df
        
        # è½‰æ›æ—¥æœŸæ ¼å¼
        if 'æ—¥æœŸ' in df.columns:
            try:
                df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
                print("æ—¥æœŸæ ¼å¼è½‰æ›æˆåŠŸ")
            except Exception as e:
                print(f"æ—¥æœŸæ ¼å¼è½‰æ›å¤±æ•—: {e}")
                # å˜—è©¦å…¶ä»–æ—¥æœŸæ ¼å¼
                try:
                    df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], format='%Y/%m/%d')
                    print("ä½¿ç”¨ %Y/%m/%d æ ¼å¼è½‰æ›æˆåŠŸ")
                except:
                    try:
                        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], format='%Y-%m-%d')
                        print("ä½¿ç”¨ %Y-%m-%d æ ¼å¼è½‰æ›æˆåŠŸ")
                    except:
                        print("æ‰€æœ‰æ—¥æœŸæ ¼å¼éƒ½è½‰æ›å¤±æ•—")
        
        # ç¢ºä¿æ”¶ç›¤åƒ¹ç‚ºæ•¸å€¼å‹
        if 'æ”¶ç›¤åƒ¹' in df.columns:
            try:
                df['æ”¶ç›¤åƒ¹'] = pd.to_numeric(df['æ”¶ç›¤åƒ¹'], errors='coerce')
                print("æ”¶ç›¤åƒ¹è½‰æ›ç‚ºæ•¸å€¼å‹æˆåŠŸ")
            except Exception as e:
                print(f"æ”¶ç›¤åƒ¹è½‰æ›å¤±æ•—: {e}")
        
        print(f"é è™•ç†å®Œæˆï¼Œæœ€çµ‚æ¬„ä½: {list(df.columns)}")
        print(f"æœ€çµ‚æ•¸æ“šå½¢ç‹€: {df.shape}")
        
        return df
        
    def _create_summary_content(self, report):
        """å‰µå»ºåˆ†ææ‘˜è¦å…§å®¹ï¼ˆä¿®ï¼šå…ˆè¨ˆç®—è®Šæ•¸ï¼Œé¿å…åœ¨ children å…§è³¦å€¼ï¼‰"""
        from dash import html, dcc
        import dash_bootstrap_components as dbc

        if not report:
            return html.P("ç„¡åˆ†æçµæœ")

        risk_count = report.get('analysis_results', {}).get('risk_valve', {}).get('risk_periods_count', 0)
        phase_count = len(report.get('analysis_results', {}).get('phase_analysis', {}))

        return html.Div([
            dbc.Row([
                dbc.Col([
                    dbc.Card([
                        dbc.CardBody([
                            html.H5("ğŸ“Š åŸºæœ¬è³‡è¨Š", className="card-title"),
                            html.P(f"åˆ†ææ™‚é–“ï¼š{report.get('analysis_timestamp', 'N/A')}"),
                            html.P(f"ç¸½äº¤æ˜“æ•¸ï¼š{report.get('total_trades', 0)}"),
                        ])
                    ])
                ], width=4),
                dbc.Col([
                    dbc.Card([
                        dbc.CardBody([
                            html.H5("âš ï¸ é¢¨éšªé–¥é–€", className="card-title"),
                            html.P(f"è§¸ç™¼æœŸé–“æ•¸ï¼š{risk_count}"),
                        ])
                    ])
                ], width=4),
                dbc.Col([
                    dbc.Card([
                        dbc.CardBody([
                            html.H5("ğŸ”„ äº¤æ˜“éšæ®µ", className="card-title"),
                            html.P(f"è­˜åˆ¥éšæ®µæ•¸ï¼š{phase_count}"),
                        ])
                    ])
                ], width=4),
            ])
        ])
        
    def _create_risk_valve_content(self, risk_results):
        """å‰µå»ºé¢¨éšªé–¥é–€åˆ†æå…§å®¹ï¼ˆä¿®ï¼šåœ¨ children ä¹‹å¤–è¨ˆç®— improvementï¼‰"""
        from dash import html
        import dash_bootstrap_components as dbc

        if not risk_results:
            return html.P("ç„¡é¢¨éšªé–¥é–€åˆ†æçµæœ")

        improvement = risk_results.get('improvement_potential', {}) or {}
        mdd_red = improvement.get('mdd_reduction', 0)
        pf_imp = improvement.get('pf_improvement', 0)

        return html.Div([
            dbc.Row([
                dbc.Col([
                    html.H6("é¢¨éšªæœŸé–“ vs æ­£å¸¸æœŸé–“å°æ¯”"),
                    html.P(f"é¢¨éšªæœŸé–“äº¤æ˜“æ•¸ï¼š{risk_results.get('risk_trades_count', 0)}"),
                    html.P(f"æ­£å¸¸æœŸé–“äº¤æ˜“æ•¸ï¼š{risk_results.get('normal_trades_count', 0)}"),
                ], width=6),
                dbc.Col([
                    html.H6("æ”¹å–„æ½›åŠ›"),
                    html.P(f"MDDæ”¹å–„æ½›åŠ›ï¼š{mdd_red:.2%}" if isinstance(mdd_red, float) else f"MDDæ”¹å–„æ½›åŠ›ï¼š{mdd_red}"),
                    html.P(f"PFæ”¹å–„æ½›åŠ›ï¼š{pf_imp:.2f}" if isinstance(pf_imp, float) else f"PFæ”¹å–„æ½›åŠ›ï¼š{pf_imp}"),
                ], width=6)
            ])
        ])
        
    def _error_outputs(self, message):
        """çµ±ä¸€éŒ¯èª¤è¼¸å‡ºï¼Œç¢ºä¿ 7 å€‹è¼¸å‡ºå®Œæ•´"""
        from dash import html
        return (
            {'display': 'block'},   # results å€åŸŸé¡¯ç¤º
            self._create_error_message(message),  # summary å¡éŒ¯èª¤å¡ç‰‡
            html.P("â€”"), html.P("â€”"), html.P("â€”"), html.P("â€”"),  # å…¶ä»–å€åŸŸä½”ä½
            True  # ç”Ÿæˆå ±å‘ŠæŒ‰éˆ• disable
        )
        
    def _create_phase_analysis_content(self, phase_results):
        """å‰µå»ºäº¤æ˜“éšæ®µåˆ†æå…§å®¹"""
        from dash import html
        import dash_bootstrap_components as dbc
        
        if not phase_results:
            return html.P("ç„¡äº¤æ˜“éšæ®µåˆ†æçµæœ")
            
        phase_cards = []
        for phase_type, phase_info in phase_results.items():
            card = dbc.Card([
                dbc.CardHeader(f"ğŸ“Š {phase_type} éšæ®µ"),
                dbc.CardBody([
                    html.P(f"äº¤æ˜“æ•¸ï¼š{phase_info.get('trade_count', 0)}"),
                    html.P(f"ç¸½å ±é…¬ï¼š{phase_info.get('total_return', 0):.2f}%"),
                    html.P(f"è²¢ç»æ¯”ä¾‹ï¼š{phase_info.get('contribution_ratio', 0):.2%}"),
                    html.P(f"æœŸé–“ï¼š{phase_info.get('start_date', 'N/A')} åˆ° {phase_info.get('end_date', 'N/A')}"),
                ])
            ], className="mb-3")
            phase_cards.append(card)
            
        return html.Div(phase_cards)
        
    def _create_gradient_optimization_content(self, gradient_results):
        """å‰µå»ºåŠ ç¢¼æ¢¯åº¦å„ªåŒ–å…§å®¹"""
        from dash import html
        import dash_bootstrap_components as dbc
        
        if not gradient_results:
            return html.P("ç„¡åŠ ç¢¼æ¢¯åº¦å„ªåŒ–çµæœ")
            
        current = gradient_results.get('current_pattern', {})
        optimized = gradient_results.get('optimized_pattern', {})
        
        return html.Div([
            dbc.Row([
                dbc.Col([
                    html.H6("ç•¶å‰åŠ ç¢¼æ¨¡å¼"),
                    html.P(f"å¹³å‡é–“è·ï¼š{current.get('avg_interval', 0):.1f} å¤©"),
                    html.P(f"æœ€å¤§é€£çºŒåŠ ç¢¼ï¼š{current.get('max_consecutive', 0)} ç­†"),
                ], width=6),
                dbc.Col([
                    html.H6("å„ªåŒ–å¾Œæ•ˆæœ"),
                    html.P(f"åŠ ç¢¼æ¬¡æ•¸ï¼šå¾ {optimized.get('original_count', 0)} æ¸›å°‘åˆ° {optimized.get('optimized_count', 0)}"),
                    html.P(f"æ¸›å°‘æ¯”ä¾‹ï¼š{optimized.get('reduction_ratio', 0):.1%}"),
                ], width=6)
            ])
        ])
        
    def _create_charts_content(self):
        """å‰µå»ºåœ–è¡¨å…§å®¹"""
        from dash import html
        
        if not self.enhanced_analyzer:
            return html.P("ç„¡åœ–è¡¨æ•¸æ“š")
            
        try:
            # é€™è£¡å¯ä»¥èª¿ç”¨åœ–è¡¨ç”Ÿæˆå‡½æ•¸
            # fig = self.enhanced_analyzer.plot_enhanced_analysis()
            return html.Div([
                html.H5("ğŸ“ˆ åˆ†æåœ–è¡¨"),
                html.P("åœ–è¡¨åŠŸèƒ½é–‹ç™¼ä¸­..."),
                html.P("ç›®å‰å¯é€šéæ§åˆ¶å°æŸ¥çœ‹åˆ†æçµæœ")
            ])
        except Exception as e:
            return html.P(f"åœ–è¡¨ç”Ÿæˆå¤±æ•—ï¼š{str(e)}")
            
    def _create_error_message(self, message):
        """å‰µå»ºéŒ¯èª¤è¨Šæ¯"""
        from dash import html
        import dash_bootstrap_components as dbc
        return html.Div([
            dbc.Alert([
                html.H4("âŒ éŒ¯èª¤", className="alert-heading"),
                html.P(message),
            ], color="danger")
        ])

    def _get_trades_data(self, strategy_selector, specific_strategy, backtest_data):
        """å¾ç­–ç•¥å›æ¸¬çµæœç²å–äº¤æ˜“æ•¸æ“š"""
        if not backtest_data or 'results' not in backtest_data:
            print("è­¦å‘Šï¼šæ²’æœ‰å¯ç”¨çš„å›æ¸¬æ•¸æ“š")
            return None
            
        results = backtest_data['results']
        
        if not results:
            print("è­¦å‘Šï¼šå›æ¸¬çµæœç‚ºç©º")
            return None
        
        # é¸ç­–ç•¥ï¼šæ‰“åˆ†æ³•ï¼ˆledger_std > ledger > trade_dfï¼‰
        def _score(res):
            s = 0
            if res.get('trade_ledger_std'): s += 3
            if res.get('trade_ledger'): s += 2
            if res.get('trades_df') or res.get('trade_df'): s += 1
            return s

        if strategy_selector in ('current', 'specific'):
            # è‹¥ future æƒ³åŠ ã€ŒæŒ‡å®šç­–ç•¥åã€å¯ç”¨ specific_strategy
            best = None
            best_name = None
            for name, res in results.items():
                if best is None or _score(res) > _score(best):
                    best, best_name = res, name
            strategy_name = best_name
        else:
            print("è­¦å‘Šï¼šæœªé¸æ“‡ç­–ç•¥")
            return None
            
        if not strategy_name or strategy_name not in results:
            print(f"è­¦å‘Šï¼šç­–ç•¥ {strategy_name} ä¸å­˜åœ¨")
            return None
            
        result = results[strategy_name]
        print(f"ä½¿ç”¨ç­–ç•¥ï¼š{strategy_name}")
        
        # å˜—è©¦ç²å–äº¤æ˜“æ•¸æ“š
        trades_df = None
        
        # å„ªå…ˆä½¿ç”¨ trade_ledgerï¼ˆæ›´å®Œæ•´çš„äº¤æ˜“è¨˜éŒ„ï¼‰
        if 'trade_ledger' in result and result['trade_ledger']:
            try:
                if isinstance(result['trade_ledger'], str):
                    import json
                    trades_df = pd.read_json(result['trade_ledger'], orient='split')
                else:
                    trades_df = result['trade_ledger']
                print(f"ä½¿ç”¨ trade_ledgerï¼Œæ¬„ä½ï¼š{list(trades_df.columns)}")
            except Exception as e:
                print(f"è§£æ trade_ledger å¤±æ•—ï¼š{e}")
        
        # å¦‚æœæ²’æœ‰ trade_ledgerï¼Œä½¿ç”¨ trade_df
        if trades_df is None and 'trade_df' in result and result['trade_df']:
            try:
                if isinstance(result['trade_df'], str):
                    import json
                    trades_df = pd.read_json(result['trade_df'], orient='split')
                else:
                    trades_df = result['trade_df']
                print(f"ä½¿ç”¨ trade_dfï¼Œæ¬„ä½ï¼š{list(trades_df.columns)}")
            except Exception as e:
                print(f"è§£æ trade_df å¤±æ•—ï¼š{e}")
        
        if trades_df is None or trades_df.empty:
            print("è­¦å‘Šï¼šç„¡æ³•ç²å–æœ‰æ•ˆçš„äº¤æ˜“æ•¸æ“š")
            return None
            
        # é è™•ç†äº¤æ˜“æ•¸æ“š
        trades_df = self._preprocess_trades_data(trades_df)
        return trades_df
    
    def _get_benchmark_data(self, benchmark_selector, custom_benchmark):
        """ç²å–åŸºæº–æ•¸æ“š"""
        if benchmark_selector == 'custom' and custom_benchmark:
            # ä½¿ç”¨è‡ªå®šç¾©ä¸Šå‚³çš„åŸºæº–æ•¸æ“š
            return self._parse_uploaded_data(custom_benchmark, "benchmark")
        else:
            # ä½¿ç”¨æœ¬åœ°è‚¡åƒ¹æ•¸æ“š
            return self._load_local_price_data(benchmark_selector)
    
    def _load_local_price_data(self, ticker):
        """å¾æœ¬åœ° data/ ç›®éŒ„è¼‰å…¥è‚¡åƒ¹æ•¸æ“š"""
        import os
        import pandas as pd
        
        try:
            # æ§‹å»ºæª”æ¡ˆè·¯å¾‘
            data_dir = 'data'
            if ticker == 'TWII':
                filename = '^TWII_data_raw.csv'
            else:
                filename = f"{ticker}_data_raw.csv"
            
            file_path = os.path.join(data_dir, filename)
            
            if not os.path.exists(file_path):
                print(f"è­¦å‘Šï¼šè‚¡åƒ¹æª”æ¡ˆä¸å­˜åœ¨ï¼š{file_path}")
                return None
            
            # ç‰¹æ®Šè™•ç† TWII æ•¸æ“šæ ¼å¼
            if ticker == 'TWII':
                # ç¬¬ä¸€è¡Œæ˜¯æ¬„ä½åç¨±ï¼Œç¬¬äºŒè¡Œæ˜¯ ticker ä¿¡æ¯ï¼Œç¬¬ä¸‰è¡Œæ˜¯ç©ºçš„ï¼Œç¬¬å››è¡Œé–‹å§‹æ˜¯æ•¸æ“š
                df = pd.read_csv(file_path, skiprows=2, index_col=0, parse_dates=True)
                # æ‰‹å‹•è¨­ç½®æ­£ç¢ºçš„æ¬„ä½åç¨±ï¼ˆindex_col=0 æœƒæŠŠç¬¬ä¸€åˆ—ç•¶ä½œç´¢å¼•ï¼Œæ‰€ä»¥å¯¦éš›æ¬„ä½åªæœ‰ 5 å€‹ï¼‰
                df.columns = ['Close', 'High', 'Low', 'Open', 'Volume']
            else:
                df = pd.read_csv(file_path, index_col=0, parse_dates=True)
            
            print(f"æˆåŠŸè¼‰å…¥è‚¡åƒ¹æ•¸æ“šï¼š{ticker}ï¼Œå½¢ç‹€ï¼š{df.shape}")
            
            # é è™•ç†åŸºæº–æ•¸æ“š
            df = self._preprocess_benchmark_data(df)
            return df
            
        except Exception as e:
            print(f"è¼‰å…¥è‚¡åƒ¹æ•¸æ“šå¤±æ•—ï¼š{e}")
            return None
    
    def _df_from_pack(self, data):
        """è§£ææ‰“åŒ…çš„æ•¸æ“šï¼ˆèˆ‡ app_dash åŒåå·¥å…·å‡½æ•¸ï¼‰"""
        import io
        import pandas as pd
        
        if data is None or data == "" or data == "[]":
            return pd.DataFrame()
        if isinstance(data, str):
            for orient in ("split", None):
                try:
                    kw = {"orient": orient} if orient else {}
                    return pd.read_json(io.StringIO(data), **kw)
                except Exception:
                    pass
            return pd.DataFrame()
        if isinstance(data, (list, dict)):
            try:
                return pd.DataFrame(data)
            except Exception:
                return pd.DataFrame()
        return pd.DataFrame()

def create_enhanced_analysis_tab():
    """å‰µå»ºå¢å¼·åˆ†ææ¨™ç±¤é çš„ä¾¿æ·å‡½æ•¸"""
    ui = EnhancedAnalysisUI()
    return ui.create_enhanced_analysis_tab()

def setup_enhanced_analysis_callbacks(app):
    """è¨­ç½®å¢å¼·åˆ†æå›èª¿å‡½æ•¸çš„ä¾¿æ·å‡½æ•¸"""
    ui = EnhancedAnalysisUI()
    ui.create_enhanced_analysis_callbacks(app)
    return ui

if __name__ == "__main__":
    print("å¢å¼·åˆ†æUIæ•´åˆæ¨¡çµ„")
    print("è·¯å¾‘ï¼š#analysis/enhanced_analysis_ui.py")
    print("å‰µå»ºæ™‚é–“ï¼š2025-08-18 04:45")
    print("\nä½¿ç”¨æ–¹æ³•ï¼š")
    print("1. åœ¨app_dash.pyä¸­å°å…¥ï¼šfrom analysis.enhanced_analysis_ui import create_enhanced_analysis_tab")
    print("2. åœ¨æ¨™ç±¤é ä¸­æ·»åŠ ï¼šcreate_enhanced_analysis_tab()")
    print("3. è¨­ç½®å›èª¿ï¼šsetup_enhanced_analysis_callbacks(app)")
