import sys
from pathlib import Path
ROOT = Path(__file__).resolve().parent.parent
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

import pandas as pd
import numpy as np
from scipy.spatial.distance import cdist
from scipy.stats import pearsonr
import ast
import shutil
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from analysis.data_loader import load_data
from SSSv096 import backtest_unified, param_presets, compute_single, compute_RMA, compute_ssma_turn_combined, compute_dual
from analysis.config import RESULT_DIR, WF_PERIODS, STRESS_PERIODS, CACHE_DIR
from analysis.metrics import calculate_max_drawdown
from analysis.logging_config import setup_logging
import logging

# åˆå§‹åŒ–å¿«å–ç›®éŒ„
# ç§»é™¤è‡ªå‹•æ¸…ç†å¿«å–ç›®éŒ„ï¼Œé¿å…èˆ‡å…¶ä»–ç¨‹å¼è¡çª
# shutil.rmtree(CACHE_DIR, ignore_errors=True)
(CACHE_DIR / "price").mkdir(parents=True, exist_ok=True)
(CACHE_DIR / "smaa").mkdir(parents=True, exist_ok=True)
(CACHE_DIR / "factor").mkdir(parents=True, exist_ok=True)

# åˆå§‹åŒ–æ—¥èªŒ
setup_logging()
logger = logging.getLogger("OSv3")

# === åƒæ•¸ç›¸é—œæ€§åˆ†æèˆ‡å¤šæ¨£æ€§éæ¿¾å‡½æ•¸ï¼ˆç§»åˆ°æª”æ¡ˆå‰é¢ï¼‰ ===
def compute_param_correlations(optuna_results_df, strategy, data_source):
    """
    è¨ˆç®—æŒ‡å®šç­–ç•¥å’Œæ•¸æ“šæºçš„åƒæ•¸èˆ‡ç¸¾æ•ˆæŒ‡æ¨™çš„ç›¸é—œæ€§
    
    Args:
        optuna_results_df: OptunaçµæœDataFrame
        strategy: ç­–ç•¥åç¨±
        data_source: æ•¸æ“šæºåç¨±
    
    Returns:
        pd.DataFrame: åƒæ•¸ç›¸é—œæ€§çŸ©é™£
    """
    # ç¯©é¸æŒ‡å®šç­–ç•¥å’Œæ•¸æ“šæºçš„è©¦é©—
    mask = (optuna_results_df['strategy'] == strategy) & (optuna_results_df['data_source'] == data_source)
    strategy_trials = optuna_results_df[mask].copy()
    
    if len(strategy_trials) < 10:
        logger.warning(f"ç­–ç•¥ {strategy} æ•¸æ“šæº {data_source} çš„è©¦é©—æ•¸é‡ä¸è¶³ ({len(strategy_trials)})ï¼Œè·³éç›¸é—œæ€§åˆ†æ")
        return pd.DataFrame()
    
    # è§£æåƒæ•¸
    strategy_trials['parameters'] = strategy_trials['parameters'].apply(
        lambda x: ast.literal_eval(x) if isinstance(x, str) else x
    )
    
    # æå–åƒæ•¸åˆ°ç¨ç«‹æ¬„ä½
    param_keys = set()
    for params in strategy_trials['parameters']:
        if isinstance(params, dict):
            param_keys.update(params.keys())
    
    for param in param_keys:
        strategy_trials[f'param_{param}'] = strategy_trials['parameters'].apply(
            lambda x: x.get(param, np.nan) if isinstance(x, dict) else np.nan
        )
    
    # è¨ˆç®—ç›¸é—œæ€§
    correlations = {}
    metric_keys = ["total_return", "sharpe_ratio"]
    
    for param in param_keys:
        param_col = f'param_{param}'
        if param_col not in strategy_trials.columns:
            continue
            
        correlations[param] = {}
        param_values = pd.to_numeric(strategy_trials[param_col], errors='coerce')
        
        for metric in metric_keys:
            if metric not in strategy_trials.columns:
                continue
                
            metric_values = pd.to_numeric(strategy_trials[metric], errors='coerce')
            
            # ç¢ºä¿æ˜¯pandas Seriesä¸¦ç§»é™¤NaNå€¼
            if not isinstance(param_values, pd.Series):
                param_values = pd.Series(param_values)
            if not isinstance(metric_values, pd.Series):
                metric_values = pd.Series(metric_values)
            
            # ç§»é™¤NaNå€¼
            valid_mask = param_values.notna() & metric_values.notna()
            if valid_mask.sum() < 3:
                correlations[param][metric] = np.nan
                continue
            
            valid_params = param_values[valid_mask]
            valid_metrics = metric_values[valid_mask]
            
            try:
                corr, p_value = pearsonr(valid_params, valid_metrics)
                correlations[param][metric] = corr
            except:
                correlations[param][metric] = np.nan
    
    return pd.DataFrame(correlations).T

def pick_topN_by_diversity(trials, metric_keys, top_n=5):
    """
    åŸºæ–¼æ€§èƒ½æŒ‡æ¨™çš„å¤šæ¨£æ€§ top N è©¦é©—é¸æ“‡ï¼Œæ‡‰ç”¨å››æ¨äº”å…¥è¦å‰‡
    
    Args:
        trials: è©¦é©—åˆ—è¡¨ï¼Œæ¯å€‹è©¦é©—åŒ…å« score å’ŒæŒ‡å®šæŒ‡æ¨™
        metric_keys: ç”¨æ–¼åˆ†çµ„çš„æŒ‡æ¨™éµ
        top_n: æœ€çµ‚é¸å–çš„è©¦é©—æ•¸é‡
    
    Returns:
        List: ç¯©é¸å¾Œçš„è©¦é©—åˆ—è¡¨
    """
    logger.info(f"é–‹å§‹å¤šæ¨£æ€§ç¯©é¸: {len(trials)} å€‹è©¦é©—, ç›®æ¨™é¸å– {top_n} å€‹")
    
    # è½‰æ›ç‚º DataFrame
    df = pd.DataFrame(trials)
    
    # å››æ¨äº”å…¥è¦å‰‡
    round_rules = {
        'min_wf_return': 1,          # å°æ•¸é»å¾Œä¸€ä½
        'avg_stress_return': 2,      # å°æ•¸é»å¾Œä¸‰ä½
        'stability_score': 1,        # å°æ•¸é»å¾ŒäºŒä½
        'robust_score': 2,           # å°æ•¸é»å¾Œä¸‰ä½
        'excess_return_stress': 2,   # å°æ•¸é»å¾Œä¸‰ä½
        'stress_mdd': 2,             # å°æ•¸é»å¾Œä¸‰ä½
        'pbo_score': 2,              # å°æ•¸é»å¾ŒäºŒä½
        'sra_p_value': 2,            # å°æ•¸é»å¾Œä¸‰ä½
        'avg_hold_days': 1           # æ•´æ•¸ä½
    }
    
    logger.info(f"å››æ¨äº”å…¥è¦å‰‡: {round_rules}")
    
    # æ‡‰ç”¨å››æ¨äº”å…¥
    for key in metric_keys:
        if key in round_rules:
            df[f'rounded_{key}'] = df[key].round(round_rules[key])
            logger.info(f"æŒ‡æ¨™ {key}: åŸå§‹å€¼ç¯„åœ [{df[key].min():.3f}, {df[key].max():.3f}], å››æ¨äº”å…¥å¾Œç¯„åœ [{df[f'rounded_{key}'].min():.3f}, {df[f'rounded_{key}'].max():.3f}]")
    
    # æŒ‰å››æ¨äº”å…¥å¾Œçš„æŒ‡æ¨™åˆ†çµ„
    group_cols = [f'rounded_{key}' for key in metric_keys]
    df['group'] = df[group_cols].astype(str).agg('_'.join, axis=1)
    
    # çµ±è¨ˆåˆ†çµ„æƒ…æ³
    group_counts = df['group'].value_counts()
    logger.info(f"åˆ†çµ„çµ±è¨ˆ: å…± {len(group_counts)} å€‹ä¸åŒçµ„åˆ¥")
    logger.info(f"çµ„åˆ¥å¤§å°åˆ†å¸ƒ: {group_counts.describe()}")
    
    # é¡¯ç¤ºå‰å¹¾å€‹çµ„åˆ¥çš„è©³ç´°ä¿¡æ¯
    for i, (group, count) in enumerate(group_counts.head(5).items()):
        group_str = str(group)[:50] if group else "ç©ºçµ„åˆ¥"
        logger.info(f"çµ„åˆ¥ {i+1}: {count} å€‹è©¦é©—, çµ„åˆ¥æ¨™è­˜: {group_str}...")
    
    # æŒ‰åˆ†æ•¸æ’åºä¸¦é¸æ“‡æ¯å€‹åˆ†çµ„ä¸­åˆ†æ•¸æœ€é«˜çš„è©¦é©—
    df_sorted = df.sort_values(by='score', ascending=False)
    chosen_trials = []
    seen_groups = set()
    
    logger.info("é–‹å§‹é¸å–è©¦é©—...")
    
    for idx, row in df_sorted.iterrows():
        group = row['group']
        trial_num = row['trial_number']
        score = row['score']
        
        if group not in seen_groups:
            chosen_trials.append(row.to_dict())
            seen_groups.add(group)
            logger.info(f"é¸å–è©¦é©— {trial_num}: score={score:.3f}, çµ„åˆ¥={group[:50]}...")
        else:
            logger.debug(f"è·³éè©¦é©— {trial_num}: score={score:.3f}, çµ„åˆ¥å·²å­˜åœ¨")
        
        if len(chosen_trials) >= top_n:
            logger.info(f"å·²é¸å– {len(chosen_trials)} å€‹è©¦é©—ï¼Œé”åˆ°ç›®æ¨™æ•¸é‡")
            break
    
    if len(chosen_trials) < top_n:
        logger.warning(f"åªé¸å–äº† {len(chosen_trials)} å€‹è©¦é©—ï¼Œå°‘æ–¼ç›®æ¨™ {top_n} å€‹")
    
    # é¡¯ç¤ºæœ€çµ‚é¸å–çš„è©¦é©—ä¿¡æ¯
    logger.info("æœ€çµ‚é¸å–çš„è©¦é©—:")
    for i, trial in enumerate(chosen_trials):
        logger.info(f"  {i+1}. è©¦é©— {trial['trial_number']}: score={trial['score']:.3f}")
        # é¡¯ç¤ºé—œéµæŒ‡æ¨™
        key_metrics = {k: trial.get(k, 'N/A') for k in ['min_wf_return', 'avg_stress_return', 'stability_score']}
        logger.info(f"     é—œéµæŒ‡æ¨™: {key_metrics}")
    
    return chosen_trials

# Streamlit UI é…ç½®
st.set_page_config(layout="wide", page_title="00631L ç­–ç•¥å›æ¸¬èˆ‡èµ°æŸ¥åˆ†æ")

# è‡ªè¨‚ multiselect æ¨™ç±¤é¡è‰²ç‚ºæ°´è—è‰²
st.markdown(
    '''
    <style>
    .stMultiSelect [data-baseweb="tag"] {
        background-color: #00BFFF !important;
        color: #222 !important;
    }
    </style>
    ''',
    unsafe_allow_html=True
)

st.title("00631L ç­–ç•¥åˆ†æèˆ‡å›æ¸¬")

# å‹•æ…‹ç”Ÿæˆèµ°æŸ¥å€é–“
def generate_walk_forward_periods(data_index, n_splits, min_days=30):
    """æ ¹æ“šæ•¸æ“šæ—¥æœŸç¯„åœç”Ÿæˆå¹³åˆ†çš„èµ°æŸ¥å€é–“"""
    if data_index.empty:
        st.error("æ•¸æ“šç´¢å¼•ç‚ºç©ºï¼Œç„¡æ³•ç”Ÿæˆèµ°æŸ¥å€é–“")
        logger.error("æ•¸æ“šç´¢å¼•ç‚ºç©ºï¼Œç„¡æ³•ç”Ÿæˆèµ°æŸ¥å€é–“")
        return []
    start_date = data_index.min()
    end_date = data_index.max()
    total_days = (end_date - start_date).days
    if total_days < min_days:
        st.error(f"æ•¸æ“šç¯„åœéçŸ­ï¼ˆ{total_days} å¤©ï¼‰ï¼Œç„¡æ³•ç”Ÿæˆèµ°æŸ¥å€é–“")
        logger.error(f"æ•¸æ“šç¯„åœéçŸ­ï¼ˆ{total_days} å¤©ï¼‰ï¼Œç„¡æ³•ç”Ÿæˆèµ°æŸ¥å€é–“")
        return []
    if total_days < min_days * n_splits:
        n_splits = max(1, total_days // min_days)
        logger.warning(f"æ•¸æ“šç¯„åœéçŸ­ï¼Œèª¿æ•´åˆ†æ®µæ•¸ç‚º {n_splits}")
    days_per_split = total_days // n_splits
    periods = []
    current_start = start_date
    for i in range(n_splits):
        if i == n_splits - 1:
            current_end = end_date
        else:
            current_end = current_start + pd.Timedelta(days=days_per_split - 1)
            end_candidates = data_index[data_index <= current_end]
            if end_candidates.empty:
                break
            current_end = end_candidates[-1]
        if (current_end - current_start).days >= min_days:
            periods.append((current_start, current_end))
        current_start = current_end + pd.Timedelta(days=1)
        start_candidates = data_index[data_index >= current_start]
        if start_candidates.empty:
            break
        current_start = start_candidates[0]
    return periods

# è¨ˆç®— PR å€¼
def calculate_pr_values(series, is_mdd, is_initial_period, hedge_mask):
    """
    å ±é…¬ç‡é‡åŒ–åˆ†æ•¸ï¼ˆRelative Strength Scoreï¼‰æˆ– MDD é‡åŒ–åˆ†æ•¸ï¼ˆRisk-Adjusted MDD Scoreï¼‰
    :param series: è¦è¨ˆç®—åˆ†æ•¸çš„ç³»åˆ—ï¼ˆå ±é…¬ç‡æˆ– MDDï¼‰
    :param is_mdd: æ˜¯å¦ç‚º MDDï¼ˆTrueï¼‰æˆ–å ±é…¬ç‡ï¼ˆFalseï¼‰
    :param is_initial_period: æ˜¯å¦ç‚ºåˆå§‹æ™‚æ®µ
    :param hedge_mask: é¿éšªæ©ç¢¼ï¼ŒTrue è¡¨ç¤ºè©²ç­–ç•¥åœ¨è©²æ™‚æ®µé¿éšª
    :return: åˆ†æ•¸ç³»åˆ—
    """
    score = pd.Series(index=series.index, dtype=float)
    if is_initial_period:
        # åˆå§‹æ™‚æ®µï¼šæ’é™¤é¿éšªç­–ç•¥
        score[hedge_mask] = np.nan
        valid = ~hedge_mask
        valid_series = series[valid]
        if is_mdd:
            # MDD ä¿®æ­£ï¼šMDDè¶Šå°ï¼ˆè¶Šæ¥è¿‘0ï¼‰åˆ†æ•¸è¶Šé«˜
            # MDDé€šå¸¸æ˜¯è² å€¼ï¼Œæˆ‘å€‘å¸Œæœ›å®ƒè¶Šæ¥è¿‘0è¶Šå¥½
            benchmark = abs(valid_series.mean())
            if benchmark == 0 or np.isnan(benchmark):
                score[valid] = 0
            else:
                # ä¿®æ­£å…¬å¼ï¼šMDDè¶Šå°åˆ†æ•¸è¶Šé«˜
                # ä½¿ç”¨ (1 + valid_series/benchmark) è€Œä¸æ˜¯ (1 - valid_series/benchmark)
                # å› ç‚ºvalid_seriesæ˜¯è² å€¼ï¼Œæ‰€ä»¥åŠ è™Ÿæœƒè®“MDDè¶Šå°åˆ†æ•¸è¶Šé«˜
                score[valid] = 100 * (1 + valid_series / benchmark)
        else:
            # å ±é…¬ç‡ï¼šå ±é…¬ç‡è¶Šé«˜åˆ†æ•¸è¶Šé«˜
            benchmark = valid_series.mean()
            std = valid_series.std()
            if std == 0 or np.isnan(std):
                score[valid] = 0
            else:
                score[valid] = 100 * (valid_series - benchmark) / std
    else:
        # éåˆå§‹æ™‚æ®µï¼šé¿éšªç­–ç•¥çµ¦ 100 åˆ†
        score[hedge_mask] = 100
        valid = ~hedge_mask
        valid_series = series[valid]
        if is_mdd:
            # MDD ä¿®æ­£ï¼šMDDè¶Šå°ï¼ˆè¶Šæ¥è¿‘0ï¼‰åˆ†æ•¸è¶Šé«˜
            benchmark = abs(valid_series.mean())
            if benchmark == 0 or np.isnan(benchmark):
                score[valid] = 0
            else:
                # ä¿®æ­£å…¬å¼ï¼šMDDè¶Šå°åˆ†æ•¸è¶Šé«˜
                score[valid] = 100 * (1 + valid_series / benchmark)
        else:
            # å ±é…¬ç‡ï¼šå ±é…¬ç‡è¶Šé«˜åˆ†æ•¸è¶Šé«˜
            benchmark = valid_series.mean()
            std = valid_series.std()
            if std == 0 or np.isnan(std):
                score[valid] = 0
            else:
                score[valid] = 100 * (valid_series - benchmark) / std
    return score

# åœ¨æ–‡ä»¶é–‹é ­æ·»åŠ æ–°çš„éæ“¬åˆæª¢æ¸¬å‡½æ•¸
def calculate_overfitting_metrics(train_returns, test_returns, strategy_name):
    """
    è¨ˆç®—éæ“¬åˆæŒ‡æ¨™
    """
    if len(train_returns) == 0 or len(test_returns) == 0:
        return {}
    
    # è¨ˆç®—æ¨£æœ¬å…§å¤–è¡¨ç¾å·®ç•°
    train_sharpe = train_returns.mean() / train_returns.std() if train_returns.std() > 0 else 0
    test_sharpe = test_returns.mean() / test_returns.std() if test_returns.std() > 0 else 0
    
    # æ¨£æœ¬å…§å¤–å¤æ™®æ¯”ç‡å·®ç•°
    sharpe_degradation = train_sharpe - test_sharpe
    
    # æ¨£æœ¬å…§å¤–å ±é…¬ç‡å·®ç•°
    return_degradation = train_returns.mean() - test_returns.mean()
    
    # ç©©å®šæ€§æŒ‡æ¨™ï¼ˆè®Šç•°ä¿‚æ•¸ï¼‰
    train_cv = train_returns.std() / abs(train_returns.mean()) if train_returns.mean() != 0 else float('inf')
    test_cv = test_returns.std() / abs(test_returns.mean()) if test_returns.mean() != 0 else float('inf')
    
    # éæ“¬åˆåˆ†æ•¸ï¼ˆ0-100ï¼Œè¶Šé«˜è¶Šéæ“¬åˆï¼‰
    # ä¿®æ­£è¨ˆç®—æ–¹å¼ï¼šè€ƒæ…®å¤æ™®æ¯”ç‡å’Œå ±é…¬ç‡çš„ç›¸å°é‡è¦æ€§
    sharpe_weight = 0.6
    return_weight = 0.4
    overfitting_score = min(100, max(0, 
        abs(sharpe_degradation) * 50 * sharpe_weight + 
        abs(return_degradation) * 200 * return_weight
    ))
    
    return {
        'train_sharpe': train_sharpe,
        'test_sharpe': test_sharpe,
        'train_return': train_returns.mean(),
        'test_return': test_returns.mean(),
        'sharpe_degradation': sharpe_degradation,
        'return_degradation': return_degradation,
        'overfitting_score': overfitting_score
    }

def calculate_strategy_stability(period_returns_dict):
    """
    è¨ˆç®—ç­–ç•¥ç©©å®šæ€§æŒ‡æ¨™
    """
    if not period_returns_dict:
        return {}
    
    returns_df = pd.DataFrame(period_returns_dict).T
    stability_metrics = {}
    
    for col in returns_df.columns:
        returns = returns_df[col].dropna()
        if len(returns) < 2:
            continue
            
        # è¨ˆç®—å„æœŸé–“è¡¨ç¾çš„ä¸€è‡´æ€§ï¼ˆæ³¨æ„ï¼šperiod_returnså·²ç¶“æ˜¯ç™¾åˆ†æ¯”ï¼‰
        mean_return = returns.mean() / 100  # è½‰æ›ç‚ºå°æ•¸
        std_return = returns.std() / 100    # è½‰æ›ç‚ºå°æ•¸
        cv = std_return / abs(mean_return) if mean_return != 0 else float('inf')
        
        # è¨ˆç®—æ­£å ±é…¬æœŸé–“æ¯”ä¾‹
        positive_periods = (returns > 0).sum() / len(returns)
        
        # è¨ˆç®—è¡¨ç¾æ’åç©©å®šæ€§ï¼ˆå¦‚æœæœ‰å¤šå€‹ç­–ç•¥ï¼‰
        if len(returns_df.columns) > 1:
            rank_stability = returns_df.corr().loc[col].mean()
        else:
            rank_stability = 1.0
            
        stability_metrics[col] = {
            'mean_return': mean_return,
            'std_return': std_return,
            'cv': cv,
            'positive_periods_ratio': positive_periods,
            'rank_stability': rank_stability
        }
    
    return stability_metrics

def calculate_risk_adjusted_metrics(equity_curve, strategy_name):
    """
    è¨ˆç®—é¢¨éšªèª¿æ•´å¾Œçš„å ±é…¬ç‡æŒ‡æ¨™
    """
    if equity_curve.empty or len(equity_curve) < 2:
        return {}
    
    # è¨ˆç®—æ—¥å ±é…¬ç‡
    daily_returns = equity_curve.pct_change().dropna()
    
    # åŸºæœ¬æŒ‡æ¨™
    total_return = (equity_curve.iloc[-1] / equity_curve.iloc[0] - 1)
    annual_return = total_return * (252 / len(daily_returns))
    volatility = daily_returns.std() * np.sqrt(252)
    sharpe_ratio = annual_return / volatility if volatility > 0 else 0
    
    # æœ€å¤§å›æ’¤
    max_drawdown = calculate_max_drawdown(equity_curve)
    calmar_ratio = annual_return / max_drawdown if max_drawdown > 0 else 0
    
    # ç´¢æè«¾æ¯”ç‡ï¼ˆåªè€ƒæ…®ä¸‹è¡Œé¢¨éšªï¼‰
    downside_returns = daily_returns[daily_returns < 0]
    downside_deviation = downside_returns.std() * np.sqrt(252) if len(downside_returns) > 0 else 0
    sortino_ratio = annual_return / downside_deviation if downside_deviation > 0 else 0
    
    # å¡ç‘ªæ¯”ç‡ï¼ˆå¹´åŒ–å ±é…¬ç‡/æœ€å¤§å›æ’¤ï¼‰
    kama_ratio = annual_return / max_drawdown if max_drawdown > 0 else 0
    
    # ä¸€è‡´æ€§è©•åˆ†ï¼ˆæ­£å ±é…¬æœˆä»½æ¯”ä¾‹ï¼‰
    monthly_returns = equity_curve.resample('M').last().pct_change().dropna()
    positive_months = (monthly_returns > 0).sum() / len(monthly_returns)
    
    # ç¶œåˆè©•åˆ†ï¼ˆçµåˆå ±é…¬ç‡å’Œé¢¨éšªï¼‰
    composite_score = (sharpe_ratio * 0.3 + sortino_ratio * 0.3 + positive_months * 0.2 + (1 - max_drawdown) * 0.2)
    
    return {
        'total_return': total_return,
        'annual_return': annual_return,
        'volatility': volatility,
        'sharpe_ratio': sharpe_ratio,
        'sortino_ratio': sortino_ratio,
        'calmar_ratio': calmar_ratio,
        'kama_ratio': kama_ratio,
        'max_drawdown': max_drawdown,
        'positive_months_ratio': positive_months,
        'composite_score': composite_score
    }

# è§£ææ–‡ä»¶åä»¥æå–ç­–ç•¥å’Œæ•¸æ“šæºä¿¡æ¯
def parse_optuna_filename(filename):
    """è§£æoptunaçµæœæ–‡ä»¶åï¼Œæå–ç­–ç•¥å’Œæ•¸æ“šæºä¿¡æ¯"""
    name = Path(filename).stem  # ç§»é™¤.csvå¾Œç¶´
    
    # æª¢æŸ¥æ˜¯å¦æ˜¯optuna_resultsæ–‡ä»¶
    if not name.startswith('optuna_results_'):
        return None
    
    # ç§»é™¤å‰ç¶´
    name = name.replace('optuna_results_', '')
    
    # æŸ¥æ‰¾ç­–ç•¥åç¨±
    strategy = None
    if name.startswith('ssma_turn_'):
        strategy = 'ssma_turn'
        name = name.replace('ssma_turn_', '')
    elif name.startswith('single_'):
        strategy = 'single'
        name = name.replace('single_', '')
    elif name.startswith('dual_'):
        strategy = 'dual'
        name = name.replace('dual_', '')
    elif name.startswith('RMA_'):
        strategy = 'RMA'
        name = name.replace('RMA_', '')
    
    if not strategy:
        return None
    
    # æŸ¥æ‰¾æ•¸æ“šæº
    data_source = None
    if name.startswith('Self_'):
        data_source = 'Self'
    elif name.startswith('Factor_TWII_2412_TW_'):
        data_source = 'Factor (^TWII / 2412.TW)'
    elif name.startswith('Factor_TWII_2414_TW_'):
        data_source = 'Factor (^TWII / 2414.TW)'
    
    if not data_source:
        return None
    
    # æå–æ™‚é–“æˆ³ï¼ˆæ ¼å¼ï¼š20250623_040737ï¼‰
    timestamp = None
    parts = name.split('_')
    for i, part in enumerate(parts):
        if len(part) == 8 and part.isdigit() and i + 1 < len(parts):
            next_part = parts[i + 1]
            if len(next_part) == 6 and next_part.isdigit():
                timestamp = f"{part}_{next_part}"
                break
    
    return {
        'strategy': strategy,
        'data_source': data_source,
        'timestamp': timestamp,
        'filename': filename
    }

# è¼‰å…¥æ‰€æœ‰optunaçµæœæ–‡ä»¶
RESULT_DIR = Path("../results")
optuna_files = list(RESULT_DIR.glob("*.csv"))

# è§£ææ–‡ä»¶åä¸¦é¡¯ç¤º
file_info_list = []
for file_path in optuna_files:
    try:
        info = parse_optuna_filename(file_path.name)
        if info:
            file_info_list.append(info)
    except Exception as e:
        logger.warning(f"ç„¡æ³•è§£ææ–‡ä»¶å {file_path.name}: {e}")



# è¼‰å…¥æ‰€æœ‰optunaçµæœ
all_optuna_results = []
for file_info in file_info_list:
    file_path = RESULT_DIR / file_info['filename']
    if file_path.exists():
        try:
            df = pd.read_csv(file_path)
            df['parameters'] = df['parameters'].apply(ast.literal_eval)
            # æ·»åŠ æ–‡ä»¶ä¿¡æ¯
            df['source_file'] = file_info['filename']
            df['strategy'] = file_info['strategy']
            df['data_source'] = file_info['data_source']
            all_optuna_results.append(df)
        except Exception as e:
            st.sidebar.error(f"è¼‰å…¥å¤±æ•— {file_info['filename']}: {str(e)}")

if not all_optuna_results:
    st.error("æ²’æœ‰æˆåŠŸè¼‰å…¥ä»»ä½•optunaçµæœæ–‡ä»¶")
    st.stop()

# åˆä½µæ‰€æœ‰çµæœ
optuna_results = pd.concat(all_optuna_results, ignore_index=True)

# æŒ‰ç­–ç•¥å’Œæ•¸æ“šæºåˆ†çµ„ï¼Œæ¯å€‹çµ„åˆé¸å–top5
selected_trials = []

# æ–°å¢åƒæ•¸ç›¸é—œæ€§åˆ†æçµæœå­˜å„²
param_correlations = {}

for strategy in optuna_results['strategy'].unique():
    for data_source in optuna_results['data_source'].unique():
        # ç¯©é¸è©²ç­–ç•¥+æ•¸æ“šæºçš„è©¦é©—
        mask = (optuna_results['strategy'] == strategy) & (optuna_results['data_source'] == data_source)
        strategy_trials_raw = optuna_results[mask]
        
        if len(strategy_trials_raw) == 0:
            continue
            
        logger.info(f"è™•ç†ç­–ç•¥ {strategy} + æ•¸æ“šæº {data_source}: {len(strategy_trials_raw)} å€‹è©¦é©—")
        
        # 1. å…ˆé€²è¡Œåƒæ•¸ç›¸é—œæ€§åˆ†æ
        corr_df = compute_param_correlations(optuna_results, strategy, data_source)
        if not corr_df.empty:
            param_correlations[f"{strategy}_{data_source}"] = corr_df
            
            # æ ¹æ“šç›¸é—œæ€§å¼·åº¦é¸æ“‡ä¸»è¦åƒæ•¸ï¼ˆçµ•å°å€¼>0.1çš„åƒæ•¸ï¼‰
            important_params = []
            for param in corr_df.index:
                max_corr = corr_df.loc[param].abs().max()
                if max_corr > 0.1:  # ç›¸é—œæ€§é–¾å€¼
                    important_params.append(param)
            
            # å¦‚æœæ²’æœ‰é‡è¦åƒæ•¸ï¼Œä½¿ç”¨é è¨­åƒæ•¸
            if not important_params:
                if strategy == 'single':
                    important_params = ['linlen', 'smaalen', 'buy_mult']
                elif strategy == 'dual':
                    important_params = ['linlen', 'smaalen', 'short_win', 'long_win']
                elif strategy == 'RMA':
                    important_params = ['linlen', 'smaalen', 'rma_len', 'dev_len']
                elif strategy == 'ssma_turn':
                    important_params = ['linlen', 'smaalen', 'prom_factor', 'buy_mult']
        else:
            # ä½¿ç”¨é è¨­åƒæ•¸
            if strategy == 'single':
                important_params = ['linlen', 'smaalen', 'buy_mult']
            elif strategy == 'dual':
                important_params = ['linlen', 'smaalen', 'short_win', 'long_win']
            elif strategy == 'RMA':
                important_params = ['linlen', 'smaalen', 'rma_len', 'dev_len']
            elif strategy == 'ssma_turn':
                important_params = ['linlen', 'smaalen', 'prom_factor', 'buy_mult']
        
        # å®šç¾©æ€§èƒ½æŒ‡æ¨™ç”¨æ–¼å¤šæ¨£æ€§ç¯©é¸
        metric_keys = [
            'min_wf_return', 'avg_stress_return', 'stability_score', 'robust_score',
            'excess_return_stress', 'stress_mdd', 'pbo_score', 'sra_p_value', 'avg_hold_days'
        ]
        
        logger.info(f"ç­–ç•¥ {strategy} ä½¿ç”¨æ€§èƒ½æŒ‡æ¨™: {metric_keys}")
        
        # 2. è½‰æ›ç‚ºå­—å…¸æ ¼å¼
        trials_dict = []
        for _, trial in strategy_trials_raw.iterrows():
            trial_dict = trial.to_dict()
            trials_dict.append(trial_dict)
        
        # 3. ä½¿ç”¨å¤šæ¨£æ€§éæ¿¾é¸æ“‡top5
        logger.info(f"é–‹å§‹ç‚ºç­–ç•¥ {strategy} + {data_source} é€²è¡Œå¤šæ¨£æ€§ç¯©é¸...")
        diverse_trials = pick_topN_by_diversity(
            trials_dict, 
            metric_keys, 
            top_n=3
        )
        
        logger.info(f"ç­–ç•¥ {strategy} + {data_source} ç¯©é¸å®Œæˆï¼Œé¸å– {len(diverse_trials)} å€‹è©¦é©—")
        
        # 4. æ·»åŠ ç­–ç•¥å’Œæ•¸æ“šæºä¿¡æ¯
        for trial in diverse_trials:
            # ç”Ÿæˆç°¡çŸ­åç¨±ï¼ˆä½¿ç”¨æ›´å®‰å…¨çš„æ–¹å¼ï¼‰
            if '2412' in data_source:
                short_name = f"{strategy}_2412_{trial['trial_number']}"
            elif '2414' in data_source:
                short_name = f"{strategy}_2414_{trial['trial_number']}"
            elif 'Self' in data_source:
                short_name = f"{strategy}_Self_{trial['trial_number']}"
            else:
                # ä½¿ç”¨æ›´å®‰å…¨çš„æ–¹å¼è™•ç†data_source
                clean_source = data_source.replace('(', '').replace(')', '').replace('/', '_').replace('^', '').strip()
                short_name = f"{strategy}_{clean_source}_{trial['trial_number']}"
            
            trial['short_name'] = short_name
            selected_trials.append(trial)
            logger.info(f"æ·»åŠ è©¦é©—: {short_name} (score: {trial['score']:.3f})")

logger.info(f"æ‰€æœ‰ç­–ç•¥ç¯©é¸å®Œæˆï¼Œç¸½å…±é¸å– {len(selected_trials)} å€‹è©¦é©—")

# å»ºç«‹ç­–ç•¥æ¸…å–®
optuna_strategies = [
    {
        'name': trial['short_name'],  # ä½¿ç”¨ç°¡çŸ­åç¨±
        'strategy_type': trial['strategy'],
        'params': trial['parameters'],
        'smaa_source': trial['data_source']
    } for trial in selected_trials
]
preset_strategies = [
    {
        'name': key,
        'strategy_type': value['strategy_type'],
        'params': {k: v for k, v in value.items() if k not in ['strategy_type', 'smaa_source']},
        'smaa_source': value['smaa_source']
    } for key, value in param_presets.items()
]
all_strategies = optuna_strategies + preset_strategies

# å´é‚Šæ¬„åªåšè¨Šæ¯å‘ˆç¾
st.sidebar.header("ğŸ“Š ç³»çµ±ç‹€æ…‹")
st.sidebar.info(f"å·²è¼‰å…¥ {len(selected_trials)} å€‹è©¦é©—")
st.sidebar.info(f"å¯ç”¨ç­–ç•¥: {len(all_strategies)} å€‹")

# ç­–ç•¥çµ±è¨ˆ
strategy_counts = {}
for trial in selected_trials:
    strategy = trial['strategy']
    data_source = trial['data_source']
    key = f"{strategy}_{data_source}"
    strategy_counts[key] = strategy_counts.get(key, 0) + 1

st.sidebar.subheader("ç­–ç•¥åˆ†å¸ƒ:")
for key, count in strategy_counts.items():
    st.sidebar.text(f"â€¢ {key}: {count}")

# è¼‰å…¥ä¿¡æ¯ç§»åˆ°å°èˆªæ¬„
with st.sidebar.expander("ğŸ“Š è¼‰å…¥ä¿¡æ¯", expanded=False):
    st.info(f"æ‰¾åˆ° {len(optuna_files)} å€‹optuna resultsæ–‡ä»¶")
    
    # é¡¯ç¤ºæ‰€æœ‰æ–‡ä»¶ä¿¡æ¯
    st.subheader("å¯ç”¨çš„æ–‡ä»¶:")
    for file_info in file_info_list:
        st.text(f"â€¢ {file_info['strategy']} - {file_info['data_source']} ({file_info['timestamp']})")
    
    # é¡¯ç¤ºåƒæ•¸ç›¸é—œæ€§åˆ†æçµæœ
    if param_correlations:
        st.subheader("ğŸ“ˆ åƒæ•¸ç›¸é—œæ€§åˆ†æ")
        st.write("è¨ˆç®—æ¯å€‹åƒæ•¸å° total_return å’Œ sharpe_ratio çš„çš®çˆ¾æ£®ç›¸é—œä¿‚æ•¸")
        for key, corr_df in param_correlations.items():
            if not corr_df.empty:
                st.write(f"**{key}**")
                # æ ¼å¼åŒ–é¡¯ç¤ºç›¸é—œæ€§çŸ©é™£
                formatted_corr = corr_df.style.format("{:.3f}")
                st.dataframe(formatted_corr, use_container_width=True)
                
                # é¡¯ç¤ºé‡è¦åƒæ•¸
                important_params = []
                for param in corr_df.index:
                    max_corr = corr_df.loc[param].abs().max()
                    if max_corr > 0.1:
                        important_params.append(f"{param} ({max_corr:.3f})")
                
                if important_params:
                    st.write(f"**é‡è¦åƒæ•¸ (|ç›¸é—œæ€§| > 0.1):** {', '.join(important_params)}")
                st.divider()

# ç­–ç•¥çµ±è¨ˆ
strategy_counts = {}
for trial in selected_trials:
    strategy = trial['strategy']
    data_source = trial['data_source']
    key = f"{strategy}_{data_source}"
    strategy_counts[key] = strategy_counts.get(key, 0) + 1

st.sidebar.subheader("ç­–ç•¥åˆ†å¸ƒ:")
for key, count in strategy_counts.items():
    st.sidebar.text(f"â€¢ {key}: {count}")

# è¼‰å…¥ä¿¡æ¯ç§»åˆ°å°èˆªæ¬„
with st.sidebar.expander("ğŸ“Š è¼‰å…¥ä¿¡æ¯", expanded=False):
    st.info(f"æ‰¾åˆ° {len(optuna_files)} å€‹optuna resultsæ–‡ä»¶")
    
    # é¡¯ç¤ºæ‰€æœ‰æ–‡ä»¶ä¿¡æ¯
    st.subheader("å¯ç”¨çš„æ–‡ä»¶:")
    for file_info in file_info_list:
        st.text(f"â€¢ {file_info['strategy']} - {file_info['data_source']} ({file_info['timestamp']})")



# èµ°æŸ¥è¨­å®šç§»åˆ°ä¸»é é¢
col1, col2 = st.columns(2)
with col1:
    walk_forward_mode = st.selectbox("èµ°æŸ¥æ¨¡å¼", ["å‹•æ…‹å¹³åˆ†å€é–“", "å›ºå®š WF_PERIODS"])
with col2:
    if walk_forward_mode == "å‹•æ…‹å¹³åˆ†å€é–“":
        n_splits = st.number_input("åˆ†æ®µæ•¸", min_value=1, max_value=10, value=6, step=1)

# ç­–ç•¥é¸æ“‡ - æ“´å¤§é¸æ“‡å€å¡Š

selected_strategies = st.multiselect(
    "é¸æ“‡è¦åˆ†æçš„ç­–ç•¥", 
    options=[s['name'] for s in all_strategies], 
    default=[s['name'] for s in all_strategies],  # é è¨­å…¨é¸
    key="main_strategy_selector"
)

# å¿«é€Ÿé¸æ“‡æŒ‰éˆ•
col1, col2, col3 = st.columns(3)
with col1:
    if st.button("å…¨é¸"):
        st.session_state.main_strategies = [s['name'] for s in all_strategies]
        st.rerun()
with col2:
    if st.button("æ¸…é™¤"):
        st.session_state.main_strategies = []
        st.rerun()
with col3:
    if st.button("é¸æ“‡Optunaç­–ç•¥"):
        optuna_names = [s['name'] for s in optuna_strategies]
        st.session_state.main_strategies = optuna_names
        st.rerun()

if not selected_strategies:
    st.warning("è«‹è‡³å°‘é¸æ“‡ä¸€å€‹ç­–ç•¥é€²è¡Œåˆ†æ")
    st.stop()

st.info(f"å·²é¸æ“‡ {len(selected_strategies)} å€‹ç­–ç•¥é€²è¡Œåˆ†æ")

# ç›¸é—œæ€§çŸ©é™£è¨­å®šç§»åˆ°ä¸»é é¢
corr_range = st.slider("ç›¸é—œæ€§å€¼ç¯„åœ", min_value=-1.0, max_value=1.0, value=(0.8, 1.0), step=0.1, help="è¨­å®šç›¸é—œæ€§çŸ©é™£ç†±åœ–çš„é¡è‰²ç¯„åœ")

# åŸ·è¡Œå›æ¸¬æŒ‰éˆ•
if st.button("ğŸš€ åŸ·è¡Œå›æ¸¬èˆ‡åˆ†æ", type="primary"):
    # éæ¿¾é¸ä¸­çš„ç­–ç•¥
    strategies_to_run = [s for s in all_strategies if s['name'] in selected_strategies]

    with st.spinner("æ­£åœ¨åŸ·è¡Œå›æ¸¬..."):
        # è¼‰å…¥æ•¸æ“š
        smaa_sources = set(strategy['smaa_source'] for strategy in strategies_to_run)
        df_price_dict = {}
        df_factor_dict = {}
        all_indices = []
        
        # å°‡æ•¸æ“šè¼‰å…¥è¨Šæ¯æ”¶é›†åˆ°expanderä¸­
        with st.expander("ğŸ“Š è¼‰å…¥ä¿¡æ¯", expanded=False):
            st.subheader("æ•¸æ“šè¼‰å…¥ç‹€æ…‹:")
            for source in smaa_sources:
                df_price, df_factor = load_data(ticker="00631L.TW", smaa_source=source)
                if not df_price.empty:
                    all_indices.append(df_price.index)
                df_price_dict[source] = df_price
                df_factor_dict[source] = df_factor
                st.text(f"â€¢ {source}: å·²è¼‰å…¥ {len(df_price)} ç­†æ•¸æ“š")

        # åˆä½µæ‰€æœ‰æ™‚é–“è»¸ï¼Œå‰µå»ºä¸€å€‹å…¨åŸŸæ™‚é–“è»¸
        if all_indices:
            global_index = pd.Index([])
            for index in all_indices:
                global_index = global_index.union(index)
        else:
            global_index = pd.Index([])

        # åŸ·è¡Œå›æ¸¬
        results = {}
        initial_equity = 100000.0
        for strategy in strategies_to_run:
            name = strategy['name']
            strategy_type = strategy['strategy_type']
            params = strategy['params']
            smaa_source = strategy['smaa_source']
            df_price = df_price_dict[smaa_source]
            df_factor = df_factor_dict[smaa_source]
            
            logger.info(f"è™•ç†ç­–ç•¥ {name}ï¼Œåƒæ•¸: {params}")
            
            if strategy_type == 'single':
                df_ind = compute_single(df_price, df_factor, params['linlen'], params['factor'], params['smaalen'], params['devwin'], smaa_source=smaa_source)
                logger.info(f"ç­–ç•¥ {name} çš„ df_ind å½¢ç‹€: {df_ind.shape}, æ¬„ä½: {df_ind.columns.tolist()}")
            elif strategy_type == 'dual':
                df_ind = compute_dual(df_price, df_factor, params['linlen'], params['factor'], params['smaalen'], params['short_win'], params['long_win'], smaa_source=smaa_source)
                logger.info(f"ç­–ç•¥ {name} çš„ df_ind å½¢ç‹€: {df_ind.shape}, æ¬„ä½: {df_ind.columns.tolist()}")
            elif strategy_type == 'RMA':
                df_ind = compute_RMA(df_price, df_factor, params['linlen'], params['factor'], params['smaalen'], params['rma_len'], params['dev_len'], smaa_source=smaa_source)
                logger.info(f"ç­–ç•¥ {name} çš„ df_ind å½¢ç‹€: {df_ind.shape}, æ¬„ä½: {df_ind.columns.tolist()}")
            elif strategy_type == 'ssma_turn':
                calc_keys = ['linlen', 'factor', 'smaalen', 'prom_factor', 'min_dist', 'buy_shift', 'exit_shift', 'vol_window', 'quantile_win', 'signal_cooldown_days']
                ssma_params = {k: v for k, v in params.items() if k in calc_keys}
                backtest_params = ssma_params.copy()
                backtest_params['buy_mult'] = params.get('buy_mult', 0.5)
                backtest_params['sell_mult'] = params.get('sell_mult', 0.5)
                backtest_params['stop_loss'] = params.get('stop_loss', 0.0)
                logger.info(f"SSMA_Turn åƒæ•¸: {ssma_params}")
                df_ind, buy_dates, sell_dates = compute_ssma_turn_combined(df_price, df_factor, **ssma_params, smaa_source=smaa_source)
                logger.info(f"ç­–ç•¥ {name} ç”Ÿæˆçš„è²·å…¥ä¿¡è™Ÿæ•¸: {len(buy_dates)}, è³£å‡ºä¿¡è™Ÿæ•¸: {len(sell_dates)}")
                logger.info(f"è²·å…¥ä¿¡è™Ÿ: {buy_dates[:5] if buy_dates else 'ç„¡'}")
                logger.info(f"è³£å‡ºä¿¡è™Ÿ: {sell_dates[:5] if sell_dates else 'ç„¡'}")
                if df_ind.empty:
                    logger.error(f"ç­–ç•¥ {name} çš„ df_ind ç‚ºç©ºï¼Œè·³éå›æ¸¬")
                    st.error(f"ç­–ç•¥ {name} çš„ df_ind ç‚ºç©ºï¼Œè·³éå›æ¸¬")
                    continue
                # ä½¿ç”¨èˆ‡SSSv096ä¸€è‡´çš„é è¨­åƒæ•¸è¨­å®š
                result = backtest_unified(df_ind, strategy_type, params, buy_dates, sell_dates, 
                                         discount=0.30, trade_cooldown_bars=3, bad_holding=False)
                results[name] = result
                continue
            
            required_cols = ['open', 'close', 'smaa', 'base', 'sd']
            if df_ind.empty or not all(col in df_ind.columns for col in required_cols):
                logger.error(f"ç­–ç•¥ {name} çš„ df_ind ç¼ºå°‘å¿…è¦æ¬„ä½: {set(required_cols) - set(df_ind.columns)}ï¼Œè·³éå›æ¸¬")
                st.error(f"ç­–ç•¥ {name} çš„ df_ind ç¼ºå°‘å¿…è¦æ¬„ä½: {set(required_cols) - set(df_ind.columns)}ï¼Œè·³éå›æ¸¬")
                continue
            
            # å°æ–¼ single å’Œ RMAï¼Œç›®å‰çš„å›æ¸¬åƒæ•¸æ˜¯å›ºå®šçš„
            # æ³¨æ„ï¼šå¦‚æœé€™äº›ç­–ç•¥ä¹Ÿéœ€è¦ä¸åŒçš„ discount æˆ– cooldownï¼Œé€™è£¡éœ€è¦ä¿®æ”¹
            if df_ind.empty:
                logger.error(f"ç­–ç•¥ {name} çš„ df_ind ç‚ºç©ºï¼Œè·³éè¨ˆç®—")
                continue
            
            result = backtest_unified(df_ind, strategy_type, params, discount=0.30, trade_cooldown_bars=3, bad_holding=False)
            results[name] = result

        # æå–æ¬Šç›Šæ›²ç·š
        equity_curves = pd.DataFrame({name: result['equity_curve'].reindex(global_index, fill_value=initial_equity) for name, result in results.items()})
        
        # è¨ˆç®—ä¸¦å„²å­˜æŒ‡æ¨™
        for name, result in results.items():
            if 'equity_curve' in result and not result['equity_curve'].empty:
                # è¨ˆç®—åŸºæœ¬æŒ‡æ¨™
                equity_curve = result['equity_curve']
                total_return = (equity_curve.iloc[-1] / equity_curve.iloc[0] - 1)
                annual_return = total_return * (252 / len(equity_curve))
                daily_returns = equity_curve.pct_change().dropna()
                volatility = daily_returns.std() * np.sqrt(252)
                sharpe_ratio = annual_return / volatility if volatility > 0 else 0
                max_drawdown = calculate_max_drawdown(equity_curve)
                calmar_ratio = annual_return / max_drawdown if max_drawdown > 0 else 0
                
                # è¨ˆç®—é¢¨éšªèª¿æ•´æŒ‡æ¨™
                risk_adjusted_metrics = calculate_risk_adjusted_metrics(equity_curve, name)
                
                # ä¿®æ­£å‹ç‡è¨ˆç®— - ç§»åˆ°metricså­—å…¸å‰µå»ºä¹‹å‰
                trades_df = result.get('trades_df', pd.DataFrame())
                logger.info(f"ç­–ç•¥ {name} çš„ trades_df å½¢ç‹€: {trades_df.shape}")
                logger.info(f"ç­–ç•¥ {name} çš„ trades_df æ¬„ä½: {list(trades_df.columns)}")

                # æ·»åŠ æ›´è©³ç´°çš„èª¿è©¦ä¿¡æ¯
                if not trades_df.empty:
                    logger.info(f"ç­–ç•¥ {name} çš„ trades_df å‰5è¡Œ:")
                    logger.info(trades_df.head())
                    logger.info(f"ç­–ç•¥ {name} çš„ trades_df æ•¸æ“šé¡å‹:")
                    logger.info(trades_df.dtypes)
                    if 'ret' in trades_df.columns:
                        logger.info(f"ç­–ç•¥ {name} çš„ 'ret' æ¬„ä½çµ±è¨ˆ:")
                        logger.info(f"  éç©ºå€¼æ•¸é‡: {trades_df['ret'].notna().sum()}")
                        logger.info(f"  ç©ºå€¼æ•¸é‡: {trades_df['ret'].isna().sum()}")
                        logger.info(f"  å”¯ä¸€å€¼: {trades_df['ret'].unique()}")
                        logger.info(f"  å¤§æ–¼0çš„æ•¸é‡: {(trades_df['ret'] > 0).sum()}")
                        logger.info(f"  ç­‰æ–¼0çš„æ•¸é‡: {(trades_df['ret'] == 0).sum()}")
                        logger.info(f"  å°æ–¼0çš„æ•¸é‡: {(trades_df['ret'] < 0).sum()}")

                # è¨ˆç®—å‹ç‡
                win_rate = 0
                if not trades_df.empty and 'ret' in trades_df.columns:
                    winning_trades = trades_df[trades_df['ret'] > 0]
                    total_trades = len(trades_df)
                    winning_count = len(winning_trades)
                    win_rate = winning_count / total_trades if total_trades > 0 else 0
                    logger.info(f"ç­–ç•¥ {name} å‹ç‡è¨ˆç®—: ç¸½äº¤æ˜“æ•¸={total_trades}, ç²åˆ©äº¤æ˜“æ•¸={winning_count}, å‹ç‡={win_rate:.2%}")
                    
                    # æ·»åŠ è©³ç´°çš„äº¤æ˜“è¨˜éŒ„æ—¥èªŒ
                    if total_trades > 0:
                        logger.info(f"ç­–ç•¥ {name} äº¤æ˜“å ±é…¬ç‡çµ±è¨ˆ:")
                        logger.info(f"  æœ€å°å ±é…¬ç‡: {trades_df['ret'].min():.4f}")
                        logger.info(f"  æœ€å¤§å ±é…¬ç‡: {trades_df['ret'].max():.4f}")
                        logger.info(f"  å¹³å‡å ±é…¬ç‡: {trades_df['ret'].mean():.4f}")
                        logger.info(f"  æ­£å ±é…¬äº¤æ˜“: {winning_count} ç­†")
                        logger.info(f"  è² å ±é…¬äº¤æ˜“: {total_trades - winning_count} ç­†")
                else:
                    logger.warning(f"ç­–ç•¥ {name} çš„ trades_df ç‚ºç©ºæˆ–ç¼ºå°‘ 'ret' æ¬„ä½")
                    if not trades_df.empty:
                        logger.warning(f"ç­–ç•¥ {name} çš„ trades_df å¯¦éš›æ¬„ä½: {list(trades_df.columns)}")

                # åˆä½µæ‰€æœ‰æŒ‡æ¨™
                result['metrics'] = {
                    'total_return': total_return,
                    'annual_return': annual_return,
                    'volatility': volatility,
                    'sharpe_ratio': sharpe_ratio,
                    'calmar_ratio': calmar_ratio,
                    'max_drawdown': max_drawdown,
                    'num_trades': len(result.get('trades_df', pd.DataFrame())),
                    'win_rate': win_rate,  # ä½¿ç”¨è¨ˆç®—å‡ºçš„å‹ç‡
                    **risk_adjusted_metrics  # æ·»åŠ é¢¨éšªèª¿æ•´æŒ‡æ¨™
                }
                
                # ä¿®æ­£å‹ç‡è¨ˆç®—
                trades_df = result.get('trades_df', pd.DataFrame())
                logger.info(f"ç­–ç•¥ {name} çš„ trades_df å½¢ç‹€: {trades_df.shape}")
                logger.info(f"ç­–ç•¥ {name} çš„ trades_df æ¬„ä½: {list(trades_df.columns)}")

                if not trades_df.empty and 'ret' in trades_df.columns:
                    winning_trades = trades_df[trades_df['ret'] > 0]
                    total_trades = len(trades_df)
                    winning_count = len(winning_trades)
                    win_rate = winning_count / total_trades if total_trades > 0 else 0
                    result['metrics']['win_rate'] = win_rate
                    logger.info(f"ç­–ç•¥ {name} å‹ç‡è¨ˆç®—: ç¸½äº¤æ˜“æ•¸={total_trades}, ç²åˆ©äº¤æ˜“æ•¸={winning_count}, å‹ç‡={win_rate:.2%}")
                    
                    # æ·»åŠ è©³ç´°çš„äº¤æ˜“è¨˜éŒ„æ—¥èªŒ
                    if total_trades > 0:
                        logger.info(f"ç­–ç•¥ {name} äº¤æ˜“å ±é…¬ç‡çµ±è¨ˆ:")
                        logger.info(f"  æœ€å°å ±é…¬ç‡: {trades_df['ret'].min():.4f}")
                        logger.info(f"  æœ€å¤§å ±é…¬ç‡: {trades_df['ret'].max():.4f}")
                        logger.info(f"  å¹³å‡å ±é…¬ç‡: {trades_df['ret'].mean():.4f}")
                        logger.info(f"  æ­£å ±é…¬äº¤æ˜“: {winning_count} ç­†")
                        logger.info(f"  è² å ±é…¬äº¤æ˜“: {total_trades - winning_count} ç­†")
                else:
                    result['metrics']['win_rate'] = 0
                    logger.warning(f"ç­–ç•¥ {name} çš„ trades_df ç‚ºç©ºæˆ–ç¼ºå°‘ 'ret' æ¬„ä½")
                
                # ä¿®æ­£å¡ç‘ªæ¯”ç‡è¨ˆç®—
                if result['metrics']['max_drawdown'] != 0:
                    result['metrics']['calmar_ratio'] = result['metrics']['annual_return'] / abs(result['metrics']['max_drawdown'])
                else:
                    result['metrics']['calmar_ratio'] = 0
        
        if equity_curves.empty:
            logger.error("æœªç”Ÿæˆä»»ä½•æ¬Šç›Šæ›²ç·šï¼Œè«‹æª¢æŸ¥å›æ¸¬é‚è¼¯æˆ–æ•¸æ“š")
            st.error("æœªç”Ÿæˆä»»ä½•æ¬Šç›Šæ›²ç·šï¼Œè«‹æª¢æŸ¥å›æ¸¬é‚è¼¯æˆ–æ•¸æ“š")
        else:
            logger.info(f"æ¬Šç›Šæ›²ç·šå½¢ç‹€: {equity_curves.shape}")
            logger.info(equity_curves.head())

            # ä½¿ç”¨æ¨™ç±¤é å‘ˆç¾çµæœ
            tabs = st.tabs(["ç›¸é—œæ€§çŸ©é™£ç†±åœ–", "å ±é…¬ç‡ç›¸é—œ", "æœ€å¤§å›æ’¤ç›¸é—œ", "ç¸½çµ", "éæ“¬åˆæª¢æ¸¬"])

            # æ¨™ç±¤é  1: ç›¸é—œæ€§çŸ©é™£ç†±åœ–
            with tabs[0]:

                
                # ç›´æ¥ä½¿ç”¨å·²è¨ˆç®—çš„çµæœ
                if equity_curves.empty:
                    st.warning("æ²’æœ‰æ¬Šç›Šæ›²ç·šæ•¸æ“š")
                else:
                    # è¨ˆç®—ç›¸é—œæ€§çŸ©é™£
                    corr_matrix = equity_curves.corr()
                    corr_matrix.to_csv(RESULT_DIR / 'correlation_matrix.csv')
                    
                    # ä½¿ç”¨ä¸»é é¢è¨­å®šçš„ç›¸é—œæ€§ç¯„åœ
                    zmin, zmax = corr_range
                    
                    fig = px.imshow(
                        corr_matrix,
                        color_continuous_scale='RdBu_r',
                        zmin=zmin,
                        zmax=zmax,
                        text_auto=True,
                        title="ç­–ç•¥ç›¸é—œæ€§çŸ©é™£"
                    )
                    fig.update_layout(
                        width=2200,
                        height=1500,
                        xaxis_title="ç­–ç•¥",
                        yaxis_title="ç­–ç•¥",
                        coloraxis_colorbar_title="ç›¸é—œæ€§"
                    )
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # æ·»åŠ ç›¸é—œæ€§çµ±è¨ˆä¿¡æ¯
                    st.subheader("ç›¸é—œæ€§çµ±è¨ˆ")
                    # ä½¿ç”¨numpyçš„triu_indicesä¾†ç²å–ä¸Šä¸‰è§’çŸ©é™£çš„å€¼
                    if corr_matrix is not None:
                        upper_triangle = corr_matrix.values[np.triu_indices_from(corr_matrix.values, k=1)]
                        corr_stats = {
                            'å¹³å‡ç›¸é—œæ€§': upper_triangle.mean(),
                            'æœ€å¤§ç›¸é—œæ€§': upper_triangle.max(),
                            'æœ€å°ç›¸é—œæ€§': upper_triangle.min(),
                            'ç›¸é—œæ€§æ¨™æº–å·®': upper_triangle.std()
                        }
                        
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("å¹³å‡ç›¸é—œæ€§", f"{corr_stats['å¹³å‡ç›¸é—œæ€§']:.3f}")
                        with col2:
                            st.metric("æœ€å¤§ç›¸é—œæ€§", f"{corr_stats['æœ€å¤§ç›¸é—œæ€§']:.3f}")
                        with col3:
                            st.metric("æœ€å°ç›¸é—œæ€§", f"{corr_stats['æœ€å°ç›¸é—œæ€§']:.3f}")
                        with col4:
                            st.metric("ç›¸é—œæ€§æ¨™æº–å·®", f"{corr_stats['ç›¸é—œæ€§æ¨™æº–å·®']:.3f}")

            # æ¨™ç±¤é  2: å ±é…¬ç‡ç›¸é—œ
            with tabs[1]:
                st.subheader("èµ°æŸ¥æ™‚æ®µå ±é…¬ç‡åˆ†æ•¸ (%)")
                period_returns = {}
                period_mdd = {}
                period_pr = {}
                period_mdd_pr = {}
                period_hedge_counts = {}
                periods = WF_PERIODS if walk_forward_mode == "å›ºå®š WF_PERIODS" else generate_walk_forward_periods(equity_curves.index, n_splits)

                for i, period in enumerate([(p['test'] if isinstance(p, dict) else p) for p in periods]):
                    start = pd.to_datetime(period[0])
                    end = pd.to_datetime(period[1])
                    valid_dates = pd.to_datetime(equity_curves.index)
                    if start < valid_dates[0]:
                        adjusted_start = valid_dates[0]
                        logger.warning(f"èµ·å§‹æ—¥æœŸ {start.strftime('%Y-%m-%d')} æ—©æ–¼æ•¸æ“šé–‹å§‹ï¼Œèª¿æ•´ç‚º {adjusted_start.strftime('%Y-%m-%d')}")
                    else:
                        adjusted_start = valid_dates[valid_dates >= start][0]
                    if end > valid_dates[-1]:
                        adjusted_end = valid_dates[-1]
                        logger.warning(f"çµæŸæ—¥æœŸ {end.strftime('%Y-%m-%d')} æ™šæ–¼æ•¸æ“šçµæŸï¼Œèª¿æ•´ç‚º {adjusted_end.strftime('%Y-%m-%d')}")
                    else:
                        adjusted_end = valid_dates[valid_dates <= end][-1]
                    if (adjusted_end - adjusted_start).days < 30:
                        logger.warning(f"èµ°æŸ¥å€é–“ {adjusted_start.strftime('%Y-%m-%d')} è‡³ {adjusted_end.strftime('%Y-%m-%d')} éçŸ­ï¼Œè·³é")
                        continue
                    period_equity = equity_curves.loc[adjusted_start:adjusted_end]
                    for col in period_equity.columns:
                        if pd.isna(period_equity[col].iloc[0]):
                            period_equity[col].iloc[0] = initial_equity
                    # è¨ˆç®—å ±é…¬ç‡å’Œ MDD
                    period_return = (period_equity.iloc[-1] / period_equity.iloc[0] - 1) * 100
                    period_mdd_value = period_equity.apply(calculate_max_drawdown) * 100
                    # è¨ˆç®—é¿éšªæ©ç¢¼
                    hedge_mask = (period_return == 0) & (period_mdd_value == 0)
                    # è¨˜éŒ„é¿éšªæ¬¡æ•¸
                    if i > 0:  # éåˆå§‹æ™‚æ®µ
                        period_hedge_counts[(adjusted_start.strftime('%Y-%m-%d'), adjusted_end.strftime('%Y-%m-%d'))] = hedge_mask.astype(int)
                    else:  # åˆå§‹æ™‚æ®µ
                        period_hedge_counts[(adjusted_start.strftime('%Y-%m-%d'), adjusted_end.strftime('%Y-%m-%d'))] = pd.Series(0, index=hedge_mask.index)
                    # è¨ˆç®—å ±é…¬ç‡ PR å€¼
                    pr_values_ret = calculate_pr_values(period_return, is_mdd=False, is_initial_period=(i == 0), hedge_mask=hedge_mask)
                    period_pr[(adjusted_start.strftime('%Y-%m-%d'), adjusted_end.strftime('%Y-%m-%d'))] = pr_values_ret
                    # å„²å­˜å ±é…¬ç‡
                    period_returns[(adjusted_start.strftime('%Y-%m-%d'), adjusted_end.strftime('%Y-%m-%d'))] = period_return

                period_returns_df = pd.DataFrame(period_returns).T
                period_returns_df.to_csv(RESULT_DIR / 'period_returns.csv')
                st.dataframe(period_returns_df.style.format("{:.2f}%"))
                period_pr_df = pd.DataFrame(period_pr).T
                period_pr_df.to_csv(RESULT_DIR / 'period_pr.csv')
                st.subheader("èµ°æŸ¥æ™‚æ®µå ±é…¬ç‡åˆ†æ•¸ (%)")
                st.dataframe(period_pr_df.style.format("{:.2f}"))
                period_hedge_counts_df = pd.DataFrame(period_hedge_counts).T
                period_hedge_counts_df.to_csv(RESULT_DIR / 'period_hedge_counts.csv')
                st.subheader("èµ°æŸ¥æ™‚æ®µé¿éšªæ¬¡æ•¸")
                st.dataframe(period_hedge_counts_df)
                stress_returns = {}
                stress_pr = {}
                stress_hedge_counts = {}
                for i, (start, end) in enumerate(STRESS_PERIODS):
                    start = pd.to_datetime(start)
                    end = pd.to_datetime(end)
                    if start in equity_curves.index and end in equity_curves.index:
                        period_equity = equity_curves.loc[start:end]
                        for col in period_equity.columns:
                            if pd.isna(period_equity[col].iloc[0]):
                                period_equity[col].iloc[0] = initial_equity
                        # è¨ˆç®—å ±é…¬ç‡å’Œ MDD
                        period_return = (period_equity.iloc[-1] / period_equity.iloc[0] - 1) * 100
                        period_mdd_value = period_equity.apply(calculate_max_drawdown) * 100
                        # è¨ˆç®—é¿éšªæ©ç¢¼
                        hedge_mask = (period_return == 0) & (period_mdd_value == 0)
                        # è¨˜éŒ„é¿éšªæ¬¡æ•¸ï¼ˆå£“åŠ›æ™‚æ®µç¬¬ä¸€å€‹ç‚ºåˆå§‹æ™‚æ®µï¼‰
                        if i > 0:  # éåˆå§‹æ™‚æ®µ
                            stress_hedge_counts[(start.strftime('%Y-%m-%d'), end.strftime('%Y-%m-%d'))] = hedge_mask.astype(int)
                        else:  # åˆå§‹æ™‚æ®µ
                            stress_hedge_counts[(start.strftime('%Y-%m-%d'), end.strftime('%Y-%m-%d'))] = pd.Series(0, index=hedge_mask.index)
                        # è¨ˆç®—å ±é…¬ç‡ PR å€¼
                        pr_values_ret = calculate_pr_values(period_return, is_mdd=False, is_initial_period=(i == 0), hedge_mask=hedge_mask)
                        stress_pr[(start.strftime('%Y-%m-%d'), end.strftime('%Y-%m-%d'))] = pr_values_ret
                        # å„²å­˜å ±é…¬ç‡
                        stress_returns[(start.strftime('%Y-%m-%d'), end.strftime('%Y-%m-%d'))] = period_return

                stress_returns_df = pd.DataFrame(stress_returns).T
                stress_returns_df.to_csv(RESULT_DIR / 'stress_returns.csv')
                st.subheader("å£“åŠ›æ™‚æ®µå ±é…¬ç‡ (%)")
                st.dataframe(stress_returns_df.style.format("{:.2f}%"))
                stress_pr_df = pd.DataFrame(stress_pr).T
                stress_pr_df.to_csv(RESULT_DIR / 'stress_pr.csv')
                st.subheader("å£“åŠ›æ™‚æ®µå ±é…¬ç‡åˆ†æ•¸ (%)")
                st.dataframe(stress_pr_df.style.format("{:.2f}"))
                stress_hedge_counts_df = pd.DataFrame(stress_hedge_counts).T
                stress_hedge_counts_df.to_csv(RESULT_DIR / 'stress_hedge_counts.csv')
                st.subheader("å£“åŠ›æ™‚æ®µé¿éšªæ¬¡æ•¸")
                st.dataframe(stress_hedge_counts_df)

            # æ¨™ç±¤é  3: æœ€å¤§å›æ’¤ç›¸é—œ
            with tabs[2]:
                st.subheader("èµ°æŸ¥æ™‚æ®µæœ€å¤§å›æ’¤åˆ†æ•¸ (%)")
                period_mdd = {}
                period_mdd_pr = {}
                period_mdd_hedge_counts = {}
                periods = WF_PERIODS if walk_forward_mode == "å›ºå®š WF_PERIODS" else generate_walk_forward_periods(equity_curves.index, n_splits)
                for i, period in enumerate([(p['test'] if isinstance(p, dict) else p) for p in periods]):
                    start = pd.to_datetime(period[0])
                    end = pd.to_datetime(period[1])
                    valid_dates = pd.to_datetime(equity_curves.index)
                    if start < valid_dates[0]:
                        adjusted_start = valid_dates[0]
                    else:
                        adjusted_start = valid_dates[valid_dates >= start][0]
                    if end > valid_dates[-1]:
                        adjusted_end = valid_dates[-1]
                    else:
                        adjusted_end = valid_dates[valid_dates <= end][-1]
                    if (adjusted_end - adjusted_start).days < 30:
                        continue
                    period_equity = equity_curves.loc[adjusted_start:adjusted_end]
                    for col in period_equity.columns:
                        if pd.isna(period_equity[col].iloc[0]):
                            period_equity[col].iloc[0] = initial_equity
                    # è¨ˆç®—å ±é…¬ç‡ï¼ˆç”¨æ–¼é¿éšªæ©ç¢¼ï¼‰
                    period_return = (period_equity.iloc[-1] / period_equity.iloc[0] - 1) * 100
                    # è¨ˆç®— MDD
                    period_mdd_value = period_equity.apply(calculate_max_drawdown) * 100
                    # è¨ˆç®—é¿éšªæ©ç¢¼
                    hedge_mask = (period_return == 0) & (period_mdd_value == 0)
                    # è¨˜éŒ„é¿éšªæ¬¡æ•¸
                    if i > 0:  # éåˆå§‹æ™‚æ®µ
                        period_mdd_hedge_counts[(adjusted_start.strftime('%Y-%m-%d'), adjusted_end.strftime('%Y-%m-%d'))] = hedge_mask.astype(int)
                    else:  # åˆå§‹æ™‚æ®µ
                        period_mdd_hedge_counts[(adjusted_start.strftime('%Y-%m-%d'), adjusted_end.strftime('%Y-%m-%d'))] = pd.Series(0, index=hedge_mask.index)
                    # è¨ˆç®— MDD åˆ†æ•¸
                    pr_values_mdd = calculate_pr_values(period_mdd_value, is_mdd=True, is_initial_period=(i == 0), hedge_mask=hedge_mask)
                    period_mdd_pr[(adjusted_start.strftime('%Y-%m-%d'), adjusted_end.strftime('%Y-%m-%d'))] = pr_values_mdd
                    # å„²å­˜ MDD
                    period_mdd[(adjusted_start.strftime('%Y-%m-%d'), adjusted_end.strftime('%Y-%m-%d'))] = period_mdd_value

                period_mdd_df = pd.DataFrame(period_mdd).T
                period_mdd_df.to_csv(RESULT_DIR / 'period_mdd.csv')
                st.dataframe(period_mdd_df.style.format("{:.2f}%"))
                period_mdd_pr_df = pd.DataFrame(period_mdd_pr).T
                period_mdd_pr_df.to_csv(RESULT_DIR / 'period_mdd_pr.csv')
                st.subheader("èµ°æŸ¥æ™‚æ®µæœ€å¤§å›æ’¤åˆ†æ•¸ (%)")
                st.dataframe(period_mdd_pr_df.style.format("{:.2f}"))
                period_mdd_hedge_counts_df = pd.DataFrame(period_mdd_hedge_counts).T
                period_mdd_hedge_counts_df.to_csv(RESULT_DIR / 'period_mdd_hedge_counts.csv')
                st.subheader("èµ°æŸ¥æ™‚æ®µæœ€å¤§å›æ’¤é¿éšªæ¬¡æ•¸")
                st.dataframe(period_mdd_hedge_counts_df)


                stress_mdd = {}
                stress_mdd_pr = {}
                stress_mdd_hedge_counts = {}
                for i, (start, end) in enumerate(STRESS_PERIODS):
                    start = pd.to_datetime(start)
                    end = pd.to_datetime(end)
                    if start in equity_curves.index and end in equity_curves.index:
                        period_equity = equity_curves.loc[start:end]
                        for col in period_equity.columns:
                            if pd.isna(period_equity[col].iloc[0]):
                                period_equity[col].iloc[0] = initial_equity
                        # è¨ˆç®—å ±é…¬ç‡å’Œ MDD
                        period_return = (period_equity.iloc[-1] / period_equity.iloc[0] - 1) * 100
                        period_mdd_value = period_equity.apply(calculate_max_drawdown) * 100
                        # è¨ˆç®—é¿éšªæ©ç¢¼
                        hedge_mask = (period_return == 0) & (period_mdd_value == 0)
                        # è¨˜éŒ„é¿éšªæ¬¡æ•¸
                        if i > 0:  # éåˆå§‹æ™‚æ®µ
                            stress_mdd_hedge_counts[(start.strftime('%Y-%m-%d'), end.strftime('%Y-%m-%d'))] = hedge_mask.astype(int)
                        else:  # åˆå§‹æ™‚æ®µ
                            stress_mdd_hedge_counts[(start.strftime('%Y-%m-%d'), end.strftime('%Y-%m-%d'))] = pd.Series(0, index=hedge_mask.index)
                        # è¨ˆç®— MDD åˆ†æ•¸
                        pr_values_mdd = calculate_pr_values(period_mdd_value, is_mdd=True, is_initial_period=(i == 0), hedge_mask=hedge_mask)
                        stress_mdd_pr[(start.strftime('%Y-%m-%d'), end.strftime('%Y-%m-%d'))] = pr_values_mdd
                        # å„²å­˜ MDD
                        stress_mdd[(start.strftime('%Y-%m-%d'), end.strftime('%Y-%m-%d'))] = period_mdd_value

                stress_mdd_df = pd.DataFrame(stress_mdd).T
                stress_mdd_df.to_csv(RESULT_DIR / 'stress_mdd.csv')
                st.subheader("å£“åŠ›æ™‚æ®µæœ€å¤§å›æ’¤ (%)")
                st.dataframe(stress_mdd_df.style.format("{:.2f}%"))
                stress_mdd_pr_df = pd.DataFrame(stress_mdd_pr).T
                stress_mdd_pr_df.to_csv(RESULT_DIR / 'stress_mdd_pr.csv')
                st.subheader("å£“åŠ›æ™‚æ®µæœ€å¤§å›æ’¤åˆ†æ•¸ (%)")
                st.dataframe(stress_mdd_pr_df.style.format("{:.2f}"))
                stress_mdd_hedge_counts_df = pd.DataFrame(stress_mdd_hedge_counts).T
                stress_mdd_hedge_counts_df.to_csv(RESULT_DIR / 'stress_mdd_hedge_counts.csv')
                st.subheader("å£“åŠ›æ™‚æ®µæœ€å¤§å›æ’¤é¿éšªæ¬¡æ•¸")
                st.dataframe(stress_mdd_hedge_counts_df)

                mdd = {}
                for name, equity in equity_curves.items():
                    mdd[name] = calculate_max_drawdown(equity) * 100
                mdd_df = pd.Series(mdd)
                mdd_df.to_csv(RESULT_DIR / 'mdd.csv')
                st.subheader("æ•´é«”æœ€å¤§å›æ’¤ (%)")
                st.dataframe(mdd_df.to_frame().style.format("{:.2f}%"))

            # æ¨™ç±¤é  4: ç¸½çµ
            with tabs[3]:
                st.subheader("å„ç­–ç•¥å¹³å‡åˆ†æ•¸èˆ‡é¿éšªæ¬¡æ•¸")
                # ç¢ºä¿æ‰€æœ‰è®Šæ•¸éƒ½æ˜¯DataFrameæˆ–Series
                concat_list = []
                if not period_pr_df.empty:
                    concat_list.append(period_pr_df.mean())
                if not stress_pr_df.empty:
                    concat_list.append(stress_pr_df.mean())
                if not period_mdd_pr_df.empty:
                    concat_list.append(period_mdd_pr_df.mean())
                if not stress_mdd_pr_df.empty:
                    concat_list.append(stress_mdd_pr_df.mean())
                
                if concat_list:
                    avg_pr = pd.concat(concat_list, axis=1)
                    # å‹•æ…‹è³¦å€¼åˆ—å
                    column_names = []
                    if not period_pr_df.empty:
                        column_names.append('èµ°æŸ¥å ±é…¬ç‡åˆ†æ•¸')
                    if not stress_pr_df.empty:
                        column_names.append('å£“åŠ›å ±é…¬ç‡åˆ†æ•¸')
                    if not period_mdd_pr_df.empty:
                        column_names.append('èµ°æŸ¥MDDåˆ†æ•¸')
                    if not stress_mdd_pr_df.empty:
                        column_names.append('å£“åŠ›MDDåˆ†æ•¸')
                    
                    avg_pr.columns = column_names
                    avg_pr['å¹³å‡åˆ†æ•¸'] = avg_pr.mean(axis=1)
                else:
                    avg_pr = pd.DataFrame()
                
                wf_hedge_counts = pd.DataFrame(period_hedge_counts).T.sum()
                stress_hedge_counts = pd.DataFrame(stress_hedge_counts).T.sum()
                total_hedge_counts = wf_hedge_counts + stress_hedge_counts
                summary_df = pd.concat([avg_pr, wf_hedge_counts.to_frame('èµ°æŸ¥é¿éšªæ¬¡æ•¸'), stress_hedge_counts.to_frame('å£“åŠ›é¿éšªæ¬¡æ•¸'), total_hedge_counts.to_frame('ç¸½é¿éšªæ¬¡æ•¸')], axis=1)
                st.dataframe(summary_df.style.format("{:.2f}", subset=avg_pr.columns).format("{:d}", subset=['èµ°æŸ¥é¿éšªæ¬¡æ•¸', 'å£“åŠ›é¿éšªæ¬¡æ•¸', 'ç¸½é¿éšªæ¬¡æ•¸']))

            # æ¨™ç±¤é  5: éæ“¬åˆæª¢æ¸¬
            with tabs[4]:
                st.subheader("éæ“¬åˆæª¢æ¸¬åˆ†æ")
                
                # è¨ˆç®—éæ“¬åˆæŒ‡æ¨™
                overfitting_metrics = {}
                for name, result in results.items():
                    if 'equity_curve' in result and not result['equity_curve'].empty:
                        equity_curve = result['equity_curve']
                        
                        # åˆ†å‰²è¨“ç·´å’Œæ¸¬è©¦æœŸé–“
                        split_point = int(len(equity_curve) * 0.7)
                        train_equity = equity_curve.iloc[:split_point]
                        test_equity = equity_curve.iloc[split_point:]
                        
                        if len(train_equity) > 30 and len(test_equity) > 30:
                            train_returns = train_equity.pct_change().dropna()
                            test_returns = test_equity.pct_change().dropna()
                            
                            # è¨ˆç®—å¹´åŒ–å ±é…¬ç‡
                            train_annual_return = train_returns.mean() * 252
                            test_annual_return = test_returns.mean() * 252
                            
                            # è¨ˆç®—å¤æ™®æ¯”ç‡
                            train_sharpe = train_annual_return / (train_returns.std() * np.sqrt(252)) if train_returns.std() > 0 else 0
                            test_sharpe = test_annual_return / (test_returns.std() * np.sqrt(252)) if test_returns.std() > 0 else 0
                            
                            # è¨ˆç®—éæ“¬åˆæŒ‡æ¨™
                            sharpe_degradation = train_sharpe - test_sharpe
                            return_degradation = train_annual_return - test_annual_return
                            
                            # éæ“¬åˆåˆ†æ•¸ï¼ˆ0-100ï¼Œè¶Šé«˜è¶Šéæ“¬åˆï¼‰
                            # ä¿®æ­£è¨ˆç®—æ–¹å¼ï¼šè€ƒæ…®å¤æ™®æ¯”ç‡å’Œå ±é…¬ç‡çš„ç›¸å°é‡è¦æ€§
                            sharpe_weight = 0.6
                            return_weight = 0.4
                            overfitting_score = min(100, max(0, 
                                abs(sharpe_degradation) * 50 * sharpe_weight + 
                                abs(return_degradation) * 200 * return_weight
                            ))
                            
                            overfitting_metrics[name] = {
                                'train_sharpe': train_sharpe,
                                'test_sharpe': test_sharpe,
                                'train_return': train_annual_return,
                                'test_return': test_annual_return,
                                'sharpe_degradation': sharpe_degradation,
                                'return_degradation': return_degradation,
                                'overfitting_score': overfitting_score
                            }
                
                if overfitting_metrics:
                    # éæ“¬åˆåˆ†æ•¸æ’å
                    overfitting_df = pd.DataFrame(overfitting_metrics).T
                    overfitting_df = overfitting_df.sort_values('overfitting_score')
                    
                    st.subheader("éæ“¬åˆåˆ†æ•¸æ’åï¼ˆè¶Šä½è¶Šå¥½ï¼‰")
                    st.dataframe(overfitting_df[['overfitting_score', 'sharpe_degradation', 'return_degradation']].style.format({
                        'overfitting_score': '{:.1f}',
                        'sharpe_degradation': '{:.3f}',
                        'return_degradation': '{:.3f}'
                    }))
                    
                    # éæ“¬åˆåˆ†æ•¸åˆ†å¸ƒåœ–
                    fig_overfitting = px.bar(
                        overfitting_df.reset_index(), 
                        x='index', 
                        y='overfitting_score',
                        title="ç­–ç•¥éæ“¬åˆåˆ†æ•¸åˆ†å¸ƒ",
                        labels={'index': 'ç­–ç•¥', 'overfitting_score': 'éæ“¬åˆåˆ†æ•¸'}
                    )
                    fig_overfitting.add_hline(y=30, line_dash="dash", line_color="orange", annotation_text="è¼•å¾®éæ“¬åˆ")
                    fig_overfitting.add_hline(y=50, line_dash="dash", line_color="red", annotation_text="åš´é‡éæ“¬åˆ")
                    st.plotly_chart(fig_overfitting, use_container_width=True)
                    
                    # æ¨£æœ¬å…§å¤–è¡¨ç¾å°æ¯”
                    st.subheader("æ¨£æœ¬å…§å¤–è¡¨ç¾å°æ¯”")
                    
                    # å¤æ™®æ¯”ç‡å°æ¯”
                    comparison_sharpe_df = overfitting_df[['train_sharpe', 'test_sharpe']].reset_index()
                    comparison_sharpe_df.columns = ['ç­–ç•¥', 'æ¨£æœ¬å…§å¤æ™®æ¯”ç‡', 'æ¨£æœ¬å¤–å¤æ™®æ¯”ç‡']
                    
                    fig_comparison_sharpe = px.bar(
                        comparison_sharpe_df,
                        x='ç­–ç•¥',
                        y=['æ¨£æœ¬å…§å¤æ™®æ¯”ç‡', 'æ¨£æœ¬å¤–å¤æ™®æ¯”ç‡'],
                        title="æ¨£æœ¬å…§å¤–å¤æ™®æ¯”ç‡å°æ¯”",
                        barmode='group'
                    )
                    st.plotly_chart(fig_comparison_sharpe, use_container_width=True)
                    
                    # å ±é…¬ç‡å°æ¯”
                    comparison_return_df = overfitting_df[['train_return', 'test_return']].reset_index()
                    comparison_return_df.columns = ['ç­–ç•¥', 'æ¨£æœ¬å…§å¹´åŒ–å ±é…¬ç‡', 'æ¨£æœ¬å¤–å¹´åŒ–å ±é…¬ç‡']
                    
                    fig_comparison_return = px.bar(
                        comparison_return_df,
                        x='ç­–ç•¥',
                        y=['æ¨£æœ¬å…§å¹´åŒ–å ±é…¬ç‡', 'æ¨£æœ¬å¤–å¹´åŒ–å ±é…¬ç‡'],
                        title="æ¨£æœ¬å…§å¤–å¹´åŒ–å ±é…¬ç‡å°æ¯”",
                        barmode='group'
                    )
                    st.plotly_chart(fig_comparison_return, use_container_width=True)
                else:
                    st.warning("ç„¡æ³•è¨ˆç®—éæ“¬åˆæŒ‡æ¨™ï¼Œè«‹ç¢ºä¿æœ‰è¶³å¤ çš„æ•¸æ“šé€²è¡Œæ¨£æœ¬å…§å¤–åˆ†å‰²")
                
                # ç­–ç•¥ç©©å®šæ€§åˆ†æ
                st.subheader("ç­–ç•¥ç©©å®šæ€§åˆ†æ")
                stability_metrics = calculate_strategy_stability(period_returns)
                
                if stability_metrics:
                    stability_df = pd.DataFrame(stability_metrics).T
                    st.dataframe(stability_df.style.format({
                        'mean_return': '{:.2%}',
                        'std_return': '{:.2%}',
                        'cv': '{:.2f}',
                        'positive_periods_ratio': '{:.2%}',
                        'rank_stability': '{:.3f}'
                    }))
                    
                    # ç©©å®šæ€§ç†±åŠ›åœ–
                    if len(stability_df) > 1:
                        fig_stability = px.imshow(
                            stability_df[['cv', 'positive_periods_ratio', 'rank_stability']].T,
                            title="ç­–ç•¥ç©©å®šæ€§æŒ‡æ¨™ç†±åŠ›åœ–",
                            aspect="auto"
                        )
                        st.plotly_chart(fig_stability, use_container_width=True)

            # é¡¯ç¤ºç¸½é«”å›æ¸¬çµæœ
            st.subheader("ç­–ç•¥æ¬Šç›Šæ›²ç·š")

            equity_curves_list = []
            for name, result in results.items():
                if 'equity_curve' in result and not result['equity_curve'].empty:
                    equity_curve = result['equity_curve'].rename(name)
                    equity_curves_list.append(equity_curve)

            if not equity_curves_list:
                st.warning("æ²’æœ‰å¯ç”¨çš„æ¬Šç›Šæ›²ç·šæ•¸æ“šé€²è¡Œç¹ªè£½ã€‚")
                logger.warning("æ²’æœ‰å¯ç”¨çš„æ¬Šç›Šæ›²ç·šæ•¸æ“šé€²è¡Œç¹ªè£½ã€‚")
            else:
                all_equity_curves = pd.concat(equity_curves_list, axis=1)
                all_equity_curves = all_equity_curves.reindex(global_index).ffill()
                all_equity_curves.ffill(inplace=True)
                all_equity_curves.fillna(initial_equity, inplace=True)

                df_plot = all_equity_curves.reset_index().melt(id_vars='index', var_name='ç­–ç•¥', value_name='æ¬Šç›Š')
                df_plot.rename(columns={'index': 'æ—¥æœŸ'}, inplace=True)
                
                fig_equity = px.line(df_plot, x='æ—¥æœŸ', y='æ¬Šç›Š', color='ç­–ç•¥', title="ç­–ç•¥æ¬Šç›Šæ›²ç·š")
                fig_equity.update_layout(legend_title_text='variable')
                st.plotly_chart(fig_equity, use_container_width=True, key="total_equity_curve")

            # é¡¯ç¤ºåŒ¯ç¸½æŒ‡æ¨™
            st.subheader("ç­–ç•¥åŒ¯ç¸½æŒ‡æ¨™")
            summary_data = []
            for name, result in results.items():
                if 'metrics' in result and result['metrics']:
                    metrics = result['metrics']
                    
                    row = {
                        "ç­–ç•¥": name,
                        "ç¸½å ±é…¬ç‡": metrics.get('total_return', 0),
                        "å¹´åŒ–å ±é…¬ç‡": metrics.get('annual_return', 0),
                        "æœ€å¤§å›æ’¤": metrics.get('max_drawdown', 0),
                        "å¤æ™®æ¯”ç‡": metrics.get('sharpe_ratio', 0),
                        "å¡ç‘ªæ¯”ç‡": metrics.get('calmar_ratio', 0),
                        "äº¤æ˜“æ¬¡æ•¸": metrics.get('num_trades', 0),
                        "å‹ç‡": metrics.get('win_rate', 0)
                    }
                    summary_data.append(row)
            
            if summary_data:
                summary_df = pd.DataFrame(summary_data).set_index("ç­–ç•¥")
                
                # é¡¯ç¤ºè¡¨æ ¼
                st.dataframe(summary_df.style.format({
                    "ç¸½å ±é…¬ç‡": "{:.2%}", "å¹´åŒ–å ±é…¬ç‡": "{:.2%}", "æœ€å¤§å›æ’¤": "{:.2%}",
                    "å¤æ™®æ¯”ç‡": "{:.2f}", "å¡ç‘ªæ¯”ç‡": "{:.2f}", "å‹ç‡": "{:.2%}"
                }))
            else:
                st.warning("æ²’æœ‰å¯ç”¨çš„åŒ¯ç¸½æŒ‡æ¨™æ•¸æ“šã€‚")

            # è’™åœ°å¡ç¾…æ¸¬è©¦å»ºè­°
            st.info("è’™åœ°å¡ç¾…æ¸¬è©¦ï¼šè«‹åƒè€ƒ Optuna_12.py ä¸­çš„ compute_pbo_score å’Œ compute_simplified_sra å‡½æ•¸å¯¦ç¾ PBO åˆ†æ•¸èˆ‡ SRA p å€¼è¨ˆç®—")

            # è¼‰å…¥å’ŒåŸ·è¡Œä¿¡æ¯
            with st.expander("ğŸ“‹ åŸ·è¡Œä¿¡æ¯", expanded=False):
                st.subheader("è¼‰å…¥ä¿¡æ¯")
                st.info(f"è¼‰å…¥ {len(strategies_to_run)} å€‹ç­–ç•¥ï¼Œå…± {len(results)} å€‹è©¦é©—")
                
                # é¡¯ç¤ºé¸ä¸­çš„ç­–ç•¥ä¿¡æ¯
                st.subheader("å·²é¸æ“‡çš„ç­–ç•¥:")
                for strategy in strategies_to_run:
                    st.text(f"â€¢ {strategy['name']} ({strategy['strategy_type']})")
                
                # é¡¯ç¤ºç­–ç•¥çµ±è¨ˆ
                strategy_counts = {}
                for strategy in strategies_to_run:
                    strategy_type = strategy['strategy_type']
                    data_source = strategy['smaa_source']
                    key = f"{strategy_type}_{data_source}"
                    strategy_counts[key] = strategy_counts.get(key, 0) + 1
                
                st.subheader("ç­–ç•¥åˆ†å¸ƒ:")
                for key, count in strategy_counts.items():
                    st.text(f"â€¢ {key}: {count} å€‹ç­–ç•¥")
                
                # é¡¯ç¤ºåŸ·è¡Œä¿¡æ¯
                st.subheader("åŸ·è¡Œä¿¡æ¯")
                st.text(f"â€¢ é¸ä¸­ç­–ç•¥æ•¸é‡: {len(strategies_to_run)}")
                st.text(f"â€¢ å¯¦éš›åŸ·è¡Œç­–ç•¥: {len(results)}")
                st.text(f"â€¢ æ¬Šç›Šæ›²ç·šæ•¸æ“šé»: {len(equity_curves) if not equity_curves.empty else 0}")

            # é¡¯ç¤ºæ—¥èªŒå…§å®¹
            st.subheader("æ—¥èªŒå…§å®¹")
            log_file = Path("logs") / "OS.log"
            if log_file.exists():
                with open(log_file, "r", encoding="utf-8") as f:
                    log_content = f.read()
                st.code(log_content, language="text")
            else:
                st.text("æ—¥èªŒæª”æ¡ˆä¸å­˜åœ¨")

