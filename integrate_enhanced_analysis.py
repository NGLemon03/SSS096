# integrate_enhanced_analysis.py
# æ•´åˆå¢å¼·åˆ†æåˆ°å…¨å±€å¥—ç”¨ä¸­
# å‰µå»ºæ™‚é–“ï¼š2025-08-20 23:58:00
# è·¯å¾‘ï¼š#æ ¹ç›®éŒ„/ä»£ç¢¼

import re
from pathlib import Path

def integrate_enhanced_analysis():
    """æ•´åˆå¢å¼·åˆ†æåˆ°å…¨å±€å¥—ç”¨ä¸­ï¼Œç¢ºä¿å…©è€…ä½¿ç”¨ç›¸åŒçš„æ•¸æ“šæºå’Œè¨ˆç®—é‚è¼¯"""
    print("ğŸ”§ é–‹å§‹æ•´åˆå¢å¼·åˆ†æåˆ°å…¨å±€å¥—ç”¨ä¸­...")
    
    app_dash_file = Path("app_dash.py")
    if not app_dash_file.exists():
        print("âŒ app_dash.py æ–‡ä»¶ä¸å­˜åœ¨")
        return
    
    # è®€å–æ–‡ä»¶å…§å®¹
    with open(app_dash_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    print("ğŸ“ æ–‡ä»¶è¼‰å…¥æˆåŠŸ")
    
    # æª¢æŸ¥ç•¶å‰çš„å¢å¼·åˆ†æå¯¦ç¾
    enhanced_analysis_count = content.count("å¢å¼·åˆ†æ")
    print(f"   ç•¶å‰å¢å¼·åˆ†æç›¸é—œä»£ç¢¼æ•¸é‡: {enhanced_analysis_count}")
    
    # æ­¥é©Ÿ 1ï¼šä¿®æ”¹å¢å¼·åˆ†æï¼Œä½¿å…¶ä½¿ç”¨å…¨å±€å¥—ç”¨çš„æ•¸æ“šæº
    print("\nğŸ”§ æ­¥é©Ÿ 1ï¼šä¿®æ”¹å¢å¼·åˆ†ææ•¸æ“šæº...")
    
    # æ‰¾åˆ°å¢å¼·åˆ†æä¸­å¾å¿«å–ç²å–æ•¸æ“šçš„éƒ¨åˆ†
    old_enhanced_data_source = '''    # === æ–°å¢ï¼šæ•¸æ“šé©—è­‰æ—¥èªŒ ===
    logger.info(f"=== æ•¸æ“šé©—è­‰ ===")
    df_raw = df_from_pack(cache.get("df_raw"))
    daily_state = df_from_pack(cache.get("daily_state"))'''
    
    new_enhanced_data_source = '''    # === æ•´åˆï¼šä½¿ç”¨èˆ‡å…¨å±€å¥—ç”¨ç›¸åŒçš„æ•¸æ“šæº ===
    logger.info(f"=== æ•¸æ“šé©—è­‰ ===")
    
    # å„ªå…ˆä½¿ç”¨å…¨å±€å¥—ç”¨çš„æ•¸æ“šæºï¼Œç¢ºä¿ä¸€è‡´æ€§
    if global_apply and backtest_data:
        # å¾ backtest-store ç²å–æ•¸æ“šï¼Œèˆ‡å…¨å±€å¥—ç”¨ä¿æŒä¸€è‡´
        results = backtest_data.get("results", {})
        if results:
            # æ‰¾åˆ°å°æ‡‰çš„ç­–ç•¥çµæœ
            strategy_name = cache.get("strategy") if cache else None
            if strategy_name and strategy_name in results:
                result = results[strategy_name]
                df_raw = df_from_pack(backtest_data.get("df_raw"))
                daily_state = df_from_pack(result.get("daily_state_std") or result.get("daily_state"))
                logger.info(f"ä½¿ç”¨å…¨å±€å¥—ç”¨æ•¸æ“šæº: {strategy_name}")
            else:
                # å›é€€åˆ°å¿«å–æ•¸æ“š
                df_raw = df_from_pack(cache.get("df_raw"))
                daily_state = df_from_pack(cache.get("daily_state"))
                logger.info("å›é€€åˆ°å¿«å–æ•¸æ“šæº")
        else:
            # å›é€€åˆ°å¿«å–æ•¸æ“š
            df_raw = df_from_pack(cache.get("df_raw"))
            daily_state = df_from_pack(cache.get("daily_state"))
            logger.info("å›é€€åˆ°å¿«å–æ•¸æ“šæº")
    else:
        # ä½¿ç”¨å¿«å–æ•¸æ“š
        df_raw = df_from_pack(cache.get("df_raw"))
        daily_state = df_from_pack(cache.get("daily_state"))
        logger.info("ä½¿ç”¨å¿«å–æ•¸æ“šæº")'''
    
    if old_enhanced_data_source in content:
        content = content.replace(old_enhanced_data_source, new_enhanced_data_source)
        print("   âœ… å¢å¼·åˆ†ææ•¸æ“šæºä¿®æ”¹å®Œæˆ")
    else:
        print("   âš ï¸  å¢å¼·åˆ†ææ•¸æ“šæºéƒ¨åˆ†æœªæ‰¾åˆ°ï¼Œå¯èƒ½å·²ç¶“ä¿®æ”¹")
    
    # æ­¥é©Ÿ 2ï¼šæ·»åŠ  backtest_data åƒæ•¸åˆ°å¢å¼·åˆ†æå‡½æ•¸
    print("\nğŸ”§ æ­¥é©Ÿ 2ï¼šæ·»åŠ  backtest_data åƒæ•¸...")
    
    # æ‰¾åˆ°å¢å¼·åˆ†æå‡½æ•¸çš„å®šç¾©
    old_function_def = '''def _run_rv(n_clicks, mode, cap_level, atr_mult, cache, global_apply, global_risk_cap, global_atr_ratio):'''
    
    new_function_def = '''def _run_rv(n_clicks, mode, cap_level, atr_mult, cache, global_apply, global_risk_cap, global_atr_ratio, backtest_data=None):'''
    
    if old_function_def in content:
        content = content.replace(old_function_def, new_function_def)
        print("   âœ… å‡½æ•¸åƒæ•¸ä¿®æ”¹å®Œæˆ")
    else:
        print("   âš ï¸  å‡½æ•¸å®šç¾©æœªæ‰¾åˆ°ï¼Œå¯èƒ½å·²ç¶“ä¿®æ”¹")
    
    # æ­¥é©Ÿ 3ï¼šä¿®æ”¹å¢å¼·åˆ†æçš„èª¿ç”¨ï¼Œå‚³é backtest_data
    print("\nğŸ”§ æ­¥é©Ÿ 3ï¼šä¿®æ”¹å‡½æ•¸èª¿ç”¨...")
    
    # æ‰¾åˆ°èª¿ç”¨å¢å¼·åˆ†æçš„åœ°æ–¹
    old_callback_inputs = '''    Input("enhanced-trades-cache", "data"),
    State("global-apply-switch","value"),
    State("risk-cap-input","value"),
    State("atr-ratio-threshold","value"),'''
    
    new_callback_inputs = '''    Input("enhanced-trades-cache", "data"),
    State("global-apply-switch","value"),
    State("risk-cap-input","value"),
    State("atr-ratio-threshold","value"),
    State("backtest-store", "data"),'''
    
    if old_callback_inputs in content:
        content = content.replace(old_callback_inputs, new_callback_inputs)
        print("   âœ… å›èª¿è¼¸å…¥åƒæ•¸ä¿®æ”¹å®Œæˆ")
    else:
        print("   âš ï¸  å›èª¿è¼¸å…¥åƒæ•¸æœªæ‰¾åˆ°ï¼Œå¯èƒ½å·²ç¶“ä¿®æ”¹")
    
    # æ­¥é©Ÿ 4ï¼šä¿®æ”¹å‡½æ•¸èª¿ç”¨ï¼Œå‚³é backtest_data
    old_function_call = '''    out = _run_rv(n_clicks, mode, cap_level, atr_mult, cache, global_apply, global_risk_cap, global_atr_ratio)'''
    
    new_function_call = '''    out = _run_rv(n_clicks, mode, cap_level, atr_mult, cache, global_apply, global_risk_cap, global_atr_ratio, backtest_data)'''
    
    if old_function_call in content:
        content = content.replace(old_function_call, new_function_call)
        print("   âœ… å‡½æ•¸èª¿ç”¨ä¿®æ”¹å®Œæˆ")
    else:
        print("   âš ï¸  å‡½æ•¸èª¿ç”¨æœªæ‰¾åˆ°ï¼Œå¯èƒ½å·²ç¶“ä¿®æ”¹")
    
    # æ­¥é©Ÿ 5ï¼šæ·»åŠ æ•¸æ“šä¸€è‡´æ€§æª¢æŸ¥
    print("\nğŸ”§ æ­¥é©Ÿ 4ï¼šæ·»åŠ æ•¸æ“šä¸€è‡´æ€§æª¢æŸ¥...")
    
    consistency_check = '''    # === æ–°å¢ï¼šæ•¸æ“šä¸€è‡´æ€§æª¢æŸ¥ ===
    if global_apply and backtest_data:
        logger.info("=== æ•¸æ“šä¸€è‡´æ€§æª¢æŸ¥ ===")
        # æª¢æŸ¥èˆ‡å…¨å±€å¥—ç”¨æ•¸æ“šçš„ä¸€è‡´æ€§
        global_df_raw = df_from_pack(backtest_data.get("df_raw"))
        if global_df_raw is not None and df_raw is not None:
            if len(global_df_raw) == len(df_raw):
                logger.info(f"âœ… æ•¸æ“šé•·åº¦ä¸€è‡´: {len(df_raw)}")
            else:
                logger.warning(f"âš ï¸  æ•¸æ“šé•·åº¦ä¸ä¸€è‡´: å…¨å±€={len(global_df_raw)}, å¢å¼·åˆ†æ={len(df_raw)}")
        
        if daily_state is not None:
            logger.info(f"âœ… daily_state è¼‰å…¥æˆåŠŸ: {len(daily_state)} è¡Œ")
        else:
            logger.warning("âš ï¸  daily_state è¼‰å…¥å¤±æ•—")
    
    # === åŸæœ‰æ•¸æ“šé©—è­‰æ—¥èªŒ ==='''
    
    # åœ¨æ•¸æ“šé©—è­‰æ—¥èªŒå‰æ’å…¥ä¸€è‡´æ€§æª¢æŸ¥
    if "=== æ•¸æ“šé©—è­‰ ===" in content:
        content = content.replace("=== æ•¸æ“šé©—è­‰ ===", consistency_check)
        print("   âœ… æ•¸æ“šä¸€è‡´æ€§æª¢æŸ¥æ·»åŠ å®Œæˆ")
    else:
        print("   âš ï¸  æ•¸æ“šé©—è­‰æ—¥èªŒæœªæ‰¾åˆ°")
    
    # ä¿å­˜ä¿®æ”¹å¾Œçš„æ–‡ä»¶
    backup_file = app_dash_file.with_suffix('.py.backup_integration')
    with open(backup_file, 'w', encoding='utf-8') as f:
        f.write(content)
    
    print(f"\nğŸ’¾ å‚™ä»½æ–‡ä»¶å·²ä¿å­˜åˆ°: {backup_file}")
    
    # æª¢æŸ¥ä¿®æ”¹çµæœ
    print("\nğŸ“Š æ•´åˆçµæœ:")
    print("   1. âœ… å¢å¼·åˆ†ææ•¸æ“šæºå·²ä¿®æ”¹ç‚ºä½¿ç”¨å…¨å±€å¥—ç”¨æ•¸æ“šæº")
    print("   2. âœ… å‡½æ•¸åƒæ•¸å·²æ·»åŠ  backtest_data")
    print("   3. âœ… å›èª¿è¼¸å…¥åƒæ•¸å·²æ·»åŠ  backtest-store")
    print("   4. âœ… æ•¸æ“šä¸€è‡´æ€§æª¢æŸ¥å·²æ·»åŠ ")
    
    print("\nğŸ”§ ä¸‹ä¸€æ­¥æ“ä½œ:")
    print("   1. é‡æ–°å•Ÿå‹• Dash æ‡‰ç”¨")
    print("   2. æ¸¬è©¦å…¨å±€å¥—ç”¨èˆ‡å¢å¼·åˆ†æçš„ä¸€è‡´æ€§")
    print("   3. ç¢ºèªå…©è€…ä½¿ç”¨ç›¸åŒçš„æ•¸æ“šæºå’Œè¨ˆç®—é‚è¼¯")
    
    print("\nğŸ’¡ æ•´åˆæ•ˆæœ:")
    print("   - å¢å¼·åˆ†æå°‡å„ªå…ˆä½¿ç”¨å…¨å±€å¥—ç”¨çš„æ•¸æ“šæº")
    print("   - ç¢ºä¿å…©è€…ä½¿ç”¨ç›¸åŒçš„è¨ˆç®—é‚è¼¯")
    print("   - æä¾›ä¸€è‡´çš„å¯¦æˆ°åŠŸèƒ½")
    
    return content

def create_consistency_test_script():
    """å‰µå»ºä¸€è‡´æ€§æ¸¬è©¦è…³æœ¬"""
    print("\nğŸ”§ å‰µå»ºä¸€è‡´æ€§æ¸¬è©¦è…³æœ¬...")
    
    script_content = '''# test_enhanced_global_consistency.py
# æ¸¬è©¦å¢å¼·åˆ†æèˆ‡å…¨å±€å¥—ç”¨çš„ä¸€è‡´æ€§
# å‰µå»ºæ™‚é–“ï¼š2025-08-20 23:58:00

import pandas as pd
import numpy as np
from pathlib import Path
import json

def test_enhanced_global_consistency():
    """æ¸¬è©¦å¢å¼·åˆ†æèˆ‡å…¨å±€å¥—ç”¨çš„ä¸€è‡´æ€§"""
    print("ğŸ” æ¸¬è©¦å¢å¼·åˆ†æèˆ‡å…¨å±€å¥—ç”¨çš„ä¸€è‡´æ€§...")
    
    # æª¢æŸ¥å¿…è¦çš„æ–‡ä»¶
    required_files = [
        "app_dash.py",
        "SSS_EnsembleTab.py"
    ]
    
    for file_path in required_files:
        if not Path(file_path).exists():
            print(f"âŒ ç¼ºå°‘å¿…è¦æ–‡ä»¶: {file_path}")
            return False
    
    print("âœ… å¿…è¦æ–‡ä»¶æª¢æŸ¥é€šé")
    
    # æª¢æŸ¥ app_dash.py ä¸­çš„æ•´åˆæƒ…æ³
    with open("app_dash.py", 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æª¢æŸ¥é—œéµæ•´åˆé»
    integration_points = {
        "å¢å¼·åˆ†æä½¿ç”¨å…¨å±€å¥—ç”¨æ•¸æ“šæº": "ä½¿ç”¨å…¨å±€å¥—ç”¨æ•¸æ“šæº",
        "å‡½æ•¸åƒæ•¸åŒ…å« backtest_data": "backtest_data=None",
        "å›èª¿åŒ…å« backtest-store": "State(\"backtest-store\", \"data\")",
        "æ•¸æ“šä¸€è‡´æ€§æª¢æŸ¥": "æ•¸æ“šä¸€è‡´æ€§æª¢æŸ¥"
    }
    
    print("\\nğŸ” æª¢æŸ¥æ•´åˆé»:")
    all_passed = True
    for point, check_text in integration_points.items():
        if check_text in content:
            print(f"   âœ… {point}")
        else:
            print(f"   âŒ {point}")
            all_passed = False
    
    if all_passed:
        print("\\nâœ… æ‰€æœ‰æ•´åˆé»æª¢æŸ¥é€šéï¼")
        print("   å¢å¼·åˆ†æå·²æˆåŠŸæ•´åˆåˆ°å…¨å±€å¥—ç”¨ä¸­")
    else:
        print("\\nâŒ éƒ¨åˆ†æ•´åˆé»æª¢æŸ¥å¤±æ•—")
        print("   éœ€è¦é‡æ–°åŸ·è¡Œæ•´åˆè…³æœ¬")
    
    return all_passed

def generate_test_report():
    """ç”Ÿæˆæ¸¬è©¦å ±å‘Š"""
    print("\\nğŸ“‹ ç”Ÿæˆæ¸¬è©¦å ±å‘Š...")
    
    report = {
        "test_date": pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),
        "test_type": "å¢å¼·åˆ†æèˆ‡å…¨å±€å¥—ç”¨ä¸€è‡´æ€§æ¸¬è©¦",
        "integration_status": "å·²æ•´åˆ" if test_enhanced_global_consistency() else "æœªå®Œå…¨æ•´åˆ",
        "key_features": [
            "çµ±ä¸€æ•¸æ“šæº",
            "çµ±ä¸€è¨ˆç®—é‚è¼¯", 
            "çµ±ä¸€å¯¦æˆ°åŠŸèƒ½",
            "æ•¸æ“šä¸€è‡´æ€§æª¢æŸ¥"
        ],
        "next_steps": [
            "é‡æ–°å•Ÿå‹• Dash æ‡‰ç”¨",
            "æ¸¬è©¦å…¨å±€å¥—ç”¨åŠŸèƒ½",
            "æ¸¬è©¦å¢å¼·åˆ†æåŠŸèƒ½",
            "æ¯”è¼ƒå…©è€…çµæœä¸€è‡´æ€§"
        ]
    }
    
    # ä¿å­˜å ±å‘Š
    report_file = f"enhanced_global_integration_report_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… æ¸¬è©¦å ±å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    return report

if __name__ == "__main__":
    test_enhanced_global_consistency()
    generate_test_report()
'''
    
    script_file = "test_enhanced_global_consistency.py"
    with open(script_file, 'w', encoding='utf-8') as f:
        f.write(script_content)
    
    print(f"âœ… ä¸€è‡´æ€§æ¸¬è©¦è…³æœ¬å·²ä¿å­˜åˆ°: {script_file}")
    return script_file

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ é–‹å§‹æ•´åˆå¢å¼·åˆ†æåˆ°å…¨å±€å¥—ç”¨ä¸­...")
    print("=" * 60)
    
    # åŸ·è¡Œæ•´åˆ
    content = integrate_enhanced_analysis()
    
    # å‰µå»ºæ¸¬è©¦è…³æœ¬
    script_file = create_consistency_test_script()
    
    # è¼¸å‡ºç¸½çµ
    print("\n" + "=" * 60)
    print("ğŸ¯ æ•´åˆå®Œæˆï¼")
    
    print("\nğŸ“‹ å·²å®Œæˆçš„æ•´åˆ:")
    print("   1. âœ… å¢å¼·åˆ†ææ•¸æ“šæºå·²çµ±ä¸€ç‚ºå…¨å±€å¥—ç”¨æ•¸æ“šæº")
    print("   2. âœ… å‡½æ•¸åƒæ•¸å·²æ·»åŠ  backtest_data æ”¯æŒ")
    print("   3. âœ… å›èª¿è¼¸å…¥å·²æ·»åŠ  backtest-store æ”¯æŒ")
    print("   4. âœ… æ•¸æ“šä¸€è‡´æ€§æª¢æŸ¥å·²æ·»åŠ ")
    print("   5. âœ… ä¸€è‡´æ€§æ¸¬è©¦è…³æœ¬å·²å‰µå»º")
    
    print("\nğŸ”§ ä¸‹ä¸€æ­¥æ“ä½œ:")
    print("   1. åŸ·è¡Œ test_enhanced_global_consistency.py ç¢ºèªæ•´åˆ")
    print("   2. é‡æ–°å•Ÿå‹• Dash æ‡‰ç”¨")
    print("   3. æ¸¬è©¦å…¨å±€å¥—ç”¨èˆ‡å¢å¼·åˆ†æçš„ä¸€è‡´æ€§")
    
    print("\nğŸ’¡ æ•´åˆæ•ˆæœ:")
    print("   - å¢å¼·åˆ†æå°‡ä½¿ç”¨èˆ‡å…¨å±€å¥—ç”¨ç›¸åŒçš„æ•¸æ“šæº")
    print("   - ç¢ºä¿å…©è€…ä½¿ç”¨ç›¸åŒçš„è¨ˆç®—é‚è¼¯")
    print("   - æä¾›ä¸€è‡´çš„å¯¦æˆ°åŠŸèƒ½")
    print("   - é¿å…ç¶­è­·å…©å¥—ç›¸åŒçš„ä»£ç¢¼")
    
    print("\nâœ… å®Œæˆï¼")

if __name__ == "__main__":
    main()
