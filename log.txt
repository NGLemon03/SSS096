1.

Configuring language runtimes...
# Python: 3.12
# Node.js: v20 (default: v22)
default -> 20 (-> v20.19.4)
Now using node v20.19.4 (npm v10.9.3)
# Ruby: 3.4.4 (default: 3.2.3)
mise ~/.config/mise/config.toml tools: ruby@3.4.4
# Rust: 1.88.0 (default: 1.89.0)
info: using existing install for '1.88.0-x86_64-unknown-linux-gnu'
info: default toolchain set to '1.88.0-x86_64-unknown-linux-gnu'

  1.88.0-x86_64-unknown-linux-gnu unchanged - rustc 1.88.0 (6b00bc388 2025-06-23)

# Go: go1.24.3 (default: go1.24.3)
# Swift: 6.1 (default: 6.1)
# PHP: 8.4 (default: 8.4)
Running auto setup...
Scanning repository (up to depth 3) for dependency configurations...
No known dependency configuration files found up to depth 3.
後面版本不是新增了風險閥門套用在各策略嗎
但不知道為什麼套用後 各指標會只剩下平均持倉天數,其他指標都消失了 請修復


^Cbash: mise: No such file or directory
root@478772c9b537:/workspace# cd SSS096
bash: mise: No such file or directory
bash: mise: No such file or directory
root@478772c9b537:/workspace/SSS096# ls -a
bash: ls: No such file or directory
bash: mise: No such file or directory
The "bash: ls: No such file or directory" error suggests a missing or misconfigured PATH.

root@478772c9b537:/workspace/SSS096# command -v ls
bash: mise: No such file or directory
Hmm, the "mise" seems injected by the environment, maybe causing failures. Let's try /bin/ls.

root@478772c9b537:/workspace/SSS096# /bin/ls -a
.                                   assets                        run_enhanced_ensemble.py
..                                  config.yaml                   run_workflow.py
.git                                convert_results_to_trades.py  run_workflow_example.py
.vscode                             data                          runners
AGENTS.md                           debug_enhanced_data.py        setup.sh
DEFENSIVE_CHECKS_UPDATE_SUMMARY.md  ensemble_wrapper.py           sss_backtest_outputs
ENSEMBLE_WORKFLOW.md                extract_params.py             sss_core
LOGGING_SYSTEM_UPDATE_SUMMARY.md    leverage.py                   test
PORTFOLIO_LEDGER_README.md          list.txt                      tools
SSS_EnsembleTab.py                  list_folder_structure.py      utils_payload.py
SSSv096.py                          presets                       version_history.py
analysis                            ruff.toml                     workflow_summary_20250812_023903.txt
app_dash.py                         run_enhanced_debug.py         workflow_summary_20250818_040656.txt
bash: mise: No such file or directory
I'll avoid aliases by directly using /usr/bin/git to check status.

root@478772c9b537:/workspace/SSS096# /usr/bin/git status --short
bash: mise: No such file or directory
I'm wondering if "mise" is blocking git status. I’ll check with which git.

root@478772c9b537:/workspace/SSS096# /usr/bin/which git
bash: mise: No such file or directory
Looks like the "mise" error could be from a pre-command function or alias. Let's explore AGENTS.md.

root@478772c9b537:/workspace/SSS096# /bin/cat AGENTS.md
# SSS096 專案 AI 代理工作指南

## 📋 專案概述

SSS096 是一個股票策略回測與分析系統，主要包含：
- 策略回測引擎（SSSv096.py）
- Web UI 界面（app_dash.py）
- 增強分析模組（analysis/）
- Ensemble 策略執行（runners/）
- 數據處理與轉換工具

## 🎯 工作重點區域

### 核心檔案
- `SSSv096.py` - 主要策略回測引擎
- `app_dash.py` - Web UI 主應用
- `ensemble_wrapper.py` - Ensemble 策略包裝器
- `analysis/` - 分析模組目錄

### 避免修改的檔案
- `tools/quick_check.ps1` - 自動化檢查腳本（除非必要）
- 已標記為 "past/" 的舊版本檔案
- 編譯後的 `.pyc` 檔案

## 🔧 開發環境設定

### Codex 環境設置（推薦）
```bash
# 執行自動設置腳本
chmod +x setup.sh
./setup.sh

# 測試設置是否成功
python test_setup.py
```

### Python 環境（手動設置）
```bash
# 安裝依賴套件
pip install pandas numpy matplotlib seaborn openpyxl dash dash-bootstrap-components

# 檢查 Python 版本（建議 3.8+）
python --version
```

### 代理設置（如果遇到 403 錯誤）
```bash
# 檢查代理證書
echo $CODEX_PROXY_CERT

# 配置 pip 使用代理
pip config set global.cert "$CODEX_PROXY_CERT"
pip config set global.trusted-host "proxy:8080"
```

### 專案結構導航
```bash
# 快速查看目錄結構
python list_folder_structure.py

# 查看特定目錄內容
ls analysis/
ls runners/
```

## 🧪 測試與驗證

### 快速檢查
```bash
# 執行自動化檢查（重要！）
powershell -ExecutionPolicy Bypass -File tools\quick_check.ps1
```

### 回測測試
```bash
# 執行單一策略回測
python SSSv096.py --strategy RMA_Factor --param_preset op.json

# 執行 Ensemble 策略
python run_enhanced_ensemble.py --method majority --top_k 5
```

### UI 測試
```bash
# 啟動 Web UI
python app_dash.py
```

## 📝 程式碼規範

### 註解與輸出
- **一律使用繁體中文**進行註解和輸出
- 修改紀錄需加入日期時間戳記
- 路徑說明格式：`#子資料夾/檔案名`

### 日誌記錄
- 使用 `analysis/logging_config.py` 中的日誌器
- 重要操作需記錄到日誌檔案
- 錯誤處理需包含詳細的錯誤信息

### 資料格式
- 日期欄位統一使用 ISO 格式：`YYYY-MM-DD`
- 數值欄位使用 float 類型
- 避免使用中文欄位名稱（除非必要）

## 🔍 除錯指南

### 常見問題
1. **模組導入失敗**：檢查 `sys.path` 和相對導入
2. **數據格式錯誤**：驗證 CSV 檔案結構和欄位名稱
3. **記憶體不足**：檢查大數據集的處理方式

### 除錯工具
```python
# 啟用詳細日誌
import logging
logging.basicConfig(level=logging.DEBUG)

# 檢查數據結構
print(df.info())
print(df.head())
```

## 📊 數據處理規範

### 輸入數據
- 支援 CSV、Excel、JSON 格式
- 必要欄位：交易日期、權重變化、盈虧%
- 可選欄位：交易類型、價格、成交量

### 輸出數據
- 統一 Schema：equity、trades、daily_state、trade_ledger
- 避免 KeyError 和欄位缺失
- 支援多種輸出格式

## 🚀 部署與維護

### 檔案管理
- 定期清理舊的日誌和快取檔案
- 備份重要的配置和結果檔案
- 使用版本控制追蹤變更

### 性能優化
- 大數據集使用快取機制
- 避免重複計算
- 使用適當的數據結構

## ⚠️ 注意事項

### 安全考量
- 不要硬編碼 API 金鑰
- 驗證所有用戶輸入
- 保護敏感數據

### 相容性
- 維持與現有工作流程的相容性
- 測試所有整合點
- 避免破壞現有功能

## 🚀 Codex 環境設置

### 自動設置
```bash
# 執行設置腳本
./setup.sh

# 腳本會自動：
# 1. 配置代理設置
# 2. 安裝所有必要依賴
# 3. 創建回退日誌系統
# 4. 設置環境變數
```

### 手動設置（如果自動設置失敗）
```bash
# 1. 配置代理
export PIP_CERT="$CODEX_PROXY_CERT"
export NODE_EXTRA_CA_CERTS="$CODEX_PROXY_CERT"

# 2. 安裝核心依賴
pip install --no-cache-dir pandas numpy matplotlib seaborn openpyxl dash dash-bootstrap-components yfinance pyyaml joblib

# 3. 安裝分析套件
pip install --no-cache-dir scikit-learn scipy statsmodels plotly kaleido

# 4. 創建必要目錄
mkdir -p analysis/log analysis/cache cache log results sss_backtest_outputs
```

### 常見問題解決
- **pip install 403 錯誤**：檢查 `$CODEX_PROXY_CERT` 環境變數
- **joblib 導入失敗**：使用 `logging_config_fallback.py` 回退版本
- **模組路徑問題**：設置 `PYTHONPATH` 環境變數

## 📞 技術支援

### 問題回報
- 提供完整的錯誤訊息和堆疊追蹤
- 包含重現步驟和環境信息
- 檢查相關的日誌檔案

### 文檔更新
- 修改功能時同步更新相關文檔
- 使用清晰的範例和說明
- 保持文檔的時效性

---

**版本：** v1.0
**最後更新：** 2025-08-18
**適用於：** SSS096 專案 AI 代理工作指南
bash: mise: No such file or directory
Let's search for AGENTS.md in the subdirectories to guide necessary modifications.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg "風險閥" -n
DEFENSIVE_CHECKS_UPDATE_SUMMARY.md
36:- 在繪製風險閥門時序圖前檢查必要欄位

SSS_EnsembleTab.py
1287:# === PATCH: 風險閥門施作在權重 ===
1292:    """對每日目標權重 w 施作風險閥門：

analysis/ENHANCED_ANALYSIS_README.md
11:1. **風險閥門回測** - 在極端行情下暫停加碼機制
17:### 1. 風險閥門回測 (`risk_valve_backtest`)
141:- 風險閥門觸發時序圖
184:### 1. 風險閥門策略

analysis/UI_INTEGRATION_GUIDE.md
11:1. 風險閥門回測
260:- **自定義基準數據**：上傳基準數據進行風險閥門分析

analysis/enhanced_trade_analysis.py
4:整合風險閥門回測、交易貢獻拆解、加碼梯度優化
97:        風險閥門回測
109:        print("=== 風險閥門回測分析 ===")
112:        # 模擬風險閥門觸發
115:        # 計算風險閥門效果
121:        """模擬風險閥門觸發"""
123:            print("警告：缺少基準數據，無法進行風險閥門回測")
179:        # 風險閥門觸發條件
184:        # 綜合風險閥門
194:        """計算風險閥門對績效的影響"""
200:            print("警告：benchmark_enhanced 缺少 '日期' 欄位，無法計算風險閥門影響")
204:            print("警告：benchmark_enhanced 缺少 'risk_valve_triggered' 欄位，無法計算風險閥門影響")
207:        # 找出風險閥門觸發的期間
243:        print(f"風險閥門觸發期間數：{len(risk_periods)}")
555:        # 1. 風險閥門觸發時序
559:                print("警告：benchmark_enhanced 缺少必要欄位，跳過風險閥門時序圖")
561:                print("警告：benchmark_enhanced 缺少 'risk_valve_triggered' 欄位，跳過風險閥門時序圖")
575:                               color='red', s=50, alpha=0.8, label='風險閥門觸發')
578:                ax1.set_title('風險閥門觸發時序')
637:    print("2. 執行風險閥門回測：analyzer.risk_valve_backtest()")

app_dash.py
445:                        html.Label("風險閥門 CAP", style={"fontSize":"12px","color":"#888"}),
455:                        dbc.Checkbox(id='force-valve-trigger', value=False, label="強制觸發風險閥門（測試用）", style={"font
Size":"11px","color":"#dc3545"}),
456:                        html.Small("💡 勾選後將強制觸發風險閥門，用於測試功能", style={"color":"#dc3545","fontSize":"10px"})
460:                    # === 風險閥門狀態顯示區域 ===
464:                        html.Small("🔒 風險閥門說明:", style={"color":"#28a745","fontWeight":"bold","fontSize":"11px"}),
573:# --------- 風險閥門狀態更新 ---------
587:    """動態更新風險閥門狀態顯示"""
588:    logger.info(f"=== 風險閥門狀態更新 ===")
598:        logger.info("風險閥門未啟用")
600:            html.Small("🔴 風險閥門未啟用", style={"color":"#dc3545","fontWeight":"bold"}),
655:                            # 判斷是否需要觸發風險閥門
658:                            # 如果啟用強制觸發，則強制觸發風險閥門
661:                                logger.info(f"強制觸發風險閥門啟用")
663:                            # 記錄風險閥門狀態到日誌
665:                            logger.info(f"風險閥門門檻: {atr_ratio}, 當前比值: {atr_ratio_current:.4f}")
666:                            logger.info(f"風險閥門觸發: {'是' if valve_triggered else '否'}")
667:                            logger.info(f"風險閥門狀態: {'🔴 觸發' if valve_triggered else '🟢 正常'}")
680:                                    html.Small(f"{status_icon} 風險閥門狀態: {status_text}",
742:        logger.error(f"風險閥門狀態更新失敗: {e}")
797:    # === 新增：全局風險閥門觸發狀態追蹤 ===
810:        # 應用全局風險閥門設定（如果啟用）
811:        logger.info(f"[{strat}] 風險閥門開關狀態: global_apply={global_apply}, 類型={type(global_apply)}")
813:            logger.info(f"[{strat}] 應用全局風險閥門: CAP={risk_cap}, ATR比值門檻={atr_ratio}")
836:                        logger.warning(f"[{strat}] ATR(60) 值異常: {atr_60_latest}，跳過風險閥門")
840:                        logger.warning(f"[{strat}] ATR(20) 值異常: {atr_20_latest}，跳過風險閥門")
851:                    logger.info(f"[{strat}] 🔴 強制觸發風險閥門啟用")
856:            logger.info(f"[{strat}] 未啟用全局風險閥門")
864:            # 重新計算策略信號（因為參數可能已經被風險閥門調整）
870:            # === 在 ssma_turn 也套用風險閥門（和 Ensemble 一致的後置覆寫） ===
941:                        logger.info(f"[{strat}] SSMA 風險閥門已套用（cap={risk_cap}, ratio={ratio_local:.4f}）")
943:                        logger.warning(f"[{strat}] SSMA 無法取得權重序列，跳過風險閥門套用")
945:                    logger.info(f"[{strat}] SSMA 風險閥門未觸發，使用原始結果")
981:                # 註解掉原本的無條件風險閥門調整（會造成 floor 方向錯誤）
983:                #     logger.info(f"[{strat}] Ensemble 策略應用風險閥門: 原始 delta_cap={ensemble_params.delta_cap}, floor={
ensemble_params.floor}")
1020:                # --- 新增：只在 ATR 觸發時啟用風險閥門 ---
1047:                                # 增加風險閥門觸發的詳細資訊
1049:                                    logger.info(f"[{strat}] 🔴 風險閥門觸發！ATR比值({ratio:.4f}) > 門檻({atr_ratio})")
1051:                                    logger.info(f"[{strat}] 🟢 風險閥門未觸發，ATR比值({ratio:.4f}) <= 門檻({atr_ratio})")
1063:                # 如果啟用強制觸發，則強制觸發風險閥門
1066:                    logger.info(f"[{strat}] 🔴 強制觸發風險閥門啟用")
1078:                    logger.info(f"[{strat}] 🔴 開始套用風險閥門: cap={risk_cap}, ratio={ratio:.4f}")
1093:                    logger.info(f"[{strat}] 風險閥門已套用（cap={risk_cap}, ratio={ratio:.4f}）")
1095:                    # 增加風險閥門效果的詳細資訊
1097:                        logger.info(f"[{strat}] 風險閥門效果: PF原始={rv['metrics'].get('pf_orig', 'N/A'):.2f}, PF閥門={rv[
'metrics'].get('pf_valve', 'N/A'):.2f}")
1098:                        logger.info(f"[{strat}] 風險閥門效果: MDD原始={rv['metrics'].get('mdd_orig', 'N/A'):.2f}%, MDD閥門=
{rv['metrics'].get('mdd_valve', 'N/A'):.2f}%")
1108:                        logger.info(f"[{strat}] 🟢 風險閥門未觸發，使用原始參數")
1116:                        logger.info(f"[{strat}] ⚪ 全局風險閥門未啟用")
1175:                    "applied": False,  # 其他策略類型暫時不支援風險閥門
1205:        # === 全局風險閥門：逐日動態套用（與增強分析一致） ===
1211:                logger.warning(f"[{strat}] daily_state 不含 'w'，跳過全局風險閥門")
1217:                    logger.warning(f"[{strat}] 無法計算 ATR20/60，跳過全局風險閥門")
1316:                        logger.info(f"[{strat}] 全局風險閥門已套用（逐日），風險天數={true_days}, CAP={risk_cap:.2f}")
1318:                        logger.warning(f"[{strat}] 風險閥門重算沒有返回結果")
1701:            # === 計算風險閥門徽章內容 ===
1713:                "🛡️ 風險閥門：" + valve_badge_text + ((" | " + " | ".join(valve_badge_extra)) if valve_badge_extra else ""),
1968:                html.Summary("風險閥門回測"),
1981:                    html.Button("執行風險閥門回測", id="run-rv", n_clicks=0, style={"marginTop":"8px"})
2369:# --------- 增強分析 Callback：風險閥門回測（修正版） ---------
2434:        return f"風險閥門回測執行失敗: {e}", no_update, no_update
3488:        return go.Figure(), "❌ 無法從風險閥門回測的參數組合中取得資料"
bash: mise: No such file or directory
I'm searching for "avg_holding" or "平均持倉" to understand why metrics vanish after applying the risk valve.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg "平均持倉" -n
SSSv096.py
927:    計算平均持倉天數.
933:        float: 平均持倉天數.
1828:            "avg_holding_period": "平均持倉天數",
1864:    # 計算平均持倉天數
1867:    # 將平均持倉天數加入 metrics
2293:            # 顯示策略摘要,傳入 trade_df 以計算平均持倉天數

analysis/optuna_16.py
10:v10-12  支援單一/隨機/依序數據源模式,新增平均持倉天數,相關係數分析,並自動輸出熱圖,試驗結果與最佳參數自動輸出 CSV/JSON

analysis/OSv3.py
82:        'avg_hold_days': '平均持倉天數：平均每次交易的持倉時間',

app_dash.py
1559:                "avg_holding_period": "平均持倉天數",
bash: mise: No such file or directory
I'm checking for a bug where the metrics dictionary gets overwritten after applying the risk valve.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg "avg_holding_period" -n
SSSv096.py
849:        'avg_holding_period': np.nan,# 新增
1808:        elif k in ["max_drawdown_duration", "avg_holding_period"]:
1828:            "avg_holding_period": "平均持倉天數",
1865:    avg_holding_period = calculate_holding_periods(trade_df)
1868:    metrics['avg_holding_period'] = avg_holding_period

app_dash.py
1545:            metrics['avg_holding_period'] = avg_holding
1559:                "avg_holding_period": "平均持倉天數",
1573:                elif k in ["max_drawdown_duration", "avg_holding_period"]:
bash: mise: No such file or directory
I suspect the bug could be in how "rv" results are handled in SSS_EnsembleTab.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg "avg_holding_period" SSS_EnsembleTab.py
bash: mise: No such file or directory
Looking into the "mise" error and how risk valve metrics might be affected by code reset.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg "metrics =" -n SSS_EnsembleTab.py
bash: mise: No such file or directory
I'll open the SSS_EnsembleTab around line 1075 to check the metrics merging and risk valve effect.

root@478772c9b537:/workspace/SSS096# /bin/sed -n '1060,1105p' SSS_EnsembleTab.py
                delta_cap=delta_cap,
                majority_k=6,  # 這個值會被 majority_k_pct 覆蓋
                min_cooldown_days=min_cooldown_days,
                min_trade_dw=min_trade_dw,
            )

            cost = CostParams(
                buy_fee_bp=buy_fee_bp,
                sell_fee_bp=sell_fee_bp,
                sell_tax_bp=sell_tax_bp,
            )

            cfg = RunConfig(
                ticker=ticker,
                method=method,
                params=params,
                cost=cost,
                majority_k_pct=majority_k_pct
            )

            # 運行 ensemble
            with st.spinner("執行中..."):
                open_px, w, trades, stats, method_name, equity, daily_state, trade_ledger = run_ensemble(cfg)

            # 顯示結果
            st.success(f"執行完成: {method_name}")

            # 績效指標
            col6, col7, col8 = st.columns(3)
            with col6:
                st.metric("總報酬率", f"{stats.get('total_return', 0):.2%}")
                st.metric("年化報酬率", f"{stats.get('annual_return', 0):.2%}")
            with col7:
                st.metric("最大回撤", f"{stats.get('max_drawdown', 0):.2%}")
                st.metric("夏普比率", f"{stats.get('sharpe_ratio', 0):.2f}")
            with col8:
                st.metric("卡瑪比率", f"{stats.get('calmar_ratio', 0):.2f}")
                st.metric("交易次數", stats.get('num_trades', 0))

            # === 新增：交易明細顯示 ===
            st.subheader("交易明細 (trade_ledger)")
            if trade_ledger is not None and not trade_ledger.empty:
                # 使用 normalize_trades_for_ui 標準化交易明細
                trades_ui = normalize_trades_for_ui(trade_ledger)

                # === 新增：刪除費用欄位（僅UI層移除顯示） ===
bash: mise: No such file or directory
I'm thinking the issue might be in the risk valve apply function, like "apply_risk_valve".

root@478772c9b537:/workspace/SSS096# /usr/bin/rg "apply_risk_valve" -n
bash: mise: No such file or directory
I’ll check for “risk_valve” in SSSv096 to explore its integration with daily weights.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg "risk_valve" -n SSSv096.py
bash: mise: No such file or directory
I think the risk valve could be mishandling dictionary merging, so I'll search for related lines.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg "rv\['metrics'\]" -n SSS_EnsembleTab.py
bash: mise: No such file or directory
I'll search around the risk valve code in SSS_EnsembleTab, especially near lines 1700-1200.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg "metrics" SSS_EnsembleTab.py | head -n 50
bash: head: No such file or directory
bash: mise: No such file or directory
Looks like the head command isn't in the path. I'll use /bin/head instead.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg "metrics" SSS_EnsembleTab.py | /bin/head -n 50
        "metrics": {
bash: mise: No such file or directory
I'll switch to using rg -n to get line numbers instead of just the first chunk.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg -n "metrics" SSS_EnsembleTab.py | /bin/head -n 50
1405:        "metrics": {
bash: mise: No such file or directory
I'll check line 1405 and the surrounding area to see what's going on with "metrics".

root@478772c9b537:/workspace/SSS096# /bin/sed -n '1390,1420p' SSS_EnsembleTab.py
        if x.empty: return 0.0
        thr = x.quantile(0.90)
        return float(x[x > max(thr, 0)].sum())
    rt1 = right_tail_sum(r1)
    rt2 = right_tail_sum(r2)
    right_tail_reduction = (rt1 - rt2)

    return {
        "signals": sig,
        "weights_orig": w,
        "weights_valve": w2,
        "daily_state_orig": daily_state1,
        "daily_state_valve": daily_state2,
        "trade_ledger_orig": ledger1,
        "trade_ledger_valve": ledger2,
        "metrics": {
            "pf_orig": float(pf1), "pf_valve": float(pf2),
            "mdd_orig": float(mdd1), "mdd_valve": float(mdd2),
            "right_tail_sum_orig": float(rt1), "right_tail_sum_valve": float(rt2),
            "right_tail_reduction": float(right_tail_reduction)
        }
    }


# === PATCH: 交易貢獻拆解（按加碼/減碼階段）===
def trade_contribution_by_phase(trade_ledger: pd.DataFrame,
                                daily_equity: pd.Series,
                                min_spacing_days: int = 0,
                                cooldown_days: int = 0) -> pd.DataFrame:
    """將交易依『權重變化正/負』分段，統計各階段的賣出實現報酬與該段內的 MDD。"""
    tl = trade_ledger.copy()
bash: mise: No such file or directory
Seems like the metrics dictionary is getting replaced after the risk valve. Let's search for merging.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg -n "rv\['metrics'\]" -g "SSS_EnsembleTab.py"
bash: mise: No such file or directory
I’m trying variations of search terms to home in on the right metrics or functions.

root@478772c9b537:/workspace/SSS096# /bin/sed -n '1280,1320p' SSS_EnsembleTab.py
    # 風險觸發：兩斜率皆 < 門檻，且 ATR 抬頭超過倍率
    b["risk_trigger"] = (b["slope_20d"] < slope20_thresh) & \
                        (b["slope_60d"] < slope60_thresh) & \
                        (b["atr_ratio"] > atr_ratio_mult)
    return b[["slope_20d", "slope_60d", "atr", "atr_ratio", "risk_trigger"]]


# === PATCH: 風險閥門施作在權重 ===
def apply_valve_to_weights(w: pd.Series,
                           risk_trigger: pd.Series,
                           mode: str = "cap",   # "cap" 或 "ban_add"
                           cap_level: float = 0.5) -> pd.Series:
    """對每日目標權重 w 施作風險閥門：
       - cap: 風險日將 w 限在 cap_level 以下
       - ban_add: 風險日禁止「提高」倉位（允許減倉），用迭代法確保單調"""
    w = w.copy().reindex(risk_trigger.index).ffill().fillna(0.0)
    out = w.copy()

    if mode == "cap":
        mask = risk_trigger.reindex(w.index).fillna(False).astype(bool)
        out[mask] = np.minimum(out[mask], cap_level)

    elif mode == "ban_add":
        mask = risk_trigger.reindex(w.index).fillna(False).astype(bool)
        for i in range(1, len(out)):
            if mask.iloc[i] and (out.iloc[i] > out.iloc[i-1]):
                out.iloc[i] = out.iloc[i-1]  # 禁止增加
    else:
        raise ValueError("mode 需為 'cap' 或 'ban_add'")
    return out.clip(0.0, 1.0)


# === PATCH: 由 trade_ledger 建立「每筆盈虧%」與快照（引用 re.txt 做法）===
def build_trade_snapshots_from_ledger(trade_ledger: pd.DataFrame) -> pd.DataFrame:
    """以交易後權益/現金為資產快照，計算每筆盈虧%（只在有變動的交易日記一筆）"""
    df = trade_ledger.copy()
    # 欄名對齊
    if "date" in df.columns: df.rename(columns={"date": "交易日期"}, inplace=True)
    if "type" in df.columns: df.rename(columns={"type": "交易類型"}, inplace=True)
    if "equity_after" in df.columns: df.rename(columns={"equity_after": "交易後權益"}, inplace=True)
    if "cash_after" in df.columns: df.rename(columns={"cash_after": "交易後現金"}, inplace=True)
bash: mise: No such file or directory
I suspect the risk valve is replacing metrics, not merging them as expected. Let's search.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg -n "metrics\s*=\s*{" -l
rg: regex parse error:
    (?:metrics\s*=\s*{)
                      ^
error: repetition quantifier expects a valid decimal
bash: mise: No such file or directory
I'll escape the curly braces (\{) to fix the parse error.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg -n "metrics\s*=\s*\{" -l
SSSv096.py
analysis/optuna_16.py
analysis/OSv3.py
analysis/walk_forward_v14.py
analysis/stress_testv1.py
analysis/past/risk_enhanced_clustering_analysis_v2.py
analysis/OSv3_6270833.py
bash: mise: No such file or directory
I'll start by checking around where SSSv096 defines the metrics dictionary.

root@478772c9b537:/workspace/SSS096# /bin/sed -n '1800,1880p' SSSv096.py
    # 先把 metrics 的 key/value 轉成「顯示用的 label」和「格式化後的 value 字串」
    items = []
    for k, v in metrics.items():
        # 依據 k 決定要不要以百分比、或小數、或純文字來格式化
        if k in ["total_return", "annual_return", "win_rate", "max_drawdown", "annualized_volatility", "avg_win", "avg_loss"]:
            txt = f"{v:.2%}" if pd.notna(v) else ""
        elif k in ["calmar_ratio", "sharpe_ratio", "sortino_ratio", "payoff_ratio", "profit_factor"]:
            txt = f"{v:.2f}" if pd.notna(v) else ""
        elif k in ["max_drawdown_duration", "avg_holding_period"]:
            txt = f"{v:.1f} 天" if pd.notna(v) else ""
        elif k in ["num_trades", "max_consecutive_wins", "max_consecutive_losses"]:
            txt = str(int(v)) if pd.notna(v) else ""
        else:
            # 其他就先盡量當純文字顯示
            txt = f"{v}"
        # 把字典 key → 中文顯示 label
        label_map = {
            "total_return": "總回報率",
            "annual_return": "年化回報率",
            "win_rate": "勝率",
            "max_drawdown": "最大回撤",
            "max_drawdown_duration": "回撤持續",
            "calmar_ratio": "卡瑪比率",
            "sharpe_ratio": "夏普比率",
            "sortino_ratio": "索提諾比率",
            "payoff_ratio": "盈虧比",
            "profit_factor": "盈虧因子",
            "num_trades": "交易次數",
            "avg_holding_period": "平均持倉天數",
            "annualized_volatility": "年化波動率",
            "max_consecutive_wins": "最大連續盈利",
            "max_consecutive_losses": "最大連續虧損",
            "avg_win": "平均盈利",
            "avg_loss": "平均虧損",
        }
        label = label_map.get(k, k)
        items.append((label, txt))

    # 開始產生 HTML:外層一個 flex container,內層每組(指標+數值) 都是 flex item
    html = """
<div style="display:flex;flex-wrap:wrap;gap:12px;align-items:flex-start;">
"""
    for label, val in items:
        html += f"""
  <div style="flex:0 1 150px;border:1px solid #444;border-radius:4px;padding:8px 12px;background:#1a1a1a;">
    <div style="font-size:14px;color:#aaa;">{label}</div>
    <div style="font-size:20px;font-weight:bold;color:#fff;margin-top:4px;">{val}</div>
  </div>
"""
    html += "</div>"

    # 去掉多餘縮排,避免開頭空白被解讀成 code block
    html = textwrap.dedent(html)

    st.markdown(html, unsafe_allow_html=True)

def display_strategy_summary(strategy: str, params: Dict, metrics: Dict, smaa_source: str, trade_df: pd.DataFrame):
    """
    顯示策略參數與回測績效摘要,使用 HTML Flexbox 卡片展示.
    """
    # 參數展示
    param_display = {k: v for k, v in params.items() if k != "strategy_type"}
    st.write("**參數設定**: " + ", ".join(f"{k}: {v}" for k, v in param_display.items()))

    # 計算平均持倉天數
    avg_holding_period = calculate_holding_periods(trade_df)

    # 將平均持倉天數加入 metrics
    metrics['avg_holding_period'] = avg_holding_period

    # 績效指標展示
    if metrics:
        display_metrics_flex(metrics)
    else:
        st.warning("尚未執行回測,無法顯示績效指標.")
# --- 主應用程式 ---
def run_app():
    st.set_page_config(layout="wide")
    st.sidebar.title("00631L策略系統")
    page = st.sidebar.selectbox("📑 頁面導航", ["策略回測", "投資組合權重分析", "各版本沿革紀錄", "快取管理"])

bash: mise: No such file or directory
It seems the risk valve might be resetting the metrics to only include avg_holding_period.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg -n "risk_valve" -g "SSS_EnsembleTab.py"
SSS_EnsembleTab.py
1241:def compute_risk_valve_signals(benchmark_df: pd.DataFrame,
1359:def risk_valve_backtest(open_px: pd.Series,
1371:    sig = compute_risk_valve_signals(benchmark_df, slope20_thresh, slope60_thresh,
bash: mise: No such file or directory
The bug arises when applying risk valve to strategies; metrics only show avg holding days.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg -n "apply_valve" -g "*.py"
SSS_EnsembleTab.py
1288:def apply_valve_to_weights(w: pd.Series,
1373:    w2 = apply_valve_to_weights(w, sig["risk_trigger"], mode, cap_level)
bash: mise: No such file or directory
The bug might be in the metrics display from the risk valve code. I'm checking for possible overwriting of the metrics variable.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg -n "metrics = {}" -g "SSSv096.py"
rg: regex parse error:
    (?:metrics = {})
                  ^
error: repetition quantifier expects a valid decimal
bash: mise: No such file or directory
I realized I missed something because of the regex. I need to escape the braces.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg -n "metrics = \{\}" SSSv096.py
2480:            performance_metrics = {}
bash: mise: No such file or directory
I see line 2480 sets performance_metrics to an empty dictionary—let's check the surrounding code.

root@478772c9b537:/workspace/SSS096# /bin/sed -n '2440,2490p' SSSv096.py
    # 初始權重
    n_strategies = len(equity_curves)
    current_weights = {strategy: 1.0 / n_strategies for strategy in equity_curves.keys()}

    # 重新平衡頻率轉換
    if rebalance_freq == "季度":
        rebalance_months = 3
    elif rebalance_freq == "年度":
        rebalance_months = 12
    else:
        rebalance_months = None

    # 計算重新平衡日期
    rebalance_dates = []
    if rebalance_months:
        current_date = pd.to_datetime(common_dates[0])
        end_date = pd.to_datetime(common_dates[-1])

        while current_date <= end_date:
            rebalance_dates.append(current_date)
            # 計算下一個重新平衡日期
            if current_date.month + rebalance_months > 12:
                year = current_date.year + 1
                month = (current_date.month + rebalance_months) % 12
                if month == 0:
                    month = 12
            else:
                year = current_date.year
                month = current_date.month + rebalance_months

            current_date = current_date.replace(year=year, month=month)

    # 執行投資組合計算
    for i, date in enumerate(common_dates):
        if i == 0:
            continue

        # 檢查是否需要重新平衡
        if rebalance_months and pd.to_datetime(date) in rebalance_dates:
            # 計算新的權重
            performance_metrics = {}
            for strategy_name, equity_curve in equity_curves.items():
                if date in equity_curve.index:
                    # 計算過去期間的表現
                    lookback_start = max(0, i - lookback_period)
                    if lookback_start < len(equity_curve):
                        past_equity = equity_curve.iloc[lookback_start:i+1]
                        if len(past_equity) > 1:
                            if weight_method == "等權重":
                                performance_metrics[strategy_name] = 1.0
                            elif weight_method == "夏普比率權重":
bash: mise: No such file or directory
Looks like the bug is due to risk valve replacing strategy metrics, leaving only avg_holding.

The issue likely occurs when metrics is reset to {} in display_strategy_summary after risk valve.

Inside display_strategy_summary, metrics defaults to {}, adding avg_holding_period. Likely, caller omits original metrics.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg -n "display_strategy_summary" -g "SSSv096.py"
SSSv096.py
1856:def display_strategy_summary(strategy: str, params: Dict, metrics: Dict, smaa_source: str, trade_df: pd.DataFrame):
2294:            display_strategy_summary(strategy, params, result['metrics'], smaa_source, result['trade_df'])
bash: mise: No such file or directory
It looks like display_strategy_summary is triggered near line 2294 in run_app/CLI.

root@478772c9b537:/workspace/SSS096# /bin/sed -n '2240,2310p' SSSv096.py
                ticker,
                start_date=start_date_input,
                end_date=end_date_input if end_date_input else None,
                smaa_source=smaa_source,
                force_update=force_update
            )

            # 計算回測結果
            if strategy_type == 'ssma_turn':
                calc_keys = ['linlen', 'factor', 'smaalen', 'prom_factor', 'min_dist',
                             'buy_shift', 'exit_shift', 'vol_window', 'signal_cooldown_days',
                             'quantile_win']
                ssma_params = {k: v for k, v in params.items() if k in calc_keys}
                # 2) 確保 stop_loss 傳遞給 backtest_unified
                backtest_params = ssma_params.copy()
                backtest_params['stop_loss'] = params.get('stop_loss', 0.0)
                df_ind, buy_dates, sell_dates = compute_ssma_turn_combined(
                    df_raw, df_factor, **ssma_params, smaa_source=smaa_source
                )
                if df_ind.empty:
                    st.warning(f"{strategy} 策略計算失敗,可能是數據不足.")
                    continue
                result = backtest_unified(
                    df_ind, strategy_type, backtest_params, buy_dates, sell_dates,
                    discount=discount, trade_cooldown_bars=trade_cooldown_bars, bad_holding=bad_holding
                )
            else:
                if strategy_type == 'single':
                    df_ind = compute_single(
                        df_raw, df_factor, params["linlen"], params["factor"], params["smaalen"],
                        params["devwin"], smaa_source=smaa_source
                    )
                elif strategy_type == 'dual':
                    df_ind = compute_dual(
                        df_raw, df_factor, params["linlen"], params["factor"], params["smaalen"],
                        params["short_win"], params["long_win"], smaa_source=smaa_source
                    )
                elif strategy_type == 'RMA':
                    df_ind = compute_RMA(
                        df_raw, df_factor, params["linlen"], params["factor"], params["smaalen"],
                        params["rma_len"], params["dev_len"], smaa_source=smaa_source
                    )
                if df_ind.empty:
                    st.warning(f"{strategy} 策略計算失敗,可能是數據不足.")
                    continue
                result = backtest_unified(
                    df_ind, strategy_type, params, discount=discount,
                    trade_cooldown_bars=trade_cooldown_bars, bad_holding=bad_holding
                )

            results[strategy] = (df_ind, result['trades'], result['trade_df'],
                                 result['signals_df'], result['metrics'])

            # 顯示策略摘要,傳入 trade_df 以計算平均持倉天數
            display_strategy_summary(strategy, params, result['metrics'], smaa_source, result['trade_df'])

            # 顯示圖表與交易明細
            has_trades = ('trade_df' in result) and (result['trade_df'] is not None) and (not result['trade_df'].empty)
            if has_trades:
                st.plotly_chart(plot_stock_price(df_raw, result['trade_df'], ticker),
                                use_container_width=True, key=f"stock_price_{strategy}")

                # ✅ 優先使用 daily_state（Ensemble 正確路徑），沒有再退回 trade_df
                ds_or_trades = result.get('daily_state', result.get('trade_df'))
                # 標準化 daily_state 再繪圖，避免欄位名誤用
                if ds_or_trades is not None and not ds_or_trades.empty:
                    ds_or_trades = normalize_daily_state(ds_or_trades)

                # 🔍 偵錯輸出：把真正要畫的資料直接吐出 csv
                try:
                    print(f"🔍 開始偵錯輸出：{strategy}")
bash: mise: No such file or directory
I need to locate the backtest_unified function to see how metrics are computed.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg -n "backtest_unified" -g "*.py"
SSSv096.py
39:    "compute_ssma_turn_combined", "backtest_unified",
953:def backtest_unified(
1360:            result = backtest_unified(df_ind, strategy_type, params, buy_dates, sell_dates,
1380:            result = backtest_unified(df_ind, strategy_type, params, discount=discount, trade_cooldown_bars=trade_cooldown_
bars, bad_holding=bad_holding)
2057:                            result = backtest_unified(
2082:                            result = backtest_unified(
2169:                    result = backtest_unified(
2192:                    result = backtest_unified(
2253:                # 2) 確保 stop_loss 傳遞給 backtest_unified
2262:                result = backtest_unified(
2285:                result = backtest_unified(

version_history.py
121:      <li>版本號提升為 092，新增 <code>backtest_unified</code> 函式以集中管理回測流程。</li>
Error: Output for session 'shell' contained a line exceeding the max of 4096 bytes (observed at least 4429 bytes).

The byte sequence which exceeded the limit started with: b'\x1b[0m\x1b[32m127\x1b[0m:  <'

The exec session has been deleted. Please start a new session.

Tip - rerun the command and extract only what you need, e.g.:
  * grep -nE 'PATTERN' FILE | cut -c1-200
  * grep -o 'PATTERN' FILE
  * jq -r '.json.path' FILE
  * grep -a PATTERN FILE
I'm going to change my directory back to the repo.



root@478772c9b537:/workspace# cd /workspace/SSS096
root@478772c9b537:/workspace/SSS096# ^C
I'll limit the backtest to a smaller portion to avoid overwhelming output.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg -n "def backtest_unified" SSSv096.py
953:def backtest_unified(
I'll take a closer look at the function and dive into the details.

root@478772c9b537:/workspace/SSS096# /bin/sed -n '953,1040p' SSSv096.py
def backtest_unified(
    df_ind: pd.DataFrame,
    strategy_type: str,
    params: Dict,
    buy_dates: Optional[List[pd.Timestamp]] = None,
    sell_dates: Optional[List[pd.Timestamp]] = None,
    discount: float = 0.30,
    trade_cooldown_bars: int = 3,
    bad_holding: bool = False,
    use_leverage: bool = False,
    lev_params: Optional[Dict] = None
) -> Dict:
    if not isinstance(df_ind, pd.DataFrame):
        logger.error(f"df_ind 必須是一個 pandas.DataFrame，卻傳入 {type(df_ind)}")
        return {'trades': [], 'trade_df': pd.DataFrame(), 'trades_df': pd.DataFrame(), 'signals_df': pd.DataFrame(), 'metrics':
[], 'equity_curve': pd.Series()}

    # 處理 ensemble 策略類型
    elif strategy_type == "ensemble":
        import traceback
        from contextlib import nullcontext

        status_ctx = st.status("執行 Ensemble 回測中…", state="running") if hasattr(st, "status") else nullcontext()
        try:
            with status_ctx:
                # 從 Streamlit session_state 取得 ensemble 參數
                method = st.session_state.get('ensemble_method', 'majority')
                floor  = st.session_state.get('ensemble_floor', 0.2)
                ema    = st.session_state.get('ensemble_ema', 3)
                delta  = st.session_state.get('ensemble_delta', 0.3)

                # ---- CostParams：UI 以 bp 設定，內部轉成 rate ----
                buy_fee_bp  = float(st.session_state.get('buy_fee_bp',  4.27))
                sell_fee_bp = float(st.session_state.get('sell_fee_bp', 4.27))
                sell_tax_bp = float(st.session_state.get('sell_tax_bp', 30.0))
                slip_bp     = float(st.session_state.get('slippage_bp', 0.0))

                # 在 ensemble 分支裡面先決定 ticker_name
                ticker_name = (
                    params.get('ticker')
                    or (getattr(df_ind, 'name', None) if hasattr(df_ind, 'name') else None)
                    or 'UNKNOWN'
                )

                cost = CostParams(
                    buy_fee_bp   = buy_fee_bp,
                    sell_fee_bp  = sell_fee_bp,
                    sell_tax_bp  = sell_tax_bp,
                )
                params = EnsembleParams(
                    floor=floor,
                    ema_span=ema,
                    delta_cap=delta,
                    majority_k=6,
                    min_cooldown_days=1,
                    min_trade_dw=0.01
                )
                cfg = RunConfig(
                    ticker=ticker_name,
                    method=method,          # method 放在 RunConfig
                    params=params,
                    cost=cost,
                    majority_k_pct=0.55    # 預設比例門檻
                )

                open_px, w, trades, stats, method_name, equity, daily_state, trade_ledger = run_ensemble(cfg)

                trade_df_ui = normalize_trades_for_ui(trades)
                ledger_ui   = normalize_trades_for_ui(trade_ledger)

                result = {
                    'trades': trades.to_dict('records') if hasattr(trades,'to_dict') else [],
                    'trade_df': trade_df_ui,
                    'trade_ledger': ledger_ui,
                    'signals_df': pd.DataFrame(),
                    'metrics': stats if isinstance(stats, dict) else {},
                    'equity_curve': equity,
                    'daily_state': daily_state,  # 加入 daily_state 供偵錯使用
                    'weight_curve': w,  # 加入 weight_curve 供偵錯使用
                }

                # 執行摘要訊息
                st.info(f"[Ensemble] {method} @ {ticker_name} | 交易筆數={len(trades)} | 回測列數={len(equity)}")

                # 基本訊息
                st.success(f"Ensemble 完成：{method_name}")
                st.caption(f"參數：method={method}, floor={floor}, ema={ema}, delta={delta}, "
                           f"買/賣手續費bp={buy_fee_bp}/{sell_fee_bp}，證交稅bp={sell_tax_bp}，滑價bp={slip_bp}")
This function is large, but the metrics issue might be elsewhere. I'll search for "apply_risk_valve".

root@478772c9b537:/workspace/SSS096# /usr/bin/rg -n "風險閥門" SSSv096.py
I'll search the repo for "result['metrics'] = {}" to pin down the bug.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg -n "result\['metrics'\]" -g "*.py"
SSSv096.py
2198:                                     result['signals_df'], result['metrics'])
2291:                                 result['signals_df'], result['metrics'])
2294:            display_strategy_summary(strategy, params, result['metrics'], smaa_source, result['trade_df'])

app_dash.py
1878:            metrics = result['metrics']

analysis/optuna_16.py
266:    metrics = result['metrics']

analysis/OSv3.py
1668:                result['metrics'] = {
1681:                if result['metrics']['max_drawdown'] != 0:
1682:                    result['metrics']['calmar_ratio'] = result['metrics']['annual_return'] / abs(result['metrics']['max_dra
wdown'])
1684:                    result['metrics']['calmar_ratio'] = 0
1981:                    if 'metrics' in result and result['metrics']:
1982:                        metrics = result['metrics']
2360:                if 'metrics' in result and result['metrics']:
2361:                    metrics = result['metrics']

analysis/exit_shift_test_v3.py
88:        **result['metrics']

analysis/OSv3_6270833.py
918:                result['metrics'] = {
940:                    result['metrics']['win_rate'] = win_rate
952:                    result['metrics']['win_rate'] = 0
956:                if result['metrics']['max_drawdown'] != 0:
957:                    result['metrics']['calmar_ratio'] = result['metrics']['annual_return'] / abs(result['metrics']['max_draw
down'])
959:                    result['metrics']['calmar_ratio'] = 0
1421:                if 'metrics' in result and result['metrics']:
1422:                    metrics = result['metrics']
I’ll check app_dash.py around lines 797-870 where the global risk valve might be applied.

root@478772c9b537:/workspace/SSS096# /bin/sed -n '780,880p' app_dash.py

    # 載入數據
    df_raw, df_factor = load_data(ticker, start_date, end_date, "Self")
    if df_raw.empty:
        logger.warning(f"無法載入 {ticker} 的數據")
        return {"error": f"無法載入 {ticker} 的數據"}

    ctx_trigger = ctx.triggered_id

    # 只在 auto-run 為 True 或按鈕被點擊時運算
    if not auto_run and ctx_trigger != 'run-btn':
        logger.debug(f"跳過回測：auto_run={auto_run}, ctx_trigger={ctx_trigger}")
        return stored_data

    logger.info(f"開始執行回測 - ticker: {ticker}, 策略數: {len(strategy_names)}")
    results = {}

    # === 新增：全局風險閥門觸發狀態追蹤 ===
    valve_triggered = False
    atr_ratio_current = None

    for strat in strategy_names:
        # 只使用 param_presets 中的參數
        strat_params = param_presets[strat].copy()
        strat_type = strat_params["strategy_type"]
        smaa_src = strat_params.get("smaa_source", "Self")

        # 為每個策略載入對應的數據
        df_raw, df_factor = load_data(ticker, start_date, end_date if end_date else None, smaa_source=smaa_src)

        # 應用全局風險閥門設定（如果啟用）
        logger.info(f"[{strat}] 風險閥門開關狀態: global_apply={global_apply}, 類型={type(global_apply)}")
        if global_apply:
            logger.info(f"[{strat}] 應用全局風險閥門: CAP={risk_cap}, ATR比值門檻={atr_ratio}")

            # 計算 ATR 比值（使用最新數據，僅用於日誌顯示）
            try:
                atr_20 = calculate_atr(df_raw, 20)
                atr_60 = calculate_atr(df_raw, 60)

                # 確保 ATR 數據有效
                if not atr_20.empty and not atr_60.empty:
                    atr_20_valid = atr_20.dropna()
                    atr_60_valid = atr_60.dropna()

                    # 檢查樣本數量是否足夠
                    min_samples_20, min_samples_60 = 30, 60  # 至少需要 30 和 60 個樣本
                    if len(atr_20_valid) < min_samples_20 or len(atr_60_valid) < min_samples_60:
                        logger.warning(f"[{strat}] ATR 樣本不足，20期:{len(atr_20_valid)}/{min_samples_20}, 60期:{len(atr_60_val
id)}/{min_samples_60}")
                        continue

                    atr_20_latest = atr_20_valid.iloc[-1]
                    atr_60_latest = atr_60_valid.iloc[-1]

                    # 檢查 ATR 值是否合理
                    if atr_60_latest <= 0 or not np.isfinite(atr_60_latest):
                        logger.warning(f"[{strat}] ATR(60) 值異常: {atr_60_latest}，跳過風險閥門")
                        continue

                    if atr_20_latest <= 0 or not np.isfinite(atr_20_latest):
                        logger.warning(f"[{strat}] ATR(20) 值異常: {atr_20_latest}，跳過風險閥門")
                        continue

                    atr_ratio_current = atr_20_latest / atr_60_latest
                    logger.info(f"[{strat}] 最新ATR比值: {atr_ratio_current:.4f} (20期:{atr_20_latest:.4f}, 60期:{atr_60_latest:
.4f})")
                else:
                    logger.warning(f"[{strat}] ATR 計算結果為空")

                # 強制觸發時設置標記
                if force_trigger:
                    valve_triggered = True
                    logger.info(f"[{strat}] 🔴 強制觸發風險閥門啟用")

            except Exception as e:
                logger.warning(f"[{strat}] ATR 計算失敗: {e}")
        else:
            logger.info(f"[{strat}] 未啟用全局風險閥門")

        if strat_type == 'ssma_turn':
            calc_keys = ['linlen', 'factor', 'smaalen', 'prom_factor', 'min_dist', 'buy_shift', 'exit_shift', 'vol_window', 'sig
nal_cooldown_days', 'quantile_win']
            ssma_params = {k: v for k, v in strat_params.items() if k in calc_keys}
            backtest_params = ssma_params.copy()
            backtest_params['stop_loss'] = strat_params.get('stop_loss', 0.0)

            # 重新計算策略信號（因為參數可能已經被風險閥門調整）
            df_ind, buy_dates, sell_dates = compute_ssma_turn_combined(df_raw, df_factor, **ssma_params, smaa_source=smaa_src)
            if df_ind.empty:
                continue
            result = backtest_unified(df_ind, strat_type, backtest_params, buy_dates, sell_dates, discount=discount, trade_coold
own_bars=cooldown, bad_holding=bad_holding)

            # === 在 ssma_turn 也套用風險閥門（和 Ensemble 一致的後置覆寫） ===
            if global_apply:
                # 判斷是否要觸發（與你的 ATR 檢查或強制觸發一致）
                valve_triggered_local = False
                ratio_local = None
                try:
                    atr_20 = calculate_atr(df_raw, 20)
                    atr_60 = calculate_atr(df_raw, 60)
                    if not atr_20.empty and not atr_60.empty:
                        a20 = atr_20.dropna().iloc[-1]
                        a60 = atr_60.dropna().iloc[-1]
root@478772c9b537:/workspace/SSS096# /bin/sed -n '880,980p' app_dash.py
                        a60 = atr_60.dropna().iloc[-1]
                        if a60 > 0:
                            ratio_local = float(a20 / a60)
                            valve_triggered_local = (ratio_local >= atr_ratio)  # 建議使用 >=
                except Exception:
                    pass

                if force_trigger:
                    valve_triggered_local = True
                    if ratio_local is None:
                        ratio_local = 1.5

                if valve_triggered_local:
                    from SSS_EnsembleTab import risk_valve_backtest, CostParams
                    # 取得 open 價；df_raw 欄位名稱是小寫
                    open_px = df_raw['open'] if 'open' in df_raw.columns else df_raw['close']
                    # 從回測輸出抓 w（先用標準化 daily_state，如果沒有就用原 daily_state）
                    w_series = None
                    try:
                        ds_std = df_from_pack(result.get('daily_state_std'))
                        if ds_std is not None and not ds_std.empty and 'w' in ds_std.columns:
                            w_series = ds_std['w']
                    except Exception:
                        pass
                    if w_series is None:
                        ds = df_from_pack(result.get('daily_state'))
                        if ds is not None and not ds.empty and 'w' in ds.columns:
                            w_series = ds['w']

                    if w_series is not None:
                        # 交易成本（與 Ensemble 分支一致）
                        trade_cost = strat_params.get('trade_cost', {})
                        cost_params = CostParams(
                            buy_fee_bp=float(trade_cost.get("buy_fee_bp", 4.27)),
                            sell_fee_bp=float(trade_cost.get("sell_fee_bp", 4.27)),
                            sell_tax_bp=float(trade_cost.get("sell_tax_bp", 30.0))
                        )

                        rv = risk_valve_backtest(
                            open_px=open_px,
                            w=w_series,
                            cost=cost_params,
                            benchmark_df=df_raw,
                            mode="cap",
                            cap_level=float(risk_cap),
                        )

                        # 覆寫結果，確保 UI 與輸出一致（和 Ensemble 分支對齊）
                        result['equity_curve']     = pack_series(rv["daily_state_valve"]["equity"])
                        result['daily_state']      = pack_df(rv["daily_state_valve"])
                        result['daily_state_std']  = pack_df(rv["daily_state_valve"])
                        result['trade_ledger']     = pack_df(rv["trade_ledger_valve"])
                        result['trade_ledger_std'] = pack_df(rv["trade_ledger_valve"])
                        result['weight_curve']     = pack_series(rv["weights_valve"])
                        # 給 UI 的標記（下個小節會用到）
                        result['valve'] = {
                            "applied": True,
                            "cap": float(risk_cap),
                            "atr_ratio": ratio_local
                        }

                        logger.info(f"[{strat}] SSMA 風險閥門已套用（cap={risk_cap}, ratio={ratio_local:.4f}）")
                    else:
                        logger.warning(f"[{strat}] SSMA 無法取得權重序列，跳過風險閥門套用")
                else:
                    logger.info(f"[{strat}] SSMA 風險閥門未觸發，使用原始結果")
                    # 給 UI 的標記（未觸發）
                    result['valve'] = {
                        "applied": False,
                        "cap": float(risk_cap),
                        "atr_ratio": ratio_local if ratio_local is not None else "N/A"
                    }
        elif strat_type == 'ensemble':
            # 使用新的 ensemble_runner 避免循環依賴
            try:
                from runners.ensemble_runner import run_ensemble_backtest
                from SSS_EnsembleTab import EnsembleParams, CostParams, RunConfig

                # 把 SSSv096 的巢狀參數攤平
                flat_params = {}
                flat_params.update(strat_params.get('params', {}))
                flat_params.update(strat_params.get('trade_cost', {}))
                flat_params['method'] = strat_params.get('method', 'majority')
                flat_params['ticker'] = ticker

                # 使用比例門檻避免 N 變動時失真
                if 'majority_k' in flat_params and flat_params.get('method') == 'majority':
                    flat_params['majority_k_pct'] = 0.55
                    flat_params.pop('majority_k', None)
                    logger.info(f"[Ensemble] 使用比例門檻 majority_k_pct={flat_params['majority_k_pct']}")

                # 創建配置
                ensemble_params = EnsembleParams(
                    floor=flat_params.get("floor", 0.2),
                    ema_span=flat_params.get("ema_span", 3),
                    delta_cap=flat_params.get("delta_cap", 0.3),
                    majority_k=flat_params.get("majority_k", 6),
                    min_cooldown_days=flat_params.get("min_cooldown_days", 1),
                    min_trade_dw=flat_params.get("min_trade_dw", 0.01)
                )
I'm checking the end of backtest_unified for its return in non-ensemble cases.

root@478772c9b537:/workspace/SSS096# /bin/sed -n '1040,1160p' SSSv096.py

                # 沒交易時的診斷
                if (trades is None) or (len(trades) == 0):
                    st.warning(
                        f"Ensemble 沒有產生交易，可能原因：\n"
                        f"• 子策略持倉全 0 或被健康檢查過濾\n"
                        f"• 門檻過高（majority_k_pct={cfg.majority_k_pct}）或 delta_cap / min_trade_dw 過嚴\n"
                        f"• 成本設定使得微小變動被忽略\n"
                        f"請降低門檻、放寬 delta_cap 或檢查子策略 trades 檔。"
                    )
                    # 額外提示：顯示部分 daily_state / w 供使用者自查
                    if daily_state is not None and not daily_state.empty:
                        st.info("以下為最近 10 筆權重變化供檢視：")
                        st.dataframe(daily_state[['w']].tail(10) if 'w' in daily_state.columns else daily_state.tail(10))

                logger.info(f"[Ensemble] 成功執行 {method_name} 策略，產生 {len(trades)} 筆交易")
                return result

        except Exception as e:
            logger.exception("[Ensemble] 執行失敗: %s", e)
            st.error(f"[Ensemble] 執行失敗：{e}")
            st.code(traceback.format_exc(), language="text")
            st.stop()
        finally:
            if hasattr(st, "status"):
                status_ctx.update(label="完成" if 'trades' in locals() else "結束（可能失敗）",
                                  state=("complete" if 'trades' in locals() else "error"))

    BUY_FEE_RATE = BASE_FEE_RATE * discount
    SELL_FEE_RATE = BASE_FEE_RATE * discount + TAX_RATE
    ROUND_TRIP_FEE = BUY_FEE_RATE + SELL_FEE_RATE

    if use_leverage:
        from leverage import LeverageEngine
        lev = LeverageEngine(**(lev_params or {}))
    else:
        lev = None

    required_cols = ['open', 'close'] if strategy_type == 'ssma_turn' else ['open', 'close', 'smaa', 'base', 'sd']
    if df_ind.empty or not all(col in df_ind.columns for col in required_cols):
        logger.warning(f"指標數據不完整，無法執行回測(缺少欄位: {set(required_cols) - set(df_ind.columns)})")
        return {'trades': [], 'trade_df': pd.DataFrame(), 'trades_df': pd.DataFrame(), 'signals_df': pd.DataFrame(), 'metrics':
{'total_return': 0.0, 'annual_return': 0.0, 'max_drawdown': 0.0, 'sharpe_ratio': 0.0, 'calmar_ratio': 0.0, 'num_trades': 0}, 'eq
uity_curve': pd.Series()}

    try:
        trade_cooldown_bars = int(trade_cooldown_bars)
        if trade_cooldown_bars < 0:
            raise ValueError("trade_cooldown_bars 必須為非負整數")
        params['stop_loss'] = float(params.get('stop_loss', 0.0))
        if bad_holding and params['stop_loss'] <= 0:
            raise ValueError("當啟用 bad_holding 時，stop_loss 必須為正數")
        if strategy_type == 'ssma_turn':
            params['exit_shift'] = int(params.get('exit_shift', 0))
            if params['exit_shift'] < 0:
                raise ValueError("exit_shift 必須為非負整數")
        else:
            params['buy_mult'] = float(params.get('buy_mult', 0.5))
            params['sell_mult'] = float(params.get('sell_mult', 0.5))
            params['prom_factor'] = float(params.get('prom_factor', 0.5))
            params['min_dist'] = int(params.get('min_dist', 5))
            if params['buy_mult'] < 0 or params['sell_mult'] < 0:
                raise ValueError("buy_mult 和 sell_mult 必須為非負數")
            if params['min_dist'] < 1:
                raise ValueError("min_dist 必須為正整數")
    except (ValueError, TypeError) as e:
        logger.error(f"參數驗證失敗: {e}")
        return {'trades': [], 'trade_df': pd.DataFrame(), 'trades_df': pd.DataFrame(), 'signals_df': pd.DataFrame(), 'metrics':
[], 'equity_curve': pd.Series()}

    initial_cash = 100000
    cash = initial_cash
    total_shares = 0
    trades = []
    trade_records = []
    signals = []
    in_pos = False
    entry_price = 0.0
    entry_date = None
    accum_interest = 0.0
    last_trade_idx = -trade_cooldown_bars - 1
    buy_idx = 0
    sell_idx = 0

    # 初始化 Equity Curve
    equity_curve = pd.Series(initial_cash, index=df_ind.index, dtype=float)
    cash_series = pd.Series(initial_cash, index=df_ind.index, dtype=float)
    shares_series = pd.Series(0, index=df_ind.index, dtype=float)

    signals_list = []
    if strategy_type == 'ssma_turn':
        buy_dates = sorted(buy_dates or [])
        sell_dates = sorted(sell_dates or [])
        for dt in buy_dates:
            signals_list.append(TradeSignal(ts=dt, side="BUY", reason="ssma_turn_valley"))
        for dt in sell_dates:
            signals_list.append(TradeSignal(ts=dt, side="SELL", reason="ssma_turn_peak"))
    else:
        for i in range(len(df_ind)):
            date = df_ind.index[i]
            if df_ind['smaa'].iloc[i] < df_ind['base'].iloc[i] + df_ind['sd'].iloc[i] * params['buy_mult']:
                signals_list.append(TradeSignal(ts=date, side="BUY", reason=f"{strategy_type}_buy"))
            elif df_ind['smaa'].iloc[i] > df_ind['base'].iloc[i] + df_ind['sd'].iloc[i] * params['sell_mult']:
                signals_list.append(TradeSignal(ts=date, side="SELL", reason=f"{strategy_type}_sell"))

    signals_list.sort(key=lambda x: x.ts)

    n = len(df_ind)
    scheduled_buy = np.zeros(n, dtype=bool)
    scheduled_sell = np.zeros(n, dtype=bool)
    scheduled_forced = np.zeros(n, dtype=bool)
    idx_by_date = {date: i for i, date in enumerate(df_ind.index)}

    for sig in signals_list:
        ts = pd.Timestamp(sig.ts).tz_localize(None) if sig.ts.tzinfo else sig.ts
        if ts in idx_by_date:
            i = idx_by_date[ts]
            if i + 1 < n:
                if sig.side == "BUY":
                    scheduled_buy[i + 1] = True
                elif sig.side in ["SELL", "STOP_LOSS", "FORCE_SELL"]:
                    scheduled_sell[i + 1] = True if sig.side == "SELL" else False
                    scheduled_forced[i + 1] = True if sig.side in ["STOP_LOSS", "FORCE_SELL"] else scheduled_forced[i + 1]
I’ll narrow down the backtest_unified function to focus on building or returning metrics.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg -n "metrics = {" SSSv096.py | /bin/head -n 20
rg: regex parse error:
    (?:metrics = {)
                  ^
error: repetition quantifier expects a valid decimal
root@478772c9b537:/workspace/SSS096# /usr/bin/rg -n "metrics = \{" SSSv096.py | /bin/head -n 20
834:    metrics = {
2480:            performance_metrics = {}
2703:        detailed_metrics = {
I'll browse the code around line 834 to check the metrics dictionary definition.

root@478772c9b537:/workspace/SSS096# /bin/sed -n '834,910p' SSSv096.py
    metrics = {
        'total_return': 0.0,
        'annual_return': 0.0,
        'max_drawdown': 0.0,  # 這裡之後會直接用 max_mmd 覆蓋
        'max_drawdown_duration': 0,
        'calmar_ratio': np.nan,
        'num_trades': 0,
        'win_rate': 0.0,
        'avg_win': np.nan,
        'avg_loss': np.nan,
        'payoff_ratio': np.nan,
        'sharpe_ratio': np.nan,
        'sortino_ratio': np.nan,
        'max_consecutive_wins': 0,# 新增
        'max_consecutive_losses': 0,# 新增
        'avg_holding_period': np.nan,# 新增
        'annualized_volatility': np.nan,# 新增
        'profit_factor': np.nan,# 新增
        # 'avg_mmd': np.nan, # 不再需要
        # 'max_mmd': np.nan, # 不再需要單獨欄位
    }
    if not trades:
        return metrics

    trade_metrics = pd.DataFrame(trades, columns=['entry_date', 'return', 'exit_date']).set_index('exit_date')
    trade_metrics['equity'] = (1 + trade_metrics['return']).cumprod()
    roll_max = trade_metrics['equity'].cummax()
    daily_drawdown = trade_metrics['equity'] / roll_max - 1

    # 基本指標
    metrics['total_return'] = trade_metrics['equity'].iloc[-1] - 1
    years = max((trade_metrics.index[-1] - trade_metrics.index[0]).days / 365.25, 1)
    metrics['annual_return'] = (1 + metrics['total_return']) ** (1 / years) - 1

    # 既有日內回撤（numpy 陣列）
    dd_np = (daily_drawdown < 0).astype(bool)

    # 轉成 pandas Series（索引用回 trade_metrics.index），才能安全 groupby
    dd_series = pd.Series(dd_np, index=trade_metrics.index)

    # 連續回撤區段的最長天數（True 連續段的長度最大值）
    blocks = (~dd_series).cumsum()
    dd_dur = int((dd_series.groupby(blocks).cumcount() + 1).where(dd_series).max() or 0)
    metrics['max_drawdown_duration'] = dd_dur

    # 回填 max_drawdown（安全地用 float 轉換）
    metrics['max_drawdown'] = float(daily_drawdown.min())
    # metrics['calmar_ratio'] = metrics['annual_return'] / abs(metrics['max_drawdown']) if metrics['max_drawdown'] < 0 else np.n
an
    metrics['num_trades'] = len(trade_metrics)
    metrics['win_rate'] = (trade_metrics['return'] > 0).sum() / metrics['num_trades'] if metrics['num_trades'] > 0 else 0
    metrics['avg_win'] = trade_metrics[trade_metrics['return'] > 0]['return'].mean() if metrics['win_rate'] > 0 else np.nan
    metrics['avg_loss'] = trade_metrics[trade_metrics['return'] < 0]['return'].mean() if metrics['win_rate'] < 1 else np.nan
    metrics['payoff_ratio'] = abs(metrics['avg_win'] / metrics['avg_loss']) if metrics['avg_loss'] != 0 and not np.isnan(metrics
['avg_win']) else np.nan

    # 新增:計算每日報酬率與波動率
    daily_dates = df_ind.index.intersection(pd.date_range(start=trade_metrics.index.min(), end=trade_metrics.index.max(), freq='
B'))
    daily_equity = pd.Series(index=daily_dates, dtype=float)
    for date, row in trade_metrics.iterrows():
        daily_equity.loc[date] = row['equity']
    daily_equity = daily_equity.ffill()
    daily_returns = daily_equity.pct_change().dropna()

    metrics['sharpe_ratio'] = (daily_returns.mean() * np.sqrt(252)) / daily_returns.std() if daily_returns.std() != 0 else np.na
n
    downside_returns = daily_returns[daily_returns < 0]
    downside_std = downside_returns.std() if len(downside_returns) > 0 else np.nan
    metrics['sortino_ratio'] = (daily_returns.mean() * np.sqrt(252)) / downside_std if downside_std != 0 else np.nan

    # 新增:計算最大連續盈利和最大連續虧損
    trade_metrics['win_flag'] = trade_metrics['return'] > 0
    trade_metrics['grp'] = (trade_metrics['win_flag'] != trade_metrics['win_flag'].shift(1)).cumsum()
    consec = trade_metrics.groupby(['grp', 'win_flag']).size()
    metrics['max_consecutive_wins'] = consec[consec.index.get_level_values('win_flag') == True].max() if True in consec.index.ge
t_level_values('win_flag') else 0
    metrics['max_consecutive_losses'] = consec[consec.index.get_level_values('win_flag') == False].max() if False in consec.inde
x.get_level_values('win_flag') else 0

    # 新增:計算年化波動率
    metrics['annualized_volatility'] = daily_returns.std() * np.sqrt(252) if len(daily_returns) > 0 else np.nan
I'm looking for where backtest_unified returns the result, searching near the bottom.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg -n "return {'trades'" SSSv096.py | /bin/head -n 20
rg: regex parse error:
    (?:return {'trades')
               ^
error: repetition quantifier expects a valid decimal
root@478772c9b537:/workspace/SSS096# /usr/bin/rg -n "return \{'trades'" SSSv096.py
967:        return {'trades': [], 'trade_df': pd.DataFrame(), 'trades_df': pd.DataFrame(), 'signals_df': pd.DataFrame(), 'metric
s': [], 'equity_curve': pd.Series()}
1081:        return {'trades': [], 'trade_df': pd.DataFrame(), 'trades_df': pd.DataFrame(), 'signals_df': pd.DataFrame(), 'metri
cs': {'total_return': 0.0, 'annual_return': 0.0, 'max_drawdown': 0.0, 'sharpe_ratio': 0.0, 'calmar_ratio': 0.0, 'num_trades': 0}
, 'equity_curve': pd.Series()}
1105:        return {'trades': [], 'trade_df': pd.DataFrame(), 'trades_df': pd.DataFrame(), 'signals_df': pd.DataFrame(), 'metri
cs': [], 'equity_curve': pd.Series()}
The metrics aren't updating in the result after applying the risk valve. I'll check if they're returned correctly from backtest_unified.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg -n "'metrics': metrics" SSSv096.py
1313:        'metrics': metrics,
I'll check out lines 1300-1320 to look at the final result dictionary with metrics.

root@478772c9b537:/workspace/SSS096# /bin/sed -n '1300,1325p' SSSv096.py
        'cash': cash_series,
        'shares': shares_series
    })
    # 計算權重（投資比例）
    daily_state['w'] = (daily_state['equity'] - daily_state['cash']) / daily_state['equity']
    daily_state['w'] = daily_state['w'].fillna(0).clip(0, 1)

    logger.info(f"{strategy_type} 回測結果: 總報酬率 = {metrics.get('total_return', 0):.2%}, 交易次數={metrics.get('num_trades',
 0)}")
    return {
        'trades': trades,
        'trade_df': trade_df,
        'trades_df': trades_df,
        'signals_df': signals_df,
        'metrics': metrics,
        'equity_curve': equity_curve,
        'daily_state': daily_state,  # 加入 daily_state
        'weight_curve': daily_state['w']  # 加入 weight_curve
    }
def compute_backtest_for_periods(ticker: str,periods: List[Tuple[str, str]],strategy_type: str,params: Dict,
    smaa_source: str = "Self",trade_cooldown_bars: int = 3,discount: float = 0.30,
    bad_holding: bool = False,df_price: Optional[pd.DataFrame] = None,df_factor: Optional[pd.DataFrame] = None
    ) -> List[Dict]:
    """
    對多個時段進行回測，確保返回標準化結果。
    """
    results = []
I’ll search for where result['metrics'] = is set near the risk valve.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg -n "result\['metrics'\]" app_dash.py
1878:            metrics = result['metrics']
I'll open lines 1870-1885 to check around line 1878.

root@478772c9b537:/workspace/SSS096# /bin/sed -n '1860,1885p' app_dash.py
                    trade_df = trade_df.copy()
                    trade_df.columns = [str(c).lower() for c in trade_df.columns]
                    if "trade_date" not in trade_df.columns and "date" in trade_df.columns:
                        trade_df["trade_date"] = pd.to_datetime(trade_df["date"], errors="coerce")
                    if "type" not in trade_df.columns and "action" in trade_df.columns:
                        trade_df["type"] = trade_df["action"].astype(str).str.lower()
                    if "price" not in trade_df.columns:
                        for c in ["open", "price_open", "exec_price", "px", "close"]:
                            if c in trade_df.columns:
                                trade_df["price"] = trade_df[c]
                                break

            if 'trade_date' in trade_df.columns:
                trade_df['trade_date'] = pd.to_datetime(trade_df['trade_date'])

            # 計算詳細統計信息
            detailed_stats = calculate_holding_periods(trade_df)

            metrics = result['metrics']
            comparison_data.append({
                '策略': strategy,
                '總回報率': f"{metrics.get('total_return', 0):.2%}",
                '年化回報率': f"{metrics.get('annual_return', 0):.2%}",
                '最大回撤': f"{metrics.get('max_drawdown', 0):.2%}",
                '卡瑪比率': f"{metrics.get('calmar_ratio', 0):.2f}",
                '交易次數': metrics.get('num_trades', 0),
I think the bug may stem from how metrics isn't being set properly or preserved.

Looks like the issue could lie in how the risk valve is applied in run_workflow.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg "風險閥門" -n run_enhanced_ensemble.py
I need to verify if we’re correctly merging, not replacing, metrics from the risk valve.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg -n "metrics" app_dash.py | /bin/head -n 100
1096:                    if "metrics" in rv:
1097:                        logger.info(f"[{strat}] 風險閥門效果: PF原始={rv['metrics'].get('pf_orig', 'N/A'):.2f}, PF閥門={rv[
'metrics'].get('pf_valve', 'N/A'):.2f}")
1098:                        logger.info(f"[{strat}] 風險閥門效果: MDD原始={rv['metrics'].get('mdd_orig', 'N/A'):.2f}%, MDD閥門=
{rv['metrics'].get('mdd_valve', 'N/A'):.2f}%")
1130:                    'metrics': backtest_result.stats,
1151:                    'metrics': {'total_return': 0.0, 'annual_return': 0.0, 'max_drawdown': 0.0, 'sharpe_ratio': 0.0, 'calma
r_ratio': 0.0, 'num_trades': 0},
1302:                        for k in ['trades_ui', 'trade_df', 'trade_ledger_std', 'metrics']:
1540:            metrics = result.get('metrics', {})
1545:            metrics['avg_holding_period'] = avg_holding
1568:            for k, v in metrics.items():
1729:                dbc.Row(metric_cards, style={"flex-wrap": "wrap"}, className='metrics-cards-row'),
1731:                dcc.Graph(figure=fig1, config={'displayModeBar': True}, className='main-metrics-graph'),
1878:            metrics = result['metrics']
1881:                '總回報率': f"{metrics.get('total_return', 0):.2%}",
1882:                '年化回報率': f"{metrics.get('annual_return', 0):.2%}",
1883:                '最大回撤': f"{metrics.get('max_drawdown', 0):.2%}",
1884:                '卡瑪比率': f"{metrics.get('calmar_ratio', 0):.2f}",
1885:                '交易次數': metrics.get('num_trades', 0),
1886:                '勝率': f"{metrics.get('win_rate', 0):.2%}",
1887:                '盈虧比': f"{metrics.get('payoff_ratio', 0):.2f}",
2436:    m = out["metrics"]
2628:    def _group_metrics(mask):
2655:    acc_metrics = dis_metrics = None
2659:        acc_metrics = _group_metrics(mask_acc)
2660:        dis_metrics = _group_metrics(mask_dis)
2664:        group_row("加碼段", acc_metrics),
2665:        group_row("減碼段", dis_metrics),
3447:                if not isinstance(out, dict) or "metrics" not in out:
3451:                m = out["metrics"]
3547:def calculate_pareto_metrics(equity_curve, trade_df):
3860:                    if out and "metrics" in out:
3861:                        m = out["metrics"]
3867:                        metrics = calculate_pareto_metrics(equity_curve, trade_df)
3868:                        if metrics:
3873:                                'max_drawdown': metrics['max_drawdown'],
3874:                                'pf': metrics['pf'],
3875:                                'right_tail_loss': metrics['right_tail_loss'],
3876:                                'risk_trigger_days': metrics['risk_trigger_days'],
I see metrics might be cleared around line 1302 during cleanup. I'll check further.

root@478772c9b537:/workspace/SSS096# /bin/sed -n '1290,1310p' app_dash.py
                        if 'weights_valve' in result_cap:
                            result['weight_curve'] = pack_series(result_cap['weights_valve'])

                        # 權益曲線：若是 Series
                        if 'daily_state_valve' in result_cap and 'equity' in result_cap['daily_state_valve']:
                            try:
                                result['equity_curve'] = pack_series(result_cap['daily_state_valve']['equity'])
                            except Exception:
                                # 若你存的是 DataFrame
                                result['equity_curve'] = pack_df(result_cap['daily_state_valve']['equity'].to_frame('equity'))

                        # 2) **關鍵**：把 UI 可能拿來用的舊快取清掉，強迫 UI 走新資料
                        for k in ['trades_ui', 'trade_df', 'trade_ledger_std', 'metrics']:
                            if k in result:
                                result.pop(k, None)

                        # 3) 給 UI 一個旗標與參數，便於顯示「已套用」
                        result['_risk_valve_applied'] = True
                        result['_risk_valve_params'] = {
                            'cap': float(risk_cap),
                            'atr_ratio': float(atr_ratio),
The issue: after popping 'metrics', no recomputation happens, leaving it empty later. I'll fix by recalculating performance metrics after applying the risk valve.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg -n "calculate_performance_metrics" -g "*.py"
I’ll search for calculate_metrics—maybe that's the function I need. Let’s see.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg -n "calculate_.*metrics" -g "*.py"
SSSv096.py
40:    "compute_backtest_for_periods", "calculate_metrics",
824:def calculate_metrics(trades: List[Tuple[pd.Timestamp, float, pd.Timestamp]], df_ind: pd.DataFrame, equity_curve: pd.Series
= None) -> Dict:
1295:    metrics = calculate_metrics(trades, df_ind, equity_curve)

app_dash.py
3547:def calculate_pareto_metrics(equity_curve, trade_df):
3867:                        metrics = calculate_pareto_metrics(equity_curve, trade_df)

analysis/optuna_16.py
312:def calculate_adjusted_score(total_ret, n_trades, sharpe_ratio, max_drawdown, profit_factor, equity_curve, cpcv_oos_mean, cp
cv_oos_min, sharpe_var, pbo_score, overfitting_metrics=None):
375:def calculate_enhanced_overfitting_metrics(equity_curve, params, strategy_name):
780:    overfitting_metrics = calculate_enhanced_overfitting_metrics(equity_curve, params, strat)
809:        score = calculate_adjusted_score(total_return, n_trades, sharpe_ratio, max_drawdown, profit_factor, equity_curve, cp
cv_oos_mean, cpcv_oos_min, sharpe_var, pbo_score, overfitting_metrics)
876:            overfitting_metrics = calculate_enhanced_overfitting_metrics(equity_curve, params, args.strategy)
878:            score = calculate_adjusted_score(total_return, n_trades, sharpe_ratio, max_drawdown, profit_factor, equity_curve
, cpcv_oos_mean, cpcv_oos_min, sharpe_var, pbo_score, overfitting_metrics)

analysis/OSv3.py
491:def calculate_overfitting_metrics(train_returns, test_returns, strategy_name):
671:def calculate_risk_adjusted_metrics(equity_curve, strategy_name):
742:        additional_metrics = calculate_risk_adjusted_metrics(equity_curve, method_name)
1623:                risk_adjusted_metrics = calculate_risk_adjusted_metrics(equity_curve, name)

analysis/enhanced_trade_analysis.py
226:        risk_metrics = self._calculate_trade_metrics(risk_trades)
227:        normal_metrics = self._calculate_trade_metrics(normal_trades)
306:            phase_metrics = self._calculate_trade_metrics(phase_trades)
455:            optimized_metrics = self._calculate_trade_metrics(optimized_trades)
464:    def _calculate_trade_metrics(self, trades_df):

analysis/ROEAv4.py
25:from SSSv095a1 import calculate_metrics, load_data_wrapper
407:    all_metric_cols = list(calculate_metrics([], pd.DataFrame()).keys())

analysis/OSv3_6270833.py
315:def calculate_overfitting_metrics(train_returns, test_returns, strategy_name):
394:def calculate_risk_adjusted_metrics(equity_curve, strategy_name):
873:                risk_adjusted_metrics = calculate_risk_adjusted_metrics(equity_curve, name)

analysis/past/risk_enhanced_clustering_analysis_v2.py
51:def calculate_risk_metrics(equity_curve, window=252):
166:                    risk_metrics = calculate_risk_metrics(equity_curve)
I’ll check out the calculate_metrics function in SSSv096 starting at line 824.

root@478772c9b537:/workspace/SSS096# /bin/sed -n '824,875p' SSSv096.py
def calculate_metrics(trades: List[Tuple[pd.Timestamp, float, pd.Timestamp]], df_ind: pd.DataFrame, equity_curve: pd.Series = No
ne) -> Dict:
    """
    計算回測績效指標.
    Args:
        trades: 交易記錄,包含日期和報酬率.
        df_ind: 指標數據 DataFrame,包含交易日索引.
        equity_curve: 全部回測期間的每日資產淨值（可選, 若要計算持有期間MMD需提供）
    Returns:
        Dict: 包含總回報率、年化回報率、最大回撤等指標.
    """
    metrics = {
        'total_return': 0.0,
        'annual_return': 0.0,
        'max_drawdown': 0.0,  # 這裡之後會直接用 max_mmd 覆蓋
        'max_drawdown_duration': 0,
        'calmar_ratio': np.nan,
        'num_trades': 0,
        'win_rate': 0.0,
        'avg_win': np.nan,
        'avg_loss': np.nan,
        'payoff_ratio': np.nan,
        'sharpe_ratio': np.nan,
        'sortino_ratio': np.nan,
        'max_consecutive_wins': 0,# 新增
        'max_consecutive_losses': 0,# 新增
        'avg_holding_period': np.nan,# 新增
        'annualized_volatility': np.nan,# 新增
        'profit_factor': np.nan,# 新增
        # 'avg_mmd': np.nan, # 不再需要
        # 'max_mmd': np.nan, # 不再需要單獨欄位
    }
    if not trades:
        return metrics

    trade_metrics = pd.DataFrame(trades, columns=['entry_date', 'return', 'exit_date']).set_index('exit_date')
    trade_metrics['equity'] = (1 + trade_metrics['return']).cumprod()
    roll_max = trade_metrics['equity'].cummax()
    daily_drawdown = trade_metrics['equity'] / roll_max - 1

    # 基本指標
    metrics['total_return'] = trade_metrics['equity'].iloc[-1] - 1
    years = max((trade_metrics.index[-1] - trade_metrics.index[0]).days / 365.25, 1)
    metrics['annual_return'] = (1 + metrics['total_return']) ** (1 / years) - 1

    # 既有日內回撤（numpy 陣列）
    dd_np = (daily_drawdown < 0).astype(bool)

    # 轉成 pandas Series（索引用回 trade_metrics.index），才能安全 groupby
    dd_series = pd.Series(dd_np, index=trade_metrics.index)

    # 連續回撤區段的最長天數（True 連續段的長度最大值）
    blocks = (~dd_series).cumsum()
I'm reviewing risk_valve_backtest to understand trade_ledger_valve and its columns.

root@478772c9b537:/workspace/SSS096# /bin/sed -n '1359,1395p' SSS_EnsembleTab.py
def risk_valve_backtest(open_px: pd.Series,
                        w: pd.Series,
                        cost,
                        benchmark_df: pd.DataFrame,
                        mode: str = "cap",
                        cap_level: float = 0.5,
                        slope20_thresh: float = 0.0,
                        slope60_thresh: float = 0.0,
                        atr_win: int = 20,
                        atr_ref_win: int = 60,
                        atr_ratio_mult: float = 1.3) -> dict:
    """回傳：原始與閥門版本的績效、右尾削減度、以及兩版 equity/ledger"""
    sig = compute_risk_valve_signals(benchmark_df, slope20_thresh, slope60_thresh,
                                     atr_win, atr_ref_win, atr_ratio_mult)
    w2 = apply_valve_to_weights(w, sig["risk_trigger"], mode, cap_level)

    # 原始版本
    daily_state1, ledger1 = build_portfolio_ledger(open_px, w, cost)
    # 閥門版本
    daily_state2, ledger2 = build_portfolio_ledger(open_px, w2, cost)

    # 交易統計（只用賣出列；符合 re.txt 對實現損益的口徑）
    r1 = _sell_returns_pct_from_ledger(ledger1)
    r2 = _sell_returns_pct_from_ledger(ledger2)
    pf1 = (r1[r1>0].sum() / abs(r1[r1<0].sum())) if (r1[r1<0].sum()!=0) else np.inf
    pf2 = (r2[r2>0].sum() / abs(r2[r2<0].sum())) if (r2[r2<0].sum()!=0) else np.inf
    mdd1 = _mdd_from_daily_equity(daily_state1["equity"])
    mdd2 = _mdd_from_daily_equity(daily_state2["equity"])

    # 右尾削減：比較兩版的「>P90 的正報酬總和」
    def right_tail_sum(x: pd.Series):
        if x.empty: return 0.0
        thr = x.quantile(0.90)
        return float(x[x > max(thr, 0)].sum())
    rt1 = right_tail_sum(r1)
    rt2 = right_tail_sum(r2)
    right_tail_reduction = (rt1 - rt2)
I need to check the build_portfolio_ledger function to confirm the ledger's structure.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg -n "build_portfolio_ledger" -g "*.py"
SSS_EnsembleTab.py
363:def build_portfolio_ledger(open_px: pd.Series, w: pd.Series, cost: CostParams,
850:    daily_state, trade_ledger = build_portfolio_ledger(
1376:    daily_state1, ledger1 = build_portfolio_ledger(open_px, w, cost)
1378:    daily_state2, ledger2 = build_portfolio_ledger(open_px, w2, cost)
I'll open the build_portfolio_ledger function definition around line 363. Let's check it out!

root@478772c9b537:/workspace/SSS096# /bin/sed -n '363,470p' SSS_EnsembleTab.py
def build_portfolio_ledger(open_px: pd.Series, w: pd.Series, cost: CostParams,
                          initial_capital: float = 1_000_000.0, lot_size: int | None = None) -> Tuple[pd.DataFrame, pd.DataFrame
]:
    """
    依照每日 open 價與目標權重 w_t（含 floor、delta_cap 等限制後的最終 w_t），
    產出兩個 DataFrame：
      1) daily_state: 每日現金/持倉/總資產/權重
      2) trade_ledger: 只有權重變動日的交易明細（買賣金額、費用、稅、交易後資產）
    """
    if cost is None:
        cost = CostParams()

    # 計算日報酬率
    r = open_px.shift(-1) / open_px - 1
    r = r.dropna()

    # 權益曲線
    E = pd.Series(index=r.index, dtype=float)
    E.iloc[0] = initial_capital

    # 現金曲線
    cash = pd.Series(index=r.index, dtype=float)
    cash.iloc[0] = initial_capital

    # 持倉價值曲線
    position_value = pd.Series(index=r.index, dtype=float)
    position_value.iloc[0] = 0.0

    # 交易記錄
    trades = []

    # 交易流水帳（詳細記錄）
    trade_ledger = []

    for i in range(1, len(r)):
        prev_w = w.iloc[i-1] if i-1 < len(w) else 0
        curr_w = w.iloc[i] if i < len(w) else 0

        # 權重變化
        dw = curr_w - prev_w

        if abs(dw) > 0.001:  # 有顯著變化
            # 1) 以「總權益」計執行名目金額
            exec_notional = abs(dw) * E.iloc[i-1]

            if dw > 0:  # 買入
                c = exec_notional * cost.buy_rate
                tax = 0.0
                total_cost = c

                # 計算顯示用股數（僅供 UI/報表，不影響邏輯）
                px = float(open_px.iloc[i])
                shares_before = (prev_w * E.iloc[i-1]) / px if px > 0 else 0.0
                delta_units   =  exec_notional / px if px > 0 else 0.0
                shares_after  = shares_before + delta_units

                # 交易明細（給圖表/表格）—補上權重欄位（買入也有）
                trades.append({
                    'trade_date': r.index[i],
                    'type': 'buy',
                    'price_open': float(open_px.iloc[i]),
                    'price': float(open_px.iloc[i]),
                    'weight_change': float(dw),          # signed dw
                    'w_before': float(prev_w),
                    'w_after': float(curr_w),
                    'shares_before': float(shares_before),
                    'shares_after': float(shares_after),
                    'exec_notional': float(exec_notional),
                    'equity_after': float(E.iloc[i-1]),  # 交易發生在 i 開盤，交易後的總資產(名目)≈前一日 E 扣費用
                    'cash_after': np.nan                 # 真正的日終現金在 daily_state 內，這裡僅供 UI 百分比推導（可選）
                })

                # 交易流水帳（詳細）
                trade_ledger.append({
                    'date': r.index[i],
                    'type': 'buy',
                    'open': open_px.iloc[i],
                    'delta_units': delta_units,
                    'exec_notional': exec_notional,
                    'fee_buy': c,
                    'fee_sell': 0.0,
                    'tax': tax,  # 賣出才會有證交稅，這裡為 0
                    'shares_before': shares_before,
                    'shares_after': shares_after,
                    'w_before': prev_w,
                    'w_after': curr_w,
                    'cash_after': cash.iloc[i-1] - exec_notional - c,
                    'equity_open_after_trade': E.iloc[i-1] - total_cost,
                    'equity_after': E.iloc[i-1] * (1 + r.iloc[i] * curr_w) - total_cost
                })
            else:  # 賣出
                c = exec_notional * cost.sell_rate
                tax = exec_notional * cost.sell_tax_rate
                total_cost = c + tax

                # 計算顯示用股數（僅供 UI/報表，不影響邏輯）
                px = float(open_px.iloc[i])
                shares_before = (prev_w * E.iloc[i-1]) / px if px > 0 else 0.0
                delta_units   = -exec_notional / px if px > 0 else 0.0
                shares_after  = shares_before + delta_units

                # 交易明細（給圖表/表格）—補上權重欄位
                trades.append({
                    'trade_date': r.index[i],
                    'type': 'sell',
                    'price_open': float(open_px.iloc[i]),
                    'price': float(open_px.iloc[i]),
                    'weight_change': float(dw),          # 負數
                    'w_before': float(prev_w),
I’m considering using calculate_pareto_metrics for basic metrics, should check its definition first.

root@478772c9b537:/workspace/SSS096# /bin/sed -n '3547,3585p' app_dash.py
def calculate_pareto_metrics(equity_curve, trade_df):
    """計算 Pareto Map 所需的指標"""
    try:
        # 初始化指標
        max_drawdown = 0.0
        pf = 1.0
        right_tail_loss = 0.0  # 預設：無調整
        risk_trigger_days = 50

        # 處理權益曲線數據
        if equity_curve is not None and not equity_curve.empty:
            # 確保權益曲線是 Series
            if isinstance(equity_curve, pd.DataFrame):
                if len(equity_curve.columns) == 1:
                    equity_curve = equity_curve.iloc[:, 0]
                else:
                    # 如果有多列，使用第一列
                    equity_curve = equity_curve.iloc[:, 0]

            # 計算日報酬率
            daily_returns = equity_curve.pct_change().dropna()

            if len(daily_returns) > 0:
                # 1. 最大回撤（愈左愈好）
                peak = equity_curve.expanding().max()
                drawdown = (equity_curve - peak) / peak
                max_drawdown = abs(drawdown.min()) if not drawdown.empty else 0.0

                # 2. PF（獲利因子，愈上愈好）
                if trade_df is not None and not trade_df.empty and 'return' in trade_df.columns:
                    profits = trade_df[trade_df['return'] > 0]['return'].sum()
                    losses = abs(trade_df[trade_df['return'] < 0]['return'].sum())
                    pf = profits / losses if losses > 0 else (profits if profits > 0 else 1.0)
                else:
                    # 如果沒有交易數據，用年化報酬率代替
                    total_return = (equity_curve.iloc[-1] / equity_curve.iloc[0] - 1)
                    annual_return = total_return * (252 / len(daily_returns))
                    pf = 1 + annual_return  # 轉換為 PF 格式
I'll recompute metrics by transforming the trade_ledger into a list of trades. Let's search for related functions.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg -n "trade_ledger" SSSv096.py | /bin.head -n 40
bash: /bin.head: No such file or directory
I'll try again with /bin/head using "rg ... | /bin/head".

root@478772c9b537:/workspace/SSS096# /usr/bin/rg -n "trade_ledger" SSSv096.py | /bin/head -n 50
1017:                open_px, w, trades, stats, method_name, equity, daily_state, trade_ledger = run_ensemble(cfg)
1020:                ledger_ui   = normalize_trades_for_ui(trade_ledger)
1025:                    'trade_ledger': ledger_ui,
2349:                # 優先使用 trade_ledger（Ensemble 的完整交易記錄），其次用 trade_df
2351:                if strategy_type == 'ensemble' and 'trade_ledger' in result and not result['trade_ledger'].empty:
2352:                    display_df = result['trade_ledger']
Looks like build_trade_snapshots_from_ledger at line 1288 might help. Checking it again.

root@478772c9b537:/workspace/SSS096# /bin/sed -n '1240,1288p' SSS_EnsembleTab.py

def compute_risk_valve_signals(benchmark_df: pd.DataFrame,
                               slope20_thresh: float = 0.0,
                               slope60_thresh: float = 0.0,
                               atr_win: int = 20,
                               atr_ref_win: int = 60,
                               atr_ratio_mult: float = 1.3) -> pd.DataFrame:
    """輸入：基準（日頻），欄至少有 close/收盤價；若無高低價自動回退。
       輸出：含 slope_20d/60d、atr、atr_ratio、risk_trigger(bool) 的 DataFrame"""
    b = benchmark_df.copy()
    # 欄位對齊
    c_close = _get_col(b, "收盤價", "close")
    c_high  = _get_col(b, "最高價", "high")
    c_low   = _get_col(b, "最低價", "low")
    if c_close is None:
        raise ValueError("benchmark_df 需包含 收盤價/close")

    b = b.sort_index()
    close = pd.to_numeric(b[c_close], errors="coerce")

    # 斜率：用「t/t-n - 1」做簡潔斜率（符合你要的方向判斷）
    b["slope_20d"] = close.pct_change(20)
    b["slope_60d"] = close.pct_change(60)

    # ATR：若無高低價，用 |Δclose| 近似 TR
    prev_close = close.shift(1)
    if c_high and c_low:
        high = pd.to_numeric(b[c_high], errors="coerce")
        low  = pd.to_numeric(b[c_low], errors="coerce")
        tr = pd.concat([
            (high - low),
            (high - prev_close).abs(),
            (low  - prev_close).abs()
        ], axis=1).max(axis=1)
    else:
        tr = close.diff().abs()

    b["atr"] = tr.rolling(atr_win, min_periods=atr_win).mean()
    b["atr_ratio"] = b["atr"] / b["atr"].rolling(atr_ref_win, min_periods=atr_ref_win).mean()

    # 風險觸發：兩斜率皆 < 門檻，且 ATR 抬頭超過倍率
    b["risk_trigger"] = (b["slope_20d"] < slope20_thresh) & \
                        (b["slope_60d"] < slope60_thresh) & \
                        (b["atr_ratio"] > atr_ratio_mult)
    return b[["slope_20d", "slope_60d", "atr", "atr_ratio", "risk_trigger"]]


# === PATCH: 風險閥門施作在權重 ===
def apply_valve_to_weights(w: pd.Series,
I can recompute metrics with build_trade_snapshots_from_ledger, convert ledger_valve to DataFrame, and derive trades. I'll also check _sell_returns_pct_from_ledger.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg -n "_sell_returns_pct_from_ledger" -g "SSS_EnsembleTab.py"
SSS_EnsembleTab.py
1338:def _sell_returns_pct_from_ledger(trade_ledger: pd.DataFrame) -> pd.Series:
1381:    r1 = _sell_returns_pct_from_ledger(ledger1)
1382:    r2 = _sell_returns_pct_from_ledger(ledger2)
1469:    sell_ret = _sell_returns_pct_from_ledger(trade_ledger)
1476:        sells_in_phase = _sell_returns_pct_from_ledger(tl_idxed.loc[mask_t])
I'll check out the definition at line 1338.

def _sell_returns_pct_from_ledger(trade_ledger: pd.DataFrame) -> pd.Series:
    tl = trade_ledger.copy()
    if "type" in tl.columns: tl.rename(columns={"type":"交易類型"}, inplace=True)
    if "equity_after" in tl.columns: tl.rename(columns={"equity_after":"交易後權益"}, inplace=True)
    if "equity_open_after_trade" in tl.columns: tl.rename(columns={"equity_open_after_trade":"交易後開盤權益"}, inplace=True)
    tl = tl.sort_values("date" if "date" in tl.columns else "交易日期")
    # 用「交易後開盤權益 → 交易日終權益」的變化當該筆交易的日損益（含成本）
    if "交易後開盤權益" in tl.columns and "交易後權益" in tl.columns:
        delta = (tl["交易後權益"] - tl["交易後開盤權益"]) / tl["交易後開盤權益"]
        tl["盈虧%"] = delta * 100.0
    elif "盈虧%" not in tl.columns:
        tl["盈虧%"] = 0.0
    mask_sell = tl["交易類型"].astype(str).str.lower().eq("sell")
    return pd.to_numeric(tl.loc[mask_sell, "盈虧%"], errors="coerce").dropna()

def _mdd_from_daily_equity(equity: pd.Series) -> float:
    eq = pd.to_numeric(equity, errors="coerce").dropna()
    if eq.empty: return 0.0
    dd = eq / eq.cummax() - 1.0
    return float(dd.min())
Since calculate_metrics requires entry and exit dates, I'll create a workaround by using the sell date. I'll leverage the equity series for key metrics like total return, max drawdown, etc., while avoiding holding periods. I'll calculate other metrics like win rate and average wins using equity and returns, then expand with additional metrics like calmar ratio and holding periods.

To fix metrics vanishing after applying the risk valve, I’ll avoid removing them, and recompute post-valve metrics. I'll gather trade details from the existing ledger and snapshots for accurate computation.

root@478772c9b537:/workspace/SSS096# /bin/sed -n '1320,1338p' SSS_EnsembleTab.py
    if "cash_after" in df.columns: df.rename(columns={"cash_after": "交易後現金"}, inplace=True)
    if "open" in df.columns: df.rename(columns={"open": "開盤價"}, inplace=True)
    if "w_before" in df.columns: df.rename(columns={"w_before": "交易前權重"}, inplace=True)
    if "w_after" in df.columns: df.rename(columns={"w_after": "交易後權重"}, inplace=True)

    df["交易日期"] = pd.to_datetime(df["交易日期"], errors="coerce")
    df = df.dropna(subset=["交易日期"]).sort_values("交易日期").reset_index(drop=True)

    df["總資產"] = pd.to_numeric(df.get("交易後權益", 0), errors="coerce").fillna(0) + \
                   pd.to_numeric(df.get("交易後現金", 0), errors="coerce").fillna(0)
    df["前次總資產"] = df["總資產"].shift(1)
    df["每筆盈虧"] = df["總資產"] - df["前次總資產"]
    df["每筆盈虧%"] = (df["每筆盈虧"] / df["前次總資產"]).replace([np.inf, -np.inf], np.nan) * 100
    df.loc[df.index.min(), ["每筆盈虧", "每筆盈虧%"]] = 0.0
    return df


# === PATCH: 只用賣出列計交易統計 & MDD 以日資產曲線算 ===
def _sell_returns_pct_from_ledger(trade_ledger: pd.DataFrame) -> pd.Series:
# 基準（有高低價就帶上）
                        bench = pd.DataFrame(index=pd.to_datetime(df_raw.index))
                        if 'close' in df_raw.columns:
                            bench["收盤價"] = pd.to_numeric(df_raw["close"], errors="coerce")
                        elif '收盤價' in df_raw.columns:
                            bench["收盤價"] = pd.to_numeric(df_raw["收盤價"], errors="coerce")
                        if 'high' in df_raw.columns and 'low' in df_raw.columns:
                            bench["最高價"] = pd.to_numeric(df_raw["high"], errors="coerce")
                            bench["最低價"] = pd.to_numeric(df_raw["low"], errors="coerce")
                        elif '最高價' in df_raw.columns and '最低價' in df_raw.columns:
                            bench["最高價"] = pd.to_numeric(df_raw["最高價"], errors="coerce")
                            bench["最低價"] = pd.to_numeric(df_raw["最低價"], errors="coerce")

                        result_cap = risk_valve_backtest(
                            open_px=open_px,
                            w=ds["w"].astype(float).reindex(open_px.index).fillna(0.0),
                            cost=cost,
                            benchmark_df=bench,
                            mode="cap",
                            cap_level=1.0,
                        )
                    except Exception as e:
                        logger.warning(f"[{strat}] 無法導入 risk_valve_backtest: {e}")
                        result_cap = None

                    if result_cap:
                        # === 安全覆寫：清掉舊鍵並補齊新鍵 ===
                        logger.info(f"[UI_CHECK] 即將覆寫：new_trades={len(result_cap.get('trade_ledger_valve', pd.DataFrame()))
} rows, new_ds={len(result_cap.get('daily_state_valve', pd.DataFrame()))} rows")

                        # 1) 覆寫結果 —— 一律用 pack_df/pack_series
                        if 'trade_ledger_valve' in result_cap:
                            result['trades'] = pack_df(result_cap['trade_ledger_valve'])
                            result['trade_ledger'] = pack_df(result_cap['trade_ledger_valve'])
                            result['trade_ledger_std'] = pack_df(result_cap['trade_ledger_valve'])

                        if 'daily_state_valve' in result_cap:
                            result['daily_state'] = pack_df(result_cap['daily_state_valve'])
                            result['daily_state_std'] = pack_df(result_cap['daily_state_valve'])

                        if 'weights_valve' in result_cap:
                            result['weight_curve'] = pack_series(result_cap['weights_valve'])

                        # 權益曲線：若是 Series
                        if 'daily_state_valve' in result_cap and 'equity' in result_cap['daily_state_valve']:
                            try:
                                result['equity_curve'] = pack_series(result_cap['daily_state_valve']['equity'])
                            except Exception:
                                # 若你存的是 DataFrame
                                result['equity_curve'] = pack_df(result_cap['daily_state_valve']['equity'].to_frame('equity'))

                        # 2) **關鍵**：把 UI 可能拿來用的舊快取清掉，強迫 UI 走新資料
                        for k in ['trades_ui', 'trade_df', 'trade_ledger_std', 'metrics']:
                            if k in result:
                                result.pop(k, None)

                        # 3) 給 UI 一個旗標與參數，便於顯示「已套用」
                        result['_risk_valve_applied'] = True
                        result['_risk_valve_params'] = {
                            'cap': float(risk_cap),
                            'atr_ratio': float(atr_ratio),
                            'atr20_last': float(atr_20_valid.iloc[-1]) if len(atr_20_valid) > 0 else None,
                            'atr60_last': float(atr_60_valid.iloc[-1]) if len(atr_60_valid) > 0 else None,
                        }

                        true_days = int(mask_aligned.sum())
                        logger.info(f"[{strat}] 全局風險閥門已套用（逐日），風險天數={true_days}, CAP={risk_cap:.2f}")
                    else:
                        logger.warning(f"[{strat}] 風險閥門重算沒有返回結果")

        results[strat] = result
I see the issue: popping trade_df causes missing values for later calculations like avg_holding.

root@478772c9b537:/workspace/SSS096# /bin/sed -n '1530,1565p' app_dash.py
                # 為了 100% 保證 weight_change 出現，先確保權重欄位
                ledger_src = _ensure_weight_columns(ledger_src)
                # 使用新的統一格式化函式
                ledger_display = format_trade_like_df_for_display(ledger_src)
                ledger_columns = [{"name": i, "id": i} for i in ledger_display.columns]
                ledger_data = ledger_display.to_dict('records')
            else:
                ledger_columns = []
                ledger_data = []

            metrics = result.get('metrics', {})
            tooltip = f"{strategy} 策略説明"
            param_display = {k: v for k, v in param_presets[strategy].items() if k != "strategy_type"}
            param_str = ", ".join(f"{k}: {v}" for k, v in param_display.items())
            avg_holding = calculate_holding_periods(trade_df)
            metrics['avg_holding_period'] = avg_holding

            label_map = {
                "total_return": "總回報率",
                "annual_return": "年化回報率",
                "win_rate": "勝率",
                "max_drawdown": "最大回撤",
                "max_drawdown_duration": "回撤持續",
                "calmar_ratio": "卡瑪比率",
                "sharpe_ratio": "夏普比率",
                "sortino_ratio": "索提諾比率",
                "payoff_ratio": "盈虧比",
                "profit_factor": "盈虧因子",
                "num_trades": "交易次數",
                "avg_holding_period": "平均持倉天數",
                "annualized_volatility": "年化波動率",
                "max_consecutive_wins": "最大連續盈利",
                "max_consecutive_losses": "最大連續虧損",
                "avg_win": "平均盈利",
                "avg_loss": "平均虧損",
            }
After popping trade_df, I need to reconstruct it from trade_ledger_valve to ensure metrics are calculated correctly. I'll compute it using build_trade_snapshots_from_ledger and store it back in result['trade_df']. Then, I can compute the remaining metrics.

I need to confirm if functions from SSS_EnsembleTab are already imported at the top of app_dash.

root@478772c9b537:/workspace/SSS096# /bin/head -n 40 app_dash.py
import dash
from dash import dcc, html, dash_table, Input, Output, State, ctx, no_update
import dash_bootstrap_components as dbc
import pandas as pd
import plotly.graph_objects as go
import json
import io
from dash.dependencies import ALL
import shutil
import os
from datetime import datetime, timedelta
from pathlib import Path
import joblib
from analysis import config as cfg
import yfinance as yf
import logging
import numpy as np
from urllib.parse import quote as urlparse

# 配置 logger - 使用新的顯式初始化
from analysis.logging_config import init_logging
import os

# 強制啟用檔案日誌，不依賴環境變數
os.environ["SSS_CREATE_LOGS"] = "1"

# 直接呼叫 init_logging，它會使用正確的日誌目錄
init_logging(enable_file=True)
logger = logging.getLogger("SSS.App")

# 設定為 DEBUG 級別，詳細調試資訊會寫入日誌檔案
logger.setLevel(logging.DEBUG)
logger.info("已啟用詳細調試模式 - 調試資訊將寫入日誌檔案")
logger.info(f"日誌目錄: {os.path.abspath('analysis/log')}")

# ATR 計算函數
def calculate_atr(df, window):
    """計算 ATR (Average True Range)"""
    try:
        # 支援多種欄位名稱格式
I need to import functions like _sell_returns_pct_from_ledger and calculate_metrics where needed.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg -n "calculate_holding_periods" app_dash.py
211:    compute_ssma_turn_combined, backtest_unified, plot_stock_price, plot_equity_cash, plot_weight_series, calculate_holding_
periods
1544:            avg_holding = calculate_holding_periods(trade_df)
1876:            detailed_stats = calculate_holding_periods(trade_df)
I see the calculate_holding_periods import on line 211. I'll check lines 200-220.

root@478772c9b537:/workspace/SSS096# /bin.sed -n '200,220p' app_dash.py
bash: /bin.sed: No such file or directory
root@478772c9b537:/workspace/SSS096# /bin/sed -n '200,220p' app_dash.py

    if isinstance(data, (list, dict)):
        try:
            return pd.Series(data)
        except Exception:
            return pd.Series(dtype=float)

    return pd.Series(dtype=float)

from SSSv096 import (
    param_presets, load_data, compute_single, compute_dual, compute_RMA,
    compute_ssma_turn_combined, backtest_unified, plot_stock_price, plot_equity_cash, plot_weight_series, calculate_holding_peri
ods
)

# 彈性匯入 pack_df/pack_series 函數
try:
    from sss_core.schemas import pack_df, pack_series
except Exception:
    from schemas import pack_df, pack_series

# 匯入權重欄位確保函式
I need to import calculate_metrics and extend the import to include additional functions.

I’ll place computation of trade_df and metrics after popping, ensuring new metrics are preserved.

I’ll add Traditional Chinese comments with timestamps and update the import for new functions.

I'll attempt running the PowerShell script if available, noting environment limitations.

root@478772c9b537:/workspace/SSS096# /bin/sed -n '200,220p' app_dash.py

    if isinstance(data, (list, dict)):
        try:
            return pd.Series(data)
        except Exception:
            return pd.Series(dtype=float)

    return pd.Series(dtype=float)

from SSSv096 import (
    param_presets, load_data, compute_single, compute_dual, compute_RMA,
    compute_ssma_turn_combined, backtest_unified, plot_stock_price, plot_equity_cash, plot_weight_series, calculate_holding_peri
ods
)

# 彈性匯入 pack_df/pack_series 函數
try:
    from sss_core.schemas import pack_df, pack_series
except Exception:
    from schemas import pack_df, pack_series

# 匯入權重欄位確保函式
I'll add calculate_metrics to the import and break the long lines. Next, finding the risk_valve_backtest import.

root@478772c9b537:/workspace/SSS096# /usr/bin/rg -n "risk_valve_backtest" -n app_dash.py
893:                    from SSS_EnsembleTab import risk_valve_backtest, CostParams
918:                        rv = risk_valve_backtest(
1075:                    from SSS_EnsembleTab import risk_valve_backtest
1080:                    rv = risk_valve_backtest(
1238:                    # 若你沿用現有的 risk_valve_backtest，給 cap_level=1.0 表示「w 已經是目標序列」
1240:                        from SSS_EnsembleTab import risk_valve_backtest, CostParams
1264:                        result_cap = risk_valve_backtest(
1273:                        logger.warning(f"[{strat}] 無法導入 risk_valve_backtest: {e}")
2426:        from SSS_EnsembleTab import risk_valve_backtest
2427:        out = risk_valve_backtest(
3424:    # 檢查是否可以匯入 risk_valve_backtest
3426:        from SSS_EnsembleTab import risk_valve_backtest
3427:        logger.info("成功匯入 risk_valve_backtest")
3429:        logger.error(f"匯入 risk_valve_backtest 失敗: {e}")
3430:        return go.Figure(), f"❌ 無法匯入 risk_valve_backtest: {e}"
3440:                out = risk_valve_backtest(
3837:        # 檢查是否可以匯入 risk_valve_backtest
3839:            from SSS_EnsembleTab import risk_valve_backtest
3840:            logger.info("成功匯入 risk_valve_backtest")
3842:            logger.error(f"匯入 risk_valve_backtest 失敗: {e}")
3853:                    out = risk_valve_backtest(
3865:                        trade_df = None  # risk_valve_backtest 不直接提供交易記錄
I’ll update imports at lines 893 and 1240 to include new functions to cover all bases.

root@478772c9b537:/workspace/SSS096# /bin/sed -n '884,904p' app_dash.py
                except Exception:
                    pass

                if force_trigger:
                    valve_triggered_local = True
                    if ratio_local is None:
                        ratio_local = 1.5

                if valve_triggered_local:
                    from SSS_EnsembleTab import risk_valve_backtest, CostParams
                    # 取得 open 價；df_raw 欄位名稱是小寫
                    open_px = df_raw['open'] if 'open' in df_raw.columns else df_raw['close']
                    # 從回測輸出抓 w（先用標準化 daily_state，如果沒有就用原 daily_state）
                    w_series = None
                    try:
                        ds_std = df_from_pack(result.get('daily_state_std'))
                        if ds_std is not None and not ds_std.empty and 'w' in ds_std.columns:
                            w_series = ds_std['w']
                    except Exception:
                        pass
                    if w_series is None:
I'm tracing the risk valve behavior for individual strategies and checking if metrics are recomputed.

root@478772c9b537:/workspace/SSS096# /bin.sed -n '904,940p' app_dash.py
bash: /bin.sed: No such file or directory
root@478772c9b537:/workspace/SSS096# /bin/sed -n '904,940p' app_dash.py
                    if w_series is None:
                        ds = df_from_pack(result.get('daily_state'))
                        if ds is not None and not ds.empty and 'w' in ds.columns:
                            w_series = ds['w']

                    if w_series is not None:
                        # 交易成本（與 Ensemble 分支一致）
                        trade_cost = strat_params.get('trade_cost', {})
                        cost_params = CostParams(
                            buy_fee_bp=float(trade_cost.get("buy_fee_bp", 4.27)),
                            sell_fee_bp=float(trade_cost.get("sell_fee_bp", 4.27)),
                            sell_tax_bp=float(trade_cost.get("sell_tax_bp", 30.0))
                        )

                        rv = risk_valve_backtest(
                            open_px=open_px,
                            w=w_series,
                            cost=cost_params,
                            benchmark_df=df_raw,
                            mode="cap",
                            cap_level=float(risk_cap),
                        )

                        # 覆寫結果，確保 UI 與輸出一致（和 Ensemble 分支對齊）
                        result['equity_curve']     = pack_series(rv["daily_state_valve"]["equity"])
                        result['daily_state']      = pack_df(rv["daily_state_valve"])
                        result['daily_state_std']  = pack_df(rv["daily_state_valve"])
                        result['trade_ledger']     = pack_df(rv["trade_ledger_valve"])
                        result['trade_ledger_std'] = pack_df(rv["trade_ledger_valve"])
                        result['weight_curve']     = pack_series(rv["weights_valve"])
                        # 給 UI 的標記（下個小節會用到）
                        result['valve'] = {
                            "applied": True,
                            "cap": float(risk_cap),
                            "atr_ratio": ratio_local
                        }
I'll carry on from line 940 to review the following sections.

root@478772c9b537:/workspace/SSS096# /bin/sed -n '940,980p' app_dash.py

                        logger.info(f"[{strat}] SSMA 風險閥門已套用（cap={risk_cap}, ratio={ratio_local:.4f}）")
                    else:
                        logger.warning(f"[{strat}] SSMA 無法取得權重序列，跳過風險閥門套用")
                else:
                    logger.info(f"[{strat}] SSMA 風險閥門未觸發，使用原始結果")
                    # 給 UI 的標記（未觸發）
                    result['valve'] = {
                        "applied": False,
                        "cap": float(risk_cap),
                        "atr_ratio": ratio_local if ratio_local is not None else "N/A"
                    }
        elif strat_type == 'ensemble':
            # 使用新的 ensemble_runner 避免循環依賴
            try:
                from runners.ensemble_runner import run_ensemble_backtest
                from SSS_EnsembleTab import EnsembleParams, CostParams, RunConfig

                # 把 SSSv096 的巢狀參數攤平
                flat_params = {}
                flat_params.update(strat_params.get('params', {}))
                flat_params.update(strat_params.get('trade_cost', {}))
                flat_params['method'] = strat_params.get('method', 'majority')
                flat_params['ticker'] = ticker

                # 使用比例門檻避免 N 變動時失真
                if 'majority_k' in flat_params and flat_params.get('method') == 'majority':
                    flat_params['majority_k_pct'] = 0.55
                    flat_params.pop('majority_k', None)
                    logger.info(f"[Ensemble] 使用比例門檻 majority_k_pct={flat_params['majority_k_pct']}")

                # 創建配置
                ensemble_params = EnsembleParams(
                    floor=flat_params.get("floor", 0.2),
                    ema_span=flat_params.get("ema_span", 3),
                    delta_cap=flat_params.get("delta_cap", 0.3),
                    majority_k=flat_params.get("majority_k", 6),
                    min_cooldown_days=flat_params.get("min_cooldown_days", 1),
                    min_trade_dw=flat_params.get("min_trade_dw", 0.01)
                )
I’ll adjust imports and recompute metrics in the global risk valve block after popping data.

root@478772c9b537:/workspace/SSS096# sed -n '200,220p' app_dash.py

    if isinstance(data, (list, dict)):
        try:
            return pd.Series(data)
        except Exception:
            return pd.Series(dtype=float)

    return pd.Series(dtype=float)

from SSSv096 import (
    param_presets, load_data, compute_single, compute_dual, compute_RMA,
    compute_ssma_turn_combined, backtest_unified, plot_stock_price, plot_equity_cash, plot_weight_series, calculate_holding_peri
ods
)

# 彈性匯入 pack_df/pack_series 函數
try:
    from sss_core.schemas import pack_df, pack_series
except Exception:
    from schemas import pack_df, pack_series

# 匯入權重欄位確保函式
I'll update the import list to include calculate_metrics.

root@478772c9b537:/workspace/SSS096# apply_patch <<'PATCH'
> *** Begin Patch
> *** Update File: app_dash.py
> @@
> -from SSSv096 import (
> -    param_presets, load_data, compute_single, compute_dual, compute_RMA,
> -    compute_ssma_turn_combined, backtest_unified, plot_stock_price, plot_equity_cash, plot_weight_series, calculate_holding_p
eriods
> -)
> +from SSSv096 import (
> +    param_presets, load_data, compute_single, compute_dual, compute_RMA,
> +    compute_ssma_turn_combined, backtest_unified, plot_stock_price,
> +    plot_equity_cash, plot_weight_series, calculate_holding_periods,
> +    calculate_metrics
> +)
> *** End Patch
> PATCH
Success. Updated the following files:
M app_dash.py
I’ll adjust the import for risk_valve_backtest around lines 1236-1248.

root@478772c9b537:/workspace/SSS096# sed -n '1232,1252p' app_dash.py

                    # 4) 回寫 ds，並重算交易/權益
                    result["daily_state_std"] = pack_df(ds)

                    # open 價（沒有 open 就退而求其次用收盤價）
                    open_px = (df_raw["open"] if "open" in df_raw.columns else df_raw.get("收盤價")).astype(float)
                    open_px = open_px.reindex(ds.index).dropna()

                    # 若你沿用現有的 risk_valve_backtest，給 cap_level=1.0 表示「w 已經是目標序列」
                    try:
                        from SSS_EnsembleTab import risk_valve_backtest, CostParams

                        # 成本參數
                        trade_cost = (strat_params.get("trade_cost", {})
                                      if isinstance(strat_params, dict) else {})
                        cost = CostParams(
                            buy_fee_bp=float(trade_cost.get("buy_fee_bp", 4.27)),
                            sell_fee_bp=float(trade_cost.get("sell_fee_bp", 4.27)),
                            sell_tax_bp=float(trade_cost.get("sell_tax_bp", 30.0)),
                        )
I’ll add a timestamp comment, like "# 2025-08-19 修正...", near the import or recompute section.

root@478772c9b537:/workspace/SSS096# apply_patch <<'PATCH'
> *** Begin Patch
> *** Update File: app_dash.py
> @@
> -                    try:
> -                        from SSS_EnsembleTab import risk_valve_backtest, CostParams
> +                    try:
> +                        from SSS_EnsembleTab import (
> +                            risk_valve_backtest,
> +                            CostParams,
> +                            build_trade_snapshots_from_ledger,
> +                            _sell_returns_pct_from_ledger,
> +                        )
> *** End Patch
> PATCH
Success. Updated the following files:
M app_dash.py
I'll find the lines around 1290 to patch the trade_df rebuilding after pop.

root@478772c9b537:/workspace/SSS096# sed -n '1274,1318p' app_dash.py
                            cost=cost,
                            benchmark_df=bench,
                            mode="cap",
                            cap_level=1.0,
                        )
                    except Exception as e:
                        logger.warning(f"[{strat}] 無法導入 risk_valve_backtest: {e}")
                        result_cap = None

                    if result_cap:
                        # === 安全覆寫：清掉舊鍵並補齊新鍵 ===
                        logger.info(f"[UI_CHECK] 即將覆寫：new_trades={len(result_cap.get('trade_ledger_valve', pd.DataFrame()))
} rows, new_ds={len(result_cap.get('daily_state_valve', pd.DataFrame()))} rows")

                        # 1) 覆寫結果 —— 一律用 pack_df/pack_series
                        if 'trade_ledger_valve' in result_cap:
                            result['trades'] = pack_df(result_cap['trade_ledger_valve'])
                            result['trade_ledger'] = pack_df(result_cap['trade_ledger_valve'])
                            result['trade_ledger_std'] = pack_df(result_cap['trade_ledger_valve'])

                        if 'daily_state_valve' in result_cap:
                            result['daily_state'] = pack_df(result_cap['daily_state_valve'])
                            result['daily_state_std'] = pack_df(result_cap['daily_state_valve'])

                        if 'weights_valve' in result_cap:
                            result['weight_curve'] = pack_series(result_cap['weights_valve'])

                        # 權益曲線：若是 Series
                        if 'daily_state_valve' in result_cap and 'equity' in result_cap['daily_state_valve']:
                            try:
                                result['equity_curve'] = pack_series(result_cap['daily_state_valve']['equity'])
                            except Exception:
                                # 若你存的是 DataFrame
                                result['equity_curve'] = pack_df(result_cap['daily_state_valve']['equity'].to_frame('equity'))

                        # 2) **關鍵**：把 UI 可能拿來用的舊快取清掉，強迫 UI 走新資料
                        for k in ['trades_ui', 'trade_df', 'trade_ledger_std', 'metrics']:
                            if k in result:
                                result.pop(k, None)

                        # 3) 給 UI 一個旗標與參數，便於顯示「已套用」
                        result['_risk_valve_applied'] = True
                        result['_risk_valve_params'] = {
                            'cap': float(risk_cap),
                            'atr_ratio': float(atr_ratio),
                            'atr20_last': float(atr_20_valid.iloc[-1]) if len(atr_20_valid) > 0 else None,
I'll add a comment in Traditional Chinese with a timestamp of 2025-08-19 and apply the patch.

root@478772c9b537:/workspace/SSS096# apply_patch <<'PATCH'
> *** Begin Patch
> *** Update File: app_dash.py
> @@
>                          # 權益曲線：若是 Series
>                          if 'daily_state_valve' in result_cap and 'equity' in result_cap['daily_state_valve']:
>                              try:
>                                  result['equity_curve'] = pack_series(result_cap['daily_state_valve']['equity'])
>                              except Exception:
>                                  # 若你存的是 DataFrame
>                                  result['equity_curve'] = pack_df(result_cap['daily_state_valve']['equity'].to_frame('equity')
)
>
> -                        # 2) **關鍵**：把 UI 可能拿來用的舊快取清掉，強迫 UI 走新資料
> -                        for k in ['trades_ui', 'trade_df', 'trade_ledger_std', 'metrics']:
> -                            if k in result:
> -                                result.pop(k, None)
> +                        # 2) **關鍵**：把 UI 可能拿來用的舊快取清掉，強迫 UI 走新資料
> +                        for k in ['trades_ui', 'trade_df', 'trade_ledger_std', 'metrics']:
> +                            if k in result:
> +                                result.pop(k, None)
> +
> +                        # 2025-08-19 修復：風險閥門套用後重建交易資料與績效指標 #app_dash.py
> +                        if 'trade_ledger_valve' in result_cap and 'daily_state_valve' in result_cap:
> +                            try:
> +                                trade_df_valve = build_trade_snapshots_from_ledger(result_cap['trade_ledger_valve'])
> +                                result['trade_df'] = pack_df(trade_df_valve)
> +                                sell_ret = _sell_returns_pct_from_ledger(result_cap['trade_ledger_valve']) / 100.0
> +                                trades_list = [(d, r, d) for d, r in sell_ret.items()]
> +                                equity_valve = result_cap['daily_state_valve']['equity']
> +                                idx_df = pd.DataFrame(index=equity_valve.index)
> +                                result['metrics'] = calculate_metrics(trades_list, idx_df, equity_valve)
> +                            except Exception as e:
> +                                logger.warning(f"[{strat}] 風險閥門績效重算失敗: {e}")
> +                                result['metrics'] = {}
> +                        else:
> +                            result['metrics'] = {}
>
>                          # 3) 給 UI 一個旗標與參數，便於顯示「已套用」
>                          result['_risk_valve_applied'] = True
>                          result['_risk_valve_params'] = {
>                              'cap': float(risk_cap),
>                              'atr_ratio': float(atr_ratio),
> *** End Patch
> PATCH
Success. Updated the following files:
M app_dash.py
I don't think I need to change the earlier imports, but I do need to check the pandas import.

root@478772c9b537:/workspace/SSS096# /usr/bin/python -m py_compile app_dash.py
bash: /usr/bin/python: No such file or directory
Hmm, maybe Python is installed under /usr/bin/python3. Let's try that instead.

root@478772c9b537:/workspace/SSS096# /usr/bin/python3 -m py_compile app_dash.py
root@478772c9b537:/workspace/SSS096# pwsh -ExecutionPolicy Bypass -File tools/quick_check.ps1
bash: command not found: pwsh
PowerShell isn't installed, so I'll try running the recommended test with Python as best I can.

root@478772c9b537:/workspace/SSS096# /usr/bin/python3 SSSv096.py --strategy RMA_Factor --param_preset op.json
Traceback (most recent call last):
  File "/workspace/SSS096/SSSv096.py", line 17, in <module>
    import pandas as pd
ModuleNotFoundError: No module named 'pandas'
The environment lacks pandas, and tests failed. Now, I'll check modifications with git status.

root@478772c9b537:/workspace/SSS096# /usr/bin/git status --short
 M app_dash.py
?? __pycache__/
I'll clean up the pycache generated by py_compile.

root@478772c9b537:/workspace/SSS096# /bin/rm -r __pycache__
root@478772c9b537:/workspace/SSS096# /usr/bin/git status --short
 M app_dash.py
Only app_dash.py was modified. I'll add a comment in Traditional Chinese as required.

root@478772c9b537:/workspace/SSS096# /usr/bin/git commit -am "fix: restore metrics after risk valve" && /usr/bin/git status --sh
ort
[work b4888bd] fix: restore metrics after risk valve
 1 file changed, 27 insertions(+), 4 deletions(-)
root@478772c9b537:/workspace/SSS096# /usr/bin/git status --short
I'll gather the line numbers for the changes in app_dash.py.

root@478772c9b537:/workspace/SSS096# nl -ba app_dash.py | sed -n '200,240p'
   200
   201      if isinstance(data, (list, dict)):
   202          try:
   203              return pd.Series(data)
   204          except Exception:
   205              return pd.Series(dtype=float)
   206
   207      return pd.Series(dtype=float)
   208
   209  from SSSv096 import (
   210      param_presets, load_data, compute_single, compute_dual, compute_RMA,
   211      compute_ssma_turn_combined, backtest_unified, plot_stock_price,
   212      plot_equity_cash, plot_weight_series, calculate_holding_periods,
   213      calculate_metrics
   214  )
   215
   216  # 彈性匯入 pack_df/pack_series 函數
   217  try:
   218      from sss_core.schemas import pack_df, pack_series
   219  except Exception:
   220      from schemas import pack_df, pack_series
   221
   222  # 匯入權重欄位確保函式
   223  try:
   224      from sss_core.normalize import _ensure_weight_columns
   225  except Exception:
   226      # 如果無法匯入，定義一個空的函式作為 fallback
   227      def _ensure_weight_columns(df):
   228          return df
   229
   230  # 假設你有 get_version_history_html
   231  try:
   232      from version_history import get_version_history_html
   233  except ImportError:
   234      def get_version_history_html() -> str:
   235          return "<b>無法載入版本歷史記錄</b>"
   236
   237  # --- 保證放進 Store 的都是 JSON-safe ---
   238  def _pack_any(x):
   239      import pandas as pd
   240      if isinstance(x, pd.DataFrame):
I'll grab the lines around 1274 to document the new code after the recomputation.

root@478772c9b537:/workspace/SSS096# nl -ba app_dash.py | sed -n '1260,1325p'
  1260                          if 'close' in df_raw.columns:
  1261                              bench["收盤價"] = pd.to_numeric(df_raw["close"], errors="coerce")
  1262                          elif '收盤價' in df_raw.columns:
  1263                              bench["收盤價"] = pd.to_numeric(df_raw["收盤價"], errors="coerce")
  1264                          if 'high' in df_raw.columns and 'low' in df_raw.columns:
  1265                              bench["最高價"] = pd.to_numeric(df_raw["high"], errors="coerce")
  1266                              bench["最低價"] = pd.to_numeric(df_raw["low"], errors="coerce")
  1267                          elif '最高價' in df_raw.columns and '最低價' in df_raw.columns:
  1268                              bench["最高價"] = pd.to_numeric(df_raw["最高價"], errors="coerce")
  1269                              bench["最低價"] = pd.to_numeric(df_raw["最低價"], errors="coerce")
  1270
  1271                          result_cap = risk_valve_backtest(
  1272                              open_px=open_px,
  1273                              w=ds["w"].astype(float).reindex(open_px.index).fillna(0.0),
  1274                              cost=cost,
  1275                              benchmark_df=bench,
  1276                              mode="cap",
  1277                              cap_level=1.0,
  1278                          )
  1279                      except Exception as e:
  1280                          logger.warning(f"[{strat}] 無法導入 risk_valve_backtest: {e}")
  1281                          result_cap = None
  1282
  1283                      if result_cap:
  1284                          # === 安全覆寫：清掉舊鍵並補齊新鍵 ===
  1285                          logger.info(f"[UI_CHECK] 即將覆寫：new_trades={len(result_cap.get('trade_ledger_valve', pd.DataF
rame()))} rows, new_ds={len(result_cap.get('daily_state_valve', pd.DataFrame()))} rows")
  1286
  1287                          # 1) 覆寫結果 —— 一律用 pack_df/pack_series
  1288                          if 'trade_ledger_valve' in result_cap:
  1289                              result['trades'] = pack_df(result_cap['trade_ledger_valve'])
  1290                              result['trade_ledger'] = pack_df(result_cap['trade_ledger_valve'])
  1291                              result['trade_ledger_std'] = pack_df(result_cap['trade_ledger_valve'])
  1292
  1293                          if 'daily_state_valve' in result_cap:
  1294                              result['daily_state'] = pack_df(result_cap['daily_state_valve'])
  1295                              result['daily_state_std'] = pack_df(result_cap['daily_state_valve'])
  1296
  1297                          if 'weights_valve' in result_cap:
  1298                              result['weight_curve'] = pack_series(result_cap['weights_valve'])
  1299
  1300                          # 權益曲線：若是 Series
  1301                          if 'daily_state_valve' in result_cap and 'equity' in result_cap['daily_state_valve']:
  1302                              try:
  1303                                  result['equity_curve'] = pack_series(result_cap['daily_state_valve']['equity'])
  1304                              except Exception:
  1305                                  # 若你存的是 DataFrame
  1306                                  result['equity_curve'] = pack_df(result_cap['daily_state_valve']['equity'].to_frame('equ
ity'))
  1307
  1308                          # 2) **關鍵**：把 UI 可能拿來用的舊快取清掉，強迫 UI 走新資料
  1309                          for k in ['trades_ui', 'trade_df', 'trade_ledger_std', 'metrics']:
  1310                              if k in result:
  1311                                  result.pop(k, None)
  1312
  1313                          # 2025-08-19 修復：風險閥門套用後重建交易資料與績效指標 #app_dash.py
  1314                          if 'trade_ledger_valve' in result_cap and 'daily_state_valve' in result_cap:
  1315                              try:
  1316                                  trade_df_valve = build_trade_snapshots_from_ledger(result_cap['trade_ledger_valve'])
  1317                                  result['trade_df'] = pack_df(trade_df_valve)
  1318                                  sell_ret = _sell_returns_pct_from_ledger(result_cap['trade_ledger_valve']) / 100.0
  1319                                  trades_list = [(d, r, d) for d, r in sell_ret.items()]
  1320                                  equity_valve = result_cap['daily_state_valve']['equity']
  1321                                  idx_df = pd.DataFrame(index=equity_valve.index)
  1322                                  result['metrics'] = calculate_metrics(trades_list, idx_df, equity_valve)
  1323                              except Exception as e:
  1324                                  logger.warning(f"[{strat}] 風險閥門績效重算失敗: {e}")
  1325                                  result['metrics'] = {}
I'll keep going and capture lines following line 1325.

root@478772c9b537:/workspace/SSS096# nl -ba app_dash.py | sed -n '1325,1345p'
  1325                                  result['metrics'] = {}
  1326                          else:
  1327                              result['metrics'] = {}
  1328
  1329                          # 3) 給 UI 一個旗標與參數，便於顯示「已套用」
  1330                          result['_risk_valve_applied'] = True
  1331                          result['_risk_valve_params'] = {
  1332                              'cap': float(risk_cap),
  1333                              'atr_ratio': float(atr_ratio),
  1334                              'atr20_last': float(atr_20_valid.iloc[-1]) if len(atr_20_valid) > 0 else None,
  1335                              'atr60_last': float(atr_60_valid.iloc[-1]) if len(atr_60_valid) > 0 else None,
  1336                          }
  1337
  1338                          true_days = int(mask_aligned.sum())
  1339                          logger.info(f"[{strat}] 全局風險閥門已套用（逐日），風險天數={true_days}, CAP={risk_cap:.2f}")
  1340                      else:
  1341                          logger.warning(f"[{strat}] 風險閥門重算沒有返回結果")
  1342
  1343          results[strat] = result
  1344
  1345      # 使用第一個策略的數據作為主要顯示數據
I'll include lines 209-214 and 1308-1327, plus a note on the bug fix and failed tests.

2.
Configuring language runtimes...
# Python: 3.12
# Node.js: v20 (default: v22)
default -> 20 (-> v20.19.4)
Now using node v20.19.4 (npm v10.9.3)
# Ruby: 3.4.4 (default: 3.2.3)
mise ~/.config/mise/config.toml tools: ruby@3.4.4
# Rust: 1.88.0 (default: 1.89.0)
info: using existing install for '1.88.0-x86_64-unknown-linux-gnu'
info: default toolchain set to '1.88.0-x86_64-unknown-linux-gnu'

  1.88.0-x86_64-unknown-linux-gnu unchanged - rustc 1.88.0 (6b00bc388 2025-06-23)

# Go: go1.24.3 (default: go1.24.3)
# Swift: 6.1 (default: 6.1)
# PHP: 8.4 (default: 8.4)
Running auto setup...
Scanning repository (up to depth 3) for dependency configurations...
No known dependency configuration files found up to depth 3.
後面版本不是新增了風險閥門套用在各策略嗎
但不知道為什麼套用後 各指標會只剩下平均持倉天數,其他指標都消失了 請修復
I'll use ls to view the top-level of the repo, avoiding ls -R or grep -R.

ls
Hm, I think output might be missing due to a timing issue. Let's try waiting.

root@5583bff288d6:/workspace# ls
SSS096
I need to cd into /workspace/SSS096 to check the repo details.

root@5583bff288d6:/workspace# cd SSS096
Ah, I need to run ls again after changing directories in the same container.

root@5583bff288d6:/workspace/SSS096# ls
AGENTS.md                           data                      run_workflow_example.py
DEFENSIVE_CHECKS_UPDATE_SUMMARY.md  debug_enhanced_data.py    runners
ENSEMBLE_WORKFLOW.md                ensemble_wrapper.py       setup.sh
LOGGING_SYSTEM_UPDATE_SUMMARY.md    extract_params.py         sss_backtest_outputs
PORTFOLIO_LEDGER_README.md          leverage.py               sss_core
SSS_EnsembleTab.py                  list.txt                  test
SSSv096.py                          list_folder_structure.py  tools
analysis                            presets                   utils_payload.py
app_dash.py                         ruff.toml                 version_history.py
assets                              run_enhanced_debug.py     workflow_summary_20250812_023903.txt
config.yaml                         run_enhanced_ensemble.py  workflow_summary_20250818_040656.txt
convert_results_to_trades.py        run_workflow.py
I've found AGENTS.md at the root. Let's open it and read what's inside.

root@5583bff288d6:/workspace/SSS096# cat AGENTS.md
# SSS096 專案 AI 代理工作指南

## 📋 專案概述

SSS096 是一個股票策略回測與分析系統，主要包含：
- 策略回測引擎（SSSv096.py）
- Web UI 界面（app_dash.py）
- 增強分析模組（analysis/）
- Ensemble 策略執行（runners/）
- 數據處理與轉換工具

## 🎯 工作重點區域

### 核心檔案
- `SSSv096.py` - 主要策略回測引擎
- `app_dash.py` - Web UI 主應用
- `ensemble_wrapper.py` - Ensemble 策略包裝器
- `analysis/` - 分析模組目錄

### 避免修改的檔案
- `tools/quick_check.ps1` - 自動化檢查腳本（除非必要）
- 已標記為 "past/" 的舊版本檔案
- 編譯後的 `.pyc` 檔案

## 🔧 開發環境設定

### Codex 環境設置（推薦）
```bash
# 執行自動設置腳本
chmod +x setup.sh
./setup.sh

# 測試設置是否成功
python test_setup.py
```

### Python 環境（手動設置）
```bash
# 安裝依賴套件
pip install pandas numpy matplotlib seaborn openpyxl dash dash-bootstrap-components

# 檢查 Python 版本（建議 3.8+）
python --version
```

### 代理設置（如果遇到 403 錯誤）
```bash
# 檢查代理證書
echo $CODEX_PROXY_CERT

# 配置 pip 使用代理
pip config set global.cert "$CODEX_PROXY_CERT"
pip config set global.trusted-host "proxy:8080"
```

### 專案結構導航
```bash
# 快速查看目錄結構
python list_folder_structure.py

# 查看特定目錄內容
ls analysis/
ls runners/
```

## 🧪 測試與驗證

### 快速檢查
```bash
# 執行自動化檢查（重要！）
powershell -ExecutionPolicy Bypass -File tools\quick_check.ps1
```

### 回測測試
```bash
# 執行單一策略回測
python SSSv096.py --strategy RMA_Factor --param_preset op.json

# 執行 Ensemble 策略
python run_enhanced_ensemble.py --method majority --top_k 5
```

### UI 測試
```bash
# 啟動 Web UI
python app_dash.py
```

## 📝 程式碼規範

### 註解與輸出
- **一律使用繁體中文**進行註解和輸出
- 修改紀錄需加入日期時間戳記
- 路徑說明格式：`#子資料夾/檔案名`

### 日誌記錄
- 使用 `analysis/logging_config.py` 中的日誌器
- 重要操作需記錄到日誌檔案
- 錯誤處理需包含詳細的錯誤信息

### 資料格式
- 日期欄位統一使用 ISO 格式：`YYYY-MM-DD`
- 數值欄位使用 float 類型
- 避免使用中文欄位名稱（除非必要）

## 🔍 除錯指南

### 常見問題
1. **模組導入失敗**：檢查 `sys.path` 和相對導入
2. **數據格式錯誤**：驗證 CSV 檔案結構和欄位名稱
3. **記憶體不足**：檢查大數據集的處理方式

### 除錯工具
```python
# 啟用詳細日誌
import logging
logging.basicConfig(level=logging.DEBUG)

# 檢查數據結構
print(df.info())
print(df.head())
```

## 📊 數據處理規範

### 輸入數據
- 支援 CSV、Excel、JSON 格式
- 必要欄位：交易日期、權重變化、盈虧%
- 可選欄位：交易類型、價格、成交量

### 輸出數據
- 統一 Schema：equity、trades、daily_state、trade_ledger
- 避免 KeyError 和欄位缺失
- 支援多種輸出格式

## 🚀 部署與維護

### 檔案管理
- 定期清理舊的日誌和快取檔案
- 備份重要的配置和結果檔案
- 使用版本控制追蹤變更

### 性能優化
- 大數據集使用快取機制
- 避免重複計算
- 使用適當的數據結構

## ⚠️ 注意事項

### 安全考量
- 不要硬編碼 API 金鑰
- 驗證所有用戶輸入
- 保護敏感數據

### 相容性
- 維持與現有工作流程的相容性
- 測試所有整合點
- 避免破壞現有功能

## 🚀 Codex 環境設置

### 自動設置
```bash
# 執行設置腳本
./setup.sh

# 腳本會自動：
# 1. 配置代理設置
# 2. 安裝所有必要依賴
# 3. 創建回退日誌系統
# 4. 設置環境變數
```

### 手動設置（如果自動設置失敗）
```bash
# 1. 配置代理
export PIP_CERT="$CODEX_PROXY_CERT"
export NODE_EXTRA_CA_CERTS="$CODEX_PROXY_CERT"

# 2. 安裝核心依賴
pip install --no-cache-dir pandas numpy matplotlib seaborn openpyxl dash dash-bootstrap-components yfinance pyyaml joblib

# 3. 安裝分析套件
pip install --no-cache-dir scikit-learn scipy statsmodels plotly kaleido

# 4. 創建必要目錄
mkdir -p analysis/log analysis/cache cache log results sss_backtest_outputs
```

### 常見問題解決
- **pip install 403 錯誤**：檢查 `$CODEX_PROXY_CERT` 環境變數
- **joblib 導入失敗**：使用 `logging_config_fallback.py` 回退版本
- **模組路徑問題**：設置 `PYTHONPATH` 環境變數

## 📞 技術支援

### 問題回報
- 提供完整的錯誤訊息和堆疊追蹤
- 包含重現步驟和環境信息
- 檢查相關的日誌檔案

### 文檔更新
- 修改功能時同步更新相關文檔
- 使用清晰的範例和說明
- 保持文檔的時效性

---

**版本：** v1.0
**最後更新：** 2025-08-18
**適用於：** SSS096 專案 AI 代理工作指南
I need to find files related to "risk valve" or "risk" using rg search.

root@5583bff288d6:/workspace/SSS096# rg "risk" -n
DEFENSIVE_CHECKS_UPDATE_SUMMARY.md
25:**1.1 _simulate_risk_valves 函式**
30:**1.2 _calculate_risk_valve_impact 函式**
32:- 檢查 `benchmark_enhanced` 是否有 `risk_valve_triggered` 欄位

app_dash.py
446:                        dcc.Input(id='risk-cap-input', type='number', min=0.1, max=1.0, step=0.1, value=0.3,
461:                    html.Div(id='risk-valve-status', style={"marginTop":"8px","padding":"8px","backgroundColor":"#f8f9fa","b
orderRadius":"4px","border":"1px solid #dee2e6"}),
575:    Output('risk-valve-status', 'children'),
578:        Input('risk-cap-input', 'value'),
586:def update_risk_valve_status(global_apply, risk_cap, atr_ratio, force_trigger, ticker, start_date, end_date):
590:    logger.info(f"risk_cap: {risk_cap}")
688:                                    html.Small(f"風險CAP: {risk_cap*100:.0f}%", style={"color":"#666","fontSize":"11px"}),
690:                                    html.Small(f"現金保留下限: {(1-risk_cap)*100:.0f}%", style={"color":"#666","fontSize":"1
1px"}),
762:        Input('risk-cap-input', 'value'),
771:def run_backtest(n_clicks, auto_run, ticker, start_date, end_date, discount, cooldown, bad_holding, global_apply, risk_cap,
atr_ratio, force_trigger, strategy, param_values, param_ids, stored_data):
813:            logger.info(f"[{strat}] 應用全局風險閥門: CAP={risk_cap}, ATR比值門檻={atr_ratio}")
893:                    from SSS_EnsembleTab import risk_valve_backtest, CostParams
918:                        rv = risk_valve_backtest(
924:                            cap_level=float(risk_cap),
937:                            "cap": float(risk_cap),
941:                        logger.info(f"[{strat}] SSMA 風險閥門已套用（cap={risk_cap}, ratio={ratio_local:.4f}）")
949:                        "cap": float(risk_cap),
986:                #     if ensemble_params.delta_cap > risk_cap:
987:                #         ensemble_params.delta_cap = risk_cap
991:                #     min_floor = 1 - risk_cap
1075:                    from SSS_EnsembleTab import risk_valve_backtest
1078:                    logger.info(f"[{strat}] 🔴 開始套用風險閥門: cap={risk_cap}, ratio={ratio:.4f}")
1080:                    rv = risk_valve_backtest(
1086:                        cap_level=float(risk_cap),
1093:                    logger.info(f"[{strat}] 風險閥門已套用（cap={risk_cap}, ratio={ratio:.4f}）")
1103:                        "cap": float(risk_cap),
1112:                            "cap": float(risk_cap),
1176:                    "cap": float(risk_cap),
1228:                    w_new[mask_aligned] = np.minimum(w_new[mask_aligned], float(risk_cap))
1238:                    # 若你沿用現有的 risk_valve_backtest，給 cap_level=1.0 表示「w 已經是目標序列」
1240:                        from SSS_EnsembleTab import risk_valve_backtest, CostParams
1264:                        result_cap = risk_valve_backtest(
1273:                        logger.warning(f"[{strat}] 無法導入 risk_valve_backtest: {e}")
1307:                        result['_risk_valve_applied'] = True
1308:                        result['_risk_valve_params'] = {
1309:                            'cap': float(risk_cap),
1316:                        logger.info(f"[{strat}] 全局風險閥門已套用（逐日），風險天數={true_days}, CAP={risk_cap:.2f}")
2426:        from SSS_EnsembleTab import risk_valve_backtest
2427:        out = risk_valve_backtest(
2439:    sig = out["signals"]["risk_trigger"]
2553:    risk_eff = np.nan
2555:        risk_eff = avg_net / abs(avg_mdd)
2624:        kpi("風險效率", f"{risk_eff:.3f}" if pd.notna(risk_eff) else "—"),
2932:                            risk_eff = avg_net / abs(avg_mdd) if avg_mdd != 0 else 0
2940:                                "風險效率": round(risk_eff, 3),
3424:    # 檢查是否可以匯入 risk_valve_backtest
3426:        from SSS_EnsembleTab import risk_valve_backtest
3427:        logger.info("成功匯入 risk_valve_backtest")
3429:        logger.error(f"匯入 risk_valve_backtest 失敗: {e}")
3430:        return go.Figure(), f"❌ 無法匯入 risk_valve_backtest: {e}"
3440:                out = risk_valve_backtest(
3452:                sig = out["signals"]["risk_trigger"]
3471:                    "risk_trigger_days": trigger_days,
3507:            size=np.clip(dfp['risk_trigger_days'] / 5.0, 6, 30),
3554:        risk_trigger_days = 50
3619:                    risk_trigger_days = len(trade_df['trade_date'].dt.date.unique())
3623:                    risk_trigger_days = min(100, int(volatility * 1000))  # 轉換為合理範圍
3636:                    risk_trigger_days = len(trade_df['trade_date'].dt.date.unique())
3638:                    risk_trigger_days = len(trade_df)
3648:            'risk_trigger_days': risk_trigger_days
3668:            size=df['risk_trigger_days'] / 10,  # 點大小：風險觸發天數
3837:        # 檢查是否可以匯入 risk_valve_backtest
3839:            from SSS_EnsembleTab import risk_valve_backtest
3840:            logger.info("成功匯入 risk_valve_backtest")
3842:            logger.error(f"匯入 risk_valve_backtest 失敗: {e}")
3853:                    out = risk_valve_backtest(
3865:                        trade_df = None  # risk_valve_backtest 不直接提供交易記錄
3876:                                'risk_trigger_days': metrics['risk_trigger_days'],

list.txt
1365:      📄 risk_enhanced_clustering_analysis_v2.py (20.9 KB, 2025-07-04 13:02:52)

analysis/OSv3_6270833.py
394:def calculate_risk_adjusted_metrics(equity_curve, strategy_name):
873:                risk_adjusted_metrics = calculate_risk_adjusted_metrics(equity_curve, name)
927:                    **risk_adjusted_metrics  # 添加風險調整指標

SSS_EnsembleTab.py
1241:def compute_risk_valve_signals(benchmark_df: pd.DataFrame,
1248:       輸出：含 slope_20d/60d、atr、atr_ratio、risk_trigger(bool) 的 DataFrame"""
1281:    b["risk_trigger"] = (b["slope_20d"] < slope20_thresh) & \
1284:    return b[["slope_20d", "slope_60d", "atr", "atr_ratio", "risk_trigger"]]
1289:                           risk_trigger: pd.Series,
1295:    w = w.copy().reindex(risk_trigger.index).ffill().fillna(0.0)
1299:        mask = risk_trigger.reindex(w.index).fillna(False).astype(bool)
1303:        mask = risk_trigger.reindex(w.index).fillna(False).astype(bool)
1359:def risk_valve_backtest(open_px: pd.Series,
1371:    sig = compute_risk_valve_signals(benchmark_df, slope20_thresh, slope60_thresh,
1373:    w2 = apply_valve_to_weights(w, sig["risk_trigger"], mode, cap_level)

analysis/OSv3.py
63:        'overfitting_risk': '過擬合風險：綜合過擬合風險評分，0-100',
89:        'low_risk': '低風險比例：過擬合風險≤30的策略比例',
90:        'medium_risk': '中風險比例：過擬合風險31-60的策略比例',
91:        'high_risk': '高風險比例：過擬合風險>60的策略比例',
92:        'risk_return_correlation': '風險報酬相關性：過擬合風險與總報酬率的相關係數'
543:    new_metrics = ['parameter_sensitivity', 'consistency_score', 'stability_score', 'overfitting_risk']
565:            if metric == 'overfitting_risk':
566:                low_risk = np.sum(valid_values <= 30) / len(valid_values)
567:                medium_risk = np.sum((valid_values > 30) & (valid_values <= 60)) / len(valid_values)
568:                high_risk = np.sum(valid_values > 60) / len(valid_values)
569:                analysis_results[f'{metric}_risk_distribution'] = {
570:                    'low_risk': low_risk,
571:                    'medium_risk': medium_risk,
572:                    'high_risk': high_risk
576:    if 'overfitting_risk' in available_metrics and 'total_return' in strategy_trials.columns:
577:        risk_values = pd.to_numeric(strategy_trials['overfitting_risk'], errors='coerce')
580:        valid_mask = risk_values.notna() & return_values.notna()
582:            correlation = risk_values[valid_mask].corr(return_values[valid_mask])
583:            analysis_results['risk_return_correlation'] = correlation
671:def calculate_risk_adjusted_metrics(equity_curve, strategy_name):
742:        additional_metrics = calculate_risk_adjusted_metrics(equity_curve, method_name)
1623:                risk_adjusted_metrics = calculate_risk_adjusted_metrics(equity_curve, name)
1677:                    **risk_adjusted_metrics  # 添加風險調整指標
...
566:                risk_dates = self.benchmark_enhanced[
567:                    self.benchmark_enhanced['risk_valve_triggered']
570:                if len(risk_dates) > 0:
571:                    ax1.scatter(risk_dates,
573:                                   self.benchmark_enhanced['risk_valve_triggered'], '收盤價'
637:    print("2. 執行風險閥門回測：analyzer.risk_valve_backtest()")

analysis/past/adaptive_clustering_analysis_v7.py
26:INPUT_DIR = 'results/risk_enhanced_clustering'
30:def load_risk_clustered_data():
32:    all_files = glob.glob(f'{INPUT_DIR}/*_risk_clustered.csv')
73:    risk_cols = ['annual_volatility', 'downside_risk', 'var_95_annual', 'cvar_95_annual']
74:    for col in risk_cols:
313:    param_risk_cols = [col for col in df.columns if col.startswith('param_') or
314:                      col in ['annual_volatility', 'downside_risk', 'var_95_annual']]
315:    available_cols = [col for col in param_risk_cols if col in df.columns]
416:    data_dict = load_risk_clustered_data()
428:        risk_cols = ['annual_volatility', 'downside_risk', 'sortino_ratio', 'var_95_annual',
434:        enhanced_risk_cols = [col for col in enhanced_df.columns if any(risk in col for risk in risk_cols)]
436:        all_feature_cols = enhanced_param_cols + enhanced_risk_cols

analysis/past/comprehensive_distance_test.py
164:            overfitting_risk = result.get('overfitting_risk', {})
172:                'overfitting_risk_score': overfitting_risk.get('risk_score', 0),
173:                'overfitting_risk_level': overfitting_risk.get('overfitting_risk', 'unknown'),
225:        self.comparison_df['overfitting_risk_score'].plot(kind='bar', ax=ax3, color='salmon')
297:                    'overfitting_risk': result.get('overfitting_risk', {}),

analysis/past/simple_fine_clustering_v17.py
25:INPUT_DIR = 'results/risk_enhanced_clustering'
29:def load_risk_clustered_data():
31:    all_files = glob.glob(f'{INPUT_DIR}/*_risk_clustered.csv')
64:        if any(keyword in col.lower() for keyword in ['return', 'score', 'sharpe', 'calmar', 'sortino', 'volatility', 'risk',
 'var', 'cvar', 'downside', 'drawdown']):
368:    data_dict = load_risk_clustered_data()

analysis/past/adaptive_fine_clustering_v16.py
25:INPUT_DIR = 'results/risk_enhanced_clustering'
29:def load_risk_clustered_data():
31:    all_files = glob.glob(f'{INPUT_DIR}/*_risk_clustered.csv')
64:        if any(keyword in col.lower() for keyword in ['return', 'score', 'sharpe', 'calmar', 'sortino', 'volatility', 'risk',
 'var', 'cvar', 'downside', 'drawdown']):
507:    data_dict = load_risk_clustered_data()

analysis/past/fast_adaptive_clustering_v8.py
25:INPUT_DIR = 'results/risk_enhanced_clustering'
29:def load_risk_clustered_data():
31:    all_files = glob.glob(f'{INPUT_DIR}/*_risk_clustered.csv')
228:                col in ['annual_volatility', 'downside_risk']]
296:    data_dict = load_risk_clustered_data()
308:        risk_cols = ['annual_volatility', 'downside_risk', 'var_95_annual', 'cvar_95_annual']
311:        all_feature_cols = param_cols + risk_cols

analysis/past/supervised_clustering_analysis_v3.py
27:INPUT_DIR = 'results/risk_enhanced_clustering'
31:def load_risk_clustered_data():
33:    all_files = glob.glob(f'{INPUT_DIR}/*_risk_clustered.csv')
66:              f"risk_cluster={row['risk_cluster']}")
94:    risk_cols = ['annual_volatility', 'downside_risk', 'var_95_annual', 'cvar_95_annual']
96:    for risk in risk_cols:
97:        if risk in case_df.columns:
98:            values = case_df[risk].values
103:                print(f"{risk}: 均值={mean_val:.3f}, 標準差={std_val:.3f}, 變異係數={cv:.3f}")
126:    risk_cols = ['annual_volatility', 'downside_risk', 'var_95_annual']
127:    feature_cols.extend([col for col in risk_cols if col in df.columns])
188:    risk_cols = ['annual_volatility', 'downside_risk', 'var_95_annual', 'cvar_95_annual']
189:    risk_cols = [col for col in risk_cols if col in df.columns]
190:    feature_cols.extend(risk_cols)
241:        'original_risk': df['risk_cluster'].values if 'risk_cluster' in df.columns else None
399:    data_dict = load_risk_clustered_data()

analysis/past/quick_distance_test.py
111:                overfitting_risk = analyzer.detect_overfitting_risk(df_processed)
121:                    'overfitting_risk_score': overfitting_risk.get('risk_score', 0),
122:                    'overfitting_risk_level': overfitting_risk.get('overfitting_risk', 'unknown'),
136:                logger.info(f"  過擬合風險分數: {results[config['name']]['overfitting_risk_score']:.3f}")
152:        key_metrics = ['similar_pairs_count', 'avg_distance', 'overfitting_risk_score', 'parameter_correlation_avg']
175:        risk_scores = comparison_df['overfitting_risk_score']
176:        best_methods['overfitting_risk'] = risk_scores.idxmin()
200:        euclidean_risk = results.get('euclidean', {}).get('overfitting_risk_score', 1.0)
201:        other_methods_risk = [v.get('overfitting_risk_score', 1.0) for k, v in results.items() if k != 'euclidean']
203:        if other_methods_risk and min(other_methods_risk) < euclidean_risk:
204:            improvement = (euclidean_risk - min(other_methods_risk)) / euclidean_risk * 100

analysis/past/fine_grained_clustering_v13.py
25:INPUT_DIR = 'results/risk_enhanced_clustering'
29:def load_risk_clustered_data():
31:    all_files = glob.glob(f'{INPUT_DIR}/*_risk_clustered.csv')
355:                col in ['annual_volatility', 'downside_risk']]
641:    data_dict = load_risk_clustered_data()
650:        risk_cols = ['annual_volatility', 'downside_risk', 'var_95_annual', 'cvar_95_annual']
652:        all_feature_cols = param_cols + risk_cols

analysis/past/balanced_clustering_analysis_v10.py
25:INPUT_DIR = 'results/risk_enhanced_clustering'
29:def load_risk_clustered_data():
31:    all_files = glob.glob(f'{INPUT_DIR}/*_risk_clustered.csv')
267:                col in ['annual_volatility', 'downside_risk']]
476:    data_dict = load_risk_clustered_data()
485:        risk_cols = ['annual_volatility', 'downside_risk', 'var_95_annual', 'cvar_95_annual']
487:        all_feature_cols = param_cols + risk_cols

analysis/past/clustering_comparison_analysis_v9.py
25:INPUT_DIR = 'results/risk_enhanced_clustering'
29:def load_risk_clustered_data():
31:    all_files = glob.glob(f'{INPUT_DIR}/*_risk_clustered.csv')
449:    data_dict = load_risk_clustered_data()
456:        risk_cols = ['annual_volatility', 'downside_risk', 'var_95_annual', 'cvar_95_annual']
458:        all_feature_cols = param_cols + risk_cols

analysis/past/small_cluster_analysis_v11.py
25:INPUT_DIR = 'results/risk_enhanced_clustering'
29:def load_risk_clustered_data():
31:    all_files = glob.glob(f'{INPUT_DIR}/*_risk_clustered.csv')
306:                col in ['annual_volatility', 'downside_risk']]
510:    data_dict = load_risk_clustered_data()
519:        risk_cols = ['annual_volatility', 'downside_risk', 'var_95_annual', 'cvar_95_annual']
521:        all_feature_cols = param_cols + risk_cols

analysis/past/improved_supervised_clustering_v5.py
27:INPUT_DIR = 'results/risk_enhanced_clustering'
31:def load_risk_clustered_data():
33:    all_files = glob.glob(f'{INPUT_DIR}/*_risk_clustered.csv')
406:    data_dict = load_risk_clustered_data()
I’ll search for “avg holding days” or related terms in the code around risk valve.

root@5583bff288d6:/workspace/SSS096# rg "平均持倉天數" -n
app_dash.py
1559:                "avg_holding_period": "平均持倉天數",

analysis/OSv3.py
82:        'avg_hold_days': '平均持倉天數：平均每次交易的持倉時間',

analysis/optuna_16.py
10:v10-12  支援單一/隨機/依序數據源模式,新增平均持倉天數,相關係數分析,並自動輸出熱圖,試驗結果與最佳參數自動輸出 CSV/JSON

SSSv096.py
927:    計算平均持倉天數.
933:        float: 平均持倉天數.
1828:            "avg_holding_period": "平均持倉天數",
1864:    # 計算平均持倉天數
1867:    # 將平均持倉天數加入 metrics
2293:            # 顯示策略摘要,傳入 trade_df 以計算平均持倉天數
I'm checking if the risk valve application is overriding metrics, leaving only avg_holding_period.

root@5583bff288d6:/workspace/SSS096# sed -n '1810,1875p' SSSv096.py
        elif k in ["num_trades", "max_consecutive_wins", "max_consecutive_losses"]:
            txt = str(int(v)) if pd.notna(v) else ""
        else:
            # 其他就先盡量當純文字顯示
            txt = f"{v}"
        # 把字典 key → 中文顯示 label
        label_map = {
            "total_return": "總回報率",
            "annual_return": "年化回報率",
            "win_rate": "勝率",
            "max_drawdown": "最大回撤",
            "max_drawdown_duration": "回撤持續",
            "calmar_ratio": "卡瑪比率",
            "sharpe_ratio": "夏普比率",
            "sortino_ratio": "索提諾比率",
            "payoff_ratio": "盈虧比",
            "profit_factor": "盈虧因子",
            "num_trades": "交易次數",
            "avg_holding_period": "平均持倉天數",
            "annualized_volatility": "年化波動率",
            "max_consecutive_wins": "最大連續盈利",
            "max_consecutive_losses": "最大連續虧損",
            "avg_win": "平均盈利",
            "avg_loss": "平均虧損",
        }
        label = label_map.get(k, k)
        items.append((label, txt))

    # 開始產生 HTML:外層一個 flex container,內層每組(指標+數值) 都是 flex item
    html = """
<div style="display:flex;flex-wrap:wrap;gap:12px;align-items:flex-start;">
"""
    for label, val in items:
        html += f"""
  <div style="flex:0 1 150px;border:1px solid #444;border-radius:4px;padding:8px 12px;background:#1a1a1a;">
    <div style="font-size:14px;color:#aaa;">{label}</div>
    <div style="font-size:20px;font-weight:bold;color:#fff;margin-top:4px;">{val}</div>
  </div>
"""
    html += "</div>"

    # 去掉多餘縮排,避免開頭空白被解讀成 code block
    html = textwrap.dedent(html)

    st.markdown(html, unsafe_allow_html=True)

def display_strategy_summary(strategy: str, params: Dict, metrics: Dict, smaa_source: str, trade_df: pd.DataFrame):
    """
    顯示策略參數與回測績效摘要,使用 HTML Flexbox 卡片展示.
    """
    # 參數展示
    param_display = {k: v for k, v in params.items() if k != "strategy_type"}
    st.write("**參數設定**: " + ", ".join(f"{k}: {v}" for k, v in param_display.items()))

    # 計算平均持倉天數
    avg_holding_period = calculate_holding_periods(trade_df)

    # 將平均持倉天數加入 metrics
    metrics['avg_holding_period'] = avg_holding_period

    # 績效指標展示
    if metrics:
        display_metrics_flex(metrics)
    else:
        st.warning("尚未執行回測,無法顯示績效指標.")
# --- 主應用程式 ---
I'll check where risk valve is applied to see if it's replacing the full metrics.

root@5583bff288d6:/workspace/SSS096# rg "metrics" -n SSS_EnsembleTab.py
1405:        "metrics": {
It looks like the metrics dictionary might be around line 1405, near the backtest.

root@5583bff288d6:/workspace/SSS096# sed -n '1390,1415p' SSS_EnsembleTab.py
        if x.empty: return 0.0
        thr = x.quantile(0.90)
        return float(x[x > max(thr, 0)].sum())
    rt1 = right_tail_sum(r1)
    rt2 = right_tail_sum(r2)
    right_tail_reduction = (rt1 - rt2)

    return {
        "signals": sig,
        "weights_orig": w,
        "weights_valve": w2,
        "daily_state_orig": daily_state1,
        "daily_state_valve": daily_state2,
        "trade_ledger_orig": ledger1,
        "trade_ledger_valve": ledger2,
        "metrics": {
            "pf_orig": float(pf1), "pf_valve": float(pf2),
            "mdd_orig": float(mdd1), "mdd_valve": float(mdd2),
            "right_tail_sum_orig": float(rt1), "right_tail_sum_valve": float(rt2),
            "right_tail_reduction": float(right_tail_reduction)
        }
    }


# === PATCH: 交易貢獻拆解（按加碼/減碼階段）===
def trade_contribution_by_phase(trade_ledger: pd.DataFrame,
I'll check around lines 1060-1110 in app_dash to understand how risk valve is applied.

root@5583bff288d6:/workspace/SSS096# sed -n '1050,1115p' app_dash.py
                                else:
                                    logger.info(f"[{strat}] 🟢 風險閥門未觸發，ATR比值({ratio:.4f}) <= 門檻({atr_ratio})")
                            else:
                                logger.warning(f"[{strat}] Ensemble ATR(60) 值為 0，無法計算比值")
                        else:
                            logger.warning(f"[{strat}] Ensemble ATR 數據不足")
                    else:
                        logger.warning(f"[{strat}] Ensemble ATR 計算結果為空")

                except Exception as e:
                    logger.warning(f"[{strat}] 無法計算 Ensemble ATR 比值: {e}")
                    logger.warning(f"[{strat}] 錯誤詳情: {type(e).__name__}: {str(e)}")

                # 如果啟用強制觸發，則強制觸發風險閥門
                if force_trigger:
                    valve_triggered = True
                    logger.info(f"[{strat}] 🔴 強制觸發風險閥門啟用")
                    if ratio is None:
                        ratio = 1.5  # 設定一個預設值用於顯示

                # 使用新的 ensemble_runner 執行
                backtest_result = run_ensemble_backtest(cfg)

                # 若全局開關開啟且達觸發條件，才在權重序列上套用 CAP
                if global_apply and valve_triggered:
                    from SSS_EnsembleTab import risk_valve_backtest
                    bench = df_raw  # 已含 open/high/low/close/volume

                    logger.info(f"[{strat}] 🔴 開始套用風險閥門: cap={risk_cap}, ratio={ratio:.4f}")

                    rv = risk_valve_backtest(
                        open_px=backtest_result.price_series,
                        w=backtest_result.weight_curve,
                        cost=cost_params,
                        benchmark_df=bench,
                        mode="cap",
                        cap_level=float(risk_cap),
                    )
                    # 覆寫結果，確保 UI 與輸出一致
                    backtest_result.daily_state = rv["daily_state_valve"]
                    backtest_result.ledger = rv["trade_ledger_valve"]
                    backtest_result.weight_curve = rv["weights_valve"]
                    backtest_result.equity_curve = rv["daily_state_valve"]["equity"]
                    logger.info(f"[{strat}] 風險閥門已套用（cap={risk_cap}, ratio={ratio:.4f}）")

                    # 增加風險閥門效果的詳細資訊
                    if "metrics" in rv:
                        logger.info(f"[{strat}] 風險閥門效果: PF原始={rv['metrics'].get('pf_orig', 'N/A'):.2f}, PF閥門={rv['metr
ics'].get('pf_valve', 'N/A'):.2f}")
                        logger.info(f"[{strat}] 風險閥門效果: MDD原始={rv['metrics'].get('mdd_orig', 'N/A'):.2f}%, MDD閥門={rv['
metrics'].get('mdd_valve', 'N/A'):.2f}%")

                    # 給 UI 的標記（與 SSMA 分支對齊）
                    result['valve'] = {
                        "applied": True,
                        "cap": float(risk_cap),
                        "atr_ratio": ratio
                    }
                else:
                    if global_apply:
                        logger.info(f"[{strat}] 🟢 風險閥門未觸發，使用原始參數")
                        # 給 UI 的標記（未觸發）
                        result['valve'] = {
                            "applied": False,
                            "cap": float(risk_cap),
                            "atr_ratio": ratio if ratio is not None else "N/A"
                        }
                    else:
I’m checking the result variable in run_backtest to see if metrics are lost.

root@5583bff288d6:/workspace/SSS096# rg "result =" -n app_dash.py
868:            result = backtest_unified(df_ind, strat_type, backtest_params, buy_dates, sell_dates, discount=discount, trade_c
ooldown_bars=cooldown, bad_holding=bad_holding)
1071:                backtest_result = run_ensemble_backtest(cfg)
1125:                result = {
1146:                result = {
1170:            result = backtest_unified(df_ind, strat_type, strat_params, discount=discount, trade_cooldown_bars=cooldown, ba
d_holding=bad_holding)
1203:        result = _pack_result_for_store(result)
1397:            result = results.get(strategy)
1795:            result = results.get(strategy)
1846:            result = results.get(strategy)
2108:    result = results.get(strategy)
2161:    result = results.get(strategy)
3095:    result = results[selected_strategy]
3227:    best_result = results[best_strategy]
3363:        result = results[selected_strategy]
3790:            result = results[selected_strategy]
I'm checking how _pack_result_for_store stores metrics to understand if they're replaced by risk valve.

root@5583bff288d6:/workspace/SSS096# rg "_pack_result_for_store" -n app_dash.py
244:def _pack_result_for_store(result: dict) -> dict:
1203:        result = _pack_result_for_store(result)
root@5583bff288d6:/workspace/SSS096# sed -n '244,262p' app_dash.py
def _pack_result_for_store(result: dict) -> dict:
    # 統一把所有 pandas 物件轉成字串（JSON）
    keys = [
        'trade_df', 'trades_df', 'signals_df',
        'equity_curve', 'cash_curve', 'price_series',
        'daily_state', 'trade_ledger',
        'daily_state_std', 'trade_ledger_std',
        'weight_curve'
    ]
    out = dict(result)
    for k in keys:
        if k in out:
            out[k] = _pack_any(out[k])
    # 另外把 datetime tuple 的 trades 轉可序列化（你原本也有做）
    if 'trades' in out and isinstance(out['trades'], list):
        out['trades'] = [
            (str(t[0]), t[1], str(t[2])) if isinstance(t, tuple) and len(t) == 3 else t
            for t in out['trades']
        ]
I’ll look for the point where 'result' is built around line 868. Let's find more!

root@5583bff288d6:/workspace/SSS096# sed -n '840,909p' app_dash.py
                        logger.warning(f"[{strat}] ATR(20) 值異常: {atr_20_latest}，跳過風險閥門")
                        continue

                    atr_ratio_current = atr_20_latest / atr_60_latest
                    logger.info(f"[{strat}] 最新ATR比值: {atr_ratio_current:.4f} (20期:{atr_20_latest:.4f}, 60期:{atr_60_latest:
.4f})")
                else:
                    logger.warning(f"[{strat}] ATR 計算結果為空")

                # 強制觸發時設置標記
                if force_trigger:
                    valve_triggered = True
                    logger.info(f"[{strat}] 🔴 強制觸發風險閥門啟用")

            except Exception as e:
                logger.warning(f"[{strat}] ATR 計算失敗: {e}")
        else:
            logger.info(f"[{strat}] 未啟用全局風險閥門")

        if strat_type == 'ssma_turn':
            calc_keys = ['linlen', 'factor', 'smaalen', 'prom_factor', 'min_dist', 'buy_shift', 'exit_shift', 'vol_window', 'sig
nal_cooldown_days', 'quantile_win']
            ssma_params = {k: v for k, v in strat_params.items() if k in calc_keys}
            backtest_params = ssma_params.copy()
            backtest_params['stop_loss'] = strat_params.get('stop_loss', 0.0)

            # 重新計算策略信號（因為參數可能已經被風險閥門調整）
            df_ind, buy_dates, sell_dates = compute_ssma_turn_combined(df_raw, df_factor, **ssma_params, smaa_source=smaa_src)
            if df_ind.empty:
                continue
            result = backtest_unified(df_ind, strat_type, backtest_params, buy_dates, sell_dates, discount=discount, trade_coold
own_bars=cooldown, bad_holding=bad_holding)

            # === 在 ssma_turn 也套用風險閥門（和 Ensemble 一致的後置覆寫） ===
            if global_apply:
                # 判斷是否要觸發（與你的 ATR 檢查或強制觸發一致）
                valve_triggered_local = False
                ratio_local = None
                try:
                    atr_20 = calculate_atr(df_raw, 20)
                    atr_60 = calculate_atr(df_raw, 60)
                    if not atr_20.empty and not atr_60.empty:
                        a20 = atr_20.dropna().iloc[-1]
                        a60 = atr_60.dropna().iloc[-1]
                        if a60 > 0:
                            ratio_local = float(a20 / a60)
                            valve_triggered_local = (ratio_local >= atr_ratio)  # 建議使用 >=
                except Exception:
                    pass

                if force_trigger:
                    valve_triggered_local = True
                    if ratio_local is None:
                        ratio_local = 1.5

                if valve_triggered_local:
                    from SSS_EnsembleTab import risk_valve_backtest, CostParams
                    # 取得 open 價；df_raw 欄位名稱是小寫
                    open_px = df_raw['open'] if 'open' in df_raw.columns else df_raw['close']
                    # 從回測輸出抓 w（先用標準化 daily_state，如果沒有就用原 daily_state）
                    w_series = None
                    try:
                        ds_std = df_from_pack(result.get('daily_state_std'))
                        if ds_std is not None and not ds_std.empty and 'w' in ds_std.columns:
                            w_series = ds_std['w']
                    except Exception:
                        pass
                    if w_series is None:
                        ds = df_from_pack(result.get('daily_state'))
                        if ds is not None and not ds.empty and 'w' in ds.columns:
                            w_series = ds['w']

                    if w_series is not None:
root@5583bff288d6:/workspace/SSS096# sed -n '909,977p' app_dash.py
                    if w_series is not None:
                        # 交易成本（與 Ensemble 分支一致）
                        trade_cost = strat_params.get('trade_cost', {})
                        cost_params = CostParams(
                            buy_fee_bp=float(trade_cost.get("buy_fee_bp", 4.27)),
                            sell_fee_bp=float(trade_cost.get("sell_fee_bp", 4.27)),
                            sell_tax_bp=float(trade_cost.get("sell_tax_bp", 30.0))
                        )

                        rv = risk_valve_backtest(
                            open_px=open_px,
                            w=w_series,
                            cost=cost_params,
                            benchmark_df=df_raw,
                            mode="cap",
                            cap_level=float(risk_cap),
                        )

                        # 覆寫結果，確保 UI 與輸出一致（和 Ensemble 分支對齊）
                        result['equity_curve']     = pack_series(rv["daily_state_valve"]["equity"])
                        result['daily_state']      = pack_df(rv["daily_state_valve"])
                        result['daily_state_std']  = pack_df(rv["daily_state_valve"])
                        result['trade_ledger']     = pack_df(rv["trade_ledger_valve"])
                        result['trade_ledger_std'] = pack_df(rv["trade_ledger_valve"])
                        result['weight_curve']     = pack_series(rv["weights_valve"])
                        # 給 UI 的標記（下個小節會用到）
                        result['valve'] = {
                            "applied": True,
                            "cap": float(risk_cap),
                            "atr_ratio": ratio_local
                        }

                        logger.info(f"[{strat}] SSMA 風險閥門已套用（cap={risk_cap}, ratio={ratio_local:.4f}）")
                    else:
                        logger.warning(f"[{strat}] SSMA 無法取得權重序列，跳過風險閥門套用")
                else:
                    logger.info(f"[{strat}] SSMA 風險閥門未觸發，使用原始結果")
                    # 給 UI 的標記（未觸發）
                    result['valve'] = {
                        "applied": False,
                        "cap": float(risk_cap),
                        "atr_ratio": ratio_local if ratio_local is not None else "N/A"
                    }
        elif strat_type == 'ensemble':
            # 使用新的 ensemble_runner 避免循環依賴
            try:
                from runners.ensemble_runner import run_ensemble_backtest
                from SSS_EnsembleTab import EnsembleParams, CostParams, RunConfig

                # 把 SSSv096 的巢狀參數攤平
                flat_params = {}
                flat_params.update(strat_params.get('params', {}))
                flat_params.update(strat_params.get('trade_cost', {}))
                flat_params['method'] = strat_params.get('method', 'majority')
                flat_params['ticker'] = ticker

                # 使用比例門檻避免 N 變動時失真
                if 'majority_k' in flat_params and flat_params.get('method') == 'majority':
                    flat_params['majority_k_pct'] = 0.55
                    flat_params.pop('majority_k', None)
                    logger.info(f"[Ensemble] 使用比例門檻 majority_k_pct={flat_params['majority_k_pct']}")

                # 創建配置
                ensemble_params = EnsembleParams(
                    floor=flat_params.get("floor", 0.2),
                    ema_span=flat_params.get("ema_span", 3),
                    delta_cap=flat_params.get("delta_cap", 0.3),
                    majority_k=flat_params.get("majority_k", 6),
                    min_cooldown_days=flat_params.get("min_cooldown_days", 1),
It looks like the metrics dictionary gets lost after applying the risk valve, affecting UI display. I'll check backtest_unified and UI functions to pinpoint where metrics should be recomputed.

I need to inspect the backtest_unified function, possibly in the SSS_EnsembleTab module.

root@5583bff288d6:/workspace/SSS096# rg "def backtest_unified" -n
SSSv096.py
953:def backtest_unified(
I see backtest_unified is in SSSv096.py. I'll check how it returns metrics.

return np.nan

    holding_periods = []
    entry_date = None

    for _, row in trade_df.iterrows():
        if row['type'] == 'buy':
            entry_date = row['trade_date']
        elif row['type'] == 'sell' and entry_date is not None:
            exit_date = row['trade_date']
            holding_days = (exit_date - entry_date).days
            holding_periods.append(holding_days)
            entry_date = None  # 重置

    return np.mean(holding_periods) if holding_periods else np.nan


def backtest_unified(
    df_ind: pd.DataFrame,
    strategy_type: str,
    params: Dict,
    buy_dates: Optional[List[pd.Timestamp]] = None,
    sell_dates: Optional[List[pd.Timestamp]] = None,
    discount: float = 0.30,
    trade_cooldown_bars: int = 3,
    bad_holding: bool = False,
    use_leverage: bool = False,
    lev_params: Optional[Dict] = None
) -> Dict:
    if not isinstance(df_ind, pd.DataFrame):
        logger.error(f"df_ind 必須是一個 pandas.DataFrame，卻傳入 {type(df_ind)}")
        return {'trades': [], 'trade_df': pd.DataFrame(), 'trades_df': pd.DataFrame(), 'signals_df': pd.DataFrame(), 'metrics':
[], 'equity_curve': pd.Series()}

    # 處理 ensemble 策略類型
    elif strategy_type == "ensemble":
        import traceback
        from contextlib import nullcontext

        status_ctx = st.status("執行 Ensemble 回測中…", state="running") if hasattr(st, "status") else nullcontext()
        try:
            with status_ctx:
                # 從 Streamlit session_state 取得 ensemble 參數
                method = st.session_state.get('ensemble_method', 'majority')
                floor  = st.session_state.get('ensemble_floor', 0.2)
                ema    = st.session_state.get('ensemble_ema', 3)
                delta  = st.session_state.get('ensemble_delta', 0.3)

                # ---- CostParams：UI 以 bp 設定，內部轉成 rate ----
                buy_fee_bp  = float(st.session_state.get('buy_fee_bp',  4.27))
                sell_fee_bp = float(st.session_state.get('sell_fee_bp', 4.27))
                sell_tax_bp = float(st.session_state.get('sell_tax_bp', 30.0))
                slip_bp     = float(st.session_state.get('slippage_bp', 0.0))

                # 在 ensemble 分支裡面先決定 ticker_name
                ticker_name = (
                    params.get('ticker')
                    or (getattr(df_ind, 'name', None) if hasattr(df_ind, 'name') else None)
                    or 'UNKNOWN'
                )

                cost = CostParams(
                    buy_fee_bp   = buy_fee_bp,
The function seems to lose metrics when the risk valve is applied. I'll check the earlier code around lines 1115-1175 to understand how the result dictionary is constructed.

root@5583bff288d6:/workspace/SSS096# sed -n '1115,1175p' app_dash.py
                    else:
                        logger.info(f"[{strat}] ⚪ 全局風險閥門未啟用")
                        # 給 UI 的標記（未啟用）
                        result['valve'] = {
                            "applied": False,
                            "cap": "N/A",
                            "atr_ratio": "N/A"
                        }

                # 轉換為舊格式以保持相容性
                result = {
                    'trades': [],
                    'trade_df': pack_df(backtest_result.trades),
                    'trades_df': pack_df(backtest_result.trades),
                    'signals_df': pack_df(backtest_result.trades[['trade_date', 'type', 'price']].rename(columns={'type': 'actio
n'}) if not backtest_result.trades.empty else pd.DataFrame(columns=['trade_date', 'action', 'price'])),
                    'metrics': backtest_result.stats,
                    'equity_curve': pack_series(backtest_result.equity_curve),
                    'cash_curve': pack_series(backtest_result.cash_curve) if backtest_result.cash_curve is not None else "",
                    'weight_curve': pack_series(backtest_result.weight_curve) if backtest_result.weight_curve is not None else p
ack_series(pd.Series(0.0, index=backtest_result.equity_curve.index)),
                    'price_series': pack_series(backtest_result.price_series) if backtest_result.price_series is not None else p
ack_series(pd.Series(1.0, index=backtest_result.equity_curve.index)),
                    'daily_state': pack_df(backtest_result.daily_state),
                    'trade_ledger': pack_df(backtest_result.ledger),
                    'daily_state_std': pack_df(backtest_result.daily_state),
                    'trade_ledger_std': pack_df(backtest_result.ledger)
                }

                logger.info(f"[Ensemble] 執行成功: 權益曲線長度={len(backtest_result.equity_curve)}, 交易數={len(backtest_result
.ledger) if backtest_result.ledger is not None and not backtest_result.ledger.empty else 0}")

            except Exception as e:
                logger.error(f"Ensemble 策略執行失敗: {e}")
                # 創建空的結果
                result = {
                    'trades': [],
                    'trade_df': pd.DataFrame(),
                    'trades_df': pd.DataFrame(),
                    'signals_df': pd.DataFrame(),
                    'metrics': {'total_return': 0.0, 'annual_return': 0.0, 'max_drawdown': 0.0, 'sharpe_ratio': 0.0, 'calmar_rat
io': 0.0, 'num_trades': 0},
                    'equity_curve': pd.Series(1.0, index=df_raw.index)
                }

            # === 修復 3：添加調試日誌，核對子策略集合是否一致 ===
            logger.info(f"[Ensemble] 執行完成，ticker={ticker}, method={flat_params.get('method')}")
            if 'equity_curve' in result and hasattr(result['equity_curve'], 'shape'):
                logger.info(f"[Ensemble] 權益曲線長度: {len(result['equity_curve'])}")
            if 'trade_df' in result and hasattr(result['trade_df'], 'shape'):
                logger.info(f"[Ensemble] 交易記錄數量: {len(result['trade_df'])}")
        else:
            if strat_type == 'single':
                df_ind = compute_single(df_raw, df_factor, strat_params["linlen"], strat_params["factor"], strat_params["smaalen
"], strat_params["devwin"], smaa_source=smaa_src)
            elif strat_type == 'dual':
                df_ind = compute_dual(df_raw, df_factor, strat_params["linlen"], strat_params["factor"], strat_params["smaalen"]
, strat_params["short_win"], strat_params["long_win"], smaa_source=smaa_src)
            elif strat_type == 'RMA':
                df_ind = compute_RMA(df_raw, df_factor, strat_params["linlen"], strat_params["factor"], strat_params["smaalen"],
 strat_params["rma_len"], strat_params["dev_len"], smaa_source=smaa_src)
            if df_ind.empty:
                continue
            result = backtest_unified(df_ind, strat_type, strat_params, discount=discount, trade_cooldown_bars=cooldown, bad_hol
ding=bad_holding)

            # 為其他策略類型添加 valve 標記
            if global_apply:
                result['valve'] = {
                    "applied": False,  # 其他策略類型暫時不支援風險閥門
I see the code applies the risk valve before constructing the result dictionary, keeping the original stats intact. Maybe the backtest_result.stats is None, which could explain the issue with metrics later.

I’ll inspect the stats property in run_ensemble_backtest to check for serialization issues.

root@5583bff288d6:/workspace/SSS096# rg "class BacktestResult" -n
sss_core/schemas.py
11:class BacktestResult:
I'll open the file now to check its contents.

# sss_core/schemas.py
from __future__ import annotations
from dataclasses import dataclass
import pandas as pd
from typing import Dict, Any, Optional
import logging

logger = logging.getLogger(__name__)

@dataclass
class BacktestResult:
    """統一的回測輸出結構，供單一策略與 Ensemble 都遵守"""
    # 曲線類
    equity_curve: pd.Series           # 每日權益（必填）
    trades: pd.DataFrame              # 標準欄位：trade_date, type, price, delta_units, w_before, w_after, ...
    stats: Dict[str, Any]            # total_return, annual_return, max_drawdown, ...

    # 可選欄位
    daily_state: Optional[pd.DataFrame] = None  # 含 equity/cash/w 等（可選，但建議提供）
    ledger: Optional[pd.DataFrame] = None       # 若有更細的流水帳（可選）
    price_series: Optional[pd.Series] = None    # 價格序列
    weight_curve: Optional[pd.Series] = None    # 權重序列
    cash_curve: Optional[pd.Series] = None      # 現金序列

    def __post_init__(self):
        """驗證必要欄位"""
        if self.equity_curve is None or len(self.equity_curve) == 0:
            raise ValueError("equity_curve 是必填欄位且不能為空")
        if self.trades is None or len(self.trades) == 0:
            raise ValueError("trades 是必填欄位且不能為空")
        if self.stats is None:
            raise ValueError("stats 是必填欄位")

    def to_dict(self) -> Dict[str, Any]:
        """轉換為字典格式，用於序列化"""
        result = {
            'equity_curve': self.equity_curve,
            'trades': self.trades,
            'stats': self.stats
        }

        # 添加可選欄位
        if self.daily_state is not None:
            result['daily_state'] = self.daily_state
        if self.ledger is not None:
            result['ledger'] = self.ledger
        if self.price_series is not None:
            result['price_series'] = self.price_series
        if self.weight_curve is not None:
            result['weight_curve'] = self.weight_curve
        if self.cash_curve is not None:
            result['cash_curve'] = self.cash_curve

        return result


def pack_df(df: pd.DataFrame) -> str:
    """將 DataFrame 序列化為 JSON 字串，使用 orient="split" + date_format="iso"

    Args:
        df: 要序列化的 DataFrame

    Returns:
        JSON 字串，空 DataFrame 回傳空字串
    """
    if df is None or len(df) == 0:
        return ""
    return df.to_json(orient="split", date_format="iso")


def pack_series(s: pd.Series) -> str:
    """將 Series 序列化為 JSON 字串，使用 orient="split" + date_format="iso"

    Args:
        s: 要序列化的 Series

    Returns:
        JSON 字串，空 Series 回傳空字串
    """
    if s is None or len(s) == 0:
        return ""
    return s.to_json(orient="split", date_format="iso")
It looks like after applying the risk valve, the metrics dictionary gets wiped. I think the solution might be to recompute the metrics using compute_backtest_metrics or similar, ensuring backtest_result.stats stays intact. Also, _pack_result_for_store isn't processing metrics, so the dictionary should remain as is.

Metrics might disappear after risk valve, possibly due to overwriting or not repacking them after updates.

The issue might be from not updating backtest_result.stats after risk valve modifications, causing empty metrics.

The issue could be that backtest_result.stats is None, affecting metrics. I'll check ensemble_runner.py to confirm.

app_dash.py
955:                from runners.ensemble_runner import run_ensemble_backtest
1071:                backtest_result = run_ensemble_backtest(cfg)

runners/__init__.py
2:from .ensemble_runner import run_ensemble_backtest
4:__all__ = ['run_ensemble_backtest']

runners/ensemble_runner.py
13:def run_ensemble_backtest(cfg) -> BacktestResult:
root@5583bff288d6:/workspace/SSS096# sed -n '1,160p' runners/ensemble_runner.py
# runners/ensemble_runner.py
from __future__ import annotations
import logging
from typing import Optional
import pandas as pd

from sss_core.schemas import BacktestResult
from sss_core.normalize import normalize_trades_for_ui, normalize_daily_state

# 設置日誌
logger = logging.getLogger(__name__)

def run_ensemble_backtest(cfg) -> BacktestResult:
    """執行 Ensemble 策略並回傳標準化的 BacktestResult"""
    try:
        # 導入 Ensemble 相關模組
        from SSS_EnsembleTab import run_ensemble, EnsembleParams, CostParams, RunConfig

        # 運行 ensemble 策略
        open_px, w, trades, stats, method_name, equity, daily_state, trade_ledger = run_ensemble(cfg)

        # 標準化資料
        trades_ui = normalize_trades_for_ui(trades)
        daily_state_std = normalize_daily_state(daily_state)

        # 構建 BacktestResult
        result = BacktestResult(
            equity_curve=equity,
            daily_state=daily_state_std,
            trades=trades_ui,
            ledger=trade_ledger,
            stats=stats,
            price_series=open_px,
            weight_curve=w,
            cash_curve=daily_state_std['cash'] if daily_state_std is not None and 'cash' in daily_state_std.columns else None
        )

        logger.info(f"[Ensemble] 執行成功: {method_name}, 權益曲線長度={len(equity)}, 交易數={len(trade_ledger) if trade_ledger
is not None and not trade_ledger.empty else 0}")

        return result

    except Exception as e:
        logger.error(f"Ensemble 策略執行失敗: {e}")
        # 創建空的結果
        empty_df = pd.DataFrame()
        empty_series = pd.Series(dtype=float)

        return BacktestResult(
            equity_curve=empty_series,
            daily_state=empty_df,
            trades=empty_df,
            ledger=empty_df,
            stats={
                'total_return': 0.0,
                'annual_return': 0.0,
                'max_drawdown': 0.0,
                'sharpe_ratio': 0.0,
                'calmar_ratio': 0.0,
                'num_trades': 0
            }
        )
It seems metrics might not be included in the keys list for _pack_result_for_store.

root@5583bff288d6:/workspace/SSS096# rg "_unpack" -n app_dash.py
I'll look up df_from_pack to understand how the metrics are being retrieved.

root@5583bff288d6:/workspace/SSS096# rg "df_from_pack" -n
app_dash.py
141:def df_from_pack(data):
899:                        ds_std = df_from_pack(result.get('daily_state_std'))
905:                        ds = df_from_pack(result.get('daily_state'))
1209:            ds = df_from_pack(ds_raw)
1365:    df_raw = df_from_pack(data['df_raw'])  # 使用 df_from_pack 統一解包
1414:                df = df_from_pack(cand) if isinstance(cand, str) else cand
1424:            daily_state_std = df_from_pack(result.get('daily_state_std'))
1426:                daily_state_std = df_from_pack(result.get('daily_state'))
1430:            trade_ledger_std = df_from_pack(result.get('trade_ledger_std'))
1432:                trade_ledger_std = df_from_pack(result.get('trade_ledger'))
1492:            ledger_df = df_from_pack(result.get('trade_ledger'))
1597:            daily_state = df_from_pack(result.get('daily_state'))
1799:            trade_df = df_from_pack(result.get('trade_df'))
1851:            trade_df = df_from_pack(result.get('trade_df'))
2114:    trade_df = df_from_pack(result.get('trade_df'))
2167:    trade_df = df_from_pack(result.get('trade_df'))
2386:    df_raw = df_from_pack(cache.get("df_raw"))
2387:    daily_state = df_from_pack(cache.get("daily_state"))
2514:    trade_df = df_from_pack(cache.get("trade_data"))
2515:    daily_state = df_from_pack(cache.get("daily_state"))
2795:    trade_df = df_from_pack(cache.get("trade_data"))
2796:    daily_state = df_from_pack(cache.get("daily_state"))
3102:        trade_data = df_from_pack(result["trade_ledger_std"])
3105:        trade_data = df_from_pack(result["trade_ledger"])
3108:        trade_data = df_from_pack(result["trade_df"])
3153:        daily_state = df_from_pack(result["daily_state_std"])
3155:        daily_state = df_from_pack(result["daily_state"])
3234:        trade_data = df_from_pack(best_result["trade_ledger_std"])
3237:        trade_data = df_from_pack(best_result["trade_ledger"])
3240:        trade_data = df_from_pack(best_result["trade_df"])
3285:        daily_state = df_from_pack(best_result["daily_state_std"])
3287:        daily_state = df_from_pack(best_result["daily_state"])
3340:        df_raw = df_from_pack(cache.get("df_raw"))
3341:        daily_state = df_from_pack(cache.get("daily_state"))
3364:        daily_state = df_from_pack(result.get("daily_state") or result.get("daily_state_std"))
3365:        df_raw = df_from_pack(backtest_data.get("df_raw"))
3776:            df_raw = df_from_pack(cache.get("df_raw"))
3777:            daily_state = df_from_pack(cache.get("daily_state"))
3791:            daily_state = df_from_pack(result.get("daily_state") or result.get("daily_state_std"))
3792:            df_raw = df_from_pack(backtest_data.get("df_raw"))

analysis/UI_INTEGRATION_GUIDE.md
63:參考 `df_from_pack` 與 `format_trade_like_df_for_display` 的欄位映射邏輯：
I'm wondering if the risk valve code affects backtest_result.stats or resets it later.

...
2621:        kpi("平均每段 MDD(%)", f"{avg_mdd:.2f}" if pd.notna(avg_mdd) else "—"),
2622:        kpi("成功率(全部)", f"{succ_all*100:.1f}%" if pd.notna(succ_all) else "—"),
2623:        kpi("成功率(加碼)", f"{succ_acc*100:.1f}%" if pd.notna(succ_acc) else "—"),
2624:        kpi("風險效率", f"{risk_eff:.3f}" if pd.notna(risk_eff) else "—"),
2625:    ], style={"display":"flex","gap":"12px","flexWrap":"wrap","marginBottom":"10px"})
2627:    # ====== 分組 KPI：加碼 vs 減碼 ======
2628:    def _group_metrics(mask):
2629:        if {"階段淨貢獻(%)","階段內MDD(%)"}.issubset(table.columns):
2630:            sub = table.loc[mask]
2631:            if sub.empty:
2632:                return None
2633:            a_net = sub["階段淨貢獻(%)"].mean()
2634:            a_mdd = sub["階段內MDD(%)"].mean()
2635:            succ  = (sub["階段淨貢獻(%)"] > 0).mean()
2636:            eff   = (a_net / abs(a_mdd)) if pd.notna(a_net) and pd.notna(a_mdd) and a_mdd != 0 else np.nan
2637:            return {"count": int(len(sub)), "avg_net": a_net, "avg_mdd": a_mdd, "succ": succ, "eff": eff}
2638:        return None
2640:    def _fmt(val, pct=False, dec=2):
2641:        if val is None or (isinstance(val, float) and (np.isnan(val) or np.isinf(val))):
2642:            return "—"
2643:        return f"{val*100:.1f}%" if pct else f"{val:.{dec}f}"
2645:    def group_row(title, m):
2646:        return html.Div([
2647:            html.Div(title, style={"fontWeight":"bold","marginRight":"12px","minWidth":"72px","alignSelf":"center"}),
2648:            kpi("段數", f"{m['count']}" if m else "—"),
2649:            kpi("平均淨貢獻(%)", _fmt(m['avg_net']) if m else "—"),
2650:            kpi("平均MDD(%)",   _fmt(m['avg_mdd']) if m else "—"),
2651:            kpi("成功率",        _fmt(m['succ'], pct=True) if m else "—"),
2652:            kpi("風險效率",      _fmt(m['eff'],  dec=3) if m else "—"),
2653:        ], style={"display":"flex","gap":"10px","flexWrap":"wrap","marginBottom":"8px"})
2655:    acc_metrics = dis_metrics = None
2656:    if "階段" in table.columns:
2657:        mask_acc = table["階段"].astype(str).str.contains("加碼", na=False)
2658:        mask_dis = table["階段"].astype(str).str.contains("減碼", na=False)
2659:        acc_metrics = _group_metrics(mask_acc)
2660:        dis_metrics = _group_metrics(mask_dis)
2662:    group_section = html.Div([
2663:        html.H6("分組 KPI（加碼 vs 減碼）", style={"margin":"8px 0 6px 0"}),
2664:        group_row("加碼段", acc_metrics),
2665:        group_row("減碼段", dis_metrics),
2666:    ], style={"marginTop":"4px"})
2668:    # ====== Top/Worst 來源切換（全部 / 只加碼 / 只減碼） ======
2669:    source_selector = html.Div([
2670:        html.Div("Top/Worst 來源", style={"marginRight":"8px", "alignSelf":"center"}),
2671:        dcc.RadioItems(
2672:            id="phase-source",
2673:            options=[
2674:                {"label": "全部",   "value": "all"},
2675:                {"label": "加碼段", "value": "acc"},
2676:                {"label": "減碼段", "value": "dis"},
2678:            value="all",
2679:            inline=True,
2680:            inputStyle={"marginRight":"4px"},
2681:            labelStyle={"marginRight":"12px"}
2683:    ], style={"display":"flex","gap":"6px","alignItems":"center","margin":"6px 0 8px 0"})
2685:    # 欄位順序（完整表 & Top/Worst 共用）
2686:    ordered = [c for c in ["階段","開始日期","結束日期","交易筆數",
2687:                           "階段淨貢獻(%)","賣出報酬總和(%)","階段內MDD(%)","是否成功"] if c in table.columns]
2688:    basis_col = "階段淨貢獻(%)" if "階段淨貢獻(%)" in table.columns else "賣出報酬總和(%)"
2691:    full_table = dash_table.DataTable(
2692:        id="phase-datatable",
2693:        columns=[{"name": c, "id": c, "type": ("numeric" if c in num_cols else "text")} for c in ordered],
2694:        data=table[ordered].to_dict("records"),
2696:        page_action="native",
2697:        page_current=0,
2698:        page_size=100,            # 預設每頁 100，若要改可在這裡
2700:        sort_action="native",
2701:        filter_action="native",
2703:        export_format="csv",
2704:        export_headers="display",
2706:        cell_selectable=True,
2707:        virtualization=False,     # 關閉虛擬化，避免複製時只複到可視區
2708:        fixed_rows={"headers": True},
2709:        style_table=style_table,
2710:        style_cell=style_cell,
2711:        style_header=style_header,
2712:        css=[{
2713:            "selector": ".dash-table-container .dash-spreadsheet-container .dash-spreadsheet-inner *",
2714:            "rule": "user-select: text; -webkit-user-select: text; -moz-user-select: text; -ms-user-select: text;"
2718:    # ====== dcc.Store：提供 Top/Worst 動態 callback 使用 ======
2719:    store = dcc.Store(id="phase-table-store", data={
2720:        "records": table[ordered].to_dict("records"),
2721:        "ordered": ordered,
2722:        "basis": basis_col,
2723:        "has_stage": "階段" in table.columns
2727:    def _subset(src):
2728:        df = table
2729:        if "階段" not in df.columns:
2730:            return df
2731:        if src == "acc":
2732:            return df[df["階段"].astype(str).str.contains("加碼", na=False)]
2733:        if src == "dis":
2734:            return df[df["階段"].astype(str).str.contains("減碼", na=False)]
2735:        return df
2736:    base = _subset("all")
2737:    top3   = base.nlargest(3, basis_col) if basis_col in base else base.head(3)
2738:    worst3 = base.nsmallest(3, basis_col) if basis_col in base else base.tail(3)
2740:    def simple_table(df, tbl_id):
2741:        return dash_table.DataTable(
2742:            id=tbl_id,
2743:            columns=[{"name": c, "id": c} for c in ordered],
2744:            data=df[ordered].to_dict("records"),
2745:            page_action="none",
2746:            style_table=style_table, style_cell=style_cell, style_header=style_header
2749:    top3_table = simple_table(top3, "phase-top-table")
2750:    worst3_table = simple_table(worst3, "phase-worst-table")
2753:    tools = html.Div([
2754:        html.Button("複製全部（CSV）", id="phase-copy-btn",
2755:                    style={"padding": "6px 10px", "borderRadius": "8px", "cursor": "pointer"}),
2756:        dcc.Clipboard(target_id="phase-csv-text", title="Copy", style={"marginLeft": "6px"}),
2757:        html.A("下載 CSV", href=csv_data_url, download="trade_contribution.csv",
2758:               style={"marginLeft": "12px", "textDecoration": "none"})
2759:    ], style={"display": "flex", "alignItems": "center", "gap": "4px", "marginBottom": "8px"})
2761:    # 隱藏的 CSV 文字來源（給 Clipboard 用）
2762:    csv_hidden = html.Pre(id="phase-csv-text", children=csv_text, style={"display": "none"})
2764:    # ====== Tabs：易讀版 / 完整表格 ======
2765:    tabs = dcc.Tabs(id="phase-tabs", value="summary", children=[
2766:        dcc.Tab(label="易讀版", value="summary", children=[
2767:            kpi_bar,
2768:            group_section,
2769:            source_selector,
2770:            html.H6("最賺的 3 段（依來源與排序欄）", style={"marginTop":"8px"}),
2771:            top3_table,
2772:            html.H6("最虧的 3 段（依來源與排序欄）", style={"marginTop":"16px"}),
...
3795:            return None
3798:        if df_raw is None or df_raw.empty or daily_state is None or daily_state.empty:
3799:            return None
3802:        c_open = "open" if "open" in df_raw.columns else _first_col(df_raw, ["Open","開盤價"])
3803:        c_close = "close" if "close" in df_raw.columns else _first_col(df_raw, ["Close","收盤價"])
3804:        c_high  = "high" if "high" in df_raw.columns else _first_col(df_raw, ["High","最高價"])
3805:        c_low   = "low"  if "low"  in df_raw.columns else _first_col(df_raw, ["Low","最低價"])
3807:        if c_open is None or c_close is None:
3808:            return None
3811:        open_px = pd.to_numeric(df_raw[c_open], errors="coerce").dropna()
3812:        open_px.index = pd.to_datetime(df_raw.index)
3813:        if "w" not in daily_state.columns:
3814:            return None
3816:        w = daily_state["w"].astype(float).reindex(open_px.index).ffill().fillna(0.0)
3818:        bench = pd.DataFrame({
3819:            "收盤價": pd.to_numeric(df_raw[c_close], errors="coerce"),
3820:        }, index=pd.to_datetime(df_raw.index))
3821:        if c_high and c_low:
3822:            bench["最高價"] = pd.to_numeric(df_raw[c_high], errors="coerce")
3823:            bench["最低價"] = pd.to_numeric(df_raw[c_low], errors="coerce")
3825:        # 使用與 generate_pareto_map 相同的參數範圍和邏輯
3826:        logger.info("=== 開始生成 Pareto Map 數據用於 CSV 下載 ===")
3827:        caps = np.round(np.arange(0.10, 1.00 + 1e-9, 0.05), 2)
3828:        atr_mults = np.round(np.arange(1.00, 2.00 + 1e-9, 0.05), 2)
3829:        logger.info(f"cap 範圍: {len(caps)} 個值，從 {caps[0]} 到 {caps[-1]}")
3830:        logger.info(f"ATR 比值範圍: {len(atr_mults)} 個值，從 {atr_mults[0]} 到 {atr_mults[-1]}")
3831:        logger.info(f"總組合數: {len(caps) * len(atr_mults)}")
3833:        pareto_data = []
3834:        tried = 0
3835:        succeeded = 0
3837:        # 檢查是否可以匯入 risk_valve_backtest
3838:        try:
3839:            from SSS_EnsembleTab import risk_valve_backtest
3840:            logger.info("成功匯入 risk_valve_backtest")
3841:        except Exception as e:
3842:            logger.error(f"匯入 risk_valve_backtest 失敗: {e}")
3843:            return None
3845:        logger.info("開始執行參數掃描...")
3846:        for cap_level in caps:
3847:            for atr_mult in atr_mults:
3848:                tried += 1
3849:                if tried % 50 == 0:  # 每50次記錄一次進度
3850:                    logger.info(f"進度: {tried}/{len(caps) * len(atr_mults)} (cap={cap_level:.2f}, atr={atr_mult:.2f})")
3852:                try:
3853:                    out = risk_valve_backtest(
3854:                        open_px=open_px, w=w, cost=None, benchmark_df=bench,
3855:                        mode=(rv_mode or "cap"), cap_level=float(cap_level),
3856:                        slope20_thresh=0.0, slope60_thresh=0.0,
3857:                        atr_win=20, atr_ref_win=60, atr_ratio_mult=float(atr_mult)
3860:                    if out and "metrics" in out:
3861:                        m = out["metrics"]
3863:                        # 計算 Pareto 指標
3864:                        equity_curve = out.get("daily_state_valve", {}).get("equity")
3865:                        trade_df = None  # risk_valve_backtest 不直接提供交易記錄
3867:                        metrics = calculate_pareto_metrics(equity_curve, trade_df)
3868:                        if metrics:
3869:                            pareto_data.append({
3870:                                'strategy': f'cap_{cap_level:.2f}_atr_{atr_mult:.2f}',
3871:                                'cap': cap_level,
3872:                                'atr_ratio': atr_mult,
3873:                                'max_drawdown': metrics['max_drawdown'],
3874:                                'pf': metrics['pf'],
3875:                                'right_tail_loss': metrics['right_tail_loss'],
3876:                                'risk_trigger_days': metrics['risk_trigger_days'],
3877:                                'pf_orig': m.get('pf_orig', 0.0),
3878:                                'pf_valve': m.get('pf_valve', 0.0),
3879:                                'mdd_orig': m.get('mdd_orig', 0.0),
3880:                                'mdd_valve': m.get('mdd_valve', 0.0),
3881:                                'right_tail_reduction': m.get('right_tail_reduction', 0.0)
3883:                            succeeded += 1
3885:                except Exception as e:
3886:                    logger.debug(f"參數組合 cap={cap_level}, atr={atr_mult} 計算失敗: {e}")
3887:                    continue
3889:        if not pareto_data:
3890:            logger.warning("沒有生成任何 Pareto 數據")
3891:            return None
3893:        logger.info(f"成功生成 {succeeded} 組 Pareto 數據")
3895:        # 轉換為 DataFrame 並準備下載
3896:        df_pareto = pd.DataFrame(pareto_data)
3899:        timestamp = pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")
3900:        filename = f"pareto_map_data_{timestamp}.csv"
3903:        return dcc.send_data_frame(
3904:            df_pareto.to_csv,
3905:            filename,
3906:            index=False,
3907:            encoding='utf-8-sig'  # 支援中文
3910:    except Exception as e:
3911:        logger.exception(f"下載 Pareto Map CSV 失敗：{e}")
3912:        return None
3914:# --------- 新增：動態切換 Top/Worst 的 callback ---------
3915:@app.callback(
3916:    [dash.Output("phase-top-table", "data"),
3917:     dash.Output("phase-worst-table", "data")],
3918:    [dash.Input("phase-source", "value"),
3919:     dash.Input("phase-table-store", "data")]
3921:def _update_top_worst(src, store):
3922:    if not store:
3923:        raise dash.exceptions.PreventUpdate
3924:    import pandas as pd
3925:    records = store.get("records", [])
3926:    ordered = store.get("ordered", [])
3927:    basis   = store.get("basis", None)
3928:    has_stage = store.get("has_stage", False)
3930:    df = pd.DataFrame(records)
3932:    if has_stage and "階段" in df.columns:
3933:        if src == "acc":
3934:            df = df[df["階段"].astype(str).str.contains("加碼", na=False)]
3935:        elif src == "dis":
3936:            df = df[df["階段"].astype(str).str.contains("減碼", na=False)]
3938:    if basis and basis in df.columns and not df.empty:
3939:        top3   = df.nlargest(3, basis)
3940:        worst3 = df.nsmallest(3, basis)
3941:    else:
3942:        top3   = df.head(3)
3943:        worst3 = df.tail(3)
3945:    return top3[ordered].to_dict("records"), worst3[ordered].to_dict("records")
3947:if __name__ == '__main__':
3949:    safe_startup()
3952:    app.run_server(
3953:        debug=True,
3954:        host='127.0.0.1',
3955:        port=8050,
3956:        threaded=True,
3957:        use_reloader=False  # 避免重載器造成的線程問題
I'm looking into why metrics disappear after applying the risk valve. It might be related to JSON serialization issues with numpy objects or the structure of backtest_result.stats after the risk valve is applied.

Looks like metrics might be missing after the risk valve application. Could be a type issue or result not returning correctly.

The metrics problem likely arises when result is reset, potentially due to improper handling after risk valve is applied. I'll check run_backtest in detail.

I need to verify how stats is handled in run_ensemble to see if conversion is missing.

root@5583bff288d6:/workspace/SSS096# rg "def run_ensemble(" -n SSS_EnsembleTab.py
rg: regex parse error:
    (?:def run_ensemble()
    ^
error: unclosed group
The error is due to parentheses, so I need to escape them properly.

root@5583bff288d6:/workspace/SSS096# rg "def run_ensemble" -n SSS_EnsembleTab.py
749:def run_ensemble(cfg: RunConfig) -> Tuple[pd.Series, pd.Series, pd.DataFrame, Dict[str, float], str, pd.Series, pd.DataFrame
, pd.DataFrame]:
root@5583bff288d6:/workspace/SSS096# sed -n '749,830p' SSS_EnsembleTab.py
def run_ensemble(cfg: RunConfig) -> Tuple[pd.Series, pd.Series, pd.DataFrame, Dict[str, float], str, pd.Series, pd.DataFrame, pd
.DataFrame]:
    """回傳：(open 價), (每日權重 w), (交易紀錄 trades), (績效指標 dict), (方法名稱), (權益曲線), (每日狀態 daily_state), (交易流
水帳 trade_ledger)"""
    # 讀價（Open）
    px_path = DATA_DIR / f"{cfg.ticker.replace(':','_')}_data_raw.csv"
    px = _read_market_csv_auto(px_path)

    # 調試信息：價格數據
    logger.info(f"[Ensemble] 價資料天數={len(px)}, 首末={px.index.min()}~{px.index.max()}")

    # 推斷策略列表
    if cfg.strategies is None:
        # 優先使用 trades_from_results_*.csv（120檔策略）
        strat_names = []
        file_map = {}  # 策略名 -> 文件路徑的映射

        # 先找 trades_from_results_*.csv
        trades_files = list(OUT_DIR.glob("trades_from_results_*.csv"))
        if trades_files:
            logger.info(f"[Ensemble] 找到 {len(trades_files)} 個 trades_from_results_*.csv 文件（120檔策略）")
            for f in sorted(trades_files):
                # 從文件名推斷策略名稱
                name = f.stem.replace("trades_from_results_", "")
                strat_names.append(name)
                file_map[name] = f
        else:
            # 找不到再使用舊的 trades_*.csv（11檔策略）
            trades_files = list(OUT_DIR.glob("trades_*.csv"))
            logger.info(f"[Ensemble] 找到 {len(trades_files)} 個 trades_*.csv 文件（11檔策略）")
            for f in sorted(trades_files):
                # 從文件名推斷策略名稱
                name = f.stem.replace("trades_", "")
                strat_names.append(name)
                file_map[name] = f

        if not strat_names:
            raise ValueError(f"在 {OUT_DIR} 中找不到任何交易文件")

        cfg.strategies = strat_names
        cfg.file_map = file_map

    # 載入持倉矩陣
    pos_df = load_positions_matrix(OUT_DIR, px.index, cfg.strategies, cfg.file_map)

    if pos_df.empty:
        raise ValueError("無法載入任何策略的持倉數據")

    N = pos_df.shape[1]  # 策略數量
    logger.info(f"[Ensemble] 載入 {N} 個策略的持倉數據")

    # 處理 majority_k 參數
    if cfg.method.lower() == "majority":
        if cfg.majority_k_pct is not None:
            # 使用比例門檻
            k_req = int(math.ceil(N * cfg.majority_k_pct))
            logger.info(f"[Ensemble] 使用比例門檻 majority_k_pct={cfg.majority_k_pct}, N={N}, 計算得到 K={k_req}")
        else:
            # 使用固定 K 值
            k_req = cfg.params.majority_k
            logger.info(f"[Ensemble] 使用固定門檻 majority_k={k_req}, N={N}")

        # 方案 A：夾擠到合法範圍
        k_eff = max(1, min(int(k_req), N))

        # 方案 B：若 k>n 採用動態多數決（建議）：ceil(N*0.5)
        if k_req > N:
            logger.warning(f"majority_k({k_req}) > N({N}); fallback to ceil(N/2)={math.ceil(N*0.5)}")
            k_eff = int(math.ceil(N*0.5))

        # 用 dataclasses.replace 覆寫參數後再算權重與命名
        import dataclasses
        cfg.params = dataclasses.replace(cfg.params, majority_k=k_eff)

        # 檢查 N 是否足夠（可選但建議）
        if N < 8:
            logger.warning(f"策略數量 N={N} < 8，可能影響 ensemble 效果。建議確保有足夠的子策略。")

    # 調試信息：子策略多倉統計
    S = pos_df.sum(axis=1)
    logger.info(f"[Ensemble] 多頭計數S分佈: mean={S.mean():.2f}, 1%={S.quantile(0.01):.2f}, 99%={S.quantile(0.99):.2f}")

    # 權重
    if cfg.method.lower() == "majority":
The issue might be that stats is a pandas Series, not a dictionary.

After the risk valve, I need to recompute stats using the updated data to avoid empty metrics.

root@5583bff288d6:/workspace/SSS096# rg "stats" -n app_dash.py
1130:                    'metrics': backtest_result.stats,
1876:            detailed_stats = calculate_holding_periods(trade_df)
1888:                '平均持有天數': f"{detailed_stats['avg_holding_days']:.1f}",
1889:                '賣後買平均天數': f"{detailed_stats['avg_sell_to_buy_days']:.1f}",
1890:                '目前狀態': detailed_stats['current_status'],
1891:                '距離上次操作天數': f"{detailed_stats['days_since_last_action']}"
2196:def calculate_strategy_detailed_stats(trade_df, df_raw):
2993:        summary_stats = html.Div([
3008:            summary_stats,
The metrics might not be packed correctly. Let's simulate _pack_result_for_store to check.

I think the risk valve branch doesn't recompute metrics. Let's test by computing them post-valve.

root@5583bff288d6:/workspace/SSS096# rg "calculate_pareto_metrics" -n
app_dash.py
3547:def calculate_pareto_metrics(equity_curve, trade_df):
3867:                        metrics = calculate_pareto_metrics(equity_curve, trade_df)
It's odd that there's no general metrics function. Let's look for calc_all_metrics or similar.

root@5583bff288d6:/workspace/SSS096# rg "metrics" -n sss_core
sss_core/__init__.py
8:    plot_performance_metrics,
22:    'plot_performance_metrics',

sss_core/plotting.py
182:def plot_performance_metrics(stats: dict, title: str = "績效指標",
186:    key_metrics = ['total_return', 'annual_return', 'max_drawdown', 'sharpe_ratio']
192:    for metric, display_name in zip(key_metrics, display_names):
It looks like the metrics may be overwritten after the risk valve. I'll check _pack_any.

root@5583bff288d6:/workspace/SSS096# rg "def _pack_any" -n app_dash.py
236:def _pack_any(x):
root@5583bff288d6:/workspace/SSS096# sed -n '236,244p' app_dash.py
def _pack_any(x):
    import pandas as pd
    if isinstance(x, pd.DataFrame):
        return pack_df(x)          # orient="split" + date_format="iso"
    if isinstance(x, pd.Series):
        return pack_series(x)      # orient="split" + date_format="iso"
    return x

def _pack_result_for_store(result: dict) -> dict:
The bug may occur when applying the risk valve to all strategies, causing metrics to vanish. The issue could be related to overwriting the result variable or serialization errors when storing numpy values.

I suspect the bug might occur because result is referenced before being defined in the risk valve block. I'll check if result = {} appears earlier in the function.

Looks like result isn't defined earlier in the function, which could be causing the bug. I should check if the code is inside a try block that might catch errors.

root@5583bff288d6:/workspace/SSS096# sed -n '735,820p' app_dash.py
            logger.info("等待數據載入：未選擇股票代號或日期")
            return html.Div([
                html.Small("🟡 等待數據載入", style={"color":"#ffc107","fontWeight":"bold"}),
                html.Br(),
                html.Small("請選擇股票代號和日期", style={"color":"#666","fontSize":"10px"})
            ])
    except Exception as e:
        logger.error(f"風險閥門狀態更新失敗: {e}")
        return html.Div([
            html.Small("🟡 計算中...", style={"color":"#ffc107","fontWeight":"bold"}),
            html.Br(),
            html.Small(f"錯誤: {str(e)}", style={"color":"#666","fontSize":"10px"})
        ])

# --------- 執行回測並存到 Store ---------
@app.callback(
    Output('backtest-store', 'data'),
    [
        Input('run-btn', 'n_clicks'),
        Input('auto-run', 'value'),
        Input('ticker-dropdown', 'value'),
        Input('start-date', 'value'),
        Input('end-date', 'value'),
        Input('discount-slider', 'value'),
        Input('cooldown-bars', 'value'),
        Input('bad-holding', 'value'),
        Input('global-apply-switch', 'value'),
        Input('risk-cap-input', 'value'),
        Input('atr-ratio-threshold', 'value'),
        Input('force-valve-trigger', 'value'),
        Input('strategy-dropdown', 'value'),
        Input({'type': 'param-input', 'param': ALL}, 'value'),
        Input({'type': 'param-input', 'param': ALL}, 'id'),
    ],
    State('backtest-store', 'data')
)
def run_backtest(n_clicks, auto_run, ticker, start_date, end_date, discount, cooldown, bad_holding, global_apply, risk_cap, atr_
ratio, force_trigger, strategy, param_values, param_ids, stored_data):
    # === 調試日誌（僅在 DEBUG 級別時顯示）===
    logger.debug(f"run_backtest 被調用 - n_clicks: {n_clicks}, auto_run: {auto_run}, trigger: {ctx.triggered_id}")

    # 移除自動快取清理，避免多用户衝突
    # 讓 joblib.Memory 自動管理快取，只在需要時手動清理
    if n_clicks is None and not auto_run:
        logger.debug(f"早期返回：n_clicks={n_clicks}, auto_run={auto_run}")
        return stored_data

    # 載入數據
    df_raw, df_factor = load_data(ticker, start_date, end_date, "Self")
    if df_raw.empty:
        logger.warning(f"無法載入 {ticker} 的數據")
        return {"error": f"無法載入 {ticker} 的數據"}

    ctx_trigger = ctx.triggered_id

    # 只在 auto-run 為 True 或按鈕被點擊時運算
    if not auto_run and ctx_trigger != 'run-btn':
        logger.debug(f"跳過回測：auto_run={auto_run}, ctx_trigger={ctx_trigger}")
        return stored_data

    logger.info(f"開始執行回測 - ticker: {ticker}, 策略數: {len(strategy_names)}")
    results = {}

    # === 新增：全局風險閥門觸發狀態追蹤 ===
    valve_triggered = False
    atr_ratio_current = None

    for strat in strategy_names:
        # 只使用 param_presets 中的參數
        strat_params = param_presets[strat].copy()
        strat_type = strat_params["strategy_type"]
        smaa_src = strat_params.get("smaa_source", "Self")

        # 為每個策略載入對應的數據
        df_raw, df_factor = load_data(ticker, start_date, end_date if end_date else None, smaa_source=smaa_src)

        # 應用全局風險閥門設定（如果啟用）
        logger.info(f"[{strat}] 風險閥門開關狀態: global_apply={global_apply}, 類型={type(global_apply)}")
        if global_apply:
            logger.info(f"[{strat}] 應用全局風險閥門: CAP={risk_cap}, ATR比值門檻={atr_ratio}")

            # 計算 ATR 比值（使用最新數據，僅用於日誌顯示）
            try:
                atr_20 = calculate_atr(df_raw, 20)
                atr_60 = calculate_atr(df_raw, 60)

                # 確保 ATR 數據有效
I suspect the result variable is being referenced before definition, causing potential bugs.

The valve info is lost after the new result dict is built without it.

Let's check if result['valve'] is reassigned after line 1125.

root@5583bff288d6:/workspace/SSS096# sed -n '1125,1165p' app_dash.py
                result = {
                    'trades': [],
                    'trade_df': pack_df(backtest_result.trades),
                    'trades_df': pack_df(backtest_result.trades),
                    'signals_df': pack_df(backtest_result.trades[['trade_date', 'type', 'price']].rename(columns={'type': 'actio
n'}) if not backtest_result.trades.empty else pd.DataFrame(columns=['trade_date', 'action', 'price'])),
                    'metrics': backtest_result.stats,
                    'equity_curve': pack_series(backtest_result.equity_curve),
                    'cash_curve': pack_series(backtest_result.cash_curve) if backtest_result.cash_curve is not None else "",
                    'weight_curve': pack_series(backtest_result.weight_curve) if backtest_result.weight_curve is not None else p
ack_series(pd.Series(0.0, index=backtest_result.equity_curve.index)),
                    'price_series': pack_series(backtest_result.price_series) if backtest_result.price_series is not None else p
ack_series(pd.Series(1.0, index=backtest_result.equity_curve.index)),
                    'daily_state': pack_df(backtest_result.daily_state),
                    'trade_ledger': pack_df(backtest_result.ledger),
                    'daily_state_std': pack_df(backtest_result.daily_state),
                    'trade_ledger_std': pack_df(backtest_result.ledger)
                }

                logger.info(f"[Ensemble] 執行成功: 權益曲線長度={len(backtest_result.equity_curve)}, 交易數={len(backtest_result
.ledger) if backtest_result.ledger is not None and not backtest_result.ledger.empty else 0}")

            except Exception as e:
                logger.error(f"Ensemble 策略執行失敗: {e}")
                # 創建空的結果
                result = {
                    'trades': [],
                    'trade_df': pd.DataFrame(),
                    'trades_df': pd.DataFrame(),
                    'signals_df': pd.DataFrame(),
                    'metrics': {'total_return': 0.0, 'annual_return': 0.0, 'max_drawdown': 0.0, 'sharpe_ratio': 0.0, 'calmar_rat
io': 0.0, 'num_trades': 0},
                    'equity_curve': pd.Series(1.0, index=df_raw.index)
                }

            # === 修復 3：添加調試日誌，核對子策略集合是否一致 ===
            logger.info(f"[Ensemble] 執行完成，ticker={ticker}, method={flat_params.get('method')}")
            if 'equity_curve' in result and hasattr(result['equity_curve'], 'shape'):
                logger.info(f"[Ensemble] 權益曲線長度: {len(result['equity_curve'])}")
            if 'trade_df' in result and hasattr(result['trade_df'], 'shape'):
                logger.info(f"[Ensemble] 交易記錄數量: {len(result['trade_df'])}")
        else:
            if strat_type == 'single':
                df_ind = compute_single(df_raw, df_factor, strat_params["linlen"], strat_params["factor"], strat_params["smaalen
"], strat_params["devwin"], smaa_source=smaa_src)
            elif strat_type == 'dual':
                df_ind = compute_dual(df_raw, df_factor, strat_params["linlen"], strat_params["factor"], strat_params["smaalen"]
, strat_params["short_win"], strat_params["long_win"], smaa_source=smaa_src)
I think metrics vanish after applying the risk valve. I'll recompute metrics post-transformation.

root@5583bff288d6:/workspace/SSS096# rg "calculate_metrics" -n
analysis/ROEAv4.py
25:from SSSv095a1 import calculate_metrics, load_data_wrapper
407:    all_metric_cols = list(calculate_metrics([], pd.DataFrame()).keys())

SSSv096.py
40:    "compute_backtest_for_periods", "calculate_metrics",
824:def calculate_metrics(trades: List[Tuple[pd.Timestamp, float, pd.Timestamp]], df_ind: pd.DataFrame, equity_curve: pd.Series
= None) -> Dict:
1295:    metrics = calculate_metrics(trades, df_ind, equity_curve)
I'll open lines 824 to 835 in SSSv096.py to check out calculate_metrics.

root@5583bff288d6:/workspace/SSS096# sed -n '824,870p' SSSv096.py
def calculate_metrics(trades: List[Tuple[pd.Timestamp, float, pd.Timestamp]], df_ind: pd.DataFrame, equity_curve: pd.Series = No
ne) -> Dict:
    """
    計算回測績效指標.
    Args:
        trades: 交易記錄,包含日期和報酬率.
        df_ind: 指標數據 DataFrame,包含交易日索引.
        equity_curve: 全部回測期間的每日資產淨值（可選, 若要計算持有期間MMD需提供）
    Returns:
        Dict: 包含總回報率、年化回報率、最大回撤等指標.
    """
    metrics = {
        'total_return': 0.0,
        'annual_return': 0.0,
        'max_drawdown': 0.0,  # 這裡之後會直接用 max_mmd 覆蓋
        'max_drawdown_duration': 0,
        'calmar_ratio': np.nan,
        'num_trades': 0,
        'win_rate': 0.0,
        'avg_win': np.nan,
        'avg_loss': np.nan,
        'payoff_ratio': np.nan,
        'sharpe_ratio': np.nan,
        'sortino_ratio': np.nan,
        'max_consecutive_wins': 0,# 新增
        'max_consecutive_losses': 0,# 新增
        'avg_holding_period': np.nan,# 新增
        'annualized_volatility': np.nan,# 新增
        'profit_factor': np.nan,# 新增
        # 'avg_mmd': np.nan, # 不再需要
        # 'max_mmd': np.nan, # 不再需要單獨欄位
    }
    if not trades:
        return metrics

    trade_metrics = pd.DataFrame(trades, columns=['entry_date', 'return', 'exit_date']).set_index('exit_date')
    trade_metrics['equity'] = (1 + trade_metrics['return']).cumprod()
    roll_max = trade_metrics['equity'].cummax()
    daily_drawdown = trade_metrics['equity'] / roll_max - 1

    # 基本指標
    metrics['total_return'] = trade_metrics['equity'].iloc[-1] - 1
    years = max((trade_metrics.index[-1] - trade_metrics.index[0]).days / 365.25, 1)
    metrics['annual_return'] = (1 + metrics['total_return']) ** (1 / years) - 1

    # 既有日內回撤（numpy 陣列）
    dd_np = (daily_drawdown < 0).astype(bool)
I’ll use existing functions to recompute metrics or preserve them from backtest_result.stats.

I need to check if run_ensemble_backtest causes stats to be a Series instead of dict.

root@5583bff288d6:/workspace/SSS096# rg "stats" -n SSS_EnsembleTab.py | head -n 40
691:def perf_stats(equity: pd.Series, w: pd.Series) -> Dict[str, float]:
871:    stats = perf_stats(equity, w)
874:    logger.info(f"[Ensemble] 績效摘要: 總報酬={stats.get('total_return', 0):.4f}, 年化={stats.get('annual_return', 0):.4f},
最大回撤={stats.get('max_drawdown', 0):.4f}")
895:        f.write(f"績效: {stats}\n")
902:    return px["open"], w, trades_ui, stats, method_name, equity, daily_state, trade_ledger_ui
904:def save_outputs(method_name: str, open_px: pd.Series, w: pd.Series, trades: pd.DataFrame, stats: Dict[str, float], equity:
pd.Series = None, cost: CostParams = None, daily_state: pd.DataFrame = None, trade_ledger: pd.DataFrame = None):
943:        "total_return": stats.get("total_return"),
944:        "annual_return": stats.get("annual_return"),
945:        "max_drawdown": stats.get("max_drawdown"),
946:        "calmar_ratio": stats.get("calmar_ratio"),
947:        "sharpe_ratio": stats.get("sharpe_ratio"),
948:        "sortino_ratio": stats.get("sortino_ratio"),
949:        "time_in_market": stats.get("time_in_market"),
950:        "turnover_py": stats.get("turnover_py"),
951:        "num_trades": stats.get("num_trades"),
1009:    open_px, w, trades, stats, method_name, equity, daily_state, trade_ledger = run_ensemble(cfg)
1012:    save_outputs(method_name, open_px, w, trades, stats, equity, cost, daily_state, trade_ledger)
1015:    print(f"績效: {stats}")
1082:                open_px, w, trades, stats, method_name, equity, daily_state, trade_ledger = run_ensemble(cfg)
1090:                st.metric("總報酬率", f"{stats.get('total_return', 0):.2%}")
1091:                st.metric("年化報酬率", f"{stats.get('annual_return', 0):.2%}")
1093:                st.metric("最大回撤", f"{stats.get('max_drawdown', 0):.2%}")
1094:                st.metric("夏普比率", f"{stats.get('sharpe_ratio', 0):.2f}")
1096:                st.metric("卡瑪比率", f"{stats.get('calmar_ratio', 0):.2f}")
1097:                st.metric("交易次數", stats.get('num_trades', 0))
1219:            save_outputs(method_name, open_px, w, trades, stats, equity, cost, daily_state, trade_ledger)
I'm looking into why metrics might be replaced with 'avg_holding_period' during result handling.

root@5583bff288d6:/workspace/SSS096# rg "avg_holding_period" -n app_dash.py
1545:            metrics['avg_holding_period'] = avg_holding
1559:                "avg_holding_period": "平均持倉天數",
1573:                elif k in ["max_drawdown_duration", "avg_holding_period"]:
I'll check around line 1545 to examine how avg_holding_period is integrated into the metrics.

root@5583bff288d6:/workspace/SSS096# sed -n '1528,1554p' app_dash.py

            if ledger_src is not None and not ledger_src.empty:
                # 為了 100% 保證 weight_change 出現，先確保權重欄位
                ledger_src = _ensure_weight_columns(ledger_src)
                # 使用新的統一格式化函式
                ledger_display = format_trade_like_df_for_display(ledger_src)
                ledger_columns = [{"name": i, "id": i} for i in ledger_display.columns]
                ledger_data = ledger_display.to_dict('records')
            else:
                ledger_columns = []
                ledger_data = []

            metrics = result.get('metrics', {})
            tooltip = f"{strategy} 策略説明"
            param_display = {k: v for k, v in param_presets[strategy].items() if k != "strategy_type"}
            param_str = ", ".join(f"{k}: {v}" for k, v in param_display.items())
            avg_holding = calculate_holding_periods(trade_df)
            metrics['avg_holding_period'] = avg_holding

            label_map = {
                "total_return": "總回報率",
                "annual_return": "年化回報率",
                "win_rate": "勝率",
                "max_drawdown": "最大回撤",
                "max_drawdown_duration": "回撤持續",
                "calmar_ratio": "卡瑪比率",
                "sharpe_ratio": "夏普比率",
It looks like result is saved with results[strat] = result. I'll search for this.

root@5583bff288d6:/workspace/SSS096# rg "results\[strat\]" -n app_dash.py
1320:        results[strat] = result
root@5583bff288d6:/workspace/SSS096# sed -n '1310,1325p' app_dash.py
                            'atr_ratio': float(atr_ratio),
                            'atr20_last': float(atr_20_valid.iloc[-1]) if len(atr_20_valid) > 0 else None,
                            'atr60_last': float(atr_60_valid.iloc[-1]) if len(atr_60_valid) > 0 else None,
                        }

                        true_days = int(mask_aligned.sum())
                        logger.info(f"[{strat}] 全局風險閥門已套用（逐日），風險天數={true_days}, CAP={risk_cap:.2f}")
                    else:
                        logger.warning(f"[{strat}] 風險閥門重算沒有返回結果")

        results[strat] = result

    # 使用第一個策略的數據作為主要顯示數據
    first_strat = list(results.keys())[0] if results else strategy_names[0]
    first_smaa_src = param_presets[first_strat].get("smaa_source", "Self")
    df_raw_main, _ = load_data(ticker, start_date, end_date if end_date else None, smaa_source=first_smaa_src)
I think the issue with empty metrics happens after modifying result—metrics get lost when risk valve triggers unintended changes. There's also a bug referencing result before its definition in the risk valve block.

The missing metrics might happen when risk valve triggers, overwriting or mutating result unexpectedly.

I’ll investigate results.get(strategy) calls that might modify results, beyond displaying at line 1397.

root@5583bff288d6:/workspace/SSS096# sed -n '1388,1408p' app_dash.py
        bg_color = '#003366'
        legend_font_color = '#ffe066'
        legend_bgcolor = '#002244'
        legend_bordercolor = '#ffe066'

    if tab == "backtest":
        # 創建策略回測的子頁籤
        strategy_tabs = []
        for strategy in strategy_names:
            result = results.get(strategy)
            if not result:
                continue

            # === 統一入口：讀取交易表、日狀態、權益曲線 ===
            # 讀交易表的統一入口：先用標準鍵，再 fallback
            trade_df = None
            candidates = [
                result.get('trades'),      # 全局覆寫後標準鍵
                result.get('trades_ui'),   # 舊格式（若還存在）
                result.get('trade_df'),    # 某些策略自帶
            ]
I’ll ensure correct metric preservation after applying the risk valve and initialize data properly.

I need to confirm the structure of the trade ledger from risk_valve_backtest before calculating metrics.

root@5583bff288d6:/workspace/SSS096# sed -n '1359,1387p' SSS_EnsembleTab.py
def risk_valve_backtest(open_px: pd.Series,
                        w: pd.Series,
                        cost,
                        benchmark_df: pd.DataFrame,
                        mode: str = "cap",
                        cap_level: float = 0.5,
                        slope20_thresh: float = 0.0,
                        slope60_thresh: float = 0.0,
                        atr_win: int = 20,
                        atr_ref_win: int = 60,
                        atr_ratio_mult: float = 1.3) -> dict:
    """回傳：原始與閥門版本的績效、右尾削減度、以及兩版 equity/ledger"""
    sig = compute_risk_valve_signals(benchmark_df, slope20_thresh, slope60_thresh,
                                     atr_win, atr_ref_win, atr_ratio_mult)
    w2 = apply_valve_to_weights(w, sig["risk_trigger"], mode, cap_level)

    # 原始版本
    daily_state1, ledger1 = build_portfolio_ledger(open_px, w, cost)
    # 閥門版本
    daily_state2, ledger2 = build_portfolio_ledger(open_px, w2, cost)

    # 交易統計（只用賣出列；符合 re.txt 對實現損益的口徑）
    r1 = _sell_returns_pct_from_ledger(ledger1)
    r2 = _sell_returns_pct_from_ledger(ledger2)
    pf1 = (r1[r1>0].sum() / abs(r1[r1<0].sum())) if (r1[r1<0].sum()!=0) else np.inf
    pf2 = (r2[r2>0].sum() / abs(r2[r2<0].sum())) if (r2[r2<0].sum()!=0) else np.inf
    mdd1 = _mdd_from_daily_equity(daily_state1["equity"])
    mdd2 = _mdd_from_daily_equity(daily_state2["equity"])
I'll scroll through from line 1387 to dive deeper into the ledger.

root@5583bff288d6:/workspace/SSS096# sed -n '1387,1410p' SSS_EnsembleTab.py

    # 右尾削減：比較兩版的「>P90 的正報酬總和」
    def right_tail_sum(x: pd.Series):
        if x.empty: return 0.0
        thr = x.quantile(0.90)
        return float(x[x > max(thr, 0)].sum())
    rt1 = right_tail_sum(r1)
    rt2 = right_tail_sum(r2)
    right_tail_reduction = (rt1 - rt2)

    return {
        "signals": sig,
        "weights_orig": w,
        "weights_valve": w2,
        "daily_state_orig": daily_state1,
        "daily_state_valve": daily_state2,
        "trade_ledger_orig": ledger1,
        "trade_ledger_valve": ledger2,
        "metrics": {
            "pf_orig": float(pf1), "pf_valve": float(pf2),
            "mdd_orig": float(mdd1), "mdd_valve": float(mdd2),
            "right_tail_sum_orig": float(rt1), "right_tail_sum_valve": float(rt2),
            "right_tail_reduction": float(right_tail_reduction)
        }
I’m exploring how to compute metrics based on trade ledger or equity curve. I'll check perf_stats.

root@5583bff288d6:/workspace/SSS096# sed -n '691,711p' SSS_EnsembleTab.py
def perf_stats(equity: pd.Series, w: pd.Series) -> Dict[str, float]:
    """計算績效指標"""
    if len(equity) < 2:
        return {}

    # 計算日報酬率
    r = equity.pct_change().dropna()

    # 基本指標
    total_return = (equity.iloc[-1] / equity.iloc[0]) - 1
    annual_return = total_return * (252 / len(equity))

    # 最大回撤
    cummax = equity.cummax()
    drawdown = (equity - cummax) / cummax
    max_drawdown = drawdown.min()

    # 風險調整指標
    sharpe_ratio = r.mean() / r.std() * np.sqrt(252) if r.std() > 0 else 0
    calmar_ratio = annual_return / abs(max_drawdown) if max_drawdown != 0 else 0
    sortino_ratio = r.mean() / r[r < 0].std() * np.sqrt(252) if len(r[r < 0]) > 0 and r[r < 0].std() > 0 else 0
root@5583bff288d6:/workspace/SSS096# sed -n '711,730p' SSS_EnsembleTab.py
    sortino_ratio = r.mean() / r[r < 0].std() * np.sqrt(252) if len(r[r < 0]) > 0 and r[r < 0].std() > 0 else 0

    # 其他指標
    time_in_market = (w > 0.5).mean()
    turnover_py = w.diff().abs().sum() / len(w) * 252

    return {
        'total_return': total_return,
        'annual_return': annual_return,
        'max_drawdown': max_drawdown,
        'sharpe_ratio': sharpe_ratio,
        'calmar_ratio': calmar_ratio,
        'sortino_ratio': sortino_ratio,
        'time_in_market': time_in_market,
        'turnover_py': turnover_py,
        'num_trades': len(w.diff()[w.diff() != 0])
    }

# ---------------------------------------------------------------------
# 主流程：讀價、讀子策略部位 -> 生成權重 -> 權益與交易 -> 輸出
After applying the risk valve, I'll recompute stats using perf_stats to ensure metrics exist.

I need to confirm AGENTS instructions for Chinese comments and modification records in app_dash.py.

root@5583bff288d6:/workspace/SSS096# head -n 20 app_dash.py
import dash
from dash import dcc, html, dash_table, Input, Output, State, ctx, no_update
import dash_bootstrap_components as dbc
import pandas as pd
import plotly.graph_objects as go
import json
import io
from dash.dependencies import ALL
import shutil
import os
from datetime import datetime, timedelta
from pathlib import Path
import joblib
from analysis import config as cfg
import yfinance as yf
import logging
import numpy as np
from urllib.parse import quote as urlparse

# 配置 logger - 使用新的顯式初始化
The instructions ask for a date-stamped record and file path at the top of modified files. I'll check other files for examples.

root@5583bff288d6:/workspace/SSS096# rg "修改紀錄" -n
AGENTS.md
93:- 修改紀錄需加入日期時間戳記
I'm adding date/time and risk valve handling in the backtest. I'll adjust the code flow.

Metrics must be recomputed after applying the risk valve in both ssma_turn and ensemble branches.

I’ll recompute metrics after applying risk valve and ensure they’re serializable for ssma_turn.

I’ll apply fixes for both branches, adjust imports, and recompute metrics as necessary.

root@5583bff288d6:/workspace/SSS096# which pwsh
root@5583bff288d6:/workspace/SSS096# which powershell
PowerShell isn't available, but I'll try using pwsh to execute the script and record errors.

root@5583bff288d6:/workspace/SSS096# sed -n '1070,1135p' app_dash.py
                # 使用新的 ensemble_runner 執行
                backtest_result = run_ensemble_backtest(cfg)

                # 若全局開關開啟且達觸發條件，才在權重序列上套用 CAP
                if global_apply and valve_triggered:
                    from SSS_EnsembleTab import risk_valve_backtest
                    bench = df_raw  # 已含 open/high/low/close/volume

                    logger.info(f"[{strat}] 🔴 開始套用風險閥門: cap={risk_cap}, ratio={ratio:.4f}")

                    rv = risk_valve_backtest(
                        open_px=backtest_result.price_series,
                        w=backtest_result.weight_curve,
                        cost=cost_params,
                        benchmark_df=bench,
                        mode="cap",
                        cap_level=float(risk_cap),
                    )
                    # 覆寫結果，確保 UI 與輸出一致
                    backtest_result.daily_state = rv["daily_state_valve"]
                    backtest_result.ledger = rv["trade_ledger_valve"]
                    backtest_result.weight_curve = rv["weights_valve"]
                    backtest_result.equity_curve = rv["daily_state_valve"]["equity"]
                    logger.info(f"[{strat}] 風險閥門已套用（cap={risk_cap}, ratio={ratio:.4f}）")

                    # 增加風險閥門效果的詳細資訊
                    if "metrics" in rv:
                        logger.info(f"[{strat}] 風險閥門效果: PF原始={rv['metrics'].get('pf_orig', 'N/A'):.2f}, PF閥門={rv['metr
ics'].get('pf_valve', 'N/A'):.2f}")
                        logger.info(f"[{strat}] 風險閥門效果: MDD原始={rv['metrics'].get('mdd_orig', 'N/A'):.2f}%, MDD閥門={rv['
metrics'].get('mdd_valve', 'N/A'):.2f}%")

                    # 給 UI 的標記（與 SSMA 分支對齊）
                    result['valve'] = {
                        "applied": True,
                        "cap": float(risk_cap),
                        "atr_ratio": ratio
                    }
                else:
                    if global_apply:
                        logger.info(f"[{strat}] 🟢 風險閥門未觸發，使用原始參數")
                        # 給 UI 的標記（未觸發）
                        result['valve'] = {
                            "applied": False,
                            "cap": float(risk_cap),
                            "atr_ratio": ratio if ratio is not None else "N/A"
                        }
                    else:
                        logger.info(f"[{strat}] ⚪ 全局風險閥門未啟用")
                        # 給 UI 的標記（未啟用）
                        result['valve'] = {
                            "applied": False,
                            "cap": "N/A",
                            "atr_ratio": "N/A"
                        }

                # 轉換為舊格式以保持相容性
                result = {
                    'trades': [],
                    'trade_df': pack_df(backtest_result.trades),
                    'trades_df': pack_df(backtest_result.trades),
                    'signals_df': pack_df(backtest_result.trades[['trade_date', 'type', 'price']].rename(columns={'type': 'actio
n'}) if not backtest_result.trades.empty else pd.DataFrame(columns=['trade_date', 'action', 'price'])),
                    'metrics': backtest_result.stats,
                    'equity_curve': pack_series(backtest_result.equity_curve),
                    'cash_curve': pack_series(backtest_result.cash_curve) if backtest_result.cash_curve is not None else "",
                    'weight_curve': pack_series(backtest_result.weight_curve) if backtest_result.weight_curve is not None else p
ack_series(pd.Series(0.0, index=backtest_result.equity_curve.index)),
                    'price_series': pack_series(backtest_result.price_series) if backtest_result.price_series is not None else p
ack_series(pd.Series(1.0, index=backtest_result.equity_curve.index)),
                    'daily_state': pack_df(backtest_result.daily_state),
I need to fix the result['valve'] issue and adjust ssma_turn from 909–977.

root@5583bff288d6:/workspace/SSS096# sed -n '909,960p' app_dash.py
                    if w_series is not None:
                        # 交易成本（與 Ensemble 分支一致）
                        trade_cost = strat_params.get('trade_cost', {})
                        cost_params = CostParams(
                            buy_fee_bp=float(trade_cost.get("buy_fee_bp", 4.27)),
                            sell_fee_bp=float(trade_cost.get("sell_fee_bp", 4.27)),
                            sell_tax_bp=float(trade_cost.get("sell_tax_bp", 30.0))
                        )

                        rv = risk_valve_backtest(
                            open_px=open_px,
                            w=w_series,
                            cost=cost_params,
                            benchmark_df=df_raw,
                            mode="cap",
                            cap_level=float(risk_cap),
                        )

                        # 覆寫結果，確保 UI 與輸出一致（和 Ensemble 分支對齊）
                        result['equity_curve']     = pack_series(rv["daily_state_valve"]["equity"])
                        result['daily_state']      = pack_df(rv["daily_state_valve"])
                        result['daily_state_std']  = pack_df(rv["daily_state_valve"])
                        result['trade_ledger']     = pack_df(rv["trade_ledger_valve"])
                        result['trade_ledger_std'] = pack_df(rv["trade_ledger_valve"])
                        result['weight_curve']     = pack_series(rv["weights_valve"])
                        # 給 UI 的標記（下個小節會用到）
                        result['valve'] = {
                            "applied": True,
                            "cap": float(risk_cap),
                            "atr_ratio": ratio_local
                        }

                        logger.info(f"[{strat}] SSMA 風險閥門已套用（cap={risk_cap}, ratio={ratio_local:.4f}）")
                    else:
                        logger.warning(f"[{strat}] SSMA 無法取得權重序列，跳過風險閥門套用")
                else:
                    logger.info(f"[{strat}] SSMA 風險閥門未觸發，使用原始結果")
                    # 給 UI 的標記（未觸發）
                    result['valve'] = {
                        "applied": False,
                        "cap": float(risk_cap),
                        "atr_ratio": ratio_local if ratio_local is not None else "N/A"
                    }
        elif strat_type == 'ensemble':
            # 使用新的 ensemble_runner 避免循環依賴
            try:
                from runners.ensemble_runner import run_ensemble_backtest
                from SSS_EnsembleTab import EnsembleParams, CostParams, RunConfig

                # 把 SSSv096 的巢狀參數攤平
                flat_params = {}
                flat_params.update(strat_params.get('params', {}))
I’ll import perf_stats inside the function, update imports, and compute metrics after risk valve. I'll patch the file now.

root@5583bff288d6:/workspace/SSS096# sed -n '100,120p' app_dash.py
        return pd.Series(index=df.index, dtype=float)

def calculate_equity_curve(open_px, w, cap, atr_ratio):
    """計算權益曲線"""
    try:
        # 簡化的權益曲線計算
        # 這裡使用開盤價和權重的乘積來模擬權益變化
        equity = (open_px * w * cap).cumsum()
        return equity
    except Exception as e:
        logger.warning(f"權益曲線計算失敗: {e}")
        return None

def calculate_trades_from_equity(equity_curve, open_px, w, cap, atr_ratio):
    """從權益曲線計算交易記錄"""
    try:
        if equity_curve is None or equity_curve.empty:
            return None

        # 簡化的交易記錄生成
        # 這裡根據權重變化來識別交易
I'll add a modification record comment at the top and apply necessary code changes.

root@5583bff288d6:/workspace/SSS096# sed -n '1,20p' app_dash.py
import dash
from dash import dcc, html, dash_table, Input, Output, State, ctx, no_update
import dash_bootstrap_components as dbc
import pandas as pd
import plotly.graph_objects as go
import json
import io
from dash.dependencies import ALL
import shutil
import os
from datetime import datetime, timedelta
from pathlib import Path
import joblib
from analysis import config as cfg
import yfinance as yf
import logging
import numpy as np
from urllib.parse import quote as urlparse

# 配置 logger - 使用新的顯式初始化
I noticed the lack of a modification record, so I'll go ahead and add one.

root@5583bff288d6:/workspace/SSS096# apply_patch<<'PATCH'
> *** Begin Patch
> *** Update File: app_dash.py
> @@
> -import dash
> -from dash import dcc, html, dash_table, Input, Output, State, ctx, no_update
> -import dash_bootstrap_components as dbc
> -import pandas as pd
> -import plotly.graph_objects as go
> -import json
> -import io
> -from dash.dependencies import ALL
> -import shutil
> -import os
> -from datetime import datetime, timedelta
> -from pathlib import Path
> -import joblib
> -from analysis import config as cfg
> -import yfinance as yf
> -import logging
> -import numpy as np
> -from urllib.parse import quote as urlparse
> -
> -# 配置 logger - 使用新的顯式初始化
> +import dash
> +from dash import dcc, html, dash_table, Input, Output, State, ctx, no_update
> +import dash_bootstrap_components as dbc
> +import pandas as pd
> +import plotly.graph_objects as go
> +import json
> +import io
> +from dash.dependencies import ALL
> +import shutil
> +import os
> +from datetime import datetime, timedelta
> +from pathlib import Path
> +import joblib
> +from analysis import config as cfg
> +import yfinance as yf
> +import logging
> +import numpy as np
> +from urllib.parse import quote as urlparse
> +
> +#app_dash.py
> +# 修改紀錄:
> +# 2025-08-19: 修正風險閥門套用後績效指標遺失問題，並在結果構建後加入閥門資訊
> +
> +# 配置 logger - 使用新的顯式初始化
> *** End Patch
> PATCH
Success. Updated the following files:
M app_dash.py
The patch worked! Now, I'll adjust the ensemble branch risk valve as planned.

root@5583bff288d6:/workspace/SSS096# apply_patch<<'PATCH'
> *** Begin Patch
> *** Update File: app_dash.py
> @@
> -                # 使用新的 ensemble_runner 執行
> -                backtest_result = run_ensemble_backtest(cfg)
> -
出一致
+                    backtest_result.daily_state = rv["daily_state_valve"]
+                    backtest_result.ledger = rv["trade_ledger_valve"]
+                    backtest_r> -                # 若全局開關開啟且達觸發條件，才在權重序列上套用 CAP
> -                if global_apply and valve_triggered:
      > -                    from SSS_EnsembleTab import risk_valve_backtest
> -                    bench = df_raw  # 已含 open/high/low/close/volume
f"[{strat}] > -
> -                    logger.info(f"[{strat}] 🔴 開始套用風險閥門: cap={risk_cap}, ratio={ratio:.4f}")
> -
> -                    rv = risk_valve_backtest(
> -                        open_px=backtest_result.price_series,
風險閥> -                        w=backtest_result.weight_curve,
> -                        cost=cost_params,
et('pf_valve> -                        benchmark_df=bench,
> -                        mode="cap",
> -                        cap_level=float(risk_cap),
mdd_orig', 'N/A'):> -                    )
> -                    # 覆寫結果，確保 UI 與輸出一致
> -                    backtest_result.daily_state = rv["daily_state_valve"]
    > -                    backtest_result.ledger = rv["trade_ledger_valve"]
> -                    backtest_result.weight_curve = rv["weights_valve"]
> -                    backtest_result.equity_curve = rv["daily_state_valve"]["equity"]
> -                    logger.info(f"[{strat}] 風險閥門已套用（cap={risk_cap}, ratio={ratio:.4f}）")
> -
> -                    # 增加風險閥門效果的詳細資訊
> -                    if "metrics" in rv:
> -                        logger.info(f"[{strat}] 風險閥門效果: PF原始={rv['metrics'].get('pf_orig', 'N/A'):.2f}, PF閥門={rv['m
etrics'].get('pf_valve', 'N/A'):.2f}")
> -                        logger.info(f"[{strat}] 風險閥門效果: MDD原始={rv['metrics'].get('mdd_orig', 'N/A'):.2f}%, MDD閥門={r
v['metrics'].get('mdd_valve', 'N/A'):.2f}%")
> -
> -                    # 給 UI 的標記（與 SSMA 分支對齊）
> -                    result['valve'] = {
{
> -                        "applied": True,
> -                        "cap": float(risk_cap),
backtest_result> -                        "atr_ratio": ratio
> -                    }
> -                else:
.trades),
@@
          > -                    if global_apply:
> -                        logger.info(f"[{strat}] 🟢 風險閥門未觸發，使用原始參數")
> -                        # 給 UI 的標記（未觸發）
> -                        result['valve'] = {
)
+       > -                            "applied": False,
o is no> -                            "cap": float(risk_cap),
valve'] = valve_> -                            "atr_ratio": ratio if ratio is not None else "N/A",
> -                        }
> -                    else:
> -                        logger.info(f"[{strat}] ⚪ 全局風險閥門未啟用")
> -                        # 給 UI 的標記（未啟用）
> -                        result['valve'] = {
> -                            "applied": False,
> -                            "cap": "N/A",
> -                            "atr_ratio": "N/A",
> -                        }
> -
> -                # 轉換為舊格式以保持相容性
> -                result = {
> +                # 使用新的 ensemble_runner 執行
> +                backtest_result = run_ensemble_backtest(cfg)
> +
> +                valve_info = None
> +                # 若全局開關開啟且達觸發條件，才在權重序列上套用 CAP
> +                if global_apply and valve_triggered:
> +                    from SSS_EnsembleTab import risk_valve_backtest, perf_stats
> +                    bench = df_raw  # 已含 open/high/low/close/volume
> +
> +                    logger.info(f"[{strat}] 🔴 開始套用風險閥門: cap={risk_cap}, ratio={ratio:.4f}")
> +
> +                    rv = risk_valve_backtest(
> +                        open_px=backtest_result.price_series,
> +                        w=backtest_result.weight_curve,
> +                        cost=cost_params,
> +                        benchmark_df=bench,
> +                        mode="cap",
> +                        cap_level=float(risk_cap),
> +                    )
> +                    # 覆寫結果，確保 UI 與輸出一致
> +                    backtest_result.daily_state = rv["daily_state_valve"]
> +                    backtest_result.ledger = rv["trade_ledger_valve"]
> +                    backtest_result.weight_curve = rv["weights_valve"]
> +                    backtest_result.equity_curve = rv["daily_state_valve"]["equity"]
> +                    backtest_result.stats = perf_stats(backtest_result.equity_curve, backtest_result.weight_curve)
> +                    logger.info(f"[{strat}] 風險閥門已套用（cap={risk_cap}, ratio={ratio:.4f}）")
> +
> +                    # 增加風險閥門效果的詳細資訊
> +                    if "metrics" in rv:
> +                        logger.info(f"[{strat}] 風險閥門效果: PF原始={rv['metrics'].get('pf_orig', 'N/A'):.2f}, PF閥門={rv['m
etrics'].get('pf_valve', 'N/A'):.2f}")
> +                        logger.info(f"[{strat}] 風險閥門效果: MDD原始={rv['metrics'].get('mdd_orig', 'N/A'):.2f}%, MDD閥門={r
v['metrics'].get('mdd_valve', 'N/A'):.2f}%")
> +
> +                    valve_info = {
> +                        "applied": True,
> +                        "cap": float(risk_cap),
> +                        "atr_ratio": ratio,
> +                    }
> +                else:
> +                    if global_apply:
> +                        logger.info(f"[{strat}] 🟢 風險閥門未觸發，使用原始參數")
> +                        valve_info = {
> +                            "applied": False,
> +                            "cap": float(risk_cap),
> +                            "atr_ratio": ratio if ratio is not None else "N/A",
> +                        }
> +                    else:
> +                        logger.info(f"[{strat}] ⚪ 全局風險閥門未啟用")
> +                        valve_info = {
> +                            "applied": False,
> +                            "cap": "N/A",
> +                            "atr_ratio": "N/A",
> +                        }
> +
> +                # 轉換為舊格式以保持相容性
> +                result = {
>                      'trades': [],
>                      'trade_df': pack_df(backtest_result.trades),
>                      'trades_df': pack_df(backtest_result.trades),
> @@
>                      'daily_state_std': pack_df(backtest_result.daily_state),
> -                    'trade_ledger_std': pack_df(backtest_result.ledger)
> -                }
> +                    'trade_ledger_std': pack_df(backtest_result.ledger)
> +                }
> +                if valve_info is not None:
> +                    result['valve'] = valve_info
> *** End Patch
> PATCH
Failed to find expected lines ["                # 使用新的 ensemble_runner 執行", "                backtest_result = run_ensembl
e_backtest(cfg)", "", "                # 若全局開關開啟且達觸發條件，才在權重序列上套用 CAP", "                if global_apply a
nd valve_triggered:", "                    from SSS_EnsembleTab import risk_valve_backtest", "                    bench = df_raw
  # 已含 open/high/low/close/volume", "", "                    logger.info(f\"[{strat}] 🔴 開始套用風險閥門: cap={risk_cap}, rat
io={ratio:.4f}\")", "", "                    rv = risk_valve_backtest(", "                        open_px=backtest_result.price_
series,", "                        w=backtest_result.weight_curve,", "                        cost=cost_params,", "
           benchmark_df=bench,", "                        mode=\"cap\",", "                        cap_level=float(risk_cap),",
"                    )", "                    # 覆寫結果，確保 UI 與輸出一致", "                    backtest_result.daily_state
= rv[\"daily_state_valve\"]", "                    backtest_result.ledger = rv[\"trade_ledger_valve\"]", "                    ba
cktest_result.weight_curve = rv[\"weights_valve\"]", "                    backtest_result.equity_curve = rv[\"daily_state_valve\
"][\"equity\"]", "                    logger.info(f\"[{strat}] 風險閥門已套用（cap={risk_cap}, ratio={ratio:.4f}）\")", "", "
                 # 增加風險閥門效果的詳細資訊", "                    if \"metrics\" in rv:", "                        logger.inf
o(f\"[{strat}] 風險閥門效果: PF原始={rv['metrics'].get('pf_orig', 'N/A'):.2f}, PF閥門={rv['metrics'].get('pf_valve', 'N/A'):.2f}
\")", "                        logger.info(f\"[{strat}] 風險閥門效果: MDD原始={rv['metrics'].get('mdd_orig', 'N/A'):.2f}%, MDD閥
門={rv['metrics'].get('mdd_valve', 'N/A'):.2f}%\")", "", "                    # 給 UI 的標記（與 SSMA 分支對齊）", "
        result['valve'] = {", "                        \"applied\": True,", "                        \"cap\": float(risk_cap),",
 "                        \"atr_ratio\": ratio", "                    }", "                else:", "                    if globa
l_apply:", "                        logger.info(f\"[{strat}] 🟢 風險閥門未觸發，使用原始參數\")", "                        # 給
UI 的標記（未觸發）", "                        result['valve'] = {", "                            \"applied\": False,", "
                     \"cap\": float(risk_cap),", "                            \"atr_ratio\": ratio if ratio is not None else \"N
/A\",", "                        }", "                    else:", "                        logger.info(f\"[{strat}] ⚪ 全局風險閥
門未啟用\")", "                        # 給 UI 的標記（未啟用）", "                        result['valve'] = {", "
              \"applied\": False,", "                            \"cap\": \"N/A\",", "                            \"atr_ratio\":
 \"N/A\",", "                        }", "", "                # 轉換為舊格式以保持相容性", "                result = {", "
              'trades': [],", "                    'trade_df': pack_df(backtest_result.trades),", "                    'trades_d
f': pack_df(backtest_result.trades),"] in app_dash.py
The lines didn't match, so I'll patch using smaller segments to ensure accuracy.

root@5583bff288d6:/workspace/SSS096# sed -n '1070,1120p' app_dash.py
                    logger.info(f"[{strat}] 🔴 強制觸發風險閥門啟用")
                    if ratio is None:
                        ratio = 1.5  # 設定一個預設值用於顯示

                # 使用新的 ensemble_runner 執行
                backtest_result = run_ensemble_backtest(cfg)

                # 若全局開關開啟且達觸發條件，才在權重序列上套用 CAP
                if global_apply and valve_triggered:
                    from SSS_EnsembleTab import risk_valve_backtest
                    bench = df_raw  # 已含 open/high/low/close/volume

                    logger.info(f"[{strat}] 🔴 開始套用風險閥門: cap={risk_cap}, ratio={ratio:.4f}")

                    rv = risk_valve_backtest(
                        open_px=backtest_result.price_series,
                        w=backtest_result.weight_curve,
                        cost=cost_params,
                        benchmark_df=bench,
                        mode="cap",
                        cap_level=float(risk_cap),
                    )
                    # 覆寫結果，確保 UI 與輸出一致
                    backtest_result.daily_state = rv["daily_state_valve"]
                    backtest_result.ledger = rv["trade_ledger_valve"]
                    backtest_result.weight_curve = rv["weights_valve"]
                    backtest_result.equity_curve = rv["daily_state_valve"]["equity"]
                    logger.info(f"[{strat}] 風險閥門已套用（cap={risk_cap}, ratio={ratio:.4f}）")

                    # 增加風險閥門效果的詳細資訊
                    if "metrics" in rv:
                        logger.info(f"[{strat}] 風險閥門效果: PF原始={rv['metrics'].get('pf_orig', 'N/A'):.2f}, PF閥門={rv['metr
ics'].get('pf_valve', 'N/A'):.2f}")
                        logger.info(f"[{strat}] 風險閥門效果: MDD原始={rv['metrics'].get('mdd_orig', 'N/A'):.2f}%, MDD閥門={rv['
metrics'].get('mdd_valve', 'N/A'):.2f}%")

                    # 給 UI 的標記（與 SSMA 分支對齊）
                    result['valve'] = {
                        "applied": True,
                        "cap": float(risk_cap),
                        "atr_ratio": ratio
                    }
                else:
                    if global_apply:
                        logger.info(f"[{strat}] 🟢 風險閥門未觸發，使用原始參數")
                        # 給 UI 的標記（未觸發）
                        result['valve'] = {
                            "applied": False,
                            "cap": float(risk_cap),
                            "atr_ratio": ratio if ratio is not None else "N/A"
                        }
                    else:
                        logger.info(f"[{strat}] ⚪ 全局風險閥門未啟用")
root@5583bff288d6:/workspace/SSS096# sed -n '1120,1168p' app_dash.py
                        logger.info(f"[{strat}] ⚪ 全局風險閥門未啟用")
                        # 給 UI 的標記（未啟用）
                        result['valve'] = {
                            "applied": False,
                            "cap": "N/A",
                            "atr_ratio": "N/A"
                        }

                # 轉換為舊格式以保持相容性
                result = {
                    'trades': [],
                    'trade_df': pack_df(backtest_result.trades),
                    'trades_df': pack_df(backtest_result.trades),
                    'signals_df': pack_df(backtest_result.trades[['trade_date', 'type', 'price']].rename(columns={'type': 'actio
n'}) if not backtest_result.trades.empty else pd.DataFrame(columns=['trade_date', 'action', 'price'])),
                    'metrics': backtest_result.stats,
                    'equity_curve': pack_series(backtest_result.equity_curve),
                    'cash_curve': pack_series(backtest_result.cash_curve) if backtest_result.cash_curve is not None else "",
                    'weight_curve': pack_series(backtest_result.weight_curve) if backtest_result.weight_curve is not None else p
ack_series(pd.Series(0.0, index=backtest_result.equity_curve.index)),
                    'price_series': pack_series(backtest_result.price_series) if backtest_result.price_series is not None else p
ack_series(pd.Series(1.0, index=backtest_result.equity_curve.index)),
                    'daily_state': pack_df(backtest_result.daily_state),
                    'trade_ledger': pack_df(backtest_result.ledger),
                    'daily_state_std': pack_df(backtest_result.daily_state),
                    'trade_ledger_std': pack_df(backtest_result.ledger)
                }

                logger.info(f"[Ensemble] 執行成功: 權益曲線長度={len(backtest_result.equity_curve)}, 交易數={len(backtest_result
.ledger) if backtest_result.ledger is not None and not backtest_result.ledger.empty else 0}")

            except Exception as e:
                logger.error(f"Ensemble 策略執行失敗: {e}")
                # 創建空的結果
                result = {
                    'trades': [],
                    'trade_df': pd.DataFrame(),
                    'trades_df': pd.DataFrame(),
                    'signals_df': pd.DataFrame(),
                    'metrics': {'total_return': 0.0, 'annual_return': 0.0, 'max_drawdown': 0.0, 'sharpe_ratio': 0.0, 'calmar_rat
io': 0.0, 'num_trades': 0},
                    'equity_curve': pd.Series(1.0, index=df_raw.index)
                }

            # === 修復 3：添加調試日誌，核對子策略集合是否一致 ===
            logger.info(f"[Ensemble] 執行完成，ticker={ticker}, method={flat_params.get('method')}")
            if 'equity_curve' in result and hasattr(result['equity_curve'], 'shape'):
                logger.info(f"[Ensemble] 權益曲線長度: {len(result['equity_curve'])}")
            if 'trade_df' in result and hasattr(result['trade_df'], 'shape'):
                logger.info(f"[Ensemble] 交易記錄數量: {len(result['trade_df'])}")
        else:
            if strat_type == 'single':
                df_ind = compute_single(df_raw, df_factor, strat_params["linlen"], strat_params["factor"], strat_params["smaalen
"], strat_params["devwin"], smaa_source=smaa_src)
            elif strat_type == 'dual':
Time to create a patch with the lines we have, preserving the necessary context.

root@5583bff288d6:/workspace/SSS096# apply_patch<<'PATCH'
> *** Begin Patch
> *** Update File: app_dash.py
 rv["da> @@
> -                # 使用新的 ensemble_runner 執行
> -                backtest_result = run_ensemble_backtest(cfg)
> -
> -                # 若全局開關開啟且達觸發條件，才在權重序列上套用 CAP
> -                if global_apply and valve_triggered:
   b> -                    from SSS_EnsembleTab import risk_valve_backtest
> -                    bench = df_raw  # 已含 open/high/low/close/volume
> -
> -                    logger.info(f"[{strat}] 🔴 開始套用風險閥門: cap={risk_cap}, ratio={ratio:.4f}")
> -
> -                    rv = risk_valve_backtest(
> -                        open_px=backtest_result.price_series,
> -                        w=backtest_result.weight_curve,
2> -                        cost=cost_params,
> -                        benchmark_df=bench,
> -                        mode="cap",
> -                        cap_level=float(risk_cap),
/A'):.2> -                    )
t> -                    # 覆寫結果，確保 UI 與輸出一致
           va> -                    backtest_result.daily_state = rv["daily_state_valve"]
,
+                   > -                    backtest_result.ledger = rv["trade_ledger_valve"]
: rati> -                    backtest_result.weight_curve = rv["weights_valve"]
  if> -                    backtest_result.equity_curve = rv["daily_state_valve"]["equity"]
> -                    logger.info(f"[{strat}] 風險閥門已套用（cap={risk_cap}, ratio={ratio:.4f}）")
"applied": > -
Fa> -                    # 增加風險閥門效果的詳細資訊
isk_cap),
+    > -                    if "metrics" in rv:
> -                        logger.info(f"[{strat}] 風險閥門效果: PF原始={rv['metrics'].get('pf_orig', 'N/A'):.2f}, PF閥門={rv['m
etrics'].get('pf_valve', 'N/A'):.2f}")
> -                        logger.info(f"[{strat}] 風險閥門效果: MDD原始={rv['metrics'].get('mdd_orig', 'N/A'):.2f}%, MDD閥門={r
v['metrics'].get('mdd_valve', 'N/A'):.2f}%")
+    > -
  > -                    # 給 UI 的標記（與 SSMA 分支對齊）
> -                    result['valve'] = {
   result = {
  > -                        "applied": True,
> -                        "cap": float(risk_cap),
> -                        "atr_ratio": ratio
> -                    }
> -                else:

            > -                    if global_apply:
er': pack_df(backt> -                        logger.info(f"[{strat}] 🟢 風險閥門未觸發，使用原始參數")
ate),
-> -                        # 給 UI 的標記（未觸發）
test_re> -                        result['valve'] = {

+            > -                            "applied": False,
> -                            "cap": float(risk_cap),
v> -                            "atr_ratio": ratio if ratio is not None else "N/A"
o
*** End> -                        }
> -                    else:
> -                        logger.info(f"[{strat}] ⚪ 全局風險閥門未啟用")
> -                        # 給 UI 的標記（未啟用）
> -                        result['valve'] = {
> -                            "applied": False,
> -                            "cap": "N/A",
> -                            "atr_ratio": "N/A"
> -                        }
> -
> -                # 轉換為舊格式以保持相容性
> -                result = {
> +                # 使用新的 ensemble_runner 執行
> +                backtest_result = run_ensemble_backtest(cfg)
> +
> +                valve_info = None
> +                # 若全局開關開啟且達觸發條件，才在權重序列上套用 CAP
> +                if global_apply and valve_triggered:
> +                    from SSS_EnsembleTab import risk_valve_backtest, perf_stats
> +                    bench = df_raw  # 已含 open/high/low/close/volume
> +
> +                    logger.info(f"[{strat}] 🔴 開始套用風險閥門: cap={risk_cap}, ratio={ratio:.4f}")
> +
> +                    rv = risk_valve_backtest(
> +                        open_px=backtest_result.price_series,
> +                        w=backtest_result.weight_curve,
> +                        cost=cost_params,
> +                        benchmark_df=bench,
> +                        mode="cap",
> +                        cap_level=float(risk_cap),
> +                    )
> +                    # 覆寫結果，確保 UI 與輸出一致
> +                    backtest_result.daily_state = rv["daily_state_valve"]
> +                    backtest_result.ledger = rv["trade_ledger_valve"]
> +                    backtest_result.weight_curve = rv["weights_valve"]
> +                    backtest_result.equity_curve = rv["daily_state_valve"]["equity"]
> +                    backtest_result.stats = perf_stats(backtest_result.equity_curve, backtest_result.weight_curve)
> +                    logger.info(f"[{strat}] 風險閥門已套用（cap={risk_cap}, ratio={ratio:.4f}）")
> +
> +                    # 增加風險閥門效果的詳細資訊
> +                    if "metrics" in rv:
> +                        logger.info(f"[{strat}] 風險閥門效果: PF原始={rv['metrics'].get('pf_orig', 'N/A'):.2f}, PF閥門={rv['m
etrics'].get('pf_valve', 'N/A'):.2f}")
> +                        logger.info(f"[{strat}] 風險閥門效果: MDD原始={rv['metrics'].get('mdd_orig', 'N/A'):.2f}%, MDD閥門={r
v['metrics'].get('mdd_valve', 'N/A'):.2f}%")
> +
> +                    valve_info = {
> +                        "applied": True,
> +                        "cap": float(risk_cap),
> +                        "atr_ratio": ratio,
> +                    }
> +                else:
> +                    if global_apply:
> +                        logger.info(f"[{strat}] 🟢 風險閥門未觸發，使用原始參數")
> +                        valve_info = {
> +                            "applied": False,
> +                            "cap": float(risk_cap),
> +                            "atr_ratio": ratio if ratio is not None else "N/A",
> +                        }
> +                    else:
> +                        logger.info(f"[{strat}] ⚪ 全局風險閥門未啟用")
> +                        valve_info = {
> +                            "applied": False,
> +                            "cap": "N/A",
> +                            "atr_ratio": "N/A",
> +                        }
> +
> +                # 轉換為舊格式以保持相容性
> +                result = {
>                      'trades': [],
>                      'trade_df': pack_df(backtest_result.trades),
>                      'trades_df': pack_df(backtest_result.trades),
> @@
>                      'trade_ledger': pack_df(backtest_result.ledger),
>                      'daily_state_std': pack_df(backtest_result.daily_state),
> -                    'trade_ledger_std': pack_df(backtest_result.ledger)
> -                }
> +                    'trade_ledger_std': pack_df(backtest_result.ledger)
> +                }
> +                if valve_info is not None:
> +                    result['valve'] = valve_info
> *** End Patch
> PATCH
Success. Updated the following files:
M app_dash.py
I'll patch the ssma_turn branch to recompute metrics around line 909.

root@5583bff288d6:/workspace/SSS096# apply_patch<<'PATCH'
> *** Begin Patch
> *** Update File: app_dash.py
> @@
> -                        rv = risk_valve_backtest(
> -                            open_px=open_px,
> -                            w=w_series,
> -                            cost=cost_params,
> -                            benchmark_df=df_raw,
> -                            mode="cap",
> -                            cap_level=float(risk_cap),
> -                        )
> -
> -                        # 覆寫結果，確保 UI 與輸出一致（和 Ensemble 分支對齊）
> -                        result['equity_curve']     = pack_series(rv["daily_state_valve"]["equity"])
> -                        result['daily_state']      = pack_df(rv["daily_state_valve"])
> -                        result['daily_state_std']  = pack_df(rv["daily_state_valve"])
> -                        result['trade_ledger']     = pack_df(rv["trade_ledger_valve"])
> -                        result['trade_ledger_std'] = pack_df(rv["trade_ledger_valve"])
> -                        result['weight_curve']     = pack_series(rv["weights_valve"])
> -                        # 給 UI 的標記（下個小節會用到）
> -                        result['valve'] = {
> -                            "applied": True,
> -                            "cap": float(risk_cap),
> -                            "atr_ratio": ratio_local
> -                        }
> -
> -                        logger.info(f"[{strat}] SSMA 風險閥門已套用（cap={risk_cap}, ratio={ratio_local:.4f}）")
> +                        rv = risk_valve_backtest(
> +                            open_px=open_px,
> +                            w=w_series,
> +                            cost=cost_params,
> +                            benchmark_df=df_raw,
> +                            mode="cap",
> +                            cap_level=float(risk_cap),
> +                        )
> +
> +                        # 覆寫結果，確保 UI 與輸出一致（和 Ensemble 分支對齊）
> +                        result['equity_curve']     = pack_series(rv["daily_state_valve"]["equity"])
> +                        result['daily_state']      = pack_df(rv["daily_state_valve"])
> +                        result['daily_state_std']  = pack_df(rv["daily_state_valve"])
> +                        result['trade_ledger']     = pack_df(rv["trade_ledger_valve"])
> +                        result['trade_ledger_std'] = pack_df(rv["trade_ledger_valve"])
> +                        result['weight_curve']     = pack_series(rv["weights_valve"])
> +                        result['metrics']          = perf_stats(rv["daily_state_valve"]["equity"], rv["weights_valve"])
> +                        # 給 UI 的標記（下個小節會用到）
> +                        result['valve'] = {
> +                            "applied": True,
> +                            "cap": float(risk_cap),
> +                            "atr_ratio": ratio_local
> +                        }
> +
> +                        logger.info(f"[{strat}] SSMA 風險閥門已套用（cap={risk_cap}, ratio={ratio_local:.4f}）")
> *** End Patch
> PATCH
Success. Updated the following files:
M app_dash.py
I'll add perf_stats to the import line and check around line 898 for context.

root@5583bff288d6:/workspace/SSS096# sed -n '888,918p' app_dash.py
                except Exception:
                    pass

                if force_trigger:
                    valve_triggered_local = True
                    if ratio_local is None:
                        ratio_local = 1.5

                if valve_triggered_local:
                    from SSS_EnsembleTab import risk_valve_backtest, CostParams
                    # 取得 open 價；df_raw 欄位名稱是小寫
                    open_px = df_raw['open'] if 'open' in df_raw.columns else df_raw['close']
                    # 從回測輸出抓 w（先用標準化 daily_state，如果沒有就用原 daily_state）
                    w_series = None
                    try:
                        ds_std = df_from_pack(result.get('daily_state_std'))
                        if ds_std is not None and not ds_std.empty and 'w' in ds_std.columns:
                            w_series = ds_std['w']
                    except Exception:
                        pass
                    if w_series is None:
                        ds = df_from_pack(result.get('daily_state'))
                        if ds is not None and not ds.empty and 'w' in ds.columns:
                            w_series = ds['w']

                    if w_series is not None:
                        # 交易成本（與 Ensemble 分支一致）
                        trade_cost = strat_params.get('trade_cost', {})
                        cost_params = CostParams(
                            buy_fee_bp=float(trade_cost.get("buy_fee_bp", 4.27)),
                            sell_fee_bp=float(trade_cost.get("sell_fee_bp", 4.27)),
I'll update the import to include perf_stats. Time to patch it!

root@5583bff288d6:/workspace/SSS096# apply_patch<<'PATCH'
> *** Begin Patch
> *** Update File: app_dash.py
> @@
> -                if valve_triggered_local:
> -                    from SSS_EnsembleTab import risk_valve_backtest, CostParams
> +                if valve_triggered_local:
> +                    from SSS_EnsembleTab import risk_valve_backtest, CostParams, perf_stats
> *** End Patch
> PATCH
Success. Updated the following files:
M app_dash.py
I added perf_stats to ensemble and fixed patches, but need to check syntax and run tests.

root@5583bff288d6:/workspace/SSS096# python -m py_compile app_dash.py
I'm moving forward to execute the quick_check script as no compile errors showed up.

root@5583bff288d6:/workspace/SSS096# pwsh -ExecutionPolicy Bypass -File tools/quick_check.ps1
bash: command not found: pwsh
The command didn't work, but I'll try running git status to check the status.

root@5583bff288d6:/workspace/SSS096# git status --short
 M app_dash.py
?? __pycache__/
I need to delete the __pycache__ directory before committing.

root@5583bff288d6:/workspace/SSS096# rm -r __pycache__
root@5583bff288d6:/workspace/SSS096# git status --short
 M app_dash.py
I'll commit now, making sure to include a message in Traditional Chinese as instructed.

root@5583bff288d6:/workspace/SSS096# git commit -am "修復風險閥門套用後績效指標遺失問題" && git status --short
[work c6468b6] 修復風險閥門套用後績效指標遺失問題
 1 file changed, 23 insertions(+), 17 deletions(-)

root@5583bff288d6:/workspace/SSS096# git status --short
I'll open the lines where I made changes, such as new metrics and modifications to app_dash.py.

root@5583bff288d6:/workspace/SSS096# nl -ba app_dash.py | sed -n '1,120p'
     1  import dash
     2  from dash import dcc, html, dash_table, Input, Output, State, ctx, no_update
     3  import dash_bootstrap_components as dbc
     4  import pandas as pd
     5  import plotly.graph_objects as go
     6  import json
     7  import io
     8  from dash.dependencies import ALL
     9  import shutil
    10  import os
    11  from datetime import datetime, timedelta
    12  from pathlib import Path
    13  import joblib
    14  from analysis import config as cfg
    15  import yfinance as yf
    16  import logging
    17  import numpy as np
    18  from urllib.parse import quote as urlparse
    19
    20  #app_dash.py
    21  # 修改紀錄:
    22  # 2025-08-19: 修正風險閥門套用後績效指標遺失問題，並在結果構建後加入閥門資訊
    23
    24  # 配置 logger - 使用新的顯式初始化
    25  from analysis.logging_config import init_logging
    26  import os
    27
    28  # 強制啟用檔案日誌，不依賴環境變數
    29  os.environ["SSS_CREATE_LOGS"] = "1"
    30
    31  # 直接呼叫 init_logging，它會使用正確的日誌目錄
    32  init_logging(enable_file=True)
    33  logger = logging.getLogger("SSS.App")
    34
    35  # 設定為 DEBUG 級別，詳細調試資訊會寫入日誌檔案
    36  logger.setLevel(logging.DEBUG)
    37  logger.info("已啟用詳細調試模式 - 調試資訊將寫入日誌檔案")
    38  logger.info(f"日誌目錄: {os.path.abspath('analysis/log')}")
    39
    40  # ATR 計算函數
    41  def calculate_atr(df, window):
    42      """計算 ATR (Average True Range)"""
    43      try:
    44          # 支援多種欄位名稱格式
    45          high_col = None
    46          low_col = None
    47          close_col = None
    48
    49          # 檢查英文欄位名稱
    50          if 'high' in df.columns and 'low' in df.columns and 'close' in df.columns:
    51              high_col = 'high'
    52              low_col = 'low'
    53              close_col = 'close'
    54          # 檢查中文欄位名稱
    55          elif '最高價' in df.columns and '最低價' in df.columns and '收盤價' in df.columns:
    56              high_col = '最高價'
    57              low_col = '最低價'
    58              close_col = '收盤價'
    59          # 檢查其他可能的欄位名稱
    60          elif 'open' in df.columns and 'close' in df.columns:
    61              # 如果沒有高低價，用開盤價和收盤價近似
    62              high_col = 'open'
    63              low_col = 'close'
    64              close_col = 'close'
    65
    66          if high_col and low_col and close_col:
    67              # 有高低價時，計算 True Range
    68              high = df[high_col]
    69              low = df[low_col]
    70              close = df[close_col]
    71
    72              # 確保數據為數值型
    73              high = pd.to_numeric(high, errors='coerce')
    74              low = pd.to_numeric(low, errors='coerce')
    75              close = pd.to_numeric(close, errors='coerce')
    76
    77              tr1 = high - low
    78              tr2 = abs(high - close.shift(1))
    79              tr3 = abs(low - close.shift(1))
    80
    81              true_range = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
    82              atr = true_range.rolling(window=window).mean()
    83          else:
    84              # 只有收盤價時，用價格變化近似
    85              if close_col:
    86                  close = pd.to_numeric(df[close_col], errors='coerce')
    87              elif 'close' in df.columns:
    88                  close = pd.to_numeric(df['close'], errors='coerce')
    89              else:
    90                  logger.warning("找不到可用的價格欄位來計算 ATR")
    91                  return pd.Series(index=df.index, dtype=float)
    92
    93              price_change = close.diff().abs()
    94              atr = price_change.rolling(window=window).mean()
    95
    96          # 檢查計算結果
    97          if atr is None or atr.empty or atr.isna().all():
    98              logger.warning(f"ATR 計算結果無效，window={window}")
    99              return pd.Series(index=df.index, dtype=float)
   100
   101          return atr
   102      except Exception as e:
   103          logger.warning(f"ATR 計算失敗: {e}")
   104          return pd.Series(index=df.index, dtype=float)
   105
   106  def calculate_equity_curve(open_px, w, cap, atr_ratio):
   107      """計算權益曲線"""
   108      try:
   109          # 簡化的權益曲線計算
   110          # 這裡使用開盤價和權重的乘積來模擬權益變化
   111          equity = (open_px * w * cap).cumsum()
   112          return equity
   113      except Exception as e:
   114          logger.warning(f"權益曲線計算失敗: {e}")
   115          return None
   116
   117  def calculate_trades_from_equity(equity_curve, open_px, w, cap, atr_ratio):
   118      """從權益曲線計算交易記錄"""
   119      try:
   120          if equity_curve is None or equity_curve.empty:
I'll grab lines starting from 897 to capture the updated metrics recomputation.

root@5583bff288d6:/workspace/SSS096# nl -ba app_dash.py | sed -n '888,960p'
   888                  except Exception:
   889                      pass
   890
   891                  if force_trigger:
   892                      valve_triggered_local = True
   893                      if ratio_local is None:
   894                          ratio_local = 1.5
   895
   896                  if valve_triggered_local:
   897                      from SSS_EnsembleTab import risk_valve_backtest, CostParams, perf_stats
   898                      # 取得 open 價；df_raw 欄位名稱是小寫
   899                      open_px = df_raw['open'] if 'open' in df_raw.columns else df_raw['close']
   900                      # 從回測輸出抓 w（先用標準化 daily_state，如果沒有就用原 daily_state）
   901                      w_series = None
   902                      try:
   903                          ds_std = df_from_pack(result.get('daily_state_std'))
   904                          if ds_std is not None and not ds_std.empty and 'w' in ds_std.columns:
   905                              w_series = ds_std['w']
   906                      except Exception:
   907                          pass
   908                      if w_series is None:
   909                          ds = df_from_pack(result.get('daily_state'))
   910                          if ds is not None and not ds.empty and 'w' in ds.columns:
   911                              w_series = ds['w']
   912
   913                      if w_series is not None:
   914                          # 交易成本（與 Ensemble 分支一致）
   915                          trade_cost = strat_params.get('trade_cost', {})
   916                          cost_params = CostParams(
   917                              buy_fee_bp=float(trade_cost.get("buy_fee_bp", 4.27)),
   918                              sell_fee_bp=float(trade_cost.get("sell_fee_bp", 4.27)),
   919                              sell_tax_bp=float(trade_cost.get("sell_tax_bp", 30.0))
   920                          )
   921
   922                          rv = risk_valve_backtest(
   923                              open_px=open_px,
   924                              w=w_series,
   925                              cost=cost_params,
   926                              benchmark_df=df_raw,
   927                              mode="cap",
   928                              cap_level=float(risk_cap),
   929                          )
   930
   931                          # 覆寫結果，確保 UI 與輸出一致（和 Ensemble 分支對齊）
   932                          result['equity_curve']     = pack_series(rv["daily_state_valve"]["equity"])
   933                          result['daily_state']      = pack_df(rv["daily_state_valve"])
   934                          result['daily_state_std']  = pack_df(rv["daily_state_valve"])
   935                          result['trade_ledger']     = pack_df(rv["trade_ledger_valve"])
   936                          result['trade_ledger_std'] = pack_df(rv["trade_ledger_valve"])
   937                          result['weight_curve']     = pack_series(rv["weights_valve"])
   938                          result['metrics']          = perf_stats(rv["daily_state_valve"]["equity"], rv["weights_valve"])
   939                          # 給 UI 的標記（下個小節會用到）
   940                          result['valve'] = {
   941                              "applied": True,
   942                              "cap": float(risk_cap),
   943                              "atr_ratio": ratio_local
   944                          }
   945
   946                          logger.info(f"[{strat}] SSMA 風險閥門已套用（cap={risk_cap}, ratio={ratio_local:.4f}）")
   947                      else:
   948                          logger.warning(f"[{strat}] SSMA 無法取得權重序列，跳過風險閥門套用")
   949                  else:
   950                      logger.info(f"[{strat}] SSMA 風險閥門未觸發，使用原始結果")
   951                      # 給 UI 的標記（未觸發）
   952                      result['valve'] = {
   953                          "applied": False,
   954                          "cap": float(risk_cap),
   955                          "atr_ratio": ratio_local if ratio_local is not None else "N/A"
   956                      }
   957          elif strat_type == 'ensemble':
   958              # 使用新的 ensemble_runner 避免循環依賴
   959              try:
   960                  from runners.ensemble_runner import run_ensemble_backtest
I'll capture the lines where the ensemble branch modifications occur.

root@5583bff288d6:/workspace/SSS096# nl -ba app_dash.py | sed -n '1060,1150p'
  1060                              logger.warning(f"[{strat}] Ensemble ATR 數據不足")
  1061                      else:
  1062                          logger.warning(f"[{strat}] Ensemble ATR 計算結果為空")
  1063
  1064                  except Exception as e:
  1065                      logger.warning(f"[{strat}] 無法計算 Ensemble ATR 比值: {e}")
  1066                      logger.warning(f"[{strat}] 錯誤詳情: {type(e).__name__}: {str(e)}")
  1067
  1068                  # 如果啟用強制觸發，則強制觸發風險閥門
  1069                  if force_trigger:
  1070                      valve_triggered = True
  1071                      logger.info(f"[{strat}] 🔴 強制觸發風險閥門啟用")
  1072                      if ratio is None:
  1073                          ratio = 1.5  # 設定一個預設值用於顯示
  1074
  1075                  # 使用新的 ensemble_runner 執行
  1076                  backtest_result = run_ensemble_backtest(cfg)
  1077
  1078                  valve_info = None
  1079                  # 若全局開關開啟且達觸發條件，才在權重序列上套用 CAP
  1080                  if global_apply and valve_triggered:
  1081                      from SSS_EnsembleTab import risk_valve_backtest, perf_stats
  1082                      bench = df_raw  # 已含 open/high/low/close/volume
  1083
  1084                      logger.info(f"[{strat}] 🔴 開始套用風險閥門: cap={risk_cap}, ratio={ratio:.4f}")
  1085
  1086                      rv = risk_valve_backtest(
  1087                          open_px=backtest_result.price_series,
  1088                          w=backtest_result.weight_curve,
  1089                          cost=cost_params,
  1090                          benchmark_df=bench,
  1091                          mode="cap",
  1092                          cap_level=float(risk_cap),
  1093                      )
  1094                      # 覆寫結果，確保 UI 與輸出一致
  1095                      backtest_result.daily_state = rv["daily_state_valve"]
  1096                      backtest_result.ledger = rv["trade_ledger_valve"]
  1097                      backtest_result.weight_curve = rv["weights_valve"]
  1098                      backtest_result.equity_curve = rv["daily_state_valve"]["equity"]
  1099                      backtest_result.stats = perf_stats(backtest_result.equity_curve, backtest_result.weight_curve)
  1100                      logger.info(f"[{strat}] 風險閥門已套用（cap={risk_cap}, ratio={ratio:.4f}）")
  1101
  1102                      # 增加風險閥門效果的詳細資訊
  1103                      if "metrics" in rv:
  1104                          logger.info(f"[{strat}] 風險閥門效果: PF原始={rv['metrics'].get('pf_orig', 'N/A'):.2f}, PF閥門={
rv['metrics'].get('pf_valve', 'N/A'):.2f}")
  1105                          logger.info(f"[{strat}] 風險閥門效果: MDD原始={rv['metrics'].get('mdd_orig', 'N/A'):.2f}%, MDD閥
門={rv['metrics'].get('mdd_valve', 'N/A'):.2f}%")
  1106
  1107                      valve_info = {
  1108                          "applied": True,
  1109                          "cap": float(risk_cap),
  1110                          "atr_ratio": ratio,
  1111                      }
  1112                  else:
  1113                      if global_apply:
  1114                          logger.info(f"[{strat}] 🟢 風險閥門未觸發，使用原始參數")
  1115                          valve_info = {
  1116                              "applied": False,
  1117                              "cap": float(risk_cap),
  1118                              "atr_ratio": ratio if ratio is not None else "N/A",
  1119                          }
  1120                      else:
  1121                          logger.info(f"[{strat}] ⚪ 全局風險閥門未啟用")
  1122                          valve_info = {
  1123                              "applied": False,
  1124                              "cap": "N/A",
  1125                              "atr_ratio": "N/A",
  1126                          }
  1127
  1128                  # 轉換為舊格式以保持相容性
  1129                  result = {
  1130                      'trades': [],
  1131                      'trade_df': pack_df(backtest_result.trades),
  1132                      'trades_df': pack_df(backtest_result.trades),
  1133                      'signals_df': pack_df(backtest_result.trades[['trade_date', 'type', 'price']].rename(columns={'type'
: 'action'}) if not backtest_result.trades.empty else pd.DataFrame(columns=['trade_date', 'action', 'price'])),
  1134                      'metrics': backtest_result.stats,
  1135                      'equity_curve': pack_series(backtest_result.equity_curve),
  1136                      'cash_curve': pack_series(backtest_result.cash_curve) if backtest_result.cash_curve is not None else
 "",
  1137                      'weight_curve': pack_series(backtest_result.weight_curve) if backtest_result.weight_curve is not Non
e else pack_series(pd.Series(0.0, index=backtest_result.equity_curve.index)),
  1138                      'price_series': pack_series(backtest_result.price_series) if backtest_result.price_series is not Non
e else pack_series(pd.Series(1.0, index=backtest_result.equity_curve.index)),
  1139                      'daily_state': pack_df(backtest_result.daily_state),
  1140                      'trade_ledger': pack_df(backtest_result.ledger),
  1141                      'daily_state_std': pack_df(backtest_result.daily_state),
  1142                      'trade_ledger_std': pack_df(backtest_result.ledger)
  1143                  }
  1144                  if valve_info is not None:
  1145                      result['valve'] = valve_info
  1146
  1147                  logger.info(f"[Ensemble] 執行成功: 權益曲線長度={len(backtest_result.equity_curve)}, 交易數={len(backtes
t_result.ledger) if backtest_result.ledger is not None and not backtest_result.ledger.empty else 0}")
  1148
  1149              except Exception as e:
  1150                  logger.error(f"Ensemble 策略執行失敗: {e}")
I'm finalizing the PR title and message, summarizing the user report and changes applied.

I’ll summarize the fix, testing, and include citations for SSMA and ensemble branches.

3.
Configuring language runtimes...
# Python: 3.12
# Node.js: v20 (default: v22)
default -> 20 (-> v20.19.4)
Now using node v20.19.4 (npm v10.9.3)
# Ruby: 3.4.4 (default: 3.2.3)
mise ~/.config/mise/config.toml tools: ruby@3.4.4
# Rust: 1.88.0 (default: 1.89.0)
info: using existing install for '1.88.0-x86_64-unknown-linux-gnu'
info: default toolchain set to '1.88.0-x86_64-unknown-linux-gnu'

  1.88.0-x86_64-unknown-linux-gnu unchanged - rustc 1.88.0 (6b00bc388 2025-06-23)

# Go: go1.24.3 (default: go1.24.3)
# Swift: 6.1 (default: 6.1)
# PHP: 8.4 (default: 8.4)
Running auto setup...
Scanning repository (up to depth 3) for dependency configurations...
No known dependency configuration files found up to depth 3.
後面版本不是新增了風險閥門套用在各策略嗎
但不知道為什麼套用後 各指標會只剩下平均持倉天數,其他指標都消失了 請修復
Opening a new session to explore the repo and locate AGENTS.md, then I'll investigate further.

ls
I think the shell isn't showing results since it's non-interactive. I'll adjust timing and retry.

root@9a3d3c80743e:/workspace# ls
SSS096
I’ll change into the SSS096 directory now. Let’s get started!

root@9a3d3c80743e:/workspace# cd SSS096
root@9a3d3c80743e:/workspace/SSS096# ls
AGENTS.md                           data                      run_workflow_example.py
DEFENSIVE_CHECKS_UPDATE_SUMMARY.md  debug_enhanced_data.py    runners
ENSEMBLE_WORKFLOW.md                ensemble_wrapper.py       setup.sh
LOGGING_SYSTEM_UPDATE_SUMMARY.md    extract_params.py         sss_backtest_outputs
PORTFOLIO_LEDGER_README.md          leverage.py               sss_core
SSS_EnsembleTab.py                  list.txt                  test
SSSv096.py                          list_folder_structure.py  tools
analysis                            presets                   utils_payload.py
app_dash.py                         ruff.toml                 version_history.py
assets                              run_enhanced_debug.py     workflow_summary_20250812_023903.txt
config.yaml                         run_enhanced_ensemble.py  workflow_summary_20250818_040656.txt
convert_results_to_trades.py        run_workflow.py
I'll open AGENTS.md to review its instructions before making any changes.

convert_results_to_trades.py        run_workflow.py
root@9a3d3c80743e:/workspace/SSS096# cat AGENTS.md
# SSS096 專案 AI 代理工作指南

## 📋 專案概述

SSS096 是一個股票策略回測與分析系統，主要包含：
- 策略回測引擎（SSSv096.py）
- Web UI 界面（app_dash.py）
- 增強分析模組（analysis/）
- Ensemble 策略執行（runners/）
- 數據處理與轉換工具

## 🎯 工作重點區域

### 核心檔案
- `SSSv096.py` - 主要策略回測引擎
- `app_dash.py` - Web UI 主應用
- `ensemble_wrapper.py` - Ensemble 策略包裝器
- `analysis/` - 分析模組目錄

### 避免修改的檔案
- `tools/quick_check.ps1` - 自動化檢查腳本（除非必要）
- 已標記為 "past/" 的舊版本檔案
- 編譯後的 `.pyc` 檔案

## 🔧 開發環境設定

### Codex 環境設置（推薦）
```bash
# 執行自動設置腳本
chmod +x setup.sh
./setup.sh

# 測試設置是否成功
python test_setup.py
```

### Python 環境（手動設置）
```bash
# 安裝依賴套件
pip install pandas numpy matplotlib seaborn openpyxl dash dash-bootstrap-components

# 檢查 Python 版本（建議 3.8+）
python --version
```

### 代理設置（如果遇到 403 錯誤）
```bash
# 檢查代理證書
echo $CODEX_PROXY_CERT

# 配置 pip 使用代理
pip config set global.cert "$CODEX_PROXY_CERT"
pip config set global.trusted-host "proxy:8080"
```

### 專案結構導航
```bash
# 快速查看目錄結構
python list_folder_structure.py

# 查看特定目錄內容
ls analysis/
ls runners/
```

## 🧪 測試與驗證

### 快速檢查
```bash
# 執行自動化檢查（重要！）
powershell -ExecutionPolicy Bypass -File tools\quick_check.ps1
```

### 回測測試
```bash
# 執行單一策略回測
python SSSv096.py --strategy RMA_Factor --param_preset op.json

# 執行 Ensemble 策略
python run_enhanced_ensemble.py --method majority --top_k 5
```

### UI 測試
```bash
# 啟動 Web UI
python app_dash.py
```

## 📝 程式碼規範

### 註解與輸出
- **一律使用繁體中文**進行註解和輸出
- 修改紀錄需加入日期時間戳記
- 路徑說明格式：`#子資料夾/檔案名`

### 日誌記錄
- 使用 `analysis/logging_config.py` 中的日誌器
- 重要操作需記錄到日誌檔案
- 錯誤處理需包含詳細的錯誤信息

### 資料格式
- 日期欄位統一使用 ISO 格式：`YYYY-MM-DD`
- 數值欄位使用 float 類型
- 避免使用中文欄位名稱（除非必要）

## 🔍 除錯指南

### 常見問題
1. **模組導入失敗**：檢查 `sys.path` 和相對導入
2. **數據格式錯誤**：驗證 CSV 檔案結構和欄位名稱
3. **記憶體不足**：檢查大數據集的處理方式

### 除錯工具
```python
# 啟用詳細日誌
import logging
logging.basicConfig(level=logging.DEBUG)

# 檢查數據結構
print(df.info())
print(df.head())
```

## 📊 數據處理規範

### 輸入數據
- 支援 CSV、Excel、JSON 格式
- 必要欄位：交易日期、權重變化、盈虧%
- 可選欄位：交易類型、價格、成交量

### 輸出數據
- 統一 Schema：equity、trades、daily_state、trade_ledger
- 避免 KeyError 和欄位缺失
- 支援多種輸出格式

## 🚀 部署與維護

### 檔案管理
- 定期清理舊的日誌和快取檔案
- 備份重要的配置和結果檔案
- 使用版本控制追蹤變更

### 性能優化
- 大數據集使用快取機制
- 避免重複計算
- 使用適當的數據結構

## ⚠️ 注意事項

### 安全考量
- 不要硬編碼 API 金鑰
- 驗證所有用戶輸入
- 保護敏感數據

### 相容性
- 維持與現有工作流程的相容性
- 測試所有整合點
- 避免破壞現有功能

## 🚀 Codex 環境設置

### 自動設置
```bash
# 執行設置腳本
./setup.sh

# 腳本會自動：
# 1. 配置代理設置
# 2. 安裝所有必要依賴
# 3. 創建回退日誌系統
# 4. 設置環境變數
```

### 手動設置（如果自動設置失敗）
```bash
# 1. 配置代理
export PIP_CERT="$CODEX_PROXY_CERT"
export NODE_EXTRA_CA_CERTS="$CODEX_PROXY_CERT"

# 2. 安裝核心依賴
pip install --no-cache-dir pandas numpy matplotlib seaborn openpyxl dash dash-bootstrap-components yfinance pyyaml joblib

# 3. 安裝分析套件
pip install --no-cache-dir scikit-learn scipy statsmodels plotly kaleido

# 4. 創建必要目錄
mkdir -p analysis/log analysis/cache cache log results sss_backtest_outputs
```

### 常見問題解決
- **pip install 403 錯誤**：檢查 `$CODEX_PROXY_CERT` 環境變數
- **joblib 導入失敗**：使用 `logging_config_fallback.py` 回退版本
- **模組路徑問題**：設置 `PYTHONPATH` 環境變數

## 📞 技術支援

### 問題回報
- 提供完整的錯誤訊息和堆疊追蹤
- 包含重現步驟和環境信息
- 檢查相關的日誌檔案

### 文檔更新
- 修改功能時同步更新相關文檔
- 使用清晰的範例和說明
- 保持文檔的時效性

---

**版本：** v1.0
**最後更新：** 2025-08-18
**適用於：** SSS096 專案 AI 代理工作指南
I need to locate where the risk valve is applied in the code. Let's search!

root@9a3d3c80743e:/workspace/SSS096# rg "風險閥" -n
DEFENSIVE_CHECKS_UPDATE_SUMMARY.md
36:- 在繪製風險閥門時序圖前檢查必要欄位

analysis/UI_INTEGRATION_GUIDE.md
11:1. 風險閥門回測
260:- **自定義基準數據**：上傳基準數據進行風險閥門分析

analysis/ENHANCED_ANALYSIS_README.md
11:1. **風險閥門回測** - 在極端行情下暫停加碼機制
17:### 1. 風險閥門回測 (`risk_valve_backtest`)
141:- 風險閥門觸發時序圖
184:### 1. 風險閥門策略

analysis/enhanced_trade_analysis.py
4:整合風險閥門回測、交易貢獻拆解、加碼梯度優化
97:        風險閥門回測
109:        print("=== 風險閥門回測分析 ===")
112:        # 模擬風險閥門觸發
115:        # 計算風險閥門效果
121:        """模擬風險閥門觸發"""
123:            print("警告：缺少基準數據，無法進行風險閥門回測")
179:        # 風險閥門觸發條件
184:        # 綜合風險閥門
194:        """計算風險閥門對績效的影響"""
200:            print("警告：benchmark_enhanced 缺少 '日期' 欄位，無法計算風險閥門影響")
204:            print("警告：benchmark_enhanced 缺少 'risk_valve_triggered' 欄位，無法計算風險閥門影響")
207:        # 找出風險閥門觸發的期間
243:        print(f"風險閥門觸發期間數：{len(risk_periods)}")
555:        # 1. 風險閥門觸發時序
559:                print("警告：benchmark_enhanced 缺少必要欄位，跳過風險閥門時序圖")
561:                print("警告：benchmark_enhanced 缺少 'risk_valve_triggered' 欄位，跳過風險閥門時序圖")
575:                               color='red', s=50, alpha=0.8, label='風險閥門觸發')
578:                ax1.set_title('風險閥門觸發時序')
637:    print("2. 執行風險閥門回測：analyzer.risk_valve_backtest()")

SSS_EnsembleTab.py
1287:# === PATCH: 風險閥門施作在權重 ===
1292:    """對每日目標權重 w 施作風險閥門：

app_dash.py
445:                        html.Label("風險閥門 CAP", style={"fontSize":"12px","color":"#888"}),
455:                        dbc.Checkbox(id='force-valve-trigger', value=False, label="強制觸發風險閥門（測試用）", style={"font
Size":"11px","color":"#dc3545"}),
456:                        html.Small("💡 勾選後將強制觸發風險閥門，用於測試功能", style={"color":"#dc3545","fontSize":"10px"})
460:                    # === 風險閥門狀態顯示區域 ===
464:                        html.Small("🔒 風險閥門說明:", style={"color":"#28a745","fontWeight":"bold","fontSize":"11px"}),
573:# --------- 風險閥門狀態更新 ---------
587:    """動態更新風險閥門狀態顯示"""
588:    logger.info(f"=== 風險閥門狀態更新 ===")
598:        logger.info("風險閥門未啟用")
600:            html.Small("🔴 風險閥門未啟用", style={"color":"#dc3545","fontWeight":"bold"}),
655:                            # 判斷是否需要觸發風險閥門
658:                            # 如果啟用強制觸發，則強制觸發風險閥門
661:                                logger.info(f"強制觸發風險閥門啟用")
663:                            # 記錄風險閥門狀態到日誌
665:                            logger.info(f"風險閥門門檻: {atr_ratio}, 當前比值: {atr_ratio_current:.4f}")
666:                            logger.info(f"風險閥門觸發: {'是' if valve_triggered else '否'}")
667:                            logger.info(f"風險閥門狀態: {'🔴 觸發' if valve_triggered else '🟢 正常'}")
680:                                    html.Small(f"{status_icon} 風險閥門狀態: {status_text}",
742:        logger.error(f"風險閥門狀態更新失敗: {e}")
797:    # === 新增：全局風險閥門觸發狀態追蹤 ===
810:        # 應用全局風險閥門設定（如果啟用）
811:        logger.info(f"[{strat}] 風險閥門開關狀態: global_apply={global_apply}, 類型={type(global_apply)}")
813:            logger.info(f"[{strat}] 應用全局風險閥門: CAP={risk_cap}, ATR比值門檻={atr_ratio}")
836:                        logger.warning(f"[{strat}] ATR(60) 值異常: {atr_60_latest}，跳過風險閥門")
840:                        logger.warning(f"[{strat}] ATR(20) 值異常: {atr_20_latest}，跳過風險閥門")
851:                    logger.info(f"[{strat}] 🔴 強制觸發風險閥門啟用")
856:            logger.info(f"[{strat}] 未啟用全局風險閥門")
864:            # 重新計算策略信號（因為參數可能已經被風險閥門調整）
870:            # === 在 ssma_turn 也套用風險閥門（和 Ensemble 一致的後置覆寫） ===
941:                        logger.info(f"[{strat}] SSMA 風險閥門已套用（cap={risk_cap}, ratio={ratio_local:.4f}）")
943:                        logger.warning(f"[{strat}] SSMA 無法取得權重序列，跳過風險閥門套用")
945:                    logger.info(f"[{strat}] SSMA 風險閥門未觸發，使用原始結果")
981:                # 註解掉原本的無條件風險閥門調整（會造成 floor 方向錯誤）
983:                #     logger.info(f"[{strat}] Ensemble 策略應用風險閥門: 原始 delta_cap={ensemble_params.delta_cap}, floor={
ensemble_params.floor}")
1020:                # --- 新增：只在 ATR 觸發時啟用風險閥門 ---
1047:                                # 增加風險閥門觸發的詳細資訊
1049:                                    logger.info(f"[{strat}] 🔴 風險閥門觸發！ATR比值({ratio:.4f}) > 門檻({atr_ratio})")
1051:                                    logger.info(f"[{strat}] 🟢 風險閥門未觸發，ATR比值({ratio:.4f}) <= 門檻({atr_ratio})")
1063:                # 如果啟用強制觸發，則強制觸發風險閥門
1066:                    logger.info(f"[{strat}] 🔴 強制觸發風險閥門啟用")
1078:                    logger.info(f"[{strat}] 🔴 開始套用風險閥門: cap={risk_cap}, ratio={ratio:.4f}")
1093:                    logger.info(f"[{strat}] 風險閥門已套用（cap={risk_cap}, ratio={ratio:.4f}）")
1095:                    # 增加風險閥門效果的詳細資訊
1097:                        logger.info(f"[{strat}] 風險閥門效果: PF原始={rv['metrics'].get('pf_orig', 'N/A'):.2f}, PF閥門={rv[
'metrics'].get('pf_valve', 'N/A'):.2f}")
1098:                        logger.info(f"[{strat}] 風險閥門效果: MDD原始={rv['metrics'].get('mdd_orig', 'N/A'):.2f}%, MDD閥門=
{rv['metrics'].get('mdd_valve', 'N/A'):.2f}%")
1108:                        logger.info(f"[{strat}] 🟢 風險閥門未觸發，使用原始參數")
1116:                        logger.info(f"[{strat}] ⚪ 全局風險閥門未啟用")
1175:                    "applied": False,  # 其他策略類型暫時不支援風險閥門
1205:        # === 全局風險閥門：逐日動態套用（與增強分析一致） ===
1211:                logger.warning(f"[{strat}] daily_state 不含 'w'，跳過全局風險閥門")
1217:                    logger.warning(f"[{strat}] 無法計算 ATR20/60，跳過全局風險閥門")
1316:                        logger.info(f"[{strat}] 全局風險閥門已套用（逐日），風險天數={true_days}, CAP={risk_cap:.2f}")
1318:                        logger.warning(f"[{strat}] 風險閥門重算沒有返回結果")
1701:            # === 計算風險閥門徽章內容 ===
1713:                "🛡️ 風險閥門：" + valve_badge_text + ((" | " + " | ".join(valve_badge_extra)) if valve_badge_extra else ""),
1968:                html.Summary("風險閥門回測"),
1981:                    html.Button("執行風險閥門回測", id="run-rv", n_clicks=0, style={"marginTop":"8px"})
2369:# --------- 增強分析 Callback：風險閥門回測（修正版） ---------
2434:        return f"風險閥門回測執行失敗: {e}", no_update, no_update
3488:        return go.Figure(), "❌ 無法從風險閥門回測的參數組合中取得資料"
I spotted the issue with missing metrics after applying the risk valve. I'll locate the function calculating those metrics.

root@9a3d3c80743e:/workspace/SSS096# rg "平均持" -n
app_dash.py
1559:                "avg_holding_period": "平均持倉天數",
1888:                '平均持有天數': f"{detailed_stats['avg_holding_days']:.1f}",
2213:    # 計算平均持有天數（買入到賣出的天數）

SSSv096.py
927:    計算平均持倉天數.
933:        float: 平均持倉天數.
1828:            "avg_holding_period": "平均持倉天數",
1864:    # 計算平均持倉天數
1867:    # 將平均持倉天數加入 metrics
2293:            # 顯示策略摘要,傳入 trade_df 以計算平均持倉天數

analysis/optuna_16.py
10:v10-12  支援單一/隨機/依序數據源模式,新增平均持倉天數,相關係數分析,並自動輸出熱圖,試驗結果與最佳參數自動輸出 CSV/JSON
254:        # 计算平均持仓天数

analysis/OSv3.py
82:        'avg_hold_days': '平均持倉天數：平均每次交易的持倉時間',
I'll look at the metrics calculation section in SSSv096 around line 1828.

root@9a3d3c80743e:/workspace/SSS096# sed -n '1800,1870p' SSSv096.py
    # 先把 metrics 的 key/value 轉成「顯示用的 label」和「格式化後的 value 字串」
    items = []
    for k, v in metrics.items():
        # 依據 k 決定要不要以百分比、或小數、或純文字來格式化
        if k in ["total_return", "annual_return", "win_rate", "max_drawdown", "annualized_volatility", "avg_win", "avg_loss"]:
            txt = f"{v:.2%}" if pd.notna(v) else ""
        elif k in ["calmar_ratio", "sharpe_ratio", "sortino_ratio", "payoff_ratio", "profit_factor"]:
            txt = f"{v:.2f}" if pd.notna(v) else ""
        elif k in ["max_drawdown_duration", "avg_holding_period"]:
            txt = f"{v:.1f} 天" if pd.notna(v) else ""
        elif k in ["num_trades", "max_consecutive_wins", "max_consecutive_losses"]:
            txt = str(int(v)) if pd.notna(v) else ""
        else:
            # 其他就先盡量當純文字顯示
            txt = f"{v}"
        # 把字典 key → 中文顯示 label
        label_map = {
            "total_return": "總回報率",
            "annual_return": "年化回報率",
            "win_rate": "勝率",
            "max_drawdown": "最大回撤",
            "max_drawdown_duration": "回撤持續",
            "calmar_ratio": "卡瑪比率",
            "sharpe_ratio": "夏普比率",
            "sortino_ratio": "索提諾比率",
            "payoff_ratio": "盈虧比",
            "profit_factor": "盈虧因子",
            "num_trades": "交易次數",
            "avg_holding_period": "平均持倉天數",
            "annualized_volatility": "年化波動率",
            "max_consecutive_wins": "最大連續盈利",
            "max_consecutive_losses": "最大連續虧損",
            "avg_win": "平均盈利",
            "avg_loss": "平均虧損",
        }
        label = label_map.get(k, k)
        items.append((label, txt))

    # 開始產生 HTML:外層一個 flex container,內層每組(指標+數值) 都是 flex item
    html = """
<div style="display:flex;flex-wrap:wrap;gap:12px;align-items:flex-start;">
"""
    for label, val in items:
        html += f"""
  <div style="flex:0 1 150px;border:1px solid #444;border-radius:4px;padding:8px 12px;background:#1a1a1a;">
    <div style="font-size:14px;color:#aaa;">{label}</div>
    <div style="font-size:20px;font-weight:bold;color:#fff;margin-top:4px;">{val}</div>
  </div>
"""
    html += "</div>"

    # 去掉多餘縮排,避免開頭空白被解讀成 code block
    html = textwrap.dedent(html)

    st.markdown(html, unsafe_allow_html=True)

def display_strategy_summary(strategy: str, params: Dict, metrics: Dict, smaa_source: str, trade_df: pd.DataFrame):
    """
    顯示策略參數與回測績效摘要,使用 HTML Flexbox 卡片展示.
    """
    # 參數展示
    param_display = {k: v for k, v in params.items() if k != "strategy_type"}
    st.write("**參數設定**: " + ", ".join(f"{k}: {v}" for k, v in param_display.items()))

    # 計算平均持倉天數
    avg_holding_period = calculate_holding_periods(trade_df)

    # 將平均持倉天數加入 metrics
    metrics['avg_holding_period'] = avg_holding_period

    # 績效指標展示
I'm looking at the code where the risk valve might be affecting the metrics, possibly overwriting them.

root@9a3d3c80743e:/workspace/SSS096# sed -n '1070,1120p' SSS_EnsembleTab.py
            )

            cfg = RunConfig(
                ticker=ticker,
                method=method,
                params=params,
                cost=cost,
                majority_k_pct=majority_k_pct
            )

            # 運行 ensemble
            with st.spinner("執行中..."):
                open_px, w, trades, stats, method_name, equity, daily_state, trade_ledger = run_ensemble(cfg)

            # 顯示結果
            st.success(f"執行完成: {method_name}")

            # 績效指標
            col6, col7, col8 = st.columns(3)
            with col6:
                st.metric("總報酬率", f"{stats.get('total_return', 0):.2%}")
                st.metric("年化報酬率", f"{stats.get('annual_return', 0):.2%}")
            with col7:
                st.metric("最大回撤", f"{stats.get('max_drawdown', 0):.2%}")
                st.metric("夏普比率", f"{stats.get('sharpe_ratio', 0):.2f}")
            with col8:
                st.metric("卡瑪比率", f"{stats.get('calmar_ratio', 0):.2f}")
                st.metric("交易次數", stats.get('num_trades', 0))

            # === 新增：交易明細顯示 ===
            st.subheader("交易明細 (trade_ledger)")
            if trade_ledger is not None and not trade_ledger.empty:
                # 使用 normalize_trades_for_ui 標準化交易明細
                trades_ui = normalize_trades_for_ui(trade_ledger)

                # === 新增：刪除費用欄位（僅UI層移除顯示） ===
                cols_to_hide = ['fee_buy','fee_sell','sell_tax','tax','shares_before','shares_after']
                trades_ui = trades_ui.drop(columns=[c for c in cols_to_hide if c in trades_ui.columns], errors='ignore')

                # === 新增：統一數字格式 ===
                # 價格格式化
                if 'price' in trades_ui.columns:
                    trades_ui['price'] = trades_ui['price'].apply(
                        lambda x: f"{x:,.2f}" if pd.notnull(x) else ""
                    )

                # 金額/數量/權重等格式化
                for col in ['exec_notional','weight_change','w_before','w_after','delta_units',
                            'cash_after','equity_after','position_value']:
                    if col in trades_ui.columns:
                        trades_ui[col] = trades_ui[col].apply(
Let me look for the run_ensemble function to check its relevance.

root@9a3d3c80743e:/workspace/SSS096# rg "run_ensemble" -n
run_workflow.py
109:def run_ensemble(config, args, method):
222:        results['Majority Ensemble'] = run_ensemble(config, args, 'majority')
225:        results['Proportional Ensemble'] = run_ensemble(config, args, 'proportional')

runners/__init__.py
2:from .ensemble_runner import run_ensemble_backtest
4:__all__ = ['run_ensemble_backtest']

runners/ensemble_runner.py
13:def run_ensemble_backtest(cfg) -> BacktestResult:
17:        from SSS_EnsembleTab import run_ensemble, EnsembleParams, CostParams, RunConfig
20:        open_px, w, trades, stats, method_name, equity, daily_state, trade_ledger = run_ensemble(cfg)

PORTFOLIO_LEDGER_README.md
78:### 1. 在 `run_ensemble()` 中自动生成

run_enhanced_ensemble.py
185:def run_ensemble_with_strategies(method: str,
291:                    result = run_ensemble_with_strategies(method, strategies, params, cost_params, trades_dir)
418:            final_result = run_ensemble_with_strategies(
437:        result = run_ensemble_with_strategies(

app_dash.py
955:                from runners.ensemble_runner import run_ensemble_backtest
1071:                backtest_result = run_ensemble_backtest(cfg)

analysis/OSv3.py
720:def run_ensemble_strategy(params, ticker="00631L.TW"):
1384:    if st.button("🚀 运行 Ensemble 策略", type="secondary", key="run_ensemble"):
1399:                equity_curve, trades, stats = run_ensemble_strategy(ensemble_params)

SSS_EnsembleTab.py
749:def run_ensemble(cfg: RunConfig) -> Tuple[pd.Series, pd.Series, pd.DataFrame, Dict[str, float], str, pd.Series, pd.DataFrame
, pd.DataFrame]:
1009:    open_px, w, trades, stats, method_name, equity, daily_state, trade_ledger = run_ensemble(cfg)
1082:                open_px, w, trades, stats, method_name, equity, daily_state, trade_ledger = run_ensemble(cfg)

SSSv096.py
33:from SSS_EnsembleTab import RunConfig, EnsembleParams, CostParams, run_ensemble
1017:                open_px, w, trades, stats, method_name, equity, daily_state, trade_ledger = run_ensemble(cfg)

ensemble_wrapper.py
6:這是一個薄包裝，不復制計算核心，直接調用現有的 run_ensemble 函數。
18:from SSS_EnsembleTab import run_ensemble, RunConfig, EnsembleParams, CostParams
166:            open_px, w, trades, stats, method_name, equity, daily_state, trade_ledger = run_ensemble(config)
I'll focus on the run_ensemble function in SSS_EnsembleTab.py to find risk valve usage.

root@9a3d3c80743e:/workspace/SSS096# rg "def run_ensemble" -n SSS_EnsembleTab.py
749:def run_ensemble(cfg: RunConfig) -> Tuple[pd.Series, pd.Series, pd.DataFrame, Dict[str, float], str, pd.Series, pd.DataFrame
, pd.DataFrame]:
root@9a3d3c80743e:/workspace/SSS096# sed -n '749,900p' SSS_EnsembleTab.py
def run_ensemble(cfg: RunConfig) -> Tuple[pd.Series, pd.Series, pd.DataFrame, Dict[str, float], str, pd.Series, pd.DataFrame, pd
.DataFrame]:
    """回傳：(open 價), (每日權重 w), (交易紀錄 trades), (績效指標 dict), (方法名稱), (權益曲線), (每日狀態 daily_state), (交易流
水帳 trade_ledger)"""
    # 讀價（Open）
    px_path = DATA_DIR / f"{cfg.ticker.replace(':','_')}_data_raw.csv"
    px = _read_market_csv_auto(px_path)

    # 調試信息：價格數據
    logger.info(f"[Ensemble] 價資料天數={len(px)}, 首末={px.index.min()}~{px.index.max()}")

    # 推斷策略列表
    if cfg.strategies is None:
        # 優先使用 trades_from_results_*.csv（120檔策略）
        strat_names = []
        file_map = {}  # 策略名 -> 文件路徑的映射

        # 先找 trades_from_results_*.csv
        trades_files = list(OUT_DIR.glob("trades_from_results_*.csv"))
        if trades_files:
            logger.info(f"[Ensemble] 找到 {len(trades_files)} 個 trades_from_results_*.csv 文件（120檔策略）")
            for f in sorted(trades_files):
                # 從文件名推斷策略名稱
                name = f.stem.replace("trades_from_results_", "")
                strat_names.append(name)
                file_map[name] = f
        else:
            # 找不到再使用舊的 trades_*.csv（11檔策略）
            trades_files = list(OUT_DIR.glob("trades_*.csv"))
            logger.info(f"[Ensemble] 找到 {len(trades_files)} 個 trades_*.csv 文件（11檔策略）")
            for f in sorted(trades_files):
                # 從文件名推斷策略名稱
                name = f.stem.replace("trades_", "")
                strat_names.append(name)
                file_map[name] = f

        if not strat_names:
            raise ValueError(f"在 {OUT_DIR} 中找不到任何交易文件")

        cfg.strategies = strat_names
        cfg.file_map = file_map

    # 載入持倉矩陣
    pos_df = load_positions_matrix(OUT_DIR, px.index, cfg.strategies, cfg.file_map)

    if pos_df.empty:
        raise ValueError("無法載入任何策略的持倉數據")

    N = pos_df.shape[1]  # 策略數量
    logger.info(f"[Ensemble] 載入 {N} 個策略的持倉數據")

    # 處理 majority_k 參數
    if cfg.method.lower() == "majority":
        if cfg.majority_k_pct is not None:
            # 使用比例門檻
            k_req = int(math.ceil(N * cfg.majority_k_pct))
            logger.info(f"[Ensemble] 使用比例門檻 majority_k_pct={cfg.majority_k_pct}, N={N}, 計算得到 K={k_req}")
        else:
            # 使用固定 K 值
            k_req = cfg.params.majority_k
            logger.info(f"[Ensemble] 使用固定門檻 majority_k={k_req}, N={N}")

        # 方案 A：夾擠到合法範圍
        k_eff = max(1, min(int(k_req), N))

        # 方案 B：若 k>n 採用動態多數決（建議）：ceil(N*0.5)
        if k_req > N:
            logger.warning(f"majority_k({k_req}) > N({N}); fallback to ceil(N/2)={math.ceil(N*0.5)}")
            k_eff = int(math.ceil(N*0.5))

        # 用 dataclasses.replace 覆寫參數後再算權重與命名
        import dataclasses
        cfg.params = dataclasses.replace(cfg.params, majority_k=k_eff)

        # 檢查 N 是否足夠（可選但建議）
        if N < 8:
            logger.warning(f"策略數量 N={N} < 8，可能影響 ensemble 效果。建議確保有足夠的子策略。")

    # 調試信息：子策略多倉統計
    S = pos_df.sum(axis=1)
    logger.info(f"[Ensemble] 多頭計數S分佈: mean={S.mean():.2f}, 1%={S.quantile(0.01):.2f}, 99%={S.quantile(0.99):.2f}")

    # 權重
    if cfg.method.lower() == "majority":
        w = weights_majority(pos_df, cfg.params)
        # 命名也用調整後的 k_eff 與 N
        method_name = f"Majority_{k_eff}_of_{N}"
    elif cfg.method.lower() == "proportional":
        w = weights_proportional(pos_df, cfg.params)
        method_name = f"Proportional_N{N}"
    else:
        raise ValueError("method 必須是 'majority' 或 'proportional'")

    # 調試信息：權重統計
    w_raw = (S >= cfg.params.majority_k).astype(float) if cfg.method.lower() == 'majority' else (S / max(N, 1))
    logger.info(f"[Ensemble] w_raw(min/mean/max)={w_raw.min():.2f}/{w_raw.mean():.2f}/{w_raw.max():.2f}")
    logger.info(f"[Ensemble] w_smooth(min/mean/max)={w.min():.2f}/{w.mean():.2f}/{w.max():.2f}")

    # 權益與事件（Open→Open）
    equity, trades, daily_state, trade_ledger = equity_open_to_open(px["open"], w, cfg.cost, start_equity=1.0)

    # 以開盤價模擬資產曲線
    open_px = px['open'].copy()  # 你現有的價格列
    daily_state, trade_ledger = build_portfolio_ledger(
        open_px=open_px,
        w=w,                    # 你要落地的最終權重序列（已經過 floor/ema/delta_cap/cooldown）
        cost=cfg.cost,          # 你的 CostParams
        initial_capital=1_000_000.0,
        lot_size=None            # 若要整股就給 1000 or 1，否則 None 允許小數
    )

    # 統一欄位格式（避免之後序列化麻煩）
    daily_state = daily_state.copy()
    daily_state.index = pd.to_datetime(daily_state.index)
    daily_state.index.name = 'date'
    for col in ['equity', 'cash', 'position_value', 'invested_pct', 'cash_pct', 'w']:
        if col not in daily_state.columns:
            daily_state[col] = np.nan

    # 調試信息：Open→Open 報酬統計
    r_oo = (px['open'].shift(-1) / px['open'] - 1).dropna()
    logger.info(f"[Ensemble] r_oo mean={r_oo.mean():.4f}, std={r_oo.std():.4f}, count={len(r_oo)}")

    # 績效指標
    stats = perf_stats(equity, w)

    # 調試信息：績效摘要
    logger.info(f"[Ensemble] 績效摘要: 總報酬={stats.get('total_return', 0):.4f}, 年化={stats.get('annual_return', 0):.4f}, 最大
回撤={stats.get('max_drawdown', 0):.4f}")

    # 標準化交易明細為統一契約
    trades_ui = normalize_trades_for_ui(trades)
    trade_ledger_ui = normalize_trades_for_ui(trade_ledger)

    # 調試信息：標準化後的交易明細
    logger.info(f"[Ensemble] 標準化後 trades_ui 欄位: {list(trades_ui.columns)}")
    logger.info(f"[Ensemble] 標準化後 trade_ledger_ui 欄位: {list(trade_ledger_ui.columns)}")
    logger.info(f"[Ensemble] 交易筆數: trades={len(trades_ui)}, trade_ledger={len(trade_ledger_ui)}")

    # 保存調試信息到文件
    debug_path = OUT_DIR / f"ensemble_debug_{method_name}.txt"
    with open(debug_path, 'w', encoding='utf-8') as f:
        f.write(f"Ensemble 調試信息\n")
        f.write(f"================\n")
        f.write(f"方法: {method_name}\n")
        f.write(f"策略數量: {N}\n")
        f.write(f"參數: {cfg.params}\n")
        f.write(f"成本: {cfg.cost}\n")
        f.write(f"權重統計: min={w.min():.4f}, mean={w.mean():.4f}, max={w.max():.4f}\n")
        f.write(f"績效: {stats}\n")
        f.write(f"交易明細欄位: trades={list(trades_ui.columns)}, trade_ledger={list(trade_ledger_ui.columns)}\n")
        f.write(f"交易筆數: trades={len(trades_ui)}, trade_ledger={len(trade_ledger_ui)}\n")

    logger.info(f"[Ensemble] 調試信息已保存到: {debug_path}")
I noticed the function doesn't reference the risk valve. I should double-check where it might apply.

root@9a3d3c80743e:/workspace/SSS096# rg "風險閥門" SSS_EnsembleTab.py
1287:# === PATCH: 風險閥門施作在權重 ===
1292:    """對每日目標權重 w 施作風險閥門：
root@9a3d3c80743e:/workspace/SSS096# sed -n '1287,1335p' SSS_EnsembleTab.py
# === PATCH: 風險閥門施作在權重 ===
def apply_valve_to_weights(w: pd.Series,
                           risk_trigger: pd.Series,
                           mode: str = "cap",   # "cap" 或 "ban_add"
                           cap_level: float = 0.5) -> pd.Series:
    """對每日目標權重 w 施作風險閥門：
       - cap: 風險日將 w 限在 cap_level 以下
       - ban_add: 風險日禁止「提高」倉位（允許減倉），用迭代法確保單調"""
    w = w.copy().reindex(risk_trigger.index).ffill().fillna(0.0)
    out = w.copy()

    if mode == "cap":
        mask = risk_trigger.reindex(w.index).fillna(False).astype(bool)
        out[mask] = np.minimum(out[mask], cap_level)

    elif mode == "ban_add":
        mask = risk_trigger.reindex(w.index).fillna(False).astype(bool)
        for i in range(1, len(out)):
            if mask.iloc[i] and (out.iloc[i] > out.iloc[i-1]):
                out.iloc[i] = out.iloc[i-1]  # 禁止增加
    else:
        raise ValueError("mode 需為 'cap' 或 'ban_add'")
    return out.clip(0.0, 1.0)


# === PATCH: 由 trade_ledger 建立「每筆盈虧%」與快照（引用 re.txt 做法）===
def build_trade_snapshots_from_ledger(trade_ledger: pd.DataFrame) -> pd.DataFrame:
    """以交易後權益/現金為資產快照，計算每筆盈虧%（只在有變動的交易日記一筆）"""
    df = trade_ledger.copy()
    # 欄名對齊
    if "date" in df.columns: df.rename(columns={"date": "交易日期"}, inplace=True)
    if "type" in df.columns: df.rename(columns={"type": "交易類型"}, inplace=True)
    if "equity_after" in df.columns: df.rename(columns={"equity_after": "交易後權益"}, inplace=True)
    if "cash_after" in df.columns: df.rename(columns={"cash_after": "交易後現金"}, inplace=True)
    if "open" in df.columns: df.rename(columns={"open": "開盤價"}, inplace=True)
    if "w_before" in df.columns: df.rename(columns={"w_before": "交易前權重"}, inplace=True)
    if "w_after" in df.columns: df.rename(columns={"w_after": "交易後權重"}, inplace=True)

    df["交易日期"] = pd.to_datetime(df["交易日期"], errors="coerce")
    df = df.dropna(subset=["交易日期"]).sort_values("交易日期").reset_index(drop=True)

    df["總資產"] = pd.to_numeric(df.get("交易後權益", 0), errors="coerce").fillna(0) + \
                   pd.to_numeric(df.get("交易後現金", 0), errors="coerce").fillna(0)
    df["前次總資產"] = df["總資產"].shift(1)
    df["每筆盈虧"] = df["總資產"] - df["前次總資產"]
    df["每筆盈虧%"] = (df["每筆盈虧"] / df["前次總資產"]).replace([np.inf, -np.inf], np.nan) * 100
    df.loc[df.index.min(), ["每筆盈虧", "每筆盈虧%"]] = 0.0
    return df
I’ll search for apply_valve_to_weights to check if it affects the metrics variable.

root@9a3d3c80743e:/workspace/SSS096# rg "apply_valve_to_weights" -n
SSS_EnsembleTab.py
1288:def apply_valve_to_weights(w: pd.Series,
1373:    w2 = apply_valve_to_weights(w, sig["risk_trigger"], mode, cap_level)
I’ll check between lines 1350 and 1385, which are related to the risk valve example.

root@9a3d3c80743e:/workspace/SSS096# sed -n '1345,1385p' SSS_EnsembleTab.py
    if "交易後開盤權益" in tl.columns and "交易後權益" in tl.columns:
        delta = (tl["交易後權益"] - tl["交易後開盤權益"]) / tl["交易後開盤權益"]
        tl["盈虧%"] = delta * 100.0
    elif "盈虧%" not in tl.columns:
        tl["盈虧%"] = 0.0
    mask_sell = tl["交易類型"].astype(str).str.lower().eq("sell")
    return pd.to_numeric(tl.loc[mask_sell, "盈虧%"], errors="coerce").dropna()

def _mdd_from_daily_equity(equity: pd.Series) -> float:
    eq = pd.to_numeric(equity, errors="coerce").dropna()
    if eq.empty: return 0.0
    dd = eq / eq.cummax() - 1.0
    return float(dd.min())

def risk_valve_backtest(open_px: pd.Series,
                        w: pd.Series,
                        cost,
                        benchmark_df: pd.DataFrame,
                        mode: str = "cap",
                        cap_level: float = 0.5,
                        slope20_thresh: float = 0.0,
                        slope60_thresh: float = 0.0,
                        atr_win: int = 20,
                        atr_ref_win: int = 60,
                        atr_ratio_mult: float = 1.3) -> dict:
    """回傳：原始與閥門版本的績效、右尾削減度、以及兩版 equity/ledger"""
    sig = compute_risk_valve_signals(benchmark_df, slope20_thresh, slope60_thresh,
                                     atr_win, atr_ref_win, atr_ratio_mult)
    w2 = apply_valve_to_weights(w, sig["risk_trigger"], mode, cap_level)

    # 原始版本
    daily_state1, ledger1 = build_portfolio_ledger(open_px, w, cost)
    # 閥門版本
    daily_state2, ledger2 = build_portfolio_ledger(open_px, w2, cost)

    # 交易統計（只用賣出列；符合 re.txt 對實現損益的口徑）
    r1 = _sell_returns_pct_from_ledger(ledger1)
    r2 = _sell_returns_pct_from_ledger(ledger2)
    pf1 = (r1[r1>0].sum() / abs(r1[r1<0].sum())) if (r1[r1<0].sum()!=0) else np.inf
    pf2 = (r2[r2>0].sum() / abs(r2[r2<0].sum())) if (r2[r2<0].sum()!=0) else np.inf
    mdd1 = _mdd_from_daily_equity(daily_state1["equity"])
The user reports missing metrics after applying the risk valve. I'll check relevant functions.

root@9a3d3c80743e:/workspace/SSS096# rg "全局風險閥門" -n
app_dash.py
797:    # === 新增：全局風險閥門觸發狀態追蹤 ===
810:        # 應用全局風險閥門設定（如果啟用）
813:            logger.info(f"[{strat}] 應用全局風險閥門: CAP={risk_cap}, ATR比值門檻={atr_ratio}")
856:            logger.info(f"[{strat}] 未啟用全局風險閥門")
1116:                        logger.info(f"[{strat}] ⚪ 全局風險閥門未啟用")
1205:        # === 全局風險閥門：逐日動態套用（與增強分析一致） ===
1211:                logger.warning(f"[{strat}] daily_state 不含 'w'，跳過全局風險閥門")
1217:                    logger.warning(f"[{strat}] 無法計算 ATR20/60，跳過全局風險閥門")
1316:                        logger.info(f"[{strat}] 全局風險閥門已套用（逐日），風險天數={true_days}, CAP={risk_cap:.2f}")
The user mentioned metrics disappearing after applying the risk valve. I'll check SSSv096 for any issues.

root@9a3d3c80743e:/workspace/SSS096# rg "風險閥門" SSSv096.py
I think the user might be seeing issues with metrics after applying the risk valve. Let's check for the function recalculating metrics in app_dash after the valve is applied, especially around the 'avg_holding_days' or similar metrics.

root@9a3d3c80743e:/workspace/SSS096# rg "metrics" -n app_dash.py
1096:                    if "metrics" in rv:
1097:                        logger.info(f"[{strat}] 風險閥門效果: PF原始={rv['metrics'].get('pf_orig', 'N/A'):.2f}, PF閥門={rv[
'metrics'].get('pf_valve', 'N/A'):.2f}")
1098:                        logger.info(f"[{strat}] 風險閥門效果: MDD原始={rv['metrics'].get('mdd_orig', 'N/A'):.2f}%, MDD閥門=
{rv['metrics'].get('mdd_valve', 'N/A'):.2f}%")
1130:                    'metrics': backtest_result.stats,
1151:                    'metrics': {'total_return': 0.0, 'annual_return': 0.0, 'max_drawdown': 0.0, 'sharpe_ratio': 0.0, 'calma
r_ratio': 0.0, 'num_trades': 0},
1302:                        for k in ['trades_ui', 'trade_df', 'trade_ledger_std', 'metrics']:
1540:            metrics = result.get('metrics', {})
1545:            metrics['avg_holding_period'] = avg_holding
1568:            for k, v in metrics.items():
1729:                dbc.Row(metric_cards, style={"flex-wrap": "wrap"}, className='metrics-cards-row'),
1731:                dcc.Graph(figure=fig1, config={'displayModeBar': True}, className='main-metrics-graph'),
1878:            metrics = result['metrics']
1881:                '總回報率': f"{metrics.get('total_return', 0):.2%}",
1882:                '年化回報率': f"{metrics.get('annual_return', 0):.2%}",
1883:                '最大回撤': f"{metrics.get('max_drawdown', 0):.2%}",
1884:                '卡瑪比率': f"{metrics.get('calmar_ratio', 0):.2f}",
1885:                '交易次數': metrics.get('num_trades', 0),
1886:                '勝率': f"{metrics.get('win_rate', 0):.2%}",
1887:                '盈虧比': f"{metrics.get('payoff_ratio', 0):.2f}",
2436:    m = out["metrics"]
2628:    def _group_metrics(mask):
2655:    acc_metrics = dis_metrics = None
2659:        acc_metrics = _group_metrics(mask_acc)
2660:        dis_metrics = _group_metrics(mask_dis)
2664:        group_row("加碼段", acc_metrics),
2665:        group_row("減碼段", dis_metrics),
3447:                if not isinstance(out, dict) or "metrics" not in out:
3451:                m = out["metrics"]
3547:def calculate_pareto_metrics(equity_curve, trade_df):
3860:                    if out and "metrics" in out:
3861:                        m = out["metrics"]
3867:                        metrics = calculate_pareto_metrics(equity_curve, trade_df)
3868:                        if metrics:
3873:                                'max_drawdown': metrics['max_drawdown'],
3874:                                'pf': metrics['pf'],
3875:                                'right_tail_loss': metrics['right_tail_loss'],
3876:                                'risk_trigger_days': metrics['risk_trigger_days'],
I'm checking around where the risk valve is applied to see if it overwrites 'metrics'.

root@9a3d3c80743e:/workspace/SSS096# rg "valve" -n app_dash.py
455:                        dbc.Checkbox(id='force-valve-trigger', value=False, label="強制觸發風險閥門（測試用）", style={"font
Size":"11px","color":"#dc3545"}),
461:                    html.Div(id='risk-valve-status', style={"marginTop":"8px","padding":"8px","backgroundColor":"#f8f9fa","b
orderRadius":"4px","border":"1px solid #dee2e6"}),
575:    Output('risk-valve-status', 'children'),
580:        Input('force-valve-trigger', 'value'),
586:def update_risk_valve_status(global_apply, risk_cap, atr_ratio, force_trigger, ticker, start_date, end_date):
656:                            valve_triggered = atr_ratio_current > atr_ratio
660:                                valve_triggered = True
666:                            logger.info(f"風險閥門觸發: {'是' if valve_triggered else '否'}")
667:                            logger.info(f"風險閥門狀態: {'🔴 觸發' if valve_triggered else '🟢 正常'}")
669:                            status_color = "#dc3545" if valve_triggered else "#28a745"
670:                            status_icon = "🔴" if valve_triggered else "🟢"
671:                            status_text = "觸發" if valve_triggered else "正常"
764:        Input('force-valve-trigger', 'value'),
798:    valve_triggered = False
850:                    valve_triggered = True
873:                valve_triggered_local = False
883:                            valve_triggered_local = (ratio_local >= atr_ratio)  # 建議使用 >=
888:                    valve_triggered_local = True
892:                if valve_triggered_local:
893:                    from SSS_EnsembleTab import risk_valve_backtest, CostParams
918:                        rv = risk_valve_backtest(
928:                        result['equity_curve']     = pack_series(rv["daily_state_valve"]["equity"])
929:                        result['daily_state']      = pack_df(rv["daily_state_valve"])
930:                        result['daily_state_std']  = pack_df(rv["daily_state_valve"])
931:                        result['trade_ledger']     = pack_df(rv["trade_ledger_valve"])
932:                        result['trade_ledger_std'] = pack_df(rv["trade_ledger_valve"])
933:                        result['weight_curve']     = pack_series(rv["weights_valve"])
935:                        result['valve'] = {
947:                    result['valve'] = {
1021:                valve_triggered = False
1044:                                valve_triggered = (ratio >= atr_ratio)
1045:                                logger.info(f"[{strat}] Ensemble ATR 比值: {ratio:.4f} (門檻={atr_ratio}) -> 觸發={valve_tr
iggered}")
1048:                                if valve_triggered:
1065:                    valve_triggered = True
1074:                if global_apply and valve_triggered:
1075:                    from SSS_EnsembleTab import risk_valve_backtest
1080:                    rv = risk_valve_backtest(
1089:                    backtest_result.daily_state = rv["daily_state_valve"]
1090:                    backtest_result.ledger = rv["trade_ledger_valve"]
1091:                    backtest_result.weight_curve = rv["weights_valve"]
1092:                    backtest_result.equity_curve = rv["daily_state_valve"]["equity"]
1097:                        logger.info(f"[{strat}] 風險閥門效果: PF原始={rv['metrics'].get('pf_orig', 'N/A'):.2f}, PF閥門={rv[
'metrics'].get('pf_valve', 'N/A'):.2f}")
1098:                        logger.info(f"[{strat}] 風險閥門效果: MDD原始={rv['metrics'].get('mdd_orig', 'N/A'):.2f}%, MDD閥門=
{rv['metrics'].get('mdd_valve', 'N/A'):.2f}%")
1101:                    result['valve'] = {
1110:                        result['valve'] = {
1118:                        result['valve'] = {
1172:            # 為其他策略類型添加 valve 標記
1174:                result['valve'] = {
1180:                result['valve'] = {
1238:                    # 若你沿用現有的 risk_valve_backtest，給 cap_level=1.0 表示「w 已經是目標序列」
1240:                        from SSS_EnsembleTab import risk_valve_backtest, CostParams
1264:                        result_cap = risk_valve_backtest(
1273:                        logger.warning(f"[{strat}] 無法導入 risk_valve_backtest: {e}")
1278:                        logger.info(f"[UI_CHECK] 即將覆寫：new_trades={len(result_cap.get('trade_ledger_valve', pd.DataFram
e()))} rows, new_ds={len(result_cap.get('daily_state_valve', pd.DataFrame()))} rows")
1281:                        if 'trade_ledger_valve' in result_cap:
1282:                            result['trades'] = pack_df(result_cap['trade_ledger_valve'])
1283:                            result['trade_ledger'] = pack_df(result_cap['trade_ledger_valve'])
1284:                            result['trade_ledger_std'] = pack_df(result_cap['trade_ledger_valve'])
1286:                        if 'daily_state_valve' in result_cap:
1287:                            result['daily_state'] = pack_df(result_cap['daily_state_valve'])
1288:                            result['daily_state_std'] = pack_df(result_cap['daily_state_valve'])
1290:                        if 'weights_valve' in result_cap:
1291:                            result['weight_curve'] = pack_series(result_cap['weights_valve'])
1294:                        if 'daily_state_valve' in result_cap and 'equity' in result_cap['daily_state_valve']:
1296:                                result['equity_curve'] = pack_series(result_cap['daily_state_valve']['equity'])
1299:                                result['equity_curve'] = pack_df(result_cap['daily_state_valve']['equity'].to_frame('equity
'))
1307:                        result['_risk_valve_applied'] = True
1308:                        result['_risk_valve_params'] = {
1702:            valve = results.get(strategy, {}).get('valve', {}) or {}
1703:            valve_badge_text = ("已套用" if valve.get("applied") else "未套用")
1704:            valve_badge_extra = []
1705:            if isinstance(valve.get("cap"), (int, float)):
1706:                valve_badge_extra.append(f"CAP={valve['cap']:.2f}")
1707:            if isinstance(valve.get("atr_ratio"), (int, float)):
1708:                valve_badge_extra.append(f"ATR比值={valve['atr_ratio']:.2f}")
1709:            elif valve.get("atr_ratio") == "forced":
1710:                valve_badge_extra.append("強制觸發")
1712:            valve_badge = html.Span(
1713:                "🛡️ 風險閥門：" + valve_badge_text + ((" | " + " | ".join(valve_badge_extra)) if valve_badge_extra else ""),
1716:                    "color": ("#dc3545" if valve.get("applied") else "#6c757d"),
1719:            ) if valve else html.Span("")
1725:                    valve_badge
2426:        from SSS_EnsembleTab import risk_valve_backtest
2427:        out = risk_valve_backtest(
2443:        html.Code(f"PF: 原始 {m['pf_orig']:.2f} → 閥門 {m['pf_valve']:.2f}"), html.Br(),
2444:        html.Code(f"MDD: 原始 {m['mdd_orig']:.2%} → 閥門 {m['mdd_valve']:.2%}"), html.Br(),
2445:        html.Code(f"右尾總和(>P90 正報酬): 原始 {m['right_tail_sum_orig']:.2f} → 閥門 {m['right_tail_sum_valve']:.2f} (↓{m[
'right_tail_reduction']:.2f})"), html.Br(),
2452:    eq2 = out["daily_state_valve"]["equity"]
2458:        "valve": {"color": "#ff7f0e", "dash": "dot"},
2469:        mode="lines", line=dict(color=palette["valve"]["color"], width=2, dash=palette["valve"]["dash"]),
2482:        mode="lines", line=dict(color=palette["valve"]["color"], width=2, dash=palette["valve"]["dash"]),
3424:    # 檢查是否可以匯入 risk_valve_backtest
3426:        from SSS_EnsembleTab import risk_valve_backtest
3427:        logger.info("成功匯入 risk_valve_backtest")
3429:        logger.error(f"匯入 risk_valve_backtest 失敗: {e}")
3430:        return go.Figure(), f"❌ 無法匯入 risk_valve_backtest: {e}"
3440:                out = risk_valve_backtest(
3456:                pf = float(m.get("pf_valve", np.nan))
3457:                mdd = float(m.get("mdd_valve", np.nan))
3458:                rt_sum_valve = float(m.get("right_tail_sum_valve", np.nan))
3460:                rt_reduction = float(m.get("right_tail_reduction", np.nan)) if m.get("right_tail_reduction") is not None el
se (rt_sum_orig - rt_sum_valve if np.isfinite(rt_sum_orig) and np.isfinite(rt_sum_valve) else np.nan)
3468:                    "right_tail_sum_valve": rt_sum_valve,
3524:        customdata=dfp[["right_tail_sum_valve","right_tail_sum_orig"]].values,
3837:        # 檢查是否可以匯入 risk_valve_backtest
3839:            from SSS_EnsembleTab import risk_valve_backtest
3840:            logger.info("成功匯入 risk_valve_backtest")
3842:            logger.error(f"匯入 risk_valve_backtest 失敗: {e}")
3853:                    out = risk_valve_backtest(
3864:                        equity_curve = out.get("daily_state_valve", {}).get("equity")
3865:                        trade_df = None  # risk_valve_backtest 不直接提供交易記錄
3878:                                'pf_valve': m.get('pf_valve', 0.0),
3880:                                'mdd_valve': m.get('mdd_valve', 0.0),
I'm checking where metrics might be overwritten after applying the risk valve. Let's dig deeper around 1130-1151.

root@9a3d3c80743e:/workspace/SSS096# sed -n '824,1170p' app_dash.py

                    # 檢查樣本數量是否足夠
                    min_samples_20, min_samples_60 = 30, 60  # 至少需要 30 和 60 個樣本
                    if len(atr_20_valid) < min_samples_20 or len(atr_60_valid) < min_samples_60:
                        logger.warning(f"[{strat}] ATR 樣本不足，20期:{len(atr_20_valid)}/{min_samples_20}, 60期:{len(atr_60_val
id)}/{min_samples_60}")
                        continue

                    atr_20_latest = atr_20_valid.iloc[-1]
                    atr_60_latest = atr_60_valid.iloc[-1]

                    # 檢查 ATR 值是否合理
                    if atr_60_latest <= 0 or not np.isfinite(atr_60_latest):
                        logger.warning(f"[{strat}] ATR(60) 值異常: {atr_60_latest}，跳過風險閥門")
                        continue

                    if atr_20_latest <= 0 or not np.isfinite(atr_20_latest):
                        logger.warning(f"[{strat}] ATR(20) 值異常: {atr_20_latest}，跳過風險閥門")
                        continue

                    atr_ratio_current = atr_20_latest / atr_60_latest
                    logger.info(f"[{strat}] 最新ATR比值: {atr_ratio_current:.4f} (20期:{atr_20_latest:.4f}, 60期:{atr_60_latest:
.4f})")
                else:
                    logger.warning(f"[{strat}] ATR 計算結果為空")

                # 強制觸發時設置標記
                if force_trigger:
                    valve_triggered = True
                    logger.info(f"[{strat}] 🔴 強制觸發風險閥門啟用")

            except Exception as e:
                logger.warning(f"[{strat}] ATR 計算失敗: {e}")
        else:
            logger.info(f"[{strat}] 未啟用全局風險閥門")

        if strat_type == 'ssma_turn':
            calc_keys = ['linlen', 'factor', 'smaalen', 'prom_factor', 'min_dist', 'buy_shift', 'exit_shift', 'vol_window', 'sig
nal_cooldown_days', 'quantile_win']
            ssma_params = {k: v for k, v in strat_params.items() if k in calc_keys}
            backtest_params = ssma_params.copy()
            backtest_params['stop_loss'] = strat_params.get('stop_loss', 0.0)

            # 重新計算策略信號（因為參數可能已經被風險閥門調整）
            df_ind, buy_dates, sell_dates = compute_ssma_turn_combined(df_raw, df_factor, **ssma_params, smaa_source=smaa_src)
            if df_ind.empty:
                continue
            result = backtest_unified(df_ind, strat_type, backtest_params, buy_dates, sell_dates, discount=discount, trade_coold
own_bars=cooldown, bad_holding=bad_holding)

            # === 在 ssma_turn 也套用風險閥門（和 Ensemble 一致的後置覆寫） ===
            if global_apply:
                # 判斷是否要觸發（與你的 ATR 檢查或強制觸發一致）
                valve_triggered_local = False
                ratio_local = None
                try:
                    atr_20 = calculate_atr(df_raw, 20)
                    atr_60 = calculate_atr(df_raw, 60)
                    if not atr_20.empty and not atr_60.empty:
                        a20 = atr_20.dropna().iloc[-1]
                        a60 = atr_60.dropna().iloc[-1]
                        if a60 > 0:
                            ratio_local = float(a20 / a60)
                            valve_triggered_local = (ratio_local >= atr_ratio)  # 建議使用 >=
                except Exception:
                    pass

                if force_trigger:
                    valve_triggered_local = True
                    if ratio_local is None:
                        ratio_local = 1.5

                if valve_triggered_local:
                    from SSS_EnsembleTab import risk_valve_backtest, CostParams
                    # 取得 open 價；df_raw 欄位名稱是小寫
                    open_px = df_raw['open'] if 'open' in df_raw.columns else df_raw['close']
                    # 從回測輸出抓 w（先用標準化 daily_state，如果沒有就用原 daily_state）
                    w_series = None
                    try:
                        ds_std = df_from_pack(result.get('daily_state_std'))
                        if ds_std is not None and not ds_std.empty and 'w' in ds_std.columns:
                            w_series = ds_std['w']
                    except Exception:
                        pass
                    if w_series is None:
                        ds = df_from_pack(result.get('daily_state'))
                        if ds is not None and not ds.empty and 'w' in ds.columns:
                            w_series = ds['w']

                    if w_series is not None:
                        # 交易成本（與 Ensemble 分支一致）
                        trade_cost = strat_params.get('trade_cost', {})
                        cost_params = CostParams(
                            buy_fee_bp=float(trade_cost.get("buy_fee_bp", 4.27)),
                            sell_fee_bp=float(trade_cost.get("sell_fee_bp", 4.27)),
                            sell_tax_bp=float(trade_cost.get("sell_tax_bp", 30.0))
                        )

                        rv = risk_valve_backtest(
                            open_px=open_px,
                            w=w_series,
                            cost=cost_params,
                            benchmark_df=df_raw,
                            mode="cap",
                            cap_level=float(risk_cap),
                        )

                        # 覆寫結果，確保 UI 與輸出一致（和 Ensemble 分支對齊）
                        result['equity_curve']     = pack_series(rv["daily_state_valve"]["equity"])
                        result['daily_state']      = pack_df(rv["daily_state_valve"])
                        result['daily_state_std']  = pack_df(rv["daily_state_valve"])
                        result['trade_ledger']     = pack_df(rv["trade_ledger_valve"])
                        result['trade_ledger_std'] = pack_df(rv["trade_ledger_valve"])
                        result['weight_curve']     = pack_series(rv["weights_valve"])
                        # 給 UI 的標記（下個小節會用到）
                        result['valve'] = {
                            "applied": True,
                            "cap": float(risk_cap),
                            "atr_ratio": ratio_local
                        }

                        logger.info(f"[{strat}] SSMA 風險閥門已套用（cap={risk_cap}, ratio={ratio_local:.4f}）")
                    else:
...

                except Exception as e:
                    logger.warning(f"[{strat}] 無法計算 Ensemble ATR 比值: {e}")
                    logger.warning(f"[{strat}] 錯誤詳情: {type(e).__name__}: {str(e)}")

                # 如果啟用強制觸發，則強制觸發風險閥門
                if force_trigger:
                    valve_triggered = True
                    logger.info(f"[{strat}] 🔴 強制觸發風險閥門啟用")
                    if ratio is None:
                        ratio = 1.5  # 設定一個預設值用於顯示

                # 使用新的 ensemble_runner 執行
                backtest_result = run_ensemble_backtest(cfg)

                # 若全局開關開啟且達觸發條件，才在權重序列上套用 CAP
                if global_apply and valve_triggered:
                    from SSS_EnsembleTab import risk_valve_backtest
                    bench = df_raw  # 已含 open/high/low/close/volume

                    logger.info(f"[{strat}] 🔴 開套用風險閥門: cap={risk_cap}, ratio={ratio:.4f}")

                    rv = risk_valve_backtest(
                        open_px=backtest_result.price_series,
                        w=backtest_result.weight_curve,
                        cost=cost_params,
                        benchmark_df=bench,
                        mode="cap",
                        cap_level=float(risk_cap),
                    )
                    # 覆寫結果，確保 UI 與輸出一致
                    backtest_result.daily_state = rv["daily_state_valve"]
                    backtest_result.ledger = rv["trade_ledger_valve"]
                    backtest_result.weight_curve = rv["weights_valve"]
                    backtest_result.equity_curve = rv["daily_state_valve"]["equity"]
                    logger.info(f"[{strat}] 風險閥門已套用（cap={risk_cap}, ratio={ratio:.4f}）")

                    # 增加風險閥門效果的詳細資訊
                    if "metrics" in rv:
                        logger.info(f"[{strat}] 風險閥門效果: PF原始={rv['metrics'].get('pf_orig', 'N/A'):.2f}, PF閥門={rv['metr
ics'].get('pf_valve', 'N/A'):.2f}")
                        logger.info(f"[{strat}] 風險閥門效果: MDD原始={rv['metrics'].get('mdd_orig', 'N/A'):.2f}%, MDD閥門={rv['
metrics'].get('mdd_valve', 'N/A'):.2f}%")

                    # 給 UI 的標記（與 SSMA 分支對齊）
                    result['valve'] = {
                        "applied": True,
                        "cap": float(risk_cap),
                        "atr_ratio": ratio
                    }
                else:
                    if global_apply:
                        logger.info(f"[{strat}] 🟢 風險閥門未觸發，使用原始參數")
                        # 給 UI 的標記（未觸發）
                        result['valve'] = {
                            "applied": False,
                            "cap": float(risk_cap),
                            "atr_ratio": ratio if ratio is not None else "N/A"
                        }
                    else:
                        logger.info(f"[{strat}] ⚪ 全局風險閥門未啟用")
                        # 給 UI 的標記（未啟用）
                        result['valve'] = {
                            "applied": False,
                            "cap": "N/A",
                            "atr_ratio": "N/A"
                        }

                # 轉換為舊格式以保持相容性
                result = {
                    'trades': [],
                    'trade_df': pack_df(backtest_result.trades),
                    'trades_df': pack_df(backtest_result.trades),
                    'signals_df': pack_df(backtest_result.trades[['trade_date', 'type', 'price']].rename(columns={'type': 'actio
n'}) if not backtest_result.trades.empty else pd.DataFrame(columns=['trade_date', 'action', 'price'])),
                    'metrics': backtest_result.stats,
                    'equity_curve': pack_series(backtest_result.equity_curve),
                    'cash_curve': pack_series(backtest_result.cash_curve) if backtest_result.cash_curve is not None else "",
                    'weight_curve': pack_series(backtest_result.weight_curve) if backtest_result.weight_curve is not None else p
ack_series(pd.Series(0.0, index=backtest_result.equity_curve.index)),
                    'price_series': pack_series(backtest_result.price_series) if backtest_result.price_series is not None else p
ack_series(pd.Series(1.0, index=backtest_result.equity_curve.index)),
                    'daily_state': pack_df(backtest_result.daily_state),
                    'trade_ledger': pack_df(backtest_result.ledger),
                    'daily_state_std': pack_df(backtest_result.daily_state),
                    'trade_ledger_std': pack_df(backtest_result.ledger)
                }

                logger.info(f"[Ensemble] 執行成功: 益曲線長度={len(backtest_result.equity_curve)}, 交易數={len(backtest_result.l
edger) if backtest_result.ledger is not None and not backtest_result.ledger.empty else 0}")

            except Exception as e:
                logger.error(f"Ensemble 策略執行失敗: {e}")
                # 創建空的結果
                result = {
                    'trades': [],
                    'trade_df': pd.DataFrame(),
                    'trades_df': pd.DataFrame(),
                    'signals_df': pd.DataFrame(),
                    'metrics': {'total_return': 0.0, 'annual_return': 0.0, 'max_drawdown': 0.0, 'sharpe_ratio': 0.0, 'calmar_rat
io': 0.0, 'num_trades': 0},
                    'equity_curve': pd.Series(1.0, index=df_raw.index)
                }

            # === 修復 3：添加調試日誌，核對子策略集合是否一致 ===
            logger.info(f"[Ensemble] 執行完成，ticker={ticker}, method={flat_params.get('method')}")
            if 'equity_curve' in result and hasattr(result['equity_curve'], 'shape'):
                logger.info(f"[Ensemble] 權益曲線長度: {len(result['equity_curve'])}")
            if 'trade_df' in result and hasattr(result['trade_df'], 'shape'):
                logger.info(f"[Ensemble] 交易記錄數量: {len(result['trade_df'])}")
        else:
            if strat_type == 'single':
                df_ind = compute_single(df_raw, df_factor, strat_params["linlen"], strat_params["factor"], strat_params["smaalen
"], strat_params["devwin"], smaa_source=smaa_src)
            elif strat_type == 'dual':
                df_ind = compute_dual(df_raw, df_factor, strat_params["linlen"], strat_params["factor"], strat_params["smaalen"]
, strat_params["short_win"], strat_params["long_win"], smaa_source=smaa_src)
            elif strat_type == 'RMA':
                df_ind = compute_RMA(df_raw, df_factor, strat_params["linlen"], strat_params["factor"], strat_params["smaalen"],
 strat_params["rma_len"], strat_params["dev_len"], smaa_source=smaa_src)
            if df_ind.empty:
                continue
            result = backtest_unified(df_ind, strat_type, strat_params, discount=discount, trade_cooldown_bars=cooldown, bad_hol
ding=bad_holding)
I'm checking how result gets transformed after run_ensemble and the impact of risk valve.

root@9a3d3c80743e:/workspace/SSS096# sed -n '1188,1324p' app_dash.py
            if hasattr(result.get('trade_df'), 'to_json'):
                result['trade_df'] = result['trade_df'].to_json(date_format='iso', orient='split')
            if 'signals_df' in result and hasattr(result['signals_df'], 'to_json'):
                result['signals_df'] = result['signals_df'].to_json(date_format='iso', orient='split')
            if 'trades_df' in result and hasattr(result['trades_df'], 'to_json'):
                result['trades_df'] = result['trades_df'].to_json(date_format='iso', orient='split')
            if 'equity_curve' in result and hasattr(result['equity_curve'], 'to_json'):
                result['equity_curve'] = result['equity_curve'].to_json(date_format='iso', orient='split')
        if 'trades' in result and isinstance(result['trades'], list):
            result['trades'] = [
                (str(t[0]), t[1], str(t[2])) if isinstance(t, tuple) and len(t) == 3 else t
                for t in result['trades']
            ]

        # << 新增：一律做最後保險打包，補上 daily_state / weight_curve 等 >>
        result = _pack_result_for_store(result)

        # === 全局風險閥門：逐日動態套用（與增強分析一致） ===
        if global_apply:
            # 1) 取 ds（daily_state），並解包
            ds_raw = result.get("daily_state_std") or result.get("daily_state")
            ds = df_from_pack(ds_raw)
            if ds is None or ds.empty or "w" not in ds.columns:
                logger.warning(f"[{strat}] daily_state 不含 'w'，跳過全局風險閥門")
            else:
                # 2) 算逐日 ATR 比值與逐日 mask
                atr20 = calculate_atr(df_raw, 20)
                atr60 = calculate_atr(df_raw, 60)
                if atr20 is None or atr60 is None:
                    logger.warning(f"[{strat}] 無法計算 ATR20/60，跳過全局風險閥門")
                else:
                    ratio = (atr20 / atr60).replace([np.inf, -np.inf], np.nan)
                    mask = (ratio >= float(atr_ratio))
                    if force_trigger:
                        mask[:] = True  # 強制全部日子套 CAP

                    # 3) 對齊到 ds.index，逐日壓 w 至 CAP
                    mask_aligned = mask.reindex(ds.index).fillna(False).to_numpy()
                    w = ds["w"].astype(float).to_numpy()
                    w_new = w.copy()
                    w_new[mask_aligned] = np.minimum(w_new[mask_aligned], float(risk_cap))
                    ds["w"] = w_new

                    # 4) 回寫 ds，並重算交易/權益
                    result["daily_state_std"] = pack_df(ds)

                    # open 價（沒有 open 就退而求其次用收盤價）
                    open_px = (df_raw["open"] if "open" in df_raw.columns else df_raw.get("收盤價")).astype(float)
                    open_px = open_px.reindex(ds.index).dropna()

                    # 若你沿用現有的 risk_valve_backtest，給 cap_level=1.0 表示「w 已經是目標序列」
                    try:
                        from SSS_EnsembleTab import risk_valve_backtest, CostParams

                        # 成本參數
                        trade_cost = (strat_params.get("trade_cost", {})
                                      if isinstance(strat_params, dict) else {})
                        cost = CostParams(
                            buy_fee_bp=float(trade_cost.get("buy_fee_bp", 4.27)),
                            sell_fee_bp=float(trade_cost.get("sell_fee_bp", 4.27)),
                            sell_tax_bp=float(trade_cost.get("sell_tax_bp", 30.0)),
                        )

                        # 基準（有高低價就帶上）
                        bench = pd.DataFrame(index=pd.to_datetime(df_raw.index))
                        if 'close' in df_raw.columns:
                            bench["收盤價"] = pd.to_numeric(df_raw["close"], errors="coerce")
                        elif '收盤價' in df_raw.columns:
                            bench["收盤價"] = pd.to_numeric(df_raw["收盤價"], errors="coerce")
                        if 'high' in df_raw.columns and 'low' in df_raw.columns:
                            bench["最高價"] = pd.to_numeric(df_raw["high"], errors="coerce")
                            bench["最低價"] = pd.to_numeric(df_raw["low"], errors="coerce")
                        elif '最高價' in df_raw.columns and '最低價' in df_raw.columns:
                            bench["最高價"] = pd.to_numeric(df_raw["最高價"], errors="coerce")
                            bench["最低價"] = pd.to_numeric(df_raw["最低價"], errors="coerce")

                        result_cap = risk_valve_backtest(
                            open_px=open_px,
                            w=ds["w"].astype(float).reindex(open_px.index).fillna(0.0),
                            cost=cost,
                            benchmark_df=bench,
                            mode="cap",
                            cap_level=1.0,
                        )
                    except Exception as e:
                        logger.warning(f"[{strat}] 無法導入 risk_valve_backtest: {e}")
                        result_cap = None

                    if result_cap:
                        # === 安全覆寫：清掉舊鍵並補齊新鍵 ===
                        logger.info(f"[UI_CHECK] 即將覆寫：new_trades={len(result_cap.get('trade_ledger_valve', pd.DataFrame()))
} rows, new_ds={len(result_cap.get('daily_state_valve', pd.DataFrame()))} rows")

                        # 1) 覆寫結果 —— 一律用 pack_df/pack_series
                        if 'trade_ledger_valve' in result_cap:
                            result['trades'] = pack_df(result_cap['trade_ledger_valve'])
                            result['trade_ledger'] = pack_df(result_cap['trade_ledger_valve'])
                            result['trade_ledger_std'] = pack_df(result_cap['trade_ledger_valve'])

                        if 'daily_state_valve' in result_cap:
                            result['daily_state'] = pack_df(result_cap['daily_state_valve'])
                            result['daily_state_std'] = pack_df(result_cap['daily_state_valve'])

                        if 'weights_valve' in result_cap:
                            result['weight_curve'] = pack_series(result_cap['weights_valve'])

                        # 權益曲線：若是 Series
                        if 'daily_state_valve' in result_cap and 'equity' in result_cap['daily_state_valve']:
                            try:
                                result['equity_curve'] = pack_series(result_cap['daily_state_valve']['equity'])
                            except Exception:
                                # 若你存的是 DataFrame
                                result['equity_curve'] = pack_df(result_cap['daily_state_valve']['equity'].to_frame('equity'))

                        # 2) **關鍵**：把 UI 可能拿來用的舊快取清掉，強迫 UI 走新資料
                        for k in ['trades_ui', 'trade_df', 'trade_ledger_std', 'metrics']:
                            if k in result:
                                result.pop(k, None)

                        # 3) 給 UI 一個旗標與參數，便於顯示「已套用」
                        result['_risk_valve_applied'] = True
                        result['_risk_valve_params'] = {
                            'cap': float(risk_cap),
                            'atr_ratio': float(atr_ratio),
                            'atr20_last': float(atr_20_valid.iloc[-1]) if len(atr_20_valid) > 0 else None,
                            'atr60_last': float(atr_60_valid.iloc[-1]) if len(atr_60_valid) > 0 else None,
                        }

                        true_days = int(mask_aligned.sum())
                        logger.info(f"[{strat}] 全局風險閥門已套用（逐日），風險天數={true_days}, CAP={risk_cap:.2f}")
                    else:
                        logger.warning(f"[{strat}] 風險閥門重算沒有返回結果")

        results[strat] = result

    # 使用第一個策略的數據作為主要顯示數據
    first_strat = list(results.keys())[0] if results else strategy_names[0]
    first_smaa_src = param_presets[first_strat].get("smaa_source", "Self")
The metrics dictionary is cleared after applying the global risk valve, but it isn't recomputed. I'll adjust the code to recompute metrics, using either calculate_pareto_metrics or perf_stats, after updating the equity_curve.

I'll search for perf_stats and calculate_pareto_metrics to compute metrics after risk valve.

root@9a3d3c80743e:/workspace/SSS096# rg "def perf_stats" -n
SSS_EnsembleTab.py
691:def perf_stats(equity: pd.Series, w: pd.Series) -> Dict[str, float]:
I'll check if perf_stats is already imported in app_dash and confirm its usage.

root@9a3d3c80743e:/workspace/SSS096# rg "perf_stats" -n app_dash.py
I’ll take a look at the top of app_dash to review existing imports and style.

root@9a3d3c80743e:/workspace/SSS096# head -n 80 app_dash.py
import dash
from dash import dcc, html, dash_table, Input, Output, State, ctx, no_update
import dash_bootstrap_components as dbc
import pandas as pd
import plotly.graph_objects as go
import json
import io
from dash.dependencies import ALL
import shutil
import os
from datetime import datetime, timedelta
from pathlib import Path
import joblib
from analysis import config as cfg
import yfinance as yf
import logging
import numpy as np
from urllib.parse import quote as urlparse

# 配置 logger - 使用新的顯式初始化
from analysis.logging_config import init_logging
import os

# 強制啟用檔案日誌，不依賴環境變數
os.environ["SSS_CREATE_LOGS"] = "1"

# 直接呼叫 init_logging，它會使用正確的日誌目錄
init_logging(enable_file=True)
logger = logging.getLogger("SSS.App")

# 設定為 DEBUG 級別，詳細調試資訊會寫入日誌檔案
logger.setLevel(logging.DEBUG)
logger.info("已啟用詳細調試模式 - 調試資訊將寫入日誌檔案")
logger.info(f"日誌目錄: {os.path.abspath('analysis/log')}")

# ATR 計算函數
def calculate_atr(df, window):
    """計算 ATR (Average True Range)"""
    try:
        # 支援多種欄位名稱格式
        high_col = None
        low_col = None
        close_col = None

        # 檢查英文欄位名稱
        if 'high' in df.columns and 'low' in df.columns and 'close' in df.columns:
            high_col = 'high'
            low_col = 'low'
            close_col = 'close'
        # 檢查中文欄位名稱
        elif '最高價' in df.columns and '最低價' in df.columns and '收盤價' in df.columns:
            high_col = '最高價'
            low_col = '最低價'
            close_col = '收盤價'
        # 檢查其他可能的欄位名稱
        elif 'open' in df.columns and 'close' in df.columns:
            # 如果沒有高低價，用開盤價和收盤價近似
            high_col = 'open'
            low_col = 'close'
            close_col = 'close'

        if high_col and low_col and close_col:
            # 有高低價時，計算 True Range
            high = df[high_col]
            low = df[low_col]
            close = df[close_col]

            # 確保數據為數值型
            high = pd.to_numeric(high, errors='coerce')
            low = pd.to_numeric(low, errors='coerce')
            close = pd.to_numeric(close, errors='coerce')

            tr1 = high - low
            tr2 = abs(high - close.shift(1))
            tr3 = abs(low - close.shift(1))

            true_range = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
            atr = true_range.rolling(window=window).mean()
        else:
            # 只有收盤價時，用價格變化近似
I'll search for "from SSS_EnsembleTab import" to check the existing import style.


root@9a3d3c80743e:/workspace/SSS096# rg "SSS_EnsembleTab" -n app_dash.py
893:                    from SSS_EnsembleTab import risk_valve_backtest, CostParams
956:                from SSS_EnsembleTab import EnsembleParams, CostParams, RunConfig
1075:                    from SSS_EnsembleTab import risk_valve_backtest
1240:                        from SSS_EnsembleTab import risk_valve_backtest, CostParams
2413:    # 成本參數（使用 SSS_EnsembleTab 預設）
2424:    # 需要用到 SSS_EnsembleTab 內新加的函式
2426:        from SSS_EnsembleTab import risk_valve_backtest
2530:        from SSS_EnsembleTab import trade_contribution_by_phase
2858:        from SSS_EnsembleTab import trade_contribution_by_phase
3426:        from SSS_EnsembleTab import risk_valve_backtest
3839:            from SSS_EnsembleTab import risk_valve_backtest
I'll check if the perf_stats function is available and contains necessary imports.

root@9a3d3c80743e:/workspace/SSS096# sed -n '681,722p' SSS_EnsembleTab.py
    # 構建每日狀態 DataFrame
    daily_state = pd.DataFrame({
        'equity': E,
        'cash': cash,
        'w': w.reindex(open_px.index).fillna(0),
        'position_value': E - cash
    })

    return E, trades_df, daily_state, trade_ledger_df

def perf_stats(equity: pd.Series, w: pd.Series) -> Dict[str, float]:
    """計算績效指標"""
    if len(equity) < 2:
        return {}

    # 計算日報酬率
    r = equity.pct_change().dropna()

    # 基本指標
    total_return = (equity.iloc[-1] / equity.iloc[0]) - 1
    annual_return = total_return * (252 / len(equity))

    # 最大回撤
    cummax = equity.cummax()
    drawdown = (equity - cummax) / cummax
    max_drawdown = drawdown.min()

    # 風險調整指標
    sharpe_ratio = r.mean() / r.std() * np.sqrt(252) if r.std() > 0 else 0
    calmar_ratio = annual_return / abs(max_drawdown) if max_drawdown != 0 else 0
    sortino_ratio = r.mean() / r[r < 0].std() * np.sqrt(252) if len(r[r < 0]) > 0 and r[r < 0].std() > 0 else 0

    # 其他指標
    time_in_market = (w > 0.5).mean()
    turnover_py = w.diff().abs().sum() / len(w) * 252

    return {
        'total_return': total_return,
        'annual_return': annual_return,
        'max_drawdown': max_drawdown,
        'sharpe_ratio': sharpe_ratio,
        'calmar_ratio': calmar_ratio,
root@9a3d3c80743e:/workspace/SSS096# sed -n '722,780p' SSS_EnsembleTab.py
        'calmar_ratio': calmar_ratio,
        'sortino_ratio': sortino_ratio,
        'time_in_market': time_in_market,
        'turnover_py': turnover_py,
        'num_trades': len(w.diff()[w.diff() != 0])
    }

# ---------------------------------------------------------------------
# 主流程：讀價、讀子策略部位 -> 生成權重 -> 權益與交易 -> 輸出
# ---------------------------------------------------------------------

@dataclass
class RunConfig:
    ticker: str
    method: str                  # "majority" | "proportional"
    strategies: List[str] | None = None  # None => 自動從 trades_* 推斷
    params: EnsembleParams = None
    cost: CostParams = None      # 預設不加成本；要貼近實盤可調整
    file_map: Dict[str, Path] = None  # 策略名 -> 文件路徑的映射
    majority_k_pct: float = None  # 比例門檻（0.0~1.0），優先於固定 majority_k

    def __post_init__(self):
        if self.params is None:
            self.params = EnsembleParams()
        if self.cost is None:
            self.cost = CostParams()

def run_ensemble(cfg: RunConfig) -> Tuple[pd.Series, pd.Series, pd.DataFrame, Dict[str, float], str, pd.Series, pd.DataFrame, pd
.DataFrame]:
    """回傳：(open 價), (每日權重 w), (交易紀錄 trades), (績效指標 dict), (方法名稱), (權益曲線), (每日狀態 daily_state), (交易流
水帳 trade_ledger)"""
    # 讀價（Open）
    px_path = DATA_DIR / f"{cfg.ticker.replace(':','_')}_data_raw.csv"
    px = _read_market_csv_auto(px_path)

    # 調試信息：價格數據
    logger.info(f"[Ensemble] 價資料天數={len(px)}, 首末={px.index.min()}~{px.index.max()}")

    # 推斷策略列表
    if cfg.strategies is None:
        # 優先使用 trades_from_results_*.csv（120檔策略）
        strat_names = []
        file_map = {}  # 策略名 -> 文件路徑的映射

        # 先找 trades_from_results_*.csv
        trades_files = list(OUT_DIR.glob("trades_from_results_*.csv"))
        if trades_files:
            logger.info(f"[Ensemble] 找到 {len(trades_files)} 個 trades_from_results_*.csv 文件（120檔策略）")
            for f in sorted(trades_files):
                # 從文件名推斷策略名稱
                name = f.stem.replace("trades_from_results_", "")
                strat_names.append(name)
                file_map[name] = f
        else:
            # 找不到再使用舊的 trades_*.csv（11檔策略）
            trades_files = list(OUT_DIR.glob("trades_*.csv"))
            logger.info(f"[Ensemble] 找到 {len(trades_files)} 個 trades_*.csv 文件（11檔策略）")
            for f in sorted(trades_files):
                # 從文件名推斷策略名稱
                name = f.stem.replace("trades_", "")
                strat_names.append(name)
After applying global risk valve, I'll recompute metrics before removing the old ones.

I'll dynamically import perf_stats, ensure comments are in Traditional Chinese, and handle test checks.

I'll ensure metrics are recomputed after the global risk valve without removing it prematurely.

I'll run date to confirm the current date and include it in the comment.

root@9a3d3c80743e:/workspace/SSS096# date
Wed Aug 20 01:22:56 UTC 2025
I'll add a timestamp to the comment in Traditional Chinese. Root AGENTS instructions apply here.

I'll confirm the storage and refreshing of metrics after recomputing, then check tests folder.

root@9a3d3c80743e:/workspace/SSS096# ls test
__init___.py  __pycache__  pytest.ini  test_payload_smoke.py
I'll list files in the 'tools' directory to see if quick_check.ps1 is there.

root@9a3d3c80743e:/workspace/SSS096# ls tools
quick_check.ps1
I'll try running pwsh first, then file the commit with changes and relevant message.

root@9a3d3c80743e:/workspace/SSS096# sed -n '1258,1288p' app_dash.py
                            bench["最高價"] = pd.to_numeric(df_raw["high"], errors="coerce")
                            bench["最低價"] = pd.to_numeric(df_raw["low"], errors="coerce")
                        elif '最高價' in df_raw.columns and '最低價' in df_raw.columns:
                            bench["最高價"] = pd.to_numeric(df_raw["最高價"], errors="coerce")
                            bench["最低價"] = pd.to_numeric(df_raw["最低價"], errors="coerce")

                        result_cap = risk_valve_backtest(
                            open_px=open_px,
                            w=ds["w"].astype(float).reindex(open_px.index).fillna(0.0),
                            cost=cost,
                            benchmark_df=bench,
                            mode="cap",
                            cap_level=1.0,
                        )
                    except Exception as e:
                        logger.warning(f"[{strat}] 無法導入 risk_valve_backtest: {e}")
                        result_cap = None

                    if result_cap:
                        # === 安全覆寫：清掉舊鍵並補齊新鍵 ===
                        logger.info(f"[UI_CHECK] 即將覆寫：new_trades={len(result_cap.get('trade_ledger_valve', pd.DataFrame()))
} rows, new_ds={len(result_cap.get('daily_state_valve', pd.DataFrame()))} rows")

                        # 1) 覆寫結果 —— 一律用 pack_df/pack_series
                        if 'trade_ledger_valve' in result_cap:
                            result['trades'] = pack_df(result_cap['trade_ledger_valve'])
                            result['trade_ledger'] = pack_df(result_cap['trade_ledger_valve'])
                            result['trade_ledger_std'] = pack_df(result_cap['trade_ledger_valve'])

                        if 'daily_state_valve' in result_cap:
                            result['daily_state'] = pack_df(result_cap['daily_state_valve'])
                            result['daily_state_std'] = pack_df(result_cap['daily_state_valve'])
root@9a3d3c80743e:/workspace/SSS096# sed -n '1288,1328p' app_dash.py
                            result['daily_state_std'] = pack_df(result_cap['daily_state_valve'])

                        if 'weights_valve' in result_cap:
                            result['weight_curve'] = pack_series(result_cap['weights_valve'])

                        # 權益曲線：若是 Series
                        if 'daily_state_valve' in result_cap and 'equity' in result_cap['daily_state_valve']:
                            try:
                                result['equity_curve'] = pack_series(result_cap['daily_state_valve']['equity'])
                            except Exception:
                                # 若你存的是 DataFrame
                                result['equity_curve'] = pack_df(result_cap['daily_state_valve']['equity'].to_frame('equity'))

                        # 2) **關鍵**：把 UI 可能拿來用的舊快取清掉，強迫 UI 走新資料
                        for k in ['trades_ui', 'trade_df', 'trade_ledger_std', 'metrics']:
                            if k in result:
                                result.pop(k, None)

                        # 3) 給 UI 一個旗標與參數，便於顯示「已套用」
                        result['_risk_valve_applied'] = True
                        result['_risk_valve_params'] = {
                            'cap': float(risk_cap),
                            'atr_ratio': float(atr_ratio),
                            'atr20_last': float(atr_20_valid.iloc[-1]) if len(atr_20_valid) > 0 else None,
                            'atr60_last': float(atr_60_valid.iloc[-1]) if len(atr_60_valid) > 0 else None,
                        }

                        true_days = int(mask_aligned.sum())
                        logger.info(f"[{strat}] 全局風險閥門已套用（逐日），風險天數={true_days}, CAP={risk_cap:.2f}")
                    else:
                        logger.warning(f"[{strat}] 風險閥門重算沒有返回結果")

        results[strat] = result

    # 使用第一個策略的數據作為主要顯示數據
    first_strat = list(results.keys())[0] if results else strategy_names[0]
    first_smaa_src = param_presets[first_strat].get("smaa_source", "Self")
    df_raw_main, _ = load_data(ticker, start_date, end_date if end_date else None, smaa_source=first_smaa_src)

    # 統一使用 orient="split" 序列化，確保一致性
    payload = {
I'll modify the code to add calculations after clearing caches but before _risk_valve_applied.

root@9a3d3c80743e:/workspace/SSS096# rg "return {" -n SSS_EnsembleTab.py | head
rg: regex parse error:
    (?:return {)
               ^
error: repetition quantifier expects a valid decimal
I realized I misused regex. I'll escape or use rg "return \{" instead.

root@9a3d3c80743e:/workspace/SSS096# rg "return \{" -n SSS_EnsembleTab.py
694:        return {}
717:    return {
1397:    return {
I'll inspect the code around line 1390 to evaluate the risk_valve_backtest return.

root@9a3d3c80743e:/workspace/SSS096# sed -n '1390,1405p' SSS_EnsembleTab.py
        if x.empty: return 0.0
        thr = x.quantile(0.90)
        return float(x[x > max(thr, 0)].sum())
    rt1 = right_tail_sum(r1)
    rt2 = right_tail_sum(r2)
    right_tail_reduction = (rt1 - rt2)

    return {
        "signals": sig,
        "weights_orig": w,
        "weights_valve": w2,
        "daily_state_orig": daily_state1,
        "daily_state_valve": daily_state2,
        "trade_ledger_orig": ledger1,
        "trade_ledger_valve": ledger2,
        "metrics": {
root@9a3d3c80743e:/workspace/SSS096# sed -n '1405,1428p' SSS_EnsembleTab.py
        "metrics": {
            "pf_orig": float(pf1), "pf_valve": float(pf2),
            "mdd_orig": float(mdd1), "mdd_valve": float(mdd2),
            "right_tail_sum_orig": float(rt1), "right_tail_sum_valve": float(rt2),
            "right_tail_reduction": float(right_tail_reduction)
        }
    }


# === PATCH: 交易貢獻拆解（按加碼/減碼階段）===
def trade_contribution_by_phase(trade_ledger: pd.DataFrame,
                                daily_equity: pd.Series,
                                min_spacing_days: int = 0,
                                cooldown_days: int = 0) -> pd.DataFrame:
    """將交易依『權重變化正/負』分段，統計各階段的賣出實現報酬與該段內的 MDD。"""
    tl = trade_ledger.copy()
    # 欄對齊
    for a,b in [("date","交易日期"),("type","交易類型"),("w_before","交易前權重"),("w_after","交易後權重")]:
        if a in tl.columns: tl.rename(columns={a:b}, inplace=True)
    tl["交易日期"] = pd.to_datetime(tl["交易日期"], errors="coerce")
    tl = tl.dropna(subset=["交易日期"]).sort_values("交易日期").reset_index(drop=True)
    tl["dw"] = pd.to_numeric(tl["交易後權重"], errors="coerce") - pd.to_numeric(tl["交易前權重"], errors="coerce")

    # 可選：施加最小間距/冷卻（在分段前對過密買單降噪）
I’m adding the necessary import, ensuring all metrics are computed, and fixing indentation.

# 若你存的是 DataFrame
                                result['equity_curve'] = pack_df(result_cap['daily_state_valve']['equity'].to_frame('equity'))

                        # 2) **關鍵**：把 UI 可能拿來用的舊快取清掉，強迫 UI 走新資料
                        for k in ['trades_ui', 'trade_df', 'trade_ledger_std', 'metrics']:
                            if k in result:
                                result.pop(k, None)

                        # 3) 給 UI 一個旗標與參數，便於顯示「已套用」
                        result['_risk_valve_applied'] = True
                        result['_risk_valve_params'] = {
                            'cap': float(risk_cap),
                            'atr_ratio': float(atr_ratio),
                            'atr20_last': float(atr_20_valid.iloc[-1]) if len(atr_20_valid) > 0 else None,
                            'atr60_last': float(atr_60_valid.iloc[-1]) if len(atr_60_valid) > 0 else None,
                        }

                        true_days = int(mask_aligned.sum())
                        logger.info(f"[{strat}] 全局風險閥門已套用（逐日），風險天數={true_days}, CAP={risk_cap:.2f}")
                    else:
                        logger.warning(f"[{strat}] 風險閥門重算沒有返回結果")

        results[strat] = result
It seems like I'll need to use container.feed_chars with patch-style editing, but apply_patch isn’t available. I'll work with tools like sed, python, or ed for modifications instead.

I'll try using python to modify files. Patch is more straightforward, if available.

root@9a3d3c80743e:/workspace/SSS096# sed -n '1296,1326p' app_dash.py
                                result['equity_curve'] = pack_series(result_cap['daily_state_valve']['equity'])
                            except Exception:
                                # 若你存的是 DataFrame
                                result['equity_curve'] = pack_df(result_cap['daily_state_valve']['equity'].to_frame('equity'))

                        # 2) **關鍵**：把 UI 可能拿來用的舊快取清掉，強迫 UI 走新資料
                        for k in ['trades_ui', 'trade_df', 'trade_ledger_std', 'metrics']:
                            if k in result:
                                result.pop(k, None)

                        # 3) 給 UI 一個旗標與參數，便於顯示「已套用」
                        result['_risk_valve_applied'] = True
                        result['_risk_valve_params'] = {
                            'cap': float(risk_cap),
                            'atr_ratio': float(atr_ratio),
                            'atr20_last': float(atr_20_valid.iloc[-1]) if len(atr_20_valid) > 0 else None,
                            'atr60_last': float(atr_60_valid.iloc[-1]) if len(atr_60_valid) > 0 else None,
                        }

                        true_days = int(mask_aligned.sum())
                        logger.info(f"[{strat}] 全局風險閥門已套用（逐日），風險天數={true_days}, CAP={risk_cap:.2f}")
                    else:
                        logger.warning(f"[{strat}] 風險閥門重算沒有返回結果")

        results[strat] = result

    # 使用第一個策略的數據作為主要顯示數據
    first_strat = list(results.keys())[0] if results else strategy_names[0]
    first_smaa_src = param_presets[first_strat].get("smaa_source", "Self")
    df_raw_main, _ = load_data(ticker, start_date, end_date if end_date else None, smaa_source=first_smaa_src)
I'll add code after the loop to clear caches, then follow it with a patch.

root@9a3d3c80743e:/workspace/SSS096# perl -0 -i -pe 's/(for k in \[\'trades_ui\', \"trade_df\", \"trade_ledger_std\", \"metrics\
"\]:\n\s+if k in result:\n\s+result.pop\(k, None\)\n\n)/$1
bash: syntax error near unexpected token `)'
root@9a3d3c80743e:/workspace/SSS096#                         # 2025-08-20 修復：重算績效指標避免清空後僅剩平均持倉天數\n
                try:\n                            from SSS_EnsembleTab import perf_stats\n                            eq_series
= result_cap.get(\'daily_state_valve\', pd.DataFrame())\n                            w_series = result_cap.get(\'weights_valve\'
, pd.Series(dtype=float))\n                            if isinstance(eq_series, pd.DataFrame) and \'equity\' in eq_series.column
s:\n                                result[\'metrics\'] = perf_stats(eq_series[\'equity\'], w_series)\n
       logger.info(f"[{strat}] 重新計算績效指標完成")\n                        except Exception as e:\n
   logger.warning(f"[{strat}] 重算績效指標失敗: {e}")\n\n/' app_dash.py
Looks like I need to reopen the file to make sure nothing got corrupted.

root@9a3d3c80743e:/workspace/SSS096# sed -n '1296,1326p' app_dash.py
                                result['equity_curve'] = pack_series(result_cap['daily_state_valve']['equity'])
                            except Exception:
                                # 若你存的是 DataFrame
                                result['equity_curve'] = pack_df(result_cap['daily_state_valve']['equity'].to_frame('equity'))

                        # 2) **關鍵**：把 UI 可能拿來用的舊快取清掉，強迫 UI 走新資料
                        for k in ['trades_ui', 'trade_df', 'trade_ledger_std', 'metrics']:
                            if k in result:
                                result.pop(k, None)

                        # 3) 給 UI 一個旗標與參數，便於顯示「已套用」
                        result['_risk_valve_applied'] = True
                        result['_risk_valve_params'] = {
                            'cap': float(risk_cap),
                            'atr_ratio': float(atr_ratio),
                            'atr20_last': float(atr_20_valid.iloc[-1]) if len(atr_20_valid) > 0 else None,
                            'atr60_last': float(atr_60_valid.iloc[-1]) if len(atr_60_valid) > 0 else None,
                        }

                        true_days = int(mask_aligned.sum())
                        logger.info(f"[{strat}] 全局風險閥門已套用（逐日），風險天數={true_days}, CAP={risk_cap:.2f}")
                    else:
                        logger.warning(f"[{strat}] 風險閥門重算沒有返回結果")

        results[strat] = result

    # 使用第一個策略的數據作為主要顯示數據
    first_strat = list(results.keys())[0] if results else strategy_names[0]
    first_smaa_src = param_presets[first_strat].get("smaa_source", "Self")
    df_raw_main, _ = load_data(ticker, start_date, end_date if end_date else None, smaa_source=first_smaa_src)
The patch command failed, so I'll implement the fix using Python, but simplifying it with ed or sed instead.

root@9a3d3c80743e:/workspace/SSS096# python - <<'PY'
> from pathlib import Path
> import pandas as pd
> file = Path('app_dash.py')
> text = file.read_text(encoding='utf-8').splitlines()
> for i,line in enumerate(text):
>     if line.strip() == "for k in ['trades_ui', 'trade_df', 'trade_ledger_std', 'metrics']:":
>         insert_index = i + 2  # after the 'result.pop' line (next line is the 'for' block's second line, not including blank?)
>         # but we will search for next blank line after the for-loop block
>         j = i + 1
>         while j < len(text) and text[j].startswith(' ' * 28):
>             j += 1
>         insert_index = j
>         snippet = [
>             "                        # 2025-08-20 修復：重算績效指標避免清空後僅剩平均持倉天數",
>             "                        try:",
>             "                            from SSS_EnsembleTab import perf_stats",
>             "                            eq_series = result_cap.get('daily_state_valve', pd.DataFrame())",
>             "                            w_series = result_cap.get('weights_valve', pd.Series(dtype=float))",
>             "                            if isinstance(eq_series, pd.DataFrame) and 'equity' in eq_series.columns:",
>             "                                result['metrics'] = perf_stats(eq_series['equity'], w_series)",
>             "                                logger.info(f'[{strat}] 重新計算績效指標完成')",
>             "                        except Exception as e:",
>             "                            logger.warning(f'[{strat}] 重算績效指標失敗: {e}')",
>             ""
>         ]
>         text[insert_index:insert_index] = snippet
>         break
> file.write_text('\n'.join(text), encoding='utf-8')
> PY
Traceback (most recent call last):
  File "<stdin>", line 2, in <module>
ModuleNotFoundError: No module named 'pandas'
The script failed due to the missing pandas import. I’ll remove it and retry.

root@9a3d3c80743e:/workspace/SSS096# python - <<'PY'
> from pathlib import Path
> file = Path('app_dash.py')
> text = file.read_text(encoding='utf-8').splitlines()
> for i,line in enumerate(text):
>     if line.strip() == "for k in ['trades_ui', 'trade_df', 'trade_ledger_std', 'metrics']:":
>         j = i + 1
>         while j < len(text) and text[j].startswith(' ' * 28):
>             j += 1
>         insert_index = j
>         snippet = [
>             "                        # 2025-08-20 修復：重算績效指標避免清空後僅剩平均持倉天數",
>             "                        try:",
>             "                            from SSS_EnsembleTab import perf_stats",
>             "                            eq_series = result_cap.get('daily_state_valve', pd.DataFrame())",
>             "                            w_series = result_cap.get('weights_valve', pd.Series(dtype=float))",
>             "                            if isinstance(eq_series, pd.DataFrame) and 'equity' in eq_series.columns:",
>             "                                result['metrics'] = perf_stats(eq_series['equity'], w_series)",
>             "                                logger.info(f'[{strat}] 重新計算績效指標完成')",
>             "                        except Exception as e:",
>             "                            logger.warning(f'[{strat}] 重算績效指標失敗: {e}')",
>             ""
>         ]
>         text[insert_index:insert_index] = snippet
>         break
> file.write_text('\n'.join(text), encoding='utf-8')
> PY
The script ran without errors. I'll check the file content now.

root@9a3d3c80743e:/workspace/SSS096# sed -n '1296,1340p' app_dash.py
                                result['equity_curve'] = pack_series(result_cap['daily_state_valve']['equity'])
                            except Exception:
                                # 若你存的是 DataFrame
                                result['equity_curve'] = pack_df(result_cap['daily_state_valve']['equity'].to_frame('equity'))

                        # 2) **關鍵**：把 UI 可能拿來用的舊快取清掉，強迫 UI 走新資料
                        for k in ['trades_ui', 'trade_df', 'trade_ledger_std', 'metrics']:
                            if k in result:
                                result.pop(k, None)
                        # 2025-08-20 修復：重算績效指標避免清空後僅剩平均持倉天數
                        try:
                            from SSS_EnsembleTab import perf_stats
                            eq_series = result_cap.get('daily_state_valve', pd.DataFrame())
                            w_series = result_cap.get('weights_valve', pd.Series(dtype=float))
                            if isinstance(eq_series, pd.DataFrame) and 'equity' in eq_series.columns:
                                result['metrics'] = perf_stats(eq_series['equity'], w_series)
                                logger.info(f'[{strat}] 重新計算績效指標完成')
                        except Exception as e:
                            logger.warning(f'[{strat}] 重算績效指標失敗: {e}')


                        # 3) 給 UI 一個旗標與參數，便於顯示「已套用」
                        result['_risk_valve_applied'] = True
                        result['_risk_valve_params'] = {
                            'cap': float(risk_cap),
                            'atr_ratio': float(atr_ratio),
                            'atr20_last': float(atr_20_valid.iloc[-1]) if len(atr_20_valid) > 0 else None,
                            'atr60_last': float(atr_60_valid.iloc[-1]) if len(atr_60_valid) > 0 else None,
                        }

                        true_days = int(mask_aligned.sum())
                        logger.info(f"[{strat}] 全局風險閥門已套用（逐日），風險天數={true_days}, CAP={risk_cap:.2f}")
                    else:
                        logger.warning(f"[{strat}] 風險閥門重算沒有返回結果")

        results[strat] = result

    # 使用第一個策略的數據作為主要顯示數據
    first_strat = list(results.keys())[0] if results else strategy_names[0]
    first_smaa_src = param_presets[first_strat].get("smaa_source", "Self")
    df_raw_main, _ = load_data(ticker, start_date, end_date if end_date else None, smaa_source=first_smaa_src)

    # 統一使用 orient="split" 序列化，確保一致性
    payload = {
        'results': results,
I confirmed pd is imported globally, and the snippet is correct. Let's check for syntax.

root@9a3d3c80743e:/workspace/SSS096# python -m py_compile app_dash.py
I'll check the git status before committing to make sure everything is ready.

root@9a3d3c80743e:/workspace/SSS096# git status --short
 M app_dash.py
?? __pycache__/
I’ll remove the __pycache__ directory to keep things tidy.

root@9a3d3c80743e:/workspace/SSS096# rm -r __pycache__
Let me quickly check the git status once more to see if anything's changed.

root@9a3d3c80743e:/workspace/SSS096# git status --short
 M app_dash.py
I'll run tests and try tools/quick_check.ps1, using pwsh or powershell if needed.

root@9a3d3c80743e:/workspace/SSS096# pwsh -ExecutionPolicy Bypass -File tools/quick_check.ps1
bash: command not found: pwsh
root@9a3d3c80743e:/workspace/SSS096# powershell -ExecutionPolicy Bypass -File tools/quick_check.ps1
bash: command not found: powershell
PowerShell isn't installed, so I'll note this in my final message and run pytest.

root@9a3d3c80743e:/workspace/SSS096# pytest -q
============================================================ ERRORS ============================================================
________________________________ ERROR collecting analysis/past/comprehensive_distance_test.py _________________________________
ImportError while importing test module '/workspace/SSS096/analysis/past/comprehensive_distance_test.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.12.10/lib/python3.12/importlib/__init__.py:90: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
analysis/past/comprehensive_distance_test.py:14: in <module>
    import pandas as pd
E   ModuleNotFoundError: No module named 'pandas'
____________________________________ ERROR collecting analysis/past/quick_distance_test.py _____________________________________
ImportError while importing test module '/workspace/SSS096/analysis/past/quick_distance_test.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.12.10/lib/python3.12/importlib/__init__.py:90: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
analysis/past/quick_distance_test.py:14: in <module>
    import pandas as pd
E   ModuleNotFoundError: No module named 'pandas'
_________________________________________ ERROR collecting test/test_payload_smoke.py __________________________________________
ImportError while importing test module '/workspace/SSS096/test/test_payload_smoke.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/root/.pyenv/versions/3.12.10/lib/python3.12/importlib/__init__.py:90: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
test/test_payload_smoke.py:3: in <module>
    import pandas as pd
E   ModuleNotFoundError: No module named 'pandas'
=================================================== short test summary info ====================================================
ERROR analysis/past/comprehensive_distance_test.py
ERROR analysis/past/quick_distance_test.py
ERROR test/test_payload_smoke.py
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 3 errors during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
3 errors in 0.23s
I'm installing pandas to resolve test failures, assuming numpy is already present in the container.

root@9a3d3c80743e:/workspace/SSS096# pip install pandas numpy
WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('
Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden'))': /simple/pandas/
WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('
Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden'))': /simple/pandas/
WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('
Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden'))': /simple/pandas/
WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('
Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden'))': /simple/pandas/

WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('
Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden'))': /simple/pandas/
ERROR: Could not find a version that satisfies the requirement pandas (from versions: none)
ERROR: No matching distribution found for pandas
Installation failed due to proxy issues. Can't run tests due to missing dependencies (pandas).

root@9a3d3c80743e:/workspace/SSS096# git status --short
 M app_dash.py
?? analysis/past/__pycache__/comprehensive_distance_test.cpython-312-pytest-8.4.1.pyc
?? analysis/past/__pycache__/quick_distance_test.cpython-312-pytest-8.4.1.pyc
?? test/__pycache__/test_payload_smoke.cpython-312-pytest-8.4.1.pyc
I'll remove the generated pycache files from running pytest.

root@9a3d3c80743e:/workspace/SSS096# rm -r analysis/past/__pycache__ test/__pycache__
Let's check the git status once more to confirm everything's up to date.

root@9a3d3c80743e:/workspace/SSS096# git status --short
 D analysis/past/__pycache__/comprehensive_distance_test.cpython-312-pytest-7.4.4.pyc
 D analysis/past/__pycache__/quick_distance_test.cpython-312-pytest-7.4.4.pyc
 M app_dash.py
 D test/__pycache__/test_payload_smoke.cpython-312-pytest-7.4.4.pyc
 D test/__pycache__/test_payload_smoke.cpython-312.pyc
I'm wondering if these .pyc files are tracked. Let me investigate the repository's baseline.

I need to check if the pycache directory is tracked in the repo. Let's list files.

root@9a3d3c80743e:/workspace/SSS096# ls analysis/past
adaptive_clustering_analysis_v7.py      compare_clustering_methods.py               op_hsa_analysis_v2.py
adaptive_fine_clustering_v16.py         comprehensive_distance_test.py              param_cluster_distribution_analysis.py
analyze_clustering_results.py           fast_adaptive_clustering_v8.py              practical_cluster_analysis_v12.py
bailey_pbo_implementation.py            fine_grained_clustering_v13.py              quick_distance_test.py
balanced_clustering_analysis_v10.py     hierarchical_cluster_stability_analysis.py  risk_enhanced_clustering_analysis_v2.py
balanced_pbo_approach.py                hierarchical_score_analysis_v1.py           simple_fine_clustering_v17.py
check_results_v15.py                    improved_layered_clustering_v6.py           single_analysis.py
cluster_trials_app.py                   improved_supervised_clustering_v5.py        small_cluster_analysis_v11.py
clustering_comparison_analysis_v9.py    multi_stage_clustering_v14.py               supervised_clustering_analysis_v3.py
clustering_interpretation_report_v4.py  op_hsa_analysis.py
I'll check if __pycache__ is listed in .gitignore or previously tracked with git ls-files.

root@9a3d3c80743e:/workspace/SSS096# git ls-files analysis/past | grep __pycache__
analysis/past/__pycache__/comprehensive_distance_test.cpython-312-pytest-7.4.4.pyc
analysis/past/__pycache__/quick_distance_test.cpython-312-pytest-7.4.4.pyc
Hmm, looks like the pycache files were tracked but not listed. I'll restore them from Git.

root@9a3d3c80743e:/workspace/SSS096# git checkout -- analysis/past/__pycache__ test/__pycache__
root@9a3d3c80743e:/workspace/SSS096# git status --short
 M app_dash.py
Ready to commit! Adding the message: "修復套用風險閥門後績效指標消失". Let's go.

root@9a3d3c80743e:/workspace/SSS096# git commit -am "修復風險閥門清空績效指標" && git status --short
[work e95a6f3] 修復風險閥門清空績效指標
 1 file changed, 11 insertions(+)
It seems the commit ran successfully, but no git status output appears—perhaps because there were no changes. I'll run git status again for clarity.

root@9a3d3c80743e:/workspace/SSS096# git status --short
I'll mark relevant lines from app_dash.py and reference the commit where metrics are recomputed.

root@9a3d3c80743e:/workspace/SSS096# nl -ba app_dash.py | sed -n '1296,1350p'
  1296                                  result['equity_curve'] = pack_series(result_cap['daily_state_valve']['equity'])
  1297                              except Exception:
  1298                                  # 若你存的是 DataFrame
  1299                                  result['equity_curve'] = pack_df(result_cap['daily_state_valve']['equity'].to_frame('equ
ity'))
  1300
  1301                          # 2) **關鍵**：把 UI 可能拿來用的舊快取清掉，強迫 UI 走新資料
  1302                          for k in ['trades_ui', 'trade_df', 'trade_ledger_std', 'metrics']:
  1303                              if k in result:
  1304                                  result.pop(k, None)
  1305                          # 2025-08-20 修復：重算績效指標避免清空後僅剩平均持倉天數
  1306                          try:
  1307                              from SSS_EnsembleTab import perf_stats
  1308                              eq_series = result_cap.get('daily_state_valve', pd.DataFrame())
  1309                              w_series = result_cap.get('weights_valve', pd.Series(dtype=float))
  1310                              if isinstance(eq_series, pd.DataFrame) and 'equity' in eq_series.columns:
  1311                                  result['metrics'] = perf_stats(eq_series['equity'], w_series)
  1312                                  logger.info(f'[{strat}] 重新計算績效指標完成')
  1313                          except Exception as e:
  1314                              logger.warning(f'[{strat}] 重算績效指標失敗: {e}')
  1315
  1316
  1317                          # 3) 給 UI 一個旗標與參數，便於顯示「已套用」
  1318                          result['_risk_valve_applied'] = True
  1319                          result['_risk_valve_params'] = {
  1320                              'cap': float(risk_cap),
  1321                              'atr_ratio': float(atr_ratio),
  1322                              'atr20_last': float(atr_20_valid.iloc[-1]) if len(atr_20_valid) > 0 else None,
  1323                              'atr60_last': float(atr_60_valid.iloc[-1]) if len(atr_60_valid) > 0 else None,
  1324                          }
  1325
  1326                          true_days = int(mask_aligned.sum())
  1327                          logger.info(f"[{strat}] 全局風險閥門已套用（逐日），風險天數={true_days}, CAP={risk_cap:.2f}")
  1328                      else:
  1329                          logger.warning(f"[{strat}] 風險閥門重算沒有返回結果")
  1330
  1331          results[strat] = result
  1332
  1333      # 使用第一個策略的數據作為主要顯示數據
  1334      first_strat = list(results.keys())[0] if results else strategy_names[0]
  1335      first_smaa_src = param_presets[first_strat].get("smaa_source", "Self")
  1336      df_raw_main, _ = load_data(ticker, start_date, end_date if end_date else None, smaa_source=first_smaa_src)
  1337
  1338      # 統一使用 orient="split" 序列化，確保一致性
  1339      payload = {
  1340          'results': results,
  1341          'df_raw': df_raw_main.to_json(date_format='iso', orient='split'),
  1342          'ticker': ticker
  1343      }
  1344
  1345      # 防守性檢查：如還有漏網的非序列化物件就能提早看出
  1346      try:
  1347          json.dumps(payload)
  1348      except Exception as e:
  1349          logger.exception("[BUG] backtest-store payload 仍含不可序列化物件：%s", e)
  1350          # 如果要強制不噴，可做 fallback：json.dumps(..., default=str) 但通常不建議吞掉
I'll summarize the fix, reference relevant lines, and mention the failed tests due to missing dependencies.

The testing summary needs commands with emojis. I'll list them in the right order.

I’ll include the fix and reference the relevant lines for the performance metrics.

4.
Configuring language runtimes...
# Python: 3.12
# Node.js: v20 (default: v22)
default -> 20 (-> v20.19.4)
Now using node v20.19.4 (npm v10.9.3)
# Ruby: 3.4.4 (default: 3.2.3)
mise ruby@3.4.4                                                            ⠁  0s
mise ~/.config/mise/config.toml tools: ruby@3.4.4
# Rust: 1.88.0 (default: 1.89.0)
info: using existing install for '1.88.0-x86_64-unknown-linux-gnu'
info: default toolchain set to '1.88.0-x86_64-unknown-linux-gnu'

  1.88.0-x86_64-unknown-linux-gnu unchanged - rustc 1.88.0 (6b00bc388 2025-06-23)

# Go: go1.24.3 (default: go1.24.3)
# Swift: 6.1 (default: 6.1)
# PHP: 8.4 (default: 8.4)
Running auto setup...
Scanning repository (up to depth 3) for dependency configurations...
No known dependency configuration files found up to depth 3.
後面版本不是新增了風險閥門套用在各策略嗎
但不知道為什麼套用後 各指標會只剩下平均持倉天數,其他指標都消失了 請修復


^C
root@a3bd66c837b3:/workspace# cd SSS096
root@a3bd66c837b3:/workspace/SSS096# ls
AGENTS.md                           data                      run_workflow_example.py
DEFENSIVE_CHECKS_UPDATE_SUMMARY.md  debug_enhanced_data.py    runners
ENSEMBLE_WORKFLOW.md                ensemble_wrapper.py       setup.sh
LOGGING_SYSTEM_UPDATE_SUMMARY.md    extract_params.py         sss_backtest_outputs
PORTFOLIO_LEDGER_README.md          leverage.py               sss_core
SSS_EnsembleTab.py                  list.txt                  test
SSSv096.py                          list_folder_structure.py  tools
analysis                            presets                   utils_payload.py
app_dash.py                         ruff.toml                 version_history.py
assets                              run_enhanced_debug.py     workflow_summary_20250812_023903.txt
config.yaml                         run_enhanced_ensemble.py  workflow_summary_20250818_040656.txt
convert_results_to_trades.py        run_workflow.py
I'll look for AGENTS.md at the repository root to check instructions.

root@a3bd66c837b3:/workspace/SSS096# cat AGENTS.md
# SSS096 專案 AI 代理工作指南

## 📋 專案概述

SSS096 是一個股票策略回測與分析系統，主要包含：
- 策略回測引擎（SSSv096.py）
- Web UI 界面（app_dash.py）
- 增強分析模組（analysis/）
- Ensemble 策略執行（runners/）
- 數據處理與轉換工具

## 🎯 工作重點區域

### 核心檔案
- `SSSv096.py` - 主要策略回測引擎
- `app_dash.py` - Web UI 主應用
- `ensemble_wrapper.py` - Ensemble 策略包裝器
- `analysis/` - 分析模組目錄

### 避免修改的檔案
- `tools/quick_check.ps1` - 自動化檢查腳本（除非必要）
- 已標記為 "past/" 的舊版本檔案
- 編譯後的 `.pyc` 檔案

## 🔧 開發環境設定

### Codex 環境設置（推薦）
```bash
# 執行自動設置腳本
chmod +x setup.sh
./setup.sh

# 測試設置是否成功
python test_setup.py
```

### Python 環境（手動設置）
```bash
# 安裝依賴套件
pip install pandas numpy matplotlib seaborn openpyxl dash dash-bootstrap-components

# 檢查 Python 版本（建議 3.8+）
python --version
```

### 代理設置（如果遇到 403 錯誤）
```bash
# 檢查代理證書
echo $CODEX_PROXY_CERT

# 配置 pip 使用代理
pip config set global.cert "$CODEX_PROXY_CERT"
pip config set global.trusted-host "proxy:8080"
```

### 專案結構導航
```bash
# 快速查看目錄結構
python list_folder_structure.py

# 查看特定目錄內容
ls analysis/
ls runners/
```

## 🧪 測試與驗證

### 快速檢查
```bash
# 執行自動化檢查（重要！）
powershell -ExecutionPolicy Bypass -File tools\quick_check.ps1
```

### 回測測試
```bash
# 執行單一策略回測
python SSSv096.py --strategy RMA_Factor --param_preset op.json

# 執行 Ensemble 策略
python run_enhanced_ensemble.py --method majority --top_k 5
```

### UI 測試
```bash
# 啟動 Web UI
python app_dash.py
```

## 📝 程式碼規範

### 註解與輸出
- **一律使用繁體中文**進行註解和輸出
- 修改紀錄需加入日期時間戳記
- 路徑說明格式：`#子資料夾/案名`

### 日誌記錄
- 使用 `analysis/logging_config.py` 中的日誌器
- 重要操作需記錄到日誌檔案
- 錯誤處理需包含詳細的錯誤信息

### 資料格式
- 日期欄位統一使用 ISO 格式：`YYYY-MM-DD`
- 數值欄位使用 float 類型
- 避免使用中文欄位名稱（除非必要）

## 🔍 除錯指南

### 常見問題
1. **模組導入失敗**：檢查 `sys.path` 和相對導入
2. **數據格式錯誤**：驗證 CSV 檔案結構和欄位名稱
3. **記憶體不足**：檢查大數據集的處理方式

### 除錯工具
```python
# 啟用詳細日誌
import logging
logging.basicConfig(level=logging.DEBUG)

# 檢查數據結構
print(df.info())
print(df.head())
```

## 📊 數據處理規範

### 輸入數據
- 支援 CSV、Excel、JSON 格式
- 必要欄位：交易日期、權重變化、盈虧%
- 可選欄位：交易類型、價格、成交量

### 輸出數據
- 統一 Schema：equity、trades、daily_state、trade_ledger
- 避免 KeyError 和欄位缺失
- 支援多種輸出格式

## 🚀 部署與維護

### 檔案管理
- 定期清理舊的日誌和快取檔案
- 備份重要的配置和結果檔案
- 使用版本控制追蹤變更

### 性能優化
- 大數據集使用快取機制
- 避免重複計算
- 使用適當的數據結構

## ⚠️ 注意事項

### 安全考量
- 不要硬編碼 API 金鑰
- 驗證所有用戶輸入
- 保護敏感數據

### 相容性
- 維持與現有工作流程的相容性
- 測試所有整合點
- 避免破壞現有功能

## 🚀 Codex 環境設置

### 自動設置
```bash
# 執行設置腳本
./setup.sh

# 腳本會自動：
# 1. 配置代理設置
# 2. 安裝所有必要依賴
# 3. 創建回退日誌系統
# 4. 設置環境變數
```

### 手動設置（如果自動設置失敗）
```bash
# 1. 配置代理
export PIP_CERT="$CODEX_PROXY_CERT"
export NODE_EXTRA_CA_CERTS="$CODEX_PROXY_CERT"

# 2. 安裝核心依賴
pip install --no-cache-dir pandas numpy matplotlib seaborn openpyxl dash dash-bootstrap-components yfinance pyyaml joblib

# 3. 安裝分析套件
pip install --no-cache-dir scikit-learn scipy statsmodels plotly kaleido

# 4. 創建必要目錄
mkdir -p analysis/log analysis/cache cache log results sss_backtest_outputs
```

### 常見問題解決
- **pip install 403 錯誤**：檢查 `$CODEX_PROXY_CERT` 環境變數
- **joblib 導入失敗**：使用 `logging_config_fallback.py` 回退版本
- **模組路徑問題**：設置 `PYTHONPATH` 環境變數

## 📞 技術支援

### 問題回報
- 提供完整的錯誤訊息和堆疊追蹤
- 包含重現步驟和環境信息
- 檢查相關的日誌檔案

### 文檔更新
- 修改功能時同步更新相關文檔
- 使用清晰的範例和說明
- 保持文檔的時效性

---

**版本：** v1.0
**最後更新：** 2025-08-18
**適用於：** SSS096 專案 AI 代理工作指南
I'll search for AGENTS.md in the directories I might modify to ensure compliance.

root@a3bd66c837b3:/workspace/SSS096# find . -name AGENTS.md -print
./AGENTS.md
I'll start by using ripgrep to search for "risk valve" or "風險閥門" in the code.

root@a3bd66c837b3:/workspace/SSS096# rg -i "風險" -n
SSS_EnsembleTab.py
708:    # 風險調整指標
1280:    # 風險觸發：兩斜率皆 < 門檻，且 ATR 抬頭超過倍率
1287:# === PATCH: 風險閥門施作在權重 ===
1292:    """對每日目標權重 w 施作風險閥門：
1293:       - cap: 風險日將 w 限在 cap_level 以下
1294:       - ban_add: 風險日禁止「提高」倉位（允許減倉），用迭代法確保單調"""

DEFENSIVE_CHECKS_UPDATE_SUMMARY.md
36:- 在繪製風險閥門時序圖前檢查必要欄位

SSSv096.py
2689:        # 計算下行風險

analysis/OSv3_6270833.py
396:    計算風險調整後的報酬率指標
414:    # 索提諾比率（只考慮下行風險）
426:    # 綜合評分（結合報酬率和風險）
872:                # 計算風險調整指標
927:                    **risk_adjusted_metrics  # 添加風險調整指標

analysis/OSv3.py
52:        'sharpe_ratio': '夏普值：超額報酬率與波動率的比值，衡量風險調整後報酬',
59:        'overfitting_score': '過擬合分數：0-100，分數越高表示過擬合風險越大',
63:        'overfitting_risk': '過擬合風險：綜合過擬合風險評分，0-100',
88:        # 風險分布
89:        'low_risk': '低風險比例：過擬合風險≤30的策略比例',
90:        'medium_risk': '中風險比例：過擬合風險31-60的策略比例',
91:        'high_risk': '高風險比例：過擬合風險>60的策略比例',
92:        'risk_return_correlation': '風險報酬相關性：過擬合風險與總報酬率的相關係數'
564:            # 計算風險等級
673:    計算風險調整後的報酬率指標
691:    # 索提諾比率（只考慮下行風險）
703:    # 綜合評分（結合報酬率和風險）
1622:                # 計算風險調整指標
1677:                    **risk_adjusted_metrics  # 添加風險調整指標
1711:                    - 低相關性（接近0）: 適合組合投資，分散風險
1712:                    - 高相關性（接近±1）: 組合效果有限，風險集中
1972:                    - 風險調整報酬: 夏普比*總報酬率
1973:                    - 綜合評分: sqrt(總報酬率)*10*0.3+夏普值*0.25+最大回撤*0.2+勝率*0.15+風險調整報酬*0.1-過擬合分數*0.5
1984:                        # 計算風險調整後報酬率
1996:                            "風險調整報酬": risk_adjusted_return
2039:                                overfitting_scores[name] = 50  # 預設中等風險
2041:                            overfitting_scores[name] = 50  # 預設中等風險
2049:                        np.sqrt(summary_df['風險調整報酬']) * 0.05
2051:                    print(f"總報酬率分數: {np.sqrt(summary_df['總報酬率']) * 10 * 0.3},夏普值分數: {summary_df['夏普值'] *
0.25},最大回撤分數: {(1 + summary_df['最大回撤']) * 0.2},勝率分數: {summary_df['勝率'] * 0.1},風險調整報酬分數: {np.sqrt(summary
_df['風險調整報酬']) * 0.05}")
2071:                        '風險調整報酬': '{:.3f}',
2091:                        # 報酬率 vs 風險散點圖
2099:                            title="報酬率 vs 風險散點圖",
2180:                        **過擬合分數**: 0-100，分數越高表示過擬合風險越大
2181:                        - 0-30: 低風險，策略較穩定
2182:                        - 31-60: 中風險，需要關注
2183:                        - 61-100: 高風險，可能存在過擬合問題
2389:                    **最大回撤**: 權益曲線從峰值到谷值的最大跌幅，衡量下行風險
2391:                    **夏普值**: 超額報酬率與波動率的比值，衡量風險調整後報酬
2393:                    **卡瑪值**: 年化報酬率與最大回撤的比值，衡量風險調整後報酬
2449:                        # 計算風險調整後報酬率
2450:                        optuna_results['風險調整報酬'] = optuna_results['sharpe_ratio'] * optuna_results['total_return']
2458:                            np.sqrt(optuna_results['風險調整報酬']) * 0.05

analysis/enhanced_trade_analysis.py
4:整合風險閥門回測、交易貢獻拆解、加碼梯度優化
97:        風險閥門回測
100:            risk_rules: 風險規則字典，預設包含TWII斜率和ATR規則
109:        print("=== 風險閥門回測分析 ===")
112:        # 模擬風險閥門觸發
115:        # 計算風險閥門效果
121:        """模擬風險閥門觸發"""
123:            print("警告：缺少基準數據，無法進行風險閥門回測")
179:        # 風險閥門觸發條件
184:        # 綜合風險閥門
194:        """計算風險閥門對績效的影響"""
200:            print("警告：benchmark_enhanced 缺少 '日期' 欄位，無法計算風險閥門影響")
204:            print("警告：benchmark_enhanced 缺少 'risk_valve_triggered' 欄位，無法計算風險閥門影響")
207:        # 找出風險閥門觸發的期間
212:        # 分析風險期間的交易表現
243:        print(f"風險閥門觸發期間數：{len(risk_periods)}")
244:        print(f"風險期間交易數：{len(risk_sells)}")
246:        print("\n風險期間表現：")
486:        # 風險指標（改用權益曲線計 MDD；把百分比轉成小數）
555:        # 1. 風險閥門觸發時序
559:                print("警告：benchmark_enhanced 缺少必要欄位，跳過風險閥門時序圖")
561:                print("警告：benchmark_enhanced 缺少 'risk_valve_triggered' 欄位，跳過風險閥門時序圖")
575:                               color='red', s=50, alpha=0.8, label='風險閥門觸發')
578:                ax1.set_title('風險閥門觸發時序')
637:    print("2. 執行風險閥門回測：analyzer.risk_valve_backtest()")

analysis/past/risk_enhanced_clustering_analysis_v2.py
1:# v2: 增強型風險分群分析，加入多種風險指標與權益曲線特徵
2:# 主要功能：自動展開參數、計算多種風險指標、分群與可視化
52:    """計算風險指標"""
67:    # 夏普比率 (假設無風險利率為0)
75:    # 下行風險 (Downside Risk)
90:    # 尾部風險指標
158:            # 載入權益曲線並計算風險指標
190:            # 將風險指標添加到DataFrame
209:    """執行風險增強的分群分析"""
284:    """創建風險分群可視化"""
302:    # 2. 風險指標箱線圖
362:    # 5. 風險-收益散點圖
390:    """創建風險分群比較分析"""
446:    """生成風險分群分析報告"""
448:    report.append("=== 風險增強分群分析報告 ===\n")
488:    print("風險增強分群分析報告已生成完成！")
493:    print("開始風險增強分群分析...")
501:    # 對每個策略-數據源組合進行風險增強分群
505:        # 執行風險增強分群
521:            # 保存帶有風險分群標籤的數據

analysis/past/bailey_pbo_implementation.py
242:        return "優秀：過擬合風險很低，策略穩健性很高"
244:        return "良好：過擬合風險較低，策略較為穩健"
246:        return "一般：有一定過擬合風險，需要謹慎"
248:        return "較差：過擬合風險較高，建議重新設計策略"
250:        return "很差：過擬合風險很高，策略可能無效"

analysis/past/comprehensive_distance_test.py
223:        # 3. 過擬合風險分數比較
226:        ax3.set_title('過擬合風險分數')
227:        ax3.set_ylabel('風險分數')

...
306:        return "一般：有一定過擬合風險，需要謹慎"
308:        return "較差：過擬合風險較高，建議重新設計策略"
310:        return "很差：過擬合風險很高，策略可能無效"

analysis/past/improved_layered_clustering_v6.py
30:    """載入風險分群後的數據"""
126:    # 方法1: 只用參數+風險分群（去除績效）
127:    print("方法1: 只用參數+風險分群")
141:    # 只用參數+風險特徵
163:    print(f"  參數+風險最佳分群數: {best_k_param_risk} (Silhouette Score: {best_score_param_risk:.3f})")
176:            # 在績效群組內進行參數+風險分群
210:    # 方法3: 階層式分群（只用參數+風險）
352:        recommendations.append("✓ 發現重複績效群組，建議使用參數+風險分群")
371:        print("1. 對於重複績效群組，使用參數+風險分群方法")
376:        print("2. 參數+風險分群作為輔助驗證")
388:        print("未找到風險分群數據")

analysis/past/quick_distance_test.py
110:                # 檢測過擬合風險
136:                logger.info(f"  過擬合風險分數: {results[config['name']]['overfitting_risk_score']:.3f}")
174:        # 過擬合風險分數（越低越好）
205:            logger.info(f"✓ 改進方法相比標準歐氏距離降低了 {improvement:.1f}% 的過擬合風險")

analysis/UI_INTEGRATION_GUIDE.md
11:1. 風險閥門回測
260:- **自定義基準數據**：上傳基準數據進行風險閥門分析

app_dash.py
445:                        html.Label("風險閥門 CAP", style={"fontSize":"12px","color":"#888"}),
455:                        dbc.Checkbox(id='force-valve-trigger', value=False, label="強制觸發風險閥門（測試用）", style={"font
Size":"11px","color":"#dc3545"}),
456:                        html.Small("💡 勾選後將強制觸發風險閥門，用於測試功能", style={"color":"#dc3545","fontSize":"10px"})
460:                    # === 風險閥門狀態顯示區域 ===
464:                        html.Small("🔒 風險閥門說明:", style={"color":"#28a745","fontWeight":"bold","fontSize":"11px"}),
465:                        html.Small("• CAP: 控制最大風險暴露 (0.1=10%, 0.3=30%)", style={"color":"#666","fontSize":"10px"}),
466:                        html.Small("• ATR比值: 當短期波動>長期波動時，自動降低風險", style={"color":"#666","fontSize":"10px"
}),
573:# --------- 風險閥門狀態更新 ---------
587:    """動態更新風險閥門狀態顯示"""
588:    logger.info(f"=== 風險閥門狀態更新 ===")
598:        logger.info("風險閥門未啟用")
600:            html.Small("🔴 風險閥門未啟用", style={"color":"#dc3545","fontWeight":"bold"}),
602:            html.Small("點擊上方複選框啟用全局風險控制", style={"color":"#666","fontSize":"10px"})
655:                            # 判斷是否需要觸發風險閥門
658:                            # 如果啟用強制觸發，則強制觸發風險閥門
661:                                logger.info(f"強制觸發風險閥門啟用")
663:                            # 記錄風險閥門狀態到日誌
665:                            logger.info(f"風險閥門門檻: {atr_ratio}, 當前比值: {atr_ratio_current:.4f}")
666:                            logger.info(f"風險閥門觸發: {'是' if valve_triggered else '否'}")
667:                            logger.info(f"風險閥門狀態: {'🔴 觸發' if valve_triggered else '🟢 正常'}")
680:                                    html.Small(f"{status_icon} 風險閥門狀態: {status_text}",
688:                                    html.Small(f"風險CAP: {risk_cap*100:.0f}%", style={"color":"#666","fontSize":"11px"}),
742:        logger.error(f"風險閥門狀態更新失敗: {e}")
797:    # === 新增：全局風險閥門觸發狀態追蹤 ===
810:        # 應用全局風險閥門設定（如果啟用）
811:        logger.info(f"[{strat}] 風險閥門開關狀態: global_apply={global_apply}, 類型={type(global_apply)}")
813:            logger.info(f"[{strat}] 應用全局風險閥門: CAP={risk_cap}, ATR比值門檻={atr_ratio}")
836:                        logger.warning(f"[{strat}] ATR(60) 值異常: {atr_60_latest}，跳過風險閥門")
840:                        logger.warning(f"[{strat}] ATR(20) 值異常: {atr_20_latest}，跳過風險閥門")
851:                    logger.info(f"[{strat}] 🔴 強制觸發風險閥門啟用")
856:            logger.info(f"[{strat}] 未啟用全局風險閥門")
864:            # 重新計算策略信號（因為參數可能已經被風險閥門調整）
870:            # === 在 ssma_turn 也套用風險閥門（和 Ensemble 一致的後置覆寫） ===
941:                        logger.info(f"[{strat}] SSMA 風險閥門已套用（cap={risk_cap}, ratio={ratio_local:.4f}）")
943:                        logger.warning(f"[{strat}] SSMA 無法取得權重序列，跳過風險閥門套用")
945:                    logger.info(f"[{strat}] SSMA 風險閥門未觸發，使用原始結果")
981:                # 註解掉原本的無條件風險閥門調整（會造成 floor 方向錯誤）
983:                #     logger.info(f"[{strat}] Ensemble 策略應用風險閥門: 原始 delta_cap={ensemble_params.delta_cap}, floor={
ensemble_params.floor}")
985:                #     # 調整 delta_cap（最大風險暴露）
1020:                # --- 新增：只在 ATR 觸發時啟用風險閥門 ---
1047:                                # 增加風險閥門觸發的詳細資訊
1049:                                    logger.info(f"[{strat}] 🔴 風險閥門觸發！ATR比值({ratio:.4f}) > 門檻({atr_ratio})")
1051:                                    logger.info(f"[{strat}] 🟢 風險閥門未觸發，ATR比值({ratio:.4f}) <= 門檻({atr_ratio})")
1063:                # 如果啟用強制觸發，則強制觸發風險閥門
1066:                    logger.info(f"[{strat}] 🔴 強制觸發風險閥門啟用")
1078:                    logger.info(f"[{strat}] 🔴 開始套用風險閥門: cap={risk_cap}, ratio={ratio:.4f}")
1093:                    logger.info(f"[{strat}] 風險閥門已套用（cap={risk_cap}, ratio={ratio:.4f}）")
1095:                    # 增加風險閥門效果的詳細資訊
1097:                        logger.info(f"[{strat}] 風險閥門效果: PF原始={rv['metrics'].get('pf_orig', 'N/A'):.2f}, PF閥門={rv[
'metrics'].get('pf_valve', 'N/A'):.2f}")
1098:                        logger.info(f"[{strat}] 風險閥門效果: MDD原始={rv['metrics'].get('mdd_orig', 'N/A'):.2f}%, MDD閥門=
{rv['metrics'].get('mdd_valve', 'N/A'):.2f}%")
1108:                        logger.info(f"[{strat}] 🟢 風險閥門未觸發，使用原始參數")
1116:                        logger.info(f"[{strat}] ⚪ 全局風險閥門未啟用")
1175:                    "applied": False,  # 其他策略類型暫時不支援風險閥門
1205:        # === 全局風險閥門：逐日動態套用（與增強分析一致） ===
1211:                logger.warning(f"[{strat}] daily_state 不含 'w'，跳過全局風險閥門")
1217:                    logger.warning(f"[{strat}] 無法計算 ATR20/60，跳過全局風險閥門")
1316:                        logger.info(f"[{strat}] 全局風險閥門已套用（逐日），風險天數={true_days}, CAP={risk_cap:.2f}")
1318:                        logger.warning(f"[{strat}] 風險閥門重算沒有返回結果")
1701:            # === 計算風險閥門徽章內容 ===
1713:                "🛡️ 風險閥門：" + valve_badge_text + ((" | " + " | ".join(valve_badge_extra)) if valve_badge_extra else ""),
1968:                html.Summary("風險閥門回測"),
1981:                    html.Button("執行風險閥門回測", id="run-rv", n_clicks=0, style={"marginTop":"8px"})
1991:            # === 新增：風險-報酬地圖（Pareto Map）區塊 ===
1993:                html.Summary("📊 風險-報酬地圖（Pareto Map）"),
1995:                    html.Div("生成策略的風險-報酬分析圖表",
2010:                            html.Li("點大小：風險觸發天數（越大＝管得越勤）"),
2369:# --------- 增強分析 Callback：風險閥門回測（修正版） ---------
2434:        return f"風險閥門回測執行失敗: {e}", no_update, no_update
2438:    # 計算風險觸發天數
2446:        html.Code(f"風險觸發天數：{trigger_days} 天")
2624:        kpi("風險效率", f"{risk_eff:.3f}" if pd.notna(risk_eff) else "—"),
2652:            kpi("風險效率",      _fmt(m['eff'],  dec=3) if m else "—"),
2940:                                "風險效率": round(risk_eff, 3),
2971:        # 按風險效率排序（降序）
2972:        results_df = results_df.sort_values("風險效率", ascending=False)
2996:            html.Div(f"最佳風險效率：{results_df['風險效率'].max():.3f}", style={"fontSize": "12px"}),
3009:            html.H6("前10名最佳參數組合（按風險效率排序）", style={"marginTop": "16px", "marginBottom": "8px"}),
3316:# --------- 新增：風險-報酬地圖（Pareto Map）Callback ---------
3327:    """生成風險-報酬地圖（Pareto Map）：掃描 cap 與 ATR(20)/ATR(60) 比值全組合"""
3488:        return go.Figure(), "❌ 無法從風險閥門回測的參數組合中取得資料"
3521:            "風險觸發天數: %{marker.size:.0f} 天<br>" +
3530:            'text': f'風險-報酬地圖（Pareto Map）- {succeeded}/{tried} 組',
3544:    status_msg = f"✅ 成功生成：掃描 cap×ATR 比值 {succeeded}/{tried} 組。顏色=右尾調整幅度（紅=削減，藍=放大），大小=風險觸
發天數。資料來源：{data_source}"
3587:                # 計算右尾風險：使用偏度和峰度來衡量
3615:                # 4. 風險觸發天數（點大小，越大＝管得越勤）
3633:                # 估算風險觸發天數
3656:    """創建風險-報酬地圖（Pareto Map）"""
3668:            size=df['risk_trigger_days'] / 10,  # 點大小：風險觸發天數
3690:            "風險觸發天數: %{marker.size:.0f}<br>" +
3727:            'text': '風險-報酬地圖（Pareto Map）',
The bug suggests only average holding days remain, possibly due to improper aggregation. I'll search for relevant code sections.

root@a3bd66c837b3:/workspace/SSS096# rg "平均持倉天數" -n
SSSv096.py
927:    計算平均持倉天數.
933:        float: 平均持倉天數.
1828:            "avg_holding_period": "平均持倉天數",
1864:    # 計算平均持倉天數
1867:    # 將平均持倉天數加入 metrics
2293:            # 顯示策略摘要,傳入 trade_df 以計算平均持倉天數

analysis/OSv3.py
82:        'avg_hold_days': '平均持倉天數：平均每次交易的持倉時間',

analysis/optuna_16.py
10:v10-12  支援單一/隨機/依序數據源模式,新增平均持倉天數,相關係數分析,並自動輸出熱圖,試驗結果與最佳參數自動輸出 CSV/JSON

app_dash.py
1559:                "avg_holding_period": "平均持倉天數",
It seems the risk valve might be overriding the metrics dictionary with only avg_holding_period.

root@a3bd66c837b3:/workspace/SSS096# sed -n '1270,1320p' SSS_EnsembleTab.py
            (high - low),
            (high - prev_close).abs(),
            (low  - prev_close).abs()
        ], axis=1).max(axis=1)
    else:
        tr = close.diff().abs()

    b["atr"] = tr.rolling(atr_win, min_periods=atr_win).mean()
    b["atr_ratio"] = b["atr"] / b["atr"].rolling(atr_ref_win, min_periods=atr_ref_win).mean()

    # 風險觸發：兩斜率皆 < 門檻，且 ATR 抬頭超過倍率
    b["risk_trigger"] = (b["slope_20d"] < slope20_thresh) & \
                        (b["slope_60d"] < slope60_thresh) & \
                        (b["atr_ratio"] > atr_ratio_mult)
    return b[["slope_20d", "slope_60d", "atr", "atr_ratio", "risk_trigger"]]


# === PATCH: 風險閥門施作在權重 ===
def apply_valve_to_weights(w: pd.Series,
                           risk_trigger: pd.Series,
                           mode: str = "cap",   # "cap" 或 "ban_add"
                           cap_level: float = 0.5) -> pd.Series:
    """對每日目標權重 w 施作風險閥門：
       - cap: 風險日將 w 限在 cap_level 以下
       - ban_add: 風險日禁止「提高」倉位（允許減倉），用迭代法確保單調"""
    w = w.copy().reindex(risk_trigger.index).ffill().fillna(0.0)
    out = w.copy()

    if mode == "cap":
        mask = risk_trigger.reindex(w.index).fillna(False).astype(bool)
        out[mask] = np.minimum(out[mask], cap_level)

    elif mode == "ban_add":
        mask = risk_trigger.reindex(w.index).fillna(False).astype(bool)
        for i in range(1, len(out)):
            if mask.iloc[i] and (out.iloc[i] > out.iloc[i-1]):
                out.iloc[i] = out.iloc[i-1]  # 禁止增加
    else:
        raise ValueError("mode 需為 'cap' 或 'ban_add'")
    return out.clip(0.0, 1.0)


# === PATCH: 由 trade_ledger 建立「每筆盈虧%」與快照（引用 re.txt 做法）===
def build_trade_snapshots_from_ledger(trade_ledger: pd.DataFrame) -> pd.DataFrame:
    """以交易後權益/現金為資產快照，計算每筆盈虧%（只在有變動的交易日記一筆）"""
    df = trade_ledger.copy()
    # 欄名對齊
    if "date" in df.columns: df.rename(columns={"date": "交易日期"}, inplace=True)
    if "type" in df.columns: df.rename(columns={"type": "交易類型"}, inplace=True)
    if "equity_after" in df.columns: df.rename(columns={"equity_after": "交易後權益"}, inplace=True)
    if "cash_after" in df.columns: df.rename(columns={"cash_after": "交易後現金"}, inplace=True)
I'll scroll more to find where the risk valve is applied to the metrics.

root@a3bd66c837b3:/workspace/SSS096# rg "risk_valve" -n SSS_EnsembleTab.py
1241:def compute_risk_valve_signals(benchmark_df: pd.DataFrame,
1359:def risk_valve_backtest(open_px: pd.Series,
1371:    sig = compute_risk_valve_signals(benchmark_df, slope20_thresh, slope60_thresh,
I'm opening the risk_valve_backtest function around line 1359 to review it.

root@a3bd66c837b3:/workspace/SSS096# sed -n '1359,1405p' SSS_EnsembleTab.py
def risk_valve_backtest(open_px: pd.Series,
                        w: pd.Series,
                        cost,
                        benchmark_df: pd.DataFrame,
                        mode: str = "cap",
                        cap_level: float = 0.5,
                        slope20_thresh: float = 0.0,
                        slope60_thresh: float = 0.0,
                        atr_win: int = 20,
                        atr_ref_win: int = 60,
                        atr_ratio_mult: float = 1.3) -> dict:
    """回傳：原始與閥門版本的績效、右尾削減度、以及兩版 equity/ledger"""
    sig = compute_risk_valve_signals(benchmark_df, slope20_thresh, slope60_thresh,
                                     atr_win, atr_ref_win, atr_ratio_mult)
    w2 = apply_valve_to_weights(w, sig["risk_trigger"], mode, cap_level)

    # 原始版本
    daily_state1, ledger1 = build_portfolio_ledger(open_px, w, cost)
    # 閥門版本
    daily_state2, ledger2 = build_portfolio_ledger(open_px, w2, cost)

    # 交易統計（只用賣出列；符合 re.txt 對實現損益的口徑）
    r1 = _sell_returns_pct_from_ledger(ledger1)
    r2 = _sell_returns_pct_from_ledger(ledger2)
    pf1 = (r1[r1>0].sum() / abs(r1[r1<0].sum())) if (r1[r1<0].sum()!=0) else np.inf
    pf2 = (r2[r2>0].sum() / abs(r2[r2<0].sum())) if (r2[r2<0].sum()!=0) else np.inf
    mdd1 = _mdd_from_daily_equity(daily_state1["equity"])
    mdd2 = _mdd_from_daily_equity(daily_state2["equity"])

    # 右尾削減：比較兩版的「>P90 的正報酬總和」
    def right_tail_sum(x: pd.Series):
        if x.empty: return 0.0
        thr = x.quantile(0.90)
        return float(x[x > max(thr, 0)].sum())
    rt1 = right_tail_sum(r1)
    rt2 = right_tail_sum(r2)
    right_tail_reduction = (rt1 - rt2)

    return {
        "signals": sig,
        "weights_orig": w,
        "weights_valve": w2,
        "daily_state_orig": daily_state1,
        "daily_state_valve": daily_state2,
        "trade_ledger_orig": ledger1,
        "trade_ledger_valve": ledger2,
        "metrics": {
root@a3bd66c837b3:/workspace/SSS096# sed -n '1405,1435p' SSS_EnsembleTab.py
        "metrics": {
            "pf_orig": float(pf1), "pf_valve": float(pf2),
            "mdd_orig": float(mdd1), "mdd_valve": float(mdd2),
            "right_tail_sum_orig": float(rt1), "right_tail_sum_valve": float(rt2),
            "right_tail_reduction": float(right_tail_reduction)
        }
    }


# === PATCH: 交易貢獻拆解（按加碼/減碼階段）===
def trade_contribution_by_phase(trade_ledger: pd.DataFrame,
                                daily_equity: pd.Series,
                                min_spacing_days: int = 0,
                                cooldown_days: int = 0) -> pd.DataFrame:
    """將交易依『權重變化正/負』分段，統計各階段的賣出實現報酬與該段內的 MDD。"""
    tl = trade_ledger.copy()
    # 欄對齊
    for a,b in [("date","交易日期"),("type","交易類型"),("w_before","交易前權重"),("w_after","交易後權重")]:
        if a in tl.columns: tl.rename(columns={a:b}, inplace=True)
    tl["交易日期"] = pd.to_datetime(tl["交易日期"], errors="coerce")
    tl = tl.dropna(subset=["交易日期"]).sort_values("交易日期").reset_index(drop=True)
    tl["dw"] = pd.to_numeric(tl["交易後權重"], errors="coerce") - pd.to_numeric(tl["交易前權重"], errors="coerce")

    # 可選：施加最小間距/冷卻（在分段前對過密買單降噪）
    if min_spacing_days > 0:
        last_buy_dt = None
        for i, row in tl.iterrows():
            if row["dw"] > 0:
                if last_buy_dt is not None and (row["交易日期"] - last_buy_dt).days < min_spacing_days:
                    tl.at[i, "dw"] = 0.0  # 忽略這筆微小加碼
                else:
I think the risk valve might overwrite metrics. I'll search for related terms in the repo.

root@a3bd66c837b3:/workspace/SSS096# rg "risk_valve" -n
SSS_EnsembleTab.py
1241:def compute_risk_valve_signals(benchmark_df: pd.DataFrame,
1359:def risk_valve_backtest(open_px: pd.Series,
1371:    sig = compute_risk_valve_signals(benchmark_df, slope20_thresh, slope60_thresh,

DEFENSIVE_CHECKS_UPDATE_SUMMARY.md
25:**1.1 _simulate_risk_valves 函式**
30:**1.2 _calculate_risk_valve_impact 函式**
32:- 檢查 `benchmark_enhanced` 是否有 `risk_valve_triggered` 欄位

analysis/enhanced_trade_analysis.py
95:    def risk_valve_backtest(self, risk_rules=None):
113:        self._simulate_risk_valves(risk_rules)
116:        self._calculate_risk_valve_impact()
118:        return self.analysis_results.get('risk_valve', {})
120:    def _simulate_risk_valves(self, risk_rules):
180:        benchmark['risk_valve_20d'] = benchmark['slope_20d'] < t20
181:        benchmark['risk_valve_60d'] = benchmark['slope_60d'] < t60
182:        benchmark['risk_valve_atr'] = benchmark['atr_ratio'] > atr_mult
185:        benchmark['risk_valve_triggered'] = (
186:            benchmark['risk_valve_20d'] &
187:            benchmark['risk_valve_60d'] &
188:            benchmark['risk_valve_atr']
193:    def _calculate_risk_valve_impact(self):
203:        if 'risk_valve_triggered' not in self.benchmark_enhanced.columns:
204:            print("警告：benchmark_enhanced 缺少 'risk_valve_triggered' 欄位，無法計算風險閥門影響")
209:            self.benchmark_enhanced['risk_valve_triggered']
229:        self.analysis_results['risk_valve'] = {
530:        self.risk_valve_backtest()
556:        if 'risk_valve' in self.analysis_results and hasattr(self, 'benchmark_enhanced'):
560:            elif 'risk_valve_triggered' not in self.benchmark_enhanced.columns:
561:                print("警告：benchmark_enhanced 缺少 'risk_valve_triggered' 欄位，跳過風險閥門時序圖")
567:                    self.benchmark_enhanced['risk_valve_triggered']
573:                                   self.benchmark_enhanced['risk_valve_triggered'], '收盤價'
637:    print("2. 執行風險閥門回測：analyzer.risk_valve_backtest()")

analysis/ENHANCED_ANALYSIS_README.md
17:### 1. 風險閥門回測 (`risk_valve_backtest`)
34:risk_results = analyzer.risk_valve_backtest()
41:custom_results = analyzer.risk_valve_backtest(custom_rules)
108:risk_results = analyzer.risk_valve_backtest()

app_dash.py
586:def update_risk_valve_status(global_apply, risk_cap, atr_ratio, force_trigger, ticker, start_date, end_date):
893:                    from SSS_EnsembleTab import risk_valve_backtest, CostParams
918:                        rv = risk_valve_backtest(
1075:                    from SSS_EnsembleTab import risk_valve_backtest
1080:                    rv = risk_valve_backtest(
1238:                    # 若你沿用現有的 risk_valve_backtest，給 cap_level=1.0 表示「w 已經是目標序列」
1240:                        from SSS_EnsembleTab import risk_valve_backtest, CostParams
1264:                        result_cap = risk_valve_backtest(
1273:                        logger.warning(f"[{strat}] 無法導入 risk_valve_backtest: {e}")
1307:                        result['_risk_valve_applied'] = True
1308:                        result['_risk_valve_params'] = {
2426:        from SSS_EnsembleTab import risk_valve_backtest
2427:        out = risk_valve_backtest(
3424:    # 檢查是否可以匯入 risk_valve_backtest
3426:        from SSS_EnsembleTab import risk_valve_backtest
3427:        logger.info("成功匯入 risk_valve_backtest")
3429:        logger.error(f"匯入 risk_valve_backtest 失敗: {e}")
3430:        return go.Figure(), f"❌ 無法匯入 risk_valve_backtest: {e}"
3440:                out = risk_valve_backtest(
3837:        # 檢查是否可以匯入 risk_valve_backtest
3839:            from SSS_EnsembleTab import risk_valve_backtest
3840:            logger.info("成功匯入 risk_valve_backtest")
3842:            logger.error(f"匯入 risk_valve_backtest 失敗: {e}")
3853:                    out = risk_valve_backtest(
3865:                        trade_df = None  # risk_valve_backtest 不直接提供交易記錄
I'm looking into why other metrics disappear when applying the risk valve—let's search for "avg_holding_period".

root@a3bd66c837b3:/workspace/SSS096# sed -n '1230,1315p' app_dash.py

                    # 4) 回寫 ds，並重算交易/權益
                    result["daily_state_std"] = pack_df(ds)

                    # open 價（沒有 open 就退而求其次用收盤價）
                    open_px = (df_raw["open"] if "open" in df_raw.columns else df_raw.get("收盤價")).astype(float)
                    open_px = open_px.reindex(ds.index).dropna()

                    # 若你沿用現有的 risk_valve_backtest，給 cap_level=1.0 表示「w 已經是目標序列」
                    try:
                        from SSS_EnsembleTab import risk_valve_backtest, CostParams

                        # 成本參數
                        trade_cost = (strat_params.get("trade_cost", {})
                                      if isinstance(strat_params, dict) else {})
                        cost = CostParams(
                            buy_fee_bp=float(trade_cost.get("buy_fee_bp", 4.27)),
                            sell_fee_bp=float(trade_cost.get("sell_fee_bp", 4.27)),
                            sell_tax_bp=float(trade_cost.get("sell_tax_bp", 30.0)),
                        )

                        # 基準（有高低價就帶上）
                        bench = pd.DataFrame(index=pd.to_datetime(df_raw.index))
                        if 'close' in df_raw.columns:
                            bench["收盤價"] = pd.to_numeric(df_raw["close"], errors="coerce")
                        elif '收盤價' in df_raw.columns:
                            bench["收盤價"] = pd.to_numeric(df_raw["收盤價"], errors="coerce")
                        if 'high' in df_raw.columns and 'low' in df_raw.columns:
                            bench["最高價"] = pd.to_numeric(df_raw["high"], errors="coerce")
                            bench["最低價"] = pd.to_numeric(df_raw["low"], errors="coerce")
                        elif '最高價' in df_raw.columns and '最低價' in df_raw.columns:
                            bench["最高價"] = pd.to_numeric(df_raw["最高價"], errors="coerce")
                            bench["最低價"] = pd.to_numeric(df_raw["最低價"], errors="coerce")

                        result_cap = risk_valve_backtest(
                            open_px=open_px,
                            w=ds["w"].astype(float).reindex(open_px.index).fillna(0.0),
                            cost=cost,
                            benchmark_df=bench,
                            mode="cap",
                            cap_level=1.0,
                        )
                    except Exception as e:
                        logger.warning(f"[{strat}] 無法導入 risk_valve_backtest: {e}")
                        result_cap = None

                    if result_cap:
                        # === 安全覆寫：清掉舊鍵並補齊新鍵 ===
                        logger.info(f"[UI_CHECK] 即將覆寫：new_trades={len(result_cap.get('trade_ledger_valve', pd.DataFrame()))
} rows, new_ds={len(result_cap.get('daily_state_valve', pd.DataFrame()))} rows")

                        # 1) 覆寫結果 —— 一律用 pack_df/pack_series
                        if 'trade_ledger_valve' in result_cap:
                            result['trades'] = pack_df(result_cap['trade_ledger_valve'])
                            result['trade_ledger'] = pack_df(result_cap['trade_ledger_valve'])
                            result['trade_ledger_std'] = pack_df(result_cap['trade_ledger_valve'])

                        if 'daily_state_valve' in result_cap:
                            result['daily_state'] = pack_df(result_cap['daily_state_valve'])
                            result['daily_state_std'] = pack_df(result_cap['daily_state_valve'])

                        if 'weights_valve' in result_cap:
                            result['weight_curve'] = pack_series(result_cap['weights_valve'])

                        # 權益曲線：若是 Series
                        if 'daily_state_valve' in result_cap and 'equity' in result_cap['daily_state_valve']:
                            try:
                                result['equity_curve'] = pack_series(result_cap['daily_state_valve']['equity'])
                            except Exception:
                                # 若你存的是 DataFrame
                                result['equity_curve'] = pack_df(result_cap['daily_state_valve']['equity'].to_frame('equity'))

                        # 2) **關鍵**：把 UI 可能拿來用的舊快取清掉，強迫 UI 走新資料
                        for k in ['trades_ui', 'trade_df', 'trade_ledger_std', 'metrics']:
                            if k in result:
                                result.pop(k, None)

                        # 3) 給 UI 一個旗標與參數，便於顯示「已套用」
                        result['_risk_valve_applied'] = True
                        result['_risk_valve_params'] = {
                            'cap': float(risk_cap),
                            'atr_ratio': float(atr_ratio),
                            'atr20_last': float(atr_20_valid.iloc[-1]) if len(atr_20_valid) > 0 else None,
                            'atr60_last': float(atr_60_valid.iloc[-1]) if len(atr_60_valid) > 0 else None,
                        }

                        true_days = int(mask_aligned.sum())
root@a3bd66c837b3:/workspace/SSS096# sed -n '1315,1345p' app_dash.py
                        true_days = int(mask_aligned.sum())
                        logger.info(f"[{strat}] 全局風險閥門已套用（逐日），風險天數={true_days}, CAP={risk_cap:.2f}")
                    else:
                        logger.warning(f"[{strat}] 風險閥門重算沒有返回結果")

        results[strat] = result

    # 使用第一個策略的數據作為主要顯示數據
    first_strat = list(results.keys())[0] if results else strategy_names[0]
    first_smaa_src = param_presets[first_strat].get("smaa_source", "Self")
    df_raw_main, _ = load_data(ticker, start_date, end_date if end_date else None, smaa_source=first_smaa_src)

    # 統一使用 orient="split" 序列化，確保一致性
    payload = {
        'results': results,
        'df_raw': df_raw_main.to_json(date_format='iso', orient='split'),
        'ticker': ticker
    }

    # 防守性檢查：如還有漏網的非序列化物件就能提早看出
    try:
        json.dumps(payload)
    except Exception as e:
        logger.exception("[BUG] backtest-store payload 仍含不可序列化物件：%s", e)
        # 如果要強制不噴，可做 fallback：json.dumps(..., default=str) 但通常不建議吞掉

    # === 回測完成日誌 ===
    logger.info(f"回測完成 - 策略數: {len(results)}, ticker: {ticker}, 數據行數: {len(df_raw_main)}")
    logger.debug(f"策略列表: {list(results.keys())}")

    return payload
After applying the risk valve, metrics were popped and not recalculated, causing them to vanish.

root@a3bd66c837b3:/workspace/SSS096# rg -n "avg_holding_period" app_dash.py
1545:            metrics['avg_holding_period'] = avg_holding
1559:                "avg_holding_period": "平均持倉天數",
1573:                elif k in ["max_drawdown_duration", "avg_holding_period"]:
root@a3bd66c837b3:/workspace/SSS096# sed -n '1525,1575p' app_dash.py
            # === 交易流水帳(ledger)表格：先準備顯示版 ===
            ledger_src = trade_ledger_std if (trade_ledger_std is not None and not trade_ledger_std.empty) else \
                         (ledger_ui if (ledger_ui is not None and not ledger_ui.empty) else pd.DataFrame())

            if ledger_src is not None and not ledger_src.empty:
                # 為了 100% 保證 weight_change 出現，先確保權重欄位
                ledger_src = _ensure_weight_columns(ledger_src)
                # 使用新的統一格式化函式
                ledger_display = format_trade_like_df_for_display(ledger_src)
                ledger_columns = [{"name": i, "id": i} for i in ledger_display.columns]
                ledger_data = ledger_display.to_dict('records')
            else:
                ledger_columns = []
                ledger_data = []

            metrics = result.get('metrics', {})
            tooltip = f"{strategy} 策略説明"
            param_display = {k: v for k, v in param_presets[strategy].items() if k != "strategy_type"}
            param_str = ", ".join(f"{k}: {v}" for k, v in param_display.items())
            avg_holding = calculate_holding_periods(trade_df)
            metrics['avg_holding_period'] = avg_holding

            label_map = {
                "total_return": "總回報率",
                "annual_return": "年化回報率",
                "win_rate": "勝率",
                "max_drawdown": "最大回撤",
                "max_drawdown_duration": "回撤持續",
                "calmar_ratio": "卡瑪比率",
                "sharpe_ratio": "夏普比率",
                "sortino_ratio": "索提諾比率",
                "payoff_ratio": "盈虧比",
                "profit_factor": "盈虧因子",
                "num_trades": "交易次數",
                "avg_holding_period": "平均持倉天數",
                "annualized_volatility": "年化波動率",
                "max_consecutive_wins": "最大連續盈利",
                "max_consecutive_losses": "最大連續虧損",
                "avg_win": "平均盈利",
                "avg_loss": "平均虧損",
            }

            metric_cards = []
            for k, v in metrics.items():
                if k in ["total_return", "annual_return", "win_rate", "max_drawdown", "annualized_volatility", "avg_win", "avg_l
oss"]:
                    txt = f"{v:.2%}" if pd.notna(v) else ""
                elif k in ["calmar_ratio", "sharpe_ratio", "sortino_ratio", "payoff_ratio", "profit_factor"]:
                    txt = f"{v:.2f}" if pd.notna(v) else ""
                elif k in ["max_drawdown_duration", "avg_holding_period"]:
                    txt = f"{v:.2f} 天" if pd.notna(v) else ""
                elif k in ["num_trades", "max_consecutive_wins", "max_consecutive_losses"]:
It seems metrics are cleared by the risk valve. I'll search for calculate_metrics.

root@a3bd66c837b3:/workspace/SSS096# rg "calculate_metrics" -n
SSSv096.py
40:    "compute_backtest_for_periods", "calculate_metrics",
824:def calculate_metrics(trades: List[Tuple[pd.Timestamp, float, pd.Timestamp]], df_ind: pd.DataFrame, equity_curve: pd.Series
= None) -> Dict:
1295:    metrics = calculate_metrics(trades, df_ind, equity_curve)

analysis/ROEAv4.py
25:from SSSv095a1 import calculate_metrics, load_data_wrapper
407:    all_metric_cols = list(calculate_metrics([], pd.DataFrame()).keys())
I’ll check the imports in app_dash to see if calculate_metrics is already imported.

root@a3bd66c837b3:/workspace/SSS096# rg -n "calculate_metrics" app_dash.py
I'll check if app_dash.py has a metrics function. If not, I'll use SSSv096.

root@a3bd66c837b3:/workspace/SSS096# sed -n '800,860p' SSSv096.py
        logger.warning(f"最終 df_ind 為空,可能是 SMAA 數據不足,策略: ssma_turn, linlen={linlen}, smaalen={smaalen}, valid_smaa={
len(smaa.dropna())}")
    return df_ind.dropna(), buy_dates, sell_dates

def calculate_trade_mmds(trades: List[Tuple[pd.Timestamp, float, pd.Timestamp]], equity_curve: pd.Series) -> List[float]:
    """
    計算每筆持有期間的最大回撤（MMD）。
    Args:
        trades: 交易記錄,包含 entry_date, return, exit_date。
        equity_curve: 全部回測期間的每日資產淨值。
    Returns:
        List[float]: 每筆持有期間的最大回撤。
    """
    mmds = []
    for entry_date, _, exit_date in trades:
        # 取出持有期間的 equity
        period_equity = equity_curve.loc[entry_date:exit_date]
        if len(period_equity) < 2:
            mmds.append(0.0)
            continue
        roll_max = period_equity.cummax()
        drawdown = period_equity / roll_max - 1
        mmds.append(drawdown.min())
    return mmds

def calculate_metrics(trades: List[Tuple[pd.Timestamp, float, pd.Timestamp]], df_ind: pd.DataFrame, equity_curve: pd.Series = No
ne) -> Dict:
    """
    計算回測績效指標.
    Args:
        trades: 交易記錄,包含日期和報酬率.
        df_ind: 指標數據 DataFrame,包含交易日索引.
        equity_curve: 全部回測期間的每日資產淨值（可選, 若要計算持有期間MMD需提供）
    Returns:
        Dict: 包含總回報率、年化回報率、最大回撤等指標.
    """
    metrics = {
        'total_return': 0.0,
        'annual_return': 0.0,
        'max_drawdown': 0.0,  # 這裡之後會直接用 max_mmd 覆蓋
        'max_drawdown_duration': 0,
        'calmar_ratio': np.nan,
        'num_trades': 0,
        'win_rate': 0.0,
        'avg_win': np.nan,
        'avg_loss': np.nan,
        'payoff_ratio': np.nan,
        'sharpe_ratio': np.nan,
        'sortino_ratio': np.nan,
        'max_consecutive_wins': 0,# 新增
        'max_consecutive_losses': 0,# 新增
        'avg_holding_period': np.nan,# 新增
        'annualized_volatility': np.nan,# 新增
        'profit_factor': np.nan,# 新增
        # 'avg_mmd': np.nan, # 不再需要
        # 'max_mmd': np.nan, # 不再需要單獨欄位
    }
    if not trades:
        return metrics

    trade_metrics = pd.DataFrame(trades, columns=['entry_date', 'return', 'exit_date']).set_index('exit_date')
    trade_metrics['equity'] = (1 + trade_metrics['return']).cumprod()
    roll_max = trade_metrics['equity'].cummax()
I’ll double-check how trades and the df_ind (indicator DataFrame) are structured for metrics.

root@a3bd66c837b3:/workspace/SSS096# rg -n "metrics'" app_dash.py
1097:                        logger.info(f"[{strat}] 風險閥門效果: PF原始={rv['metrics'].get('pf_orig', 'N/A'):.2f}, PF閥門={rv[
'metrics'].get('pf_valve', 'N/A'):.2f}")
1098:                        logger.info(f"[{strat}] 風險閥門效果: MDD原始={rv['metrics'].get('mdd_orig', 'N/A'):.2f}%, MDD閥門=
{rv['metrics'].get('mdd_valve', 'N/A'):.2f}%")
1130:                    'metrics': backtest_result.stats,
1151:                    'metrics': {'total_return': 0.0, 'annual_return': 0.0, 'max_drawdown': 0.0, 'sharpe_ratio': 0.0, 'calma
r_ratio': 0.0, 'num_trades': 0},
1302:                        for k in ['trades_ui', 'trade_df', 'trade_ledger_std', 'metrics']:
1540:            metrics = result.get('metrics', {})
1878:            metrics = result['metrics']
I see that metrics is assigned at line 1130 as 'metrics': backtest_result.stats.

root@a3bd66c837b3:/workspace/SSS096# sed -n '1120,1140p' app_dash.py
                            "cap": "N/A",
                            "atr_ratio": "N/A"
                        }

                # 轉換為舊格式以保持相容性
                result = {
                    'trades': [],
                    'trade_df': pack_df(backtest_result.trades),
                    'trades_df': pack_df(backtest_result.trades),
                    'signals_df': pack_df(backtest_result.trades[['trade_date', 'type', 'price']].rename(columns={'type': 'actio
n'}) if not backtest_result.trades.empty else pd.DataFrame(columns=['trade_date', 'action', 'price'])),
                    'metrics': backtest_result.stats,
                    'equity_curve': pack_series(backtest_result.equity_curve),
                    'cash_curve': pack_series(backtest_result.cash_curve) if backtest_result.cash_curve is not None else "",
                    'weight_curve': pack_series(backtest_result.weight_curve) if backtest_result.weight_curve is not None else p
ack_series(pd.Series(0.0, index=backtest_result.equity_curve.index)),
                    'price_series': pack_series(backtest_result.price_series) if backtest_result.price_series is not None else p
ack_series(pd.Series(1.0, index=backtest_result.equity_curve.index)),
                    'daily_state': pack_df(backtest_result.daily_state),
                    'trade_ledger': pack_df(backtest_result.ledger),
                    'daily_state_std': pack_df(backtest_result.daily_state),
                    'trade_ledger_std': pack_df(backtest_result.ledger)
                }
The backtest metrics weren't recalculated after replacing components; I'll recompute using calculate_metrics.

root@a3bd66c837b3:/workspace/SSS096# sed -n '860,940p' SSSv096.py
    roll_max = trade_metrics['equity'].cummax()
    daily_drawdown = trade_metrics['equity'] / roll_max - 1

    # 基本指標
    metrics['total_return'] = trade_metrics['equity'].iloc[-1] - 1
    years = max((trade_metrics.index[-1] - trade_metrics.index[0]).days / 365.25, 1)
    metrics['annual_return'] = (1 + metrics['total_return']) ** (1 / years) - 1

    # 既有日內回撤（numpy 陣列）
    dd_np = (daily_drawdown < 0).astype(bool)

    # 轉成 pandas Series（索引用回 trade_metrics.index），才能安全 groupby
    dd_series = pd.Series(dd_np, index=trade_metrics.index)

    # 連續回撤區段的最長天數（True 連續段的長度最大值）
    blocks = (~dd_series).cumsum()
    dd_dur = int((dd_series.groupby(blocks).cumcount() + 1).where(dd_series).max() or 0)
    metrics['max_drawdown_duration'] = dd_dur

    # 回填 max_drawdown（安全地用 float 轉換）
    metrics['max_drawdown'] = float(daily_drawdown.min())
    # metrics['calmar_ratio'] = metrics['annual_return'] / abs(metrics['max_drawdown']) if metrics['max_drawdown'] < 0 else np.n
an
    metrics['num_trades'] = len(trade_metrics)
    metrics['win_rate'] = (trade_metrics['return'] > 0).sum() / metrics['num_trades'] if metrics['num_trades'] > 0 else 0
    metrics['avg_win'] = trade_metrics[trade_metrics['return'] > 0]['return'].mean() if metrics['win_rate'] > 0 else np.nan
    metrics['avg_loss'] = trade_metrics[trade_metrics['return'] < 0]['return'].mean() if metrics['win_rate'] < 1 else np.nan
    metrics['payoff_ratio'] = abs(metrics['avg_win'] / metrics['avg_loss']) if metrics['avg_loss'] != 0 and not np.isnan(metrics
['avg_win']) else np.nan

    # 新增:計算每日報酬率與波動率
    daily_dates = df_ind.index.intersection(pd.date_range(start=trade_metrics.index.min(), end=trade_metrics.index.max(), freq='
B'))
    daily_equity = pd.Series(index=daily_dates, dtype=float)
    for date, row in trade_metrics.iterrows():
        daily_equity.loc[date] = row['equity']
    daily_equity = daily_equity.ffill()
    daily_returns = daily_equity.pct_change().dropna()

    metrics['sharpe_ratio'] = (daily_returns.mean() * np.sqrt(252)) / daily_returns.std() if daily_returns.std() != 0 else np.na
n
    downside_returns = daily_returns[daily_returns < 0]
    downside_std = downside_returns.std() if len(downside_returns) > 0 else np.nan
    metrics['sortino_ratio'] = (daily_returns.mean() * np.sqrt(252)) / downside_std if downside_std != 0 else np.nan

    # 新增:計算最大連續盈利和最大連續虧損
    trade_metrics['win_flag'] = trade_metrics['return'] > 0
    trade_metrics['grp'] = (trade_metrics['win_flag'] != trade_metrics['win_flag'].shift(1)).cumsum()
    consec = trade_metrics.groupby(['grp', 'win_flag']).size()
    metrics['max_consecutive_wins'] = consec[consec.index.get_level_values('win_flag') == True].max() if True in consec.index.ge
t_level_values('win_flag') else 0
    metrics['max_consecutive_losses'] = consec[consec.index.get_level_values('win_flag') == False].max() if False in consec.inde
x.get_level_values('win_flag') else 0

    # 新增:計算年化波動率
    metrics['annualized_volatility'] = daily_returns.std() * np.sqrt(252) if len(daily_returns) > 0 else np.nan

    # 新增:計算盈虧因子 (Profit Factor)
    total_profits = trade_metrics[trade_metrics['return'] > 0]['return'].sum()
    total_losses = abs(trade_metrics[trade_metrics['return'] < 0]['return'].sum())
    metrics['profit_factor'] = total_profits / total_losses if total_losses != 0 else np.nan

    # 新增:計算每筆持有期間MMD，並直接用 max_mmd 覆蓋 max_drawdown
    if equity_curve is not None:
        mmds = calculate_trade_mmds(trades, equity_curve)
        if mmds:
            metrics['max_drawdown'] = float(np.min(mmds)) # drawdown為負值,最小值為最大跌幅
            metrics['calmar_ratio'] = metrics['annual_return'] / abs(metrics['max_drawdown']) if metrics['max_drawdown'] < 0 els
e np.nan

    return metrics

def calculate_holding_periods(trade_df: pd.DataFrame) -> float:
    """
    計算平均持倉天數.

    Args:
        trade_df: 交易記錄 DataFrame,包含 signal_date, trade_date, type.

    Returns:
        float: 平均持倉天數.
    """
    if trade_df.empty or 'trade_date' not in trade_df.columns or 'type' not in trade_df.columns:
        return np.nan

    holding_periods = []
    entry_date = None
root@a3bd66c837b3:/workspace/SSS096# rg -n "trade_df" app_dash.py
247:        'trade_df', 'trades_df', 'signals_df',
1127:                    'trade_df': pack_df(backtest_result.trades),
1148:                    'trade_df': pd.DataFrame(),
1159:            if 'trade_df' in result and hasattr(result['trade_df'], 'shape'):
1160:                logger.info(f"[Ensemble] 交易記錄數量: {len(result['trade_df'])}")
1188:            if hasattr(result.get('trade_df'), 'to_json'):
1189:                result['trade_df'] = result['trade_df'].to_json(date_format='iso', orient='split')
1302:                        for k in ['trades_ui', 'trade_df', 'trade_ledger_std', 'metrics']:
1403:            trade_df = None
1407:                result.get('trade_df'),    # 某些策略自帶
1416:                    trade_df = df.copy()
1419:            if trade_df is None:
1421:                trade_df = pd.DataFrame(columns=['trade_date','type','price','shares','return'])
1437:            logger.info(f"[UI] {strategy} trades 來源優先序：trades -> trades_ui -> trade_df；實際使用={'trades' if 'trades
' in result else ('trades_ui' if 'trades_ui' in result else 'trade_df')}")
1443:                trade_df = norm(trade_df)
1444:                logger.info(f"標準化後 trades_ui 欄位: {list(trade_df.columns)}")
1448:                if trade_df is not None and len(trade_df) > 0:
1449:                    trade_df = trade_df.copy()
1450:                    trade_df.columns = [str(c).lower() for c in trade_df.columns]
1453:                    if "trade_date" not in trade_df.columns:
1454:                        if "date" in trade_df.columns:
1455:                            trade_df["trade_date"] = pd.to_datetime(trade_df["date"], errors="coerce")
1456:                        elif isinstance(trade_df.index, pd.DatetimeIndex):
1457:                            trade_df = trade_df.reset_index().rename(columns={"index": "trade_date"})
1459:                            trade_df["trade_date"] = pd.NaT
1461:                        trade_df["trade_date"] = pd.to_datetime(trade_df["trade_date"], errors="coerce")
1464:                    if "type" not in trade_df.columns:
1465:                        if "action" in trade_df.columns:
1466:                            trade_df["type"] = trade_df["action"].astype(str).str.lower()
1467:                        elif "side" in trade_df.columns:
1468:                            trade_df["type"] = trade_df["side"].astype(str).str.lower()
1470:                            trade_df["type"] = "hold"
1473:                    if "price" not in trade_df.columns:
1475:                            if c in trade_df.columns:
1476:                                trade_df["price"] = trade_df[c]
1478:                        if "price" not in trade_df.columns:
1479:                            trade_df["price"] = 0.0
1482:            if 'trade_date' in trade_df.columns:
1483:                trade_df['trade_date'] = pd.to_datetime(trade_df['trade_date'])
1484:            if 'signal_date' in trade_df.columns:
1485:                trade_df['signal_date'] = pd.to_datetime(trade_df['signal_date'])
1486:            if 'price' in trade_df.columns:
1487:                trade_df['price'] = pd.to_numeric(trade_df['price'], errors='coerce')
1488:            if 'shares' in trade_df.columns:
1489:                trade_df['shares'] = pd.to_numeric(trade_df['shares'], errors='coerce')
1514:                base_df = trade_df
1517:            logger.info("[UI] trade_df 原始欄位：%s", list(base_df.columns) if base_df is not None else None)
1544:            avg_holding = calculate_holding_periods(trade_df)
1590:            fig1 = plot_stock_price(df_raw, trade_df, ticker)
1611:            logger.info(f"[UI] trade_df cols={list(trade_df.columns)} head=\n{trade_df.head(3)}")
1619:                fig_w = plot_weight_series(daily_state_display, trade_df)
1678:                fig2 = plot_equity_cash(trade_df, df_raw)  # 使用 SSSv096 的 fallback 邏輯
1799:            trade_df = df_from_pack(result.get('trade_df'))
1804:                trade_df = norm(trade_df)
1807:                if trade_df is not None and len(trade_df) > 0:
1808:                    trade_df = trade_df.copy()
1809:                    trade_df.columns = [str(c).lower() for c in trade_df.columns]
1810:                    if "trade_date" not in trade_df.columns and "date" in trade_df.columns:
1811:                        trade_df["trade_date"] = pd.to_datetime(trade_df["date"], errors="coerce")
1812:                    if "type" not in trade_df.columns and "action" in trade_df.columns:
1813:                        trade_df["type"] = trade_df["action"].astype(str).str.lower()
1814:                    if "price" not in trade_df.columns:
1816:                            if c in trade_df.columns:
1817:                                trade_df["price"] = trade_df[c]
1820:            if 'trade_date' in trade_df.columns:
1821:                trade_df['trade_date'] = pd.to_datetime(trade_df['trade_date'])
1822:            if trade_df.empty:
1824:            buys = trade_df[trade_df['type'] == 'buy']
1825:            sells = trade_df[trade_df['type'] == 'sell']
1851:            trade_df = df_from_pack(result.get('trade_df'))
1856:                trade_df = norm(trade_df)
1859:                if trade_df is not None and len(trade_df) > 0:
1860:                    trade_df = trade_df.copy()
1861:                    trade_df.columns = [str(c).lower() for c in trade_df.columns]
1862:                    if "trade_date" not in trade_df.columns and "date" in trade_df.columns:
1863:                        trade_df["trade_date"] = pd.to_datetime(trade_df["date"], errors="coerce")
1864:                    if "type" not in trade_df.columns and "action" in trade_df.columns:
1865:                        trade_df["type"] = trade_df["action"].astype(str).str.lower()
1866:                    if "price" not in trade_df.columns:
1868:                            if c in trade_df.columns:
1869:                                trade_df["price"] = trade_df[c]
1872:            if 'trade_date' in trade_df.columns:
1873:                trade_df['trade_date'] = pd.to_datetime(trade_df['trade_date'])
1876:            detailed_stats = calculate_holding_periods(trade_df)
1949:                    html.Div("選擇策略（自動評分：ledger_std > ledger > trade_df）",
2114:    trade_df = df_from_pack(result.get('trade_df'))
2119:        trade_df = norm(trade_df)
2122:        if trade_df is not None and len(trade_df) > 0:
2123:            trade_df = trade_df.copy()
2124:            trade_df.columns = [str(c).lower() for c in trade_df.columns]
2125:            if "trade_date" not in trade_df.columns and "date" in trade_df.columns:
2126:                trade_df["trade_date"] = pd.to_datetime(trade_df["date"], errors="coerce")
2127:            if "type" not in trade_df.columns and "action" in trade_df.columns:
2128:                trade_df["type"] = trade_df["action"].astype(str).str.lower()
2129:            if "price" not in trade_df.columns:
2131:                    if c in trade_df.columns:
2132:                        trade_df["price"] = trade_df[c]
2138:            trade_df.to_excel(writer, sheet_name='交易紀錄', index=False)
2167:    trade_df = df_from_pack(result.get('trade_df'))
2172:        trade_df = norm(trade_df)
2175:        if trade_df is not None and len(trade_df) > 0:
2176:            trade_df = trade_df.copy()
2177:            trade_df.columns = [str(c).lower() for c in trade_df.columns]
2178:            if "trade_date" not in trade_df.columns and "date" in trade_df.columns:
2179:                trade_df["trade_date"] = pd.to_datetime(trade_df["date"], errors="coerce")
2180:            if "type" not in trade_df.columns and "action" in trade_df.columns:
2181:                trade_df["type"] = trade_df["action"].astype(str).str.lower()
2182:            if "price" not in trade_df.columns:
2184:                    if c in trade_df.columns:
2185:                        trade_df["price"] = trade_df[c]
2192:        trade_df.to_csv(bytes_io, index=False, encoding='utf-8-sig')
2196:def calculate_strategy_detailed_stats(trade_df, df_raw):
2198:    if trade_df.empty:
2207:    if 'trade_date' in trade_df.columns:
2208:        trade_df['trade_date'] = pd.to_datetime(trade_df['trade_date'])
2211:    trade_df = trade_df.sort_values('trade_date').reset_index(drop=True)
2215:    for i in range(len(trade_df) - 1):
2216:        current_type = trade_df.iloc[i]['type']
2217:        next_type = trade_df.iloc[i+1]['type']
2219:            buy_date = trade_df.iloc[i]['trade_date']
2220:            sell_date = trade_df.iloc[i+1]['trade_date']
2227:    for i in range(len(trade_df) - 1):
2228:        current_type = trade_df.iloc[i]['type']
2229:        next_type = trade_df.iloc[i+1]['type']
2231:            sell_date = trade_df.iloc[i]['trade_date']
2232:            buy_date = trade_df.iloc[i+1]['trade_date']
2238:    last_trade = trade_df.iloc[-1] if not trade_df.empty else None
2259:            last_buy = trade_df[trade_df['type'] == 'buy']
2514:    trade_df = df_from_pack(cache.get("trade_data"))
2517:    if trade_df is None or trade_df.empty:
2531:        table = trade_contribution_by_phase(trade_df, equity, min_gap, cooldown).copy()
2795:    trade_df = df_from_pack(cache.get("trade_data"))
2798:    if trade_df is None or trade_df.empty:
2811:    debug_info.append(f"原始交易資料欄位: {list(trade_df.columns)}")
2812:    debug_info.append(f"交易資料行數: {len(trade_df)}")
2827:            if name in trade_df.columns:
2838:        if "weight_change" in trade_df.columns and "w_before" not in found_columns:
2840:            trade_df = trade_df.copy()
2841:            trade_df["w_before"] = 0.0
2842:            trade_df["w_after"] = trade_df["weight_change"]
2847:        if "price" in trade_df.columns and "type" not in found_columns:
2849:            trade_df["type"] = "buy"
2878:            if "weight_change" in trade_df.columns:
2879:                debug_info.append(f"找到 weight_change 欄位，範圍: {trade_df['weight_change'].min():.4f} ~ {trade_df['weigh
t_change'].max():.4f}")
2885:            table = trade_contribution_by_phase(trade_df, equity, test_min_gap, test_cooldown)
2919:                        table = trade_contribution_by_phase(trade_df, equity, min_gap, cooldown)
3026:        (cache.get("trade_data") or cache.get("trade_df") or cache.get("trade_ledger") or cache.get("trade_ledger_std"))
3048:    # 策略評分：ledger_std > ledger > trade_df
3056:        elif result.get("trade_df"):
3097:    # 優先順序：ledger_std > ledger > trade_df
3107:    elif result.get("trade_df"):
3108:        trade_data = df_from_pack(result["trade_df"])
3109:        data_source = "trade_df (交易明細)"
3204:    # 策略評分：ledger_std > ledger > trade_df
3212:        elif result.get("trade_df"):
3229:    # 準備交易資料（優先順序：ledger_std > ledger > trade_df）
3239:    elif best_result.get("trade_df"):
3240:        trade_data = df_from_pack(best_result["trade_df"])
3241:        data_source = "trade_df (交易明細)"
3547:def calculate_pareto_metrics(equity_curve, trade_df):
3576:                if trade_df is not None and not trade_df.empty and 'return' in trade_df.columns:
3577:                    profits = trade_df[trade_df['return'] > 0]['return'].sum()
3578:                    losses = abs(trade_df[trade_df['return'] < 0]['return'].sum())
3616:                if trade_df is not None and not trade_df.empty and 'trade_date' in trade_df.columns:
3617:                    trade_df['trade_date'] = pd.to_datetime(trade_df['trade_date'])
3619:                    risk_trigger_days = len(trade_df['trade_date'].dt.date.unique())
3626:            if trade_df is not None and not trade_df.empty:
3628:                if 'return' in trade_df.columns:
3629:                    profits = trade_df[trade_df['return'] > 0]['return'].sum()
3630:                    losses = abs(trade_df[trade_df['return'] < 0]['return'].sum())
3634:                if 'trade_date' in trade_df.columns:
3635:                    trade_df['trade_date'] = pd.to_datetime(trade_df['trade_date'])
3636:                    risk_trigger_days = len(trade_df['trade_date'].dt.date.unique())
3638:                    risk_trigger_days = len(trade_df)
3865:                        trade_df = None  # risk_valve_backtest 不直接提供交易記錄
3867:                        metrics = calculate_pareto_metrics(equity_curve, trade_df)
The risk valve popped trade_df and metrics. I plan to recompute and adjust them.

root@a3bd66c837b3:/workspace/SSS096# rg "build_portfolio_ledger" -n
SSS_EnsembleTab.py
363:def build_portfolio_ledger(open_px: pd.Series, w: pd.Series, cost: CostParams,
850:    daily_state, trade_ledger = build_portfolio_ledger(
1376:    daily_state1, ledger1 = build_portfolio_ledger(open_px, w, cost)
1378:    daily_state2, ledger2 = build_portfolio_ledger(open_px, w2, cost)

PORTFOLIO_LEDGER_README.md
9:### 1. `build_portfolio_ledger()` 函数
12:def build_portfolio_ledger(open_px, w, cost: CostParams, initial_capital=1_000_000.0, lot_size=None):
82:daily_state, trade_ledger = build_portfolio_ledger(
102:from SSS_EnsembleTab import build_portfolio_ledger, CostParams
112:daily_state, trade_ledger = build_portfolio_ledger(
root@a3bd66c837b3:/workspace/SSS096# sed -n '363,470p' SSS_EnsembleTab.py
def build_portfolio_ledger(open_px: pd.Series, w: pd.Series, cost: CostParams,
                          initial_capital: float = 1_000_000.0, lot_size: int | None = None) -> Tuple[pd.DataFrame, pd.DataFrame
]:
    """
    依照每日 open 價與目標權重 w_t（含 floor、delta_cap 等限制後的最終 w_t），
    產出兩個 DataFrame：
      1) daily_state: 每日現金/持倉/總資產/權重
      2) trade_ledger: 只有權重變動日的交易明細（買賣金額、費用、稅、交易後資產）
    """
    if cost is None:
        cost = CostParams()

    # 計算日報酬率
    r = open_px.shift(-1) / open_px - 1
    r = r.dropna()

    # 權益曲線
    E = pd.Series(index=r.index, dtype=float)
    E.iloc[0] = initial_capital

    # 現金曲線
    cash = pd.Series(index=r.index, dtype=float)
    cash.iloc[0] = initial_capital

    # 持倉價值曲線
    position_value = pd.Series(index=r.index, dtype=float)
    position_value.iloc[0] = 0.0

    # 交易記錄
    trades = []

    # 交易流水帳（詳細記錄）
    trade_ledger = []

    for i in range(1, len(r)):
        prev_w = w.iloc[i-1] if i-1 < len(w) else 0
        curr_w = w.iloc[i] if i < len(w) else 0

        # 權重變化
        dw = curr_w - prev_w

        if abs(dw) > 0.001:  # 有顯著變化
            # 1) 以「總權益」計執行名目金額
            exec_notional = abs(dw) * E.iloc[i-1]

            if dw > 0:  # 買入
                c = exec_notional * cost.buy_rate
                tax = 0.0
                total_cost = c

                # 計算顯示用股數（僅供 UI/報表，不影響邏輯）
                px = float(open_px.iloc[i])
                shares_before = (prev_w * E.iloc[i-1]) / px if px > 0 else 0.0
                delta_units   =  exec_notional / px if px > 0 else 0.0
                shares_after  = shares_before + delta_units

                # 交易明細（給圖表/表格）—補上權重欄位（買入也有）
                trades.append({
                    'trade_date': r.index[i],
                    'type': 'buy',
                    'price_open': float(open_px.iloc[i]),
                    'price': float(open_px.iloc[i]),
                    'weight_change': float(dw),          # signed dw
                    'w_before': float(prev_w),
                    'w_after': float(curr_w),
                    'shares_before': float(shares_before),
                    'shares_after': float(shares_after),
                    'exec_notional': float(exec_notional),
                    'equity_after': float(E.iloc[i-1]),  # 交易發生在 i 開盤，交易後的總資產(名目)≈前一日 E 扣費用
                    'cash_after': np.nan                 # 真正的日終現金在 daily_state 內，這裡僅供 UI 百分比推導（可選）
                })

                # 交易流水帳（詳細）
                trade_ledger.append({
                    'date': r.index[i],
                    'type': 'buy',
                    'open': open_px.iloc[i],
                    'delta_units': delta_units,
                    'exec_notional': exec_notional,
                    'fee_buy': c,
                    'fee_sell': 0.0,
                    'tax': tax,  # 賣出才會有證交稅，這裡為 0
                    'shares_before': shares_before,
                    'shares_after': shares_after,
                    'w_before': prev_w,
                    'w_after': curr_w,
                    'cash_after': cash.iloc[i-1] - exec_notional - c,
                    'equity_open_after_trade': E.iloc[i-1] - total_cost,
                    'equity_after': E.iloc[i-1] * (1 + r.iloc[i] * curr_w) - total_cost
                })
            else:  # 賣出
                c = exec_notional * cost.sell_rate
                tax = exec_notional * cost.sell_tax_rate
                total_cost = c + tax

                # 計算顯示用數（僅供 UI/報表，不影響邏輯）
                px = float(open_px.iloc[i])
                shares_before = (prev_w * E.iloc[i-1]) / px if px > 0 else 0.0
                delta_units   = -exec_notional / px if px > 0 else 0.0
                shares_after  = shares_before + delta_units

                # 交易明細（給圖表/表格）—補上權重欄位
                trades.append({
                    'trade_date': r.index[i],
                    'type': 'sell',
                    'price_open': float(open_px.iloc[i]),
                    'price': float(open_px.iloc[i]),
                    'weight_change': float(dw),          # 負數
                    'w_before': float(prev_w),
'w_before': float(prev_w),
                    'w_after': float(curr_w),
                    'shares_before': float(shares_before),
                    'shares_after': float(shares_after),
                    'exec_notional': float(exec_notional),
                    'equity_after': float(E.iloc[i-1]),
                    'cash_after': np.nan
                })

                # 交易流水帳（詳細）
                trade_ledger.append({
                    'date': r.index[i],
                    'type': 'sell',
                    'open': open_px.iloc[i],
                    'delta_units': delta_units,
                    'exec_notional': exec_notional,
                    'fee_buy': 0.0,
                    'fee_sell': c,
                    'tax': tax,
                    'shares_before': shares_before,
                    'shares_after': shares_after,
                    'w_before': prev_w,
                    'w_after': curr_w,
                    'cash_after': cash.iloc[i-1] + exec_notional - total_cost,
                    'equity_open_after_trade': E.iloc[i-1] - total_cost,
                    'equity_after': E.iloc[i-1] * (1 + r.iloc[i] * curr_w) - total_cost
                })

            # 扣除交易成本
            E.iloc[i] = E.iloc[i-1] * (1 + r.iloc[i] * curr_w) - total_cost
            cash.iloc[i] = cash.iloc[i-1] - (dw * E.iloc[i-1] + total_cost) if dw > 0 else cash.iloc[i-1] + (abs(dw) * E.iloc[i-
1] - total_cost)
        else:
            E.iloc[i] = E.iloc[i-1] * (1 + r.iloc[i] * curr_w)
            cash.iloc[i] = cash.iloc[i-1]

        # 計算持倉價值
        position_value.iloc[i] = E.iloc[i] - cash.iloc[i]

    # 補齊權益曲線和現金曲線（包括沒有交易的天數）
    E = E.reindex(open_px.index).ffill().fillna(initial_capital)
    cash = cash.reindex(open_px.index).ffill().fillna(initial_capital)
    position_value = position_value.reindex(open_px.index).ffill().fillna(0.0)

    # 轉換交易記錄為 DataFrame
    if trades:
        trades_df = pd.DataFrame(trades)
    else:
        trades_df = pd.DataFrame(columns=['trade_date', 'type', 'price_open', 'weight_change', 'cost'])

    # 轉換交易流水帳為 DataFrame
    if trade_ledger:
        trade_ledger_df = pd.DataFrame(trade_ledger)
    else:
        trade_ledger_df = pd.DataFrame(columns=['date', 'type', 'open', 'delta_units', 'exec_notional', 'fee_buy', 'fee_sell', '
tax', 'cash_after', 'equity_after'])

    # 構建每日狀態 DataFrame
    daily_state = pd.DataFrame({
        'equity': E,
        'cash': cash,
        'position_value': position_value,
        'w': w.reindex(open_px.index).fillna(0),
        'invested_pct': position_value / E,
        'cash_pct': cash / E
    })

    return daily_state, trade_ledger_df


def equity_open_to_open(open_px: pd.Series, w: pd.Series, cost: CostParams | None = None,
                        start_equity: float = 1.0) -> Tuple[pd.Series, pd.DataFrame, pd.DataFrame, pd.DataFrame]:
    """計算 Open-to-Open 權益曲線、交易記錄、每日狀態和交易流水帳"""
    if cost is None:
        cost = CostParams()

    # 計算日報酬率
    r = open_px.shift(-1) / open_px - 1
    r = r.dropna()

    # 權益曲線
    E = pd.Series(index=r.index, dtype=float)
    E.iloc[0] = start_equity

    # 現金曲線
    cash = pd.Series(index=r.index, dtype=float)
    cash.iloc[0] = start_equity

    # 交易記錄
    trades = []

    # 交易流水帳（詳細記錄）
    trade_ledger = []

    for i in range(1, len(r)):
        prev_w = w.iloc[i-1] if i-1 < len(w) else 0
        curr_w = w.iloc[i] if i < len(w) else 0

        # 權重變化
        dw = curr_w - prev_w

        if abs(dw) > 0.001:  # 有顯著變化
            # 1) 以「總權益」計執行名目金額
            exec_notional = abs(dw) * E.iloc[i-1]

            if dw > 0:  # 買入
                c = exec_notional * cost.buy_rate
                tax = 0.0
                total_cost = c

                # 計算顯示用股數（僅供 UI/報表，不影響邏輯）
                px = float(open_px.iloc[i])
                shares_before = (prev_w * E.iloc[i-1]) / px if px > 0 else 0.0
                delta_units   =  exec_notional / px if px > 0 else 0.0
                shares_after  = shares_before + delta_units

                # 交易明細（給圖表/表格）—補上權重欄位（買入也有）
                trades.append({
                    'trade_date': r.index[i],
                    'type': 'buy',
                    'price_open': open_px.iloc[i],
                    'weight_change': dw,          # 用 signed dw，買為正、賣為負
                    'w_before': prev_w,
                    'w_after': curr_w,
                    'shares_before': shares_before,
                    'shares_after': shares_after,
                    'cost': total_cost
                })

                # 交易流水帳（詳細）
                trade_ledger.append({
                    'date': r.index[i],
                    'type': 'buy',
                    'open': open_px.iloc[i],
                    'delta_units': delta_units,
                    'exec_notional': exec_notional,
                    'fee_buy': c,
                    'fee_sell': 0.0,
                    'tax': tax,  # 賣出才會有證交稅，這裡為 0
                    'shares_before': shares_before,
                    'shares_after': shares_after,
                    'w_before': prev_w,
                    'w_after': curr_w,
I’ll keep the existing metrics and just add risk_valve metrics separately, avoiding removals.

After applying the risk valve, I'll recompute metrics using equity curve and ledger data.

I’ll compute basic metrics from equity and returns, avoiding full calculate_metrics complexity.

I’ll extend the imports in app_dash.py to include necessary functions from SSS_EnsembleTab.

I’ll recompute performance metrics and include a timestamped comment in the code.

root@a3bd66c837b3:/workspace/SSS096# date
Wed Aug 20 01:23:36 UTC 2025
I'll edit app_dash.py to restore trade_df and update metrics after key loops.

I should compute metrics before setting _risk_valve_applied. I'll edit with sed to implement this.

root@a3bd66c837b3:/workspace/SSS096# sed -n '1270,1310p' app_dash.py
                            cap_level=1.0,
                        )
                    except Exception as e:
                        logger.warning(f"[{strat}] 無法導入 risk_valve_backtest: {e}")
                        result_cap = None

                    if result_cap:
                        # === 安全覆寫：清掉舊鍵並補齊新鍵 ===
                        logger.info(f"[UI_CHECK] 即將覆寫：new_trades={len(result_cap.get('trade_ledger_valve', pd.DataFrame()))
} rows, new_ds={len(result_cap.get('daily_state_valve', pd.DataFrame()))} rows")

                        # 1) 覆寫結果 —— 一律用 pack_df/pack_series
                        if 'trade_ledger_valve' in result_cap:
                            result['trades'] = pack_df(result_cap['trade_ledger_valve'])
                            result['trade_ledger'] = pack_df(result_cap['trade_ledger_valve'])
                            result['trade_ledger_std'] = pack_df(result_cap['trade_ledger_valve'])

                        if 'daily_state_valve' in result_cap:
                            result['daily_state'] = pack_df(result_cap['daily_state_valve'])
                            result['daily_state_std'] = pack_df(result_cap['daily_state_valve'])

                        if 'weights_valve' in result_cap:
                            result['weight_curve'] = pack_series(result_cap['weights_valve'])

                        # 權益曲線：若是 Series
                        if 'daily_state_valve' in result_cap and 'equity' in result_cap['daily_state_valve']:
                            try:
                                result['equity_curve'] = pack_series(result_cap['daily_state_valve']['equity'])
                            except Exception:
                                # 若你存的是 DataFrame
                                result['equity_curve'] = pack_df(result_cap['daily_state_valve']['equity'].to_frame('equity'))

                        # 2) **關鍵**：把 UI 可能拿來用的舊快取清掉，強迫 UI 走新資料
                        for k in ['trades_ui', 'trade_df', 'trade_ledger_std', 'metrics']:
                            if k in result:
                                result.pop(k, None)

                        # 3) 給 UI 一個旗標與參數，便於顯示「已套用」
                        result['_risk_valve_applied'] = True
                        result['_risk_valve_params'] = {
                            'cap': float(risk_cap),
                            'atr_ratio': float(atr_ratio),
I'll add setting trade_df after trade_ledger and daily_state. Also, I'll import the necessary functions and compute metrics accordingly.

root@a3bd66c837b3:/workspace/SSS096# sed -n '1250,1330p' app_dash.py

                        # 基準（有高低價就帶上）
                        bench = pd.DataFrame(index=pd.to_datetime(df_raw.index))
                        if 'close' in df_raw.columns:
                            bench["收盤價"] = pd.to_numeric(df_raw["close"], errors="coerce")
                        elif '收盤價' in df_raw.columns:
                            bench["收盤價"] = pd.to_numeric(df_raw["收盤價"], errors="coerce")
                        if 'high' in df_raw.columns and 'low' in df_raw.columns:
                            bench["最高價"] = pd.to_numeric(df_raw["high"], errors="coerce")
                            bench["最低價"] = pd.to_numeric(df_raw["low"], errors="coerce")
                        elif '最高價' in df_raw.columns and '最低價' in df_raw.columns:
                            bench["最高價"] = pd.to_numeric(df_raw["最高價"], errors="coerce")
                            bench["最低價"] = pd.to_numeric(df_raw["最低價"], errors="coerce")

                        result_cap = risk_valve_backtest(
                            open_px=open_px,
                            w=ds["w"].astype(float).reindex(open_px.index).fillna(0.0),
                            cost=cost,
                            benchmark_df=bench,
                            mode="cap",
                            cap_level=1.0,
                        )
                    except Exception as e:
                        logger.warning(f"[{strat}] 無法導入 risk_valve_backtest: {e}")
                        result_cap = None

                    if result_cap:
                        # === 安全覆寫：清掉舊鍵並補齊新鍵 ===
                        logger.info(f"[UI_CHECK] 即將覆寫：new_trades={len(result_cap.get('trade_ledger_valve', pd.DataFrame()))
} rows, new_ds={len(result_cap.get('daily_state_valve', pd.DataFrame()))} rows")

                        # 1) 覆寫結果 —— 一律用 pack_df/pack_series
                        if 'trade_ledger_valve' in result_cap:
                            result['trades'] = pack_df(result_cap['trade_ledger_valve'])
                            result['trade_ledger'] = pack_df(result_cap['trade_ledger_valve'])
                            result['trade_ledger_std'] = pack_df(result_cap['trade_ledger_valve'])

                        if 'daily_state_valve' in result_cap:
                            result['daily_state'] = pack_df(result_cap['daily_state_valve'])
                            result['daily_state_std'] = pack_df(result_cap['daily_state_valve'])

                        if 'weights_valve' in result_cap:
                            result['weight_curve'] = pack_series(result_cap['weights_valve'])

                        # 權益曲線：若是 Series
                        if 'daily_state_valve' in result_cap and 'equity' in result_cap['daily_state_valve']:
                            try:
                                result['equity_curve'] = pack_series(result_cap['daily_state_valve']['equity'])
                            except Exception:
                                # 若你存的是 DataFrame
                                result['equity_curve'] = pack_df(result_cap['daily_state_valve']['equity'].to_frame('equity'))

                        # 2) **關鍵**：把 UI 可能拿來用的舊快取清掉，強迫 UI 走新資料
                        for k in ['trades_ui', 'trade_df', 'trade_ledger_std', 'metrics']:
                            if k in result:
                                result.pop(k, None)

                        # 3) 給 UI 一個旗標與參數，便於顯示「已套用」
                        result['_risk_valve_applied'] = True
                        result['_risk_valve_params'] = {
                            'cap': float(risk_cap),
                            'atr_ratio': float(atr_ratio),
                            'atr20_last': float(atr_20_valid.iloc[-1]) if len(atr_20_valid) > 0 else None,
                            'atr60_last': float(atr_60_valid.iloc[-1]) if len(atr_60_valid) > 0 else None,
                        }

                        true_days = int(mask_aligned.sum())
                        logger.info(f"[{strat}] 全局風險閥門已套用（逐日），風險天數={true_days}, CAP={risk_cap:.2f}")
                    else:
                        logger.warning(f"[{strat}] 風險閥門重算沒有返回結果")

        results[strat] = result

    # 使用第一個策略的數據作為主要顯示數據
    first_strat = list(results.keys())[0] if results else strategy_names[0]
    first_smaa_src = param_presets[first_strat].get("smaa_source", "Self")
    df_raw_main, _ = load_data(ticker, start_date, end_date if end_date else None, smaa_source=first_smaa_src)

    # 統一使用 orient="split" 序列化，確保一致性
    payload = {
        'results': results,
        'df_raw': df_raw_main.to_json(date_format='iso', orient='split'),
I need to import risk_valve_backtest, CostParams, and do some metric assignments.

root@a3bd66c837b3:/workspace/SSS096# apply_patch <<'PATCH'
_return': float(total> *** Begin Patch
_ret),
+        > *** Update File: app_dash.py
> @@
al_> -                        from SSS_EnsembleTab import risk_valve_backtest, CostParams
> +                        from SSS_EnsembleTab import (
tio> +                            risk_valve_backtest,
> +                            CostParams,
> +                            _mdd_from_daily_equity,
> +                            _sell_returns_pct_from_ledger,
 > +                        )
> @@
> -                        if 'trade_ledger_valve' in result_cap:
> -                            result['trades'] = pack_df(result_cap['trade_ledger_valve'])
> -                            result['trade_ledger'] = pack_df(result_cap['trade_ledger_valve'])
> -                            result['trade_ledger_std'] = pack_df(result_cap['trade_ledger_valve'])
> +                        if 'trade_ledger_valve' in result_cap:
f not np.isnan(sharpe) else np.nan,
+             > +                            result['trades'] = pack_df(result_cap['trade_ledger_valve'])
> +                            result['trade_ledger'] = pack_df(result_cap['trade_ledger_valve'])
           > +                            result['trade_ledger_std'] = pack_df(result_cap['trade_ledger_valve'])
> +                            result['trade_df'] = pack_df(result_cap['trade_ledger_valve'])
> @@
> -                        for k in ['trades_ui', 'trade_df', 'trade_ledger_std', 'metrics']:
> +                        for k in ['trades_ui', 'trade_df', 'trade_ledger_std', 'metrics']:
>                              if k in result:
>                                  result.pop(k, None)
> +
> +                        # 2025-08-20 重算指標以保留績效資訊 #app_dash.py
> +                        ledger_valve = result_cap.get('trade_ledger_valve', pd.DataFrame())
> +                        ds_valve = result_cap.get('daily_state_valve', pd.DataFrame())
> +                        if not ledger_valve.empty and not ds_valve.empty and 'equity' in ds_valve:
> +                            r = _sell_returns_pct_from_ledger(ledger_valve)
> +                            eq = ds_valve['equity']
> +                            total_ret = eq.iloc[-1] / eq.iloc[0] - 1
> +                            years = max((eq.index[-1] - eq.index[0]).days / 365.25, 1)
> +                            ann_ret = (1 + total_ret) ** (1 / years) - 1
> +                            mdd = _mdd_from_daily_equity(eq)
> +                            dd = eq / eq.cummax() - 1
> +                            blocks = (~(dd < 0)).cumsum()
> +                            dd_dur = int((dd.groupby(blocks).cumcount() + 1).where(dd < 0).max() or 0)
> +                            num_trades = len(r)
> +                            win_rate = (r > 0).sum() / num_trades if num_trades > 0 else 0
> +                            avg_win = r[r > 0].mean() if win_rate > 0 else np.nan
> +                            avg_loss = r[r < 0].mean() if win_rate < 1 else np.nan
> +                            payoff = abs(avg_win / avg_loss) if avg_loss != 0 and not np.isnan(avg_win) else np.nan
> +                            daily_r = eq.pct_change().dropna()
> +                            sharpe = (daily_r.mean() * np.sqrt(252)) / daily_r.std() if daily_r.std() != 0 else np.nan
> +                            downside = daily_r[daily_r < 0]
> +                            sortino = (daily_r.mean() * np.sqrt(252)) / downside.std() if downside.std() != 0 else np.nan
> +                            ann_vol = daily_r.std() * np.sqrt(252) if len(daily_r) > 0 else np.nan
> +                            prof = r[r > 0].sum()
> +                            loss = abs(r[r < 0].sum())
> +                            pf = prof / loss if loss != 0 else np.nan
> +                            win_flag = r > 0
> +                            grp = (win_flag != win_flag.shift()).cumsum()
> +                            consec = win_flag.groupby(grp).cumcount() + 1
> +                            max_wins = int(consec[win_flag].max() if True in win_flag.values else 0)
> +                            max_losses = int(consec[~win_flag].max() if False in win_flag.values else 0)
> +                            result['metrics'] = {
> +                                'total_return': float(total_ret),
> +                                'annual_return': float(ann_ret),
> +                                'max_drawdown': float(mdd),
> +                                'max_drawdown_duration': dd_dur,
> +                                'calmar_ratio': float(ann_ret / abs(mdd)) if mdd < 0 else np.nan,
> +                                'num_trades': int(num_trades),
> +                                'win_rate': float(win_rate),
> +                                'avg_win': float(avg_win) if not np.isnan(avg_win) else np.nan,
> +                                'avg_loss': float(avg_loss) if not np.isnan(avg_loss) else np.nan,
> +                                'payoff_ratio': float(payoff) if not np.isnan(payoff) else np.nan,
> +                                'sharpe_ratio': float(sharpe) if not np.isnan(sharpe) else np.nan,
> +                                'sortino_ratio': float(sortino) if not np.isnan(sortino) else np.nan,
> +                                'max_consecutive_wins': max_wins,
> +                                'max_consecutive_losses': max_losses,
> +                                'annualized_volatility': float(ann_vol) if not np.isnan(ann_vol) else np.nan,
> +                                'profit_factor': float(pf) if not np.isnan(pf) else np.nan,
> +                            }
> *** End Patch
> PATCH
Success. Updated the following files:
M app_dash.py
Patch succeeded, but I should verify pandas and numpy imports. Running git status next.

root@a3bd66c837b3:/workspace/SSS096# git status --short
 M app_dash.py
root@a3bd66c837b3:/workspace/SSS096# powershell -ExecutionPolicy Bypass -File tools\quick_check.ps1
bash: command not found: powershell
I'll give pwsh a shot since the PowerShell command isn't found.

root@a3bd66c837b3:/workspace/SSS096# pwsh -Command ./tools/quick_check.ps1
bash: command not found: pwsh
The container lacks PowerShell. I'll attempt to install it with apt-get, but it might not work.

root@a3bd66c837b3:/workspace/SSS096# apt-get update >/tmp/apt.log && tail -n 20 /tmp/apt.log


^C
root@a3bd66c837b3:/workspace/SSS096# tail -n 20 /tmp/apt.log
Err:1 http://security.ubuntu.com/ubuntu noble-security InRelease
  403  Forbidden [IP: 172.30.2.131 8080]
Err:2 http://apt.llvm.org/noble llvm-toolchain-noble-20 InRelease
  403  Forbidden [IP: 172.30.2.131 8080]
Ign:3 https://mise.jdx.dev/deb stable InRelease
Err:4 http://archive.ubuntu.com/ubuntu noble InRelease
  403  Forbidden [IP: 172.30.2.131 8080]
Err:5 http://archive.ubuntu.com/ubuntu noble-updates InRelease
  403  Forbidden [IP: 172.30.2.131 8080]
Err:6 http://archive.ubuntu.com/ubuntu noble-backports InRelease
  403  Forbidden [IP: 172.30.2.131 8080]
Ign:3 https://mise.jdx.dev/deb stable InRelease
Ign:3 https://mise.jdx.dev/deb stable InRelease
Since no internet, I can't install PowerShell. I'll note failed attempt in the message and test log. I'll also run python -m py_compile app_dash.py to check for syntax errors.

root@a3bd66c837b3:/workspace/SSS096# python -m py_compile app_dash.py
I'm including a timestamp and Chinese comment, confirming it's in the code with git diff.

root@a3bd66c837b3:/workspace/SSS096# git diff --staged
root@a3bd66c837b3:/workspace/SSS096# git add app_dash.py
root@a3bd66c837b3:/workspace/SSS096# git status --short
M  app_dash.py
?? __pycache__/
I need to remove pycache from git status since it shouldn't be committed.

root@a3bd66c837b3:/workspace/SSS096# git clean -fd __pycache__
Removing __pycache__/
root@a3bd66c837b3:/workspace/SSS096# git status --short
M  app_dash.py
Ah, M means modified but not staged. If no space, it’s staged already.

diff --git a/app_dash.py b/app_dash.py
index 6685ece..f2cb263 100644
--- a/app_dash.py
+++ b/app_dash.py
@@ -1237,7 +1237,12 @@ def run_backtest(n_clicks, auto_run, ticker, start_date, end_date, discount, coo

                     # 若你沿用現有的 risk_valve_backtest，給 cap_level=1.0 表示「w 已經是目標序列」
                     try:
-                        from SSS_EnsembleTab import risk_valve_backtest, CostParams
+                        from SSS_EnsembleTab import (
+                            risk_valve_backtest,
+                            CostParams,
+                            _mdd_from_daily_equity,
+                            _sell_returns_pct_from_ledger,
+                        )

                         # 成本參數
                         trade_cost = (strat_params.get("trade_cost", {})
@@ -1282,6 +1287,7 @@ def run_backtest(n_clicks, auto_run, ticker, start_date, end_date, discount, coo
                             result['trades'] = pack_df(result_cap['trade_ledger_valve'])
                             result['trade_ledger'] = pack_df(result_cap['trade_ledger_valve'])
                             result['trade_ledger_std'] = pack_df(result_cap['trade_ledger_valve'])
+                            result['trade_df'] = pack_df(result_cap['trade_ledger_valve'])

                         if 'daily_state_valve' in result_cap:
                             result['daily_state'] = pack_df(result_cap['daily_state_valve'])
@@ -1302,6 +1308,56 @@ def run_backtest(n_clicks, auto_run, ticker, start_date, end_date, discount, coo
                         for k in ['trades_ui', 'trade_df', 'trade_ledger_std', 'metrics']:
                             if k in result:
                                 result.pop(k, None)
+
+                        # 2025-08-20 重算指標以保留績效資訊 #app_dash.py
+                        ledger_valve = result_cap.get('trade_ledger_valve', pd.DataFrame())
+                        ds_valve = result_cap.get('daily_state_valve', pd.DataFrame())
+                        if not ledger_valve.empty and not ds_valve.empty and 'equity' in ds_valve:
+                            r = _sell_returns_pct_from_ledger(ledger_valve)
+                            eq = ds_valve['equity']
+                            total_ret = eq.iloc[-1] / eq.iloc[0] - 1
+                            years = max((eq.index[-1] - eq.index[0]).days / 365.25, 1)
+                            ann_ret = (1 + total_ret) ** (1 / years) - 1
+                            mdd = _mdd_from_daily_equity(eq)
+                            dd = eq / eq.cummax() - 1
+                            blocks = (~(dd < 0)).cumsum()
+                            dd_dur = int((dd.groupby(blocks).cumcount() + 1).where(dd < 0).max() or 0)
+                            num_trades = len(r)
+                            win_rate = (r > 0).sum() / num_trades if num_trades > 0 else 0
+                            avg_win = r[r > 0].mean() if win_rate > 0 else np.nan
+                            avg_loss = r[r < 0].mean() if win_rate < 1 else np.nan
+                            payoff = abs(avg_win / avg_loss) if avg_loss != 0 and not np.isnan(avg_win) else np.nan
+                            daily_r = eq.pct_change().dropna()
+                            sharpe = (daily_r.mean() * np.sqrt(252)) / daily_r.std() if daily_r.std() != 0 else np.nan
+                            downside = daily_r[daily_r < 0]
+                            sortino = (daily_r.mean() * np.sqrt(252)) / downside.std() if downside.std() != 0 else np.nan
+                            ann_vol = daily_r.std() * np.sqrt(252) if len(daily_r) > 0 else np.nan
+                            prof = r[r > 0].sum()
+                            loss = abs(r[r < 0].sum())
+                            pf = prof / loss if loss != 0 else np.nan
+                            win_flag = r > 0
+                            grp = (win_flag != win_flag.shift()).cumsum()
+                            consec = win_flag.groupby(grp).cumcount() + 1
+                            max_wins = int(consec[win_flag].max() if True in win_flag.values else 0)
+                            max_losses = int(consec[~win_flag].max() if False in win_flag.values else 0)
+                            result['metrics'] = {
+                                'total_return': float(total_ret),
+                                'annual_return': float(ann_ret),
+                                'max_drawdown': float(mdd),
+                                'max_drawdown_duration': dd_dur,
+                                'calmar_ratio': float(ann_ret / abs(mdd)) if mdd < 0 else np.nan,
+                                'num_trades': int(num_trades),
+                                'win_rate': float(win_rate),
+                                'avg_win': float(avg_win) if not np.isnan(avg_win) else np.nan,
+                                'avg_loss': float(avg_loss) if not np.isnan(avg_loss) else np.nan,
+                                'payoff_ratio': float(payoff) if not np.isnan(payoff) else np.nan,
+                                'sharpe_ratio': float(sharpe) if not np.isnan(sharpe) else np.nan,
+                                'sortino_ratio': float(sortino) if not np.isnan(sortino) else np.nan,
+                                'max_consecutive_wins': max_wins,
+                                'max_consecutive_losses': max_losses,
+                                'annualized_volatility': float(ann_vol) if not np.isnan(ann_vol) else np.nan,
+                                'profit_factor': float(pf) if not np.isnan(pf) else np.nan,
+                            }

                         # 3) 給 UI 一個旗標與參數，便於顯示「已套用」
                         result['_risk_valve_applied'] = True
The diff includes necessary comment and modifications. Timestamp and path comment look good!

root@a3bd66c837b3:/workspace/SSS096# git commit -m "fix risk valve metrics" && git status --short
[work c4d695b] fix risk valve metrics
 1 file changed, 57 insertions(+), 1 deletion(-)
root@a3bd66c837b3:/workspace/SSS096# git status --short
I'll grab the line numbers in app_dash.py by running nl -ba for citation.

root@a3bd66c837b3:/workspace/SSS096# nl -ba app_dash.py | sed -n '1237,1320p'
  1237
  1238                      # 若你沿用現有的 risk_valve_backtest，給 cap_level=1.0 表示「w 已經是目標序列」
  1239                      try:
  1240                          from SSS_EnsembleTab import (
  1241                              risk_valve_backtest,
  1242                              CostParams,
  1243                              _mdd_from_daily_equity,
  1244                              _sell_returns_pct_from_ledger,
  1245                          )
  1246
  1247                          # 成本參數
  1248                          trade_cost = (strat_params.get("trade_cost", {})
  1249                                        if isinstance(strat_params, dict) else {})
  1250                          cost = CostParams(
  1251                              buy_fee_bp=float(trade_cost.get("buy_fee_bp", 4.27)),
  1252                              sell_fee_bp=float(trade_cost.get("sell_fee_bp", 4.27)),
  1253                              sell_tax_bp=float(trade_cost.get("sell_tax_bp", 30.0)),
  1254                          )
  1255
  1256                          # 基準（有高低價就帶上）
  1257                          bench = pd.DataFrame(index=pd.to_datetime(df_raw.index))
  1258                          if 'close' in df_raw.columns:
  1259                              bench["收盤價"] = pd.to_numeric(df_raw["close"], errors="coerce")
  1260                          elif '收盤價' in df_raw.columns:
  1261                              bench["收盤價"] = pd.to_numeric(df_raw["收盤價"], errors="coerce")
  1262                          if 'high' in df_raw.columns and 'low' in df_raw.columns:
  1263                              bench["最高價"] = pd.to_numeric(df_raw["high"], errors="coerce")
  1264                              bench["最低價"] = pd.to_numeric(df_raw["low"], errors="coerce")
  1265                          elif '最高價' in df_raw.columns and '最低價' in df_raw.columns:
  1266                              bench["最高價"] = pd.to_numeric(df_raw["最高價"], errors="coerce")
  1267                              bench["最低價"] = pd.to_numeric(df_raw["最低價"], errors="coerce")
  1268
  1269                          result_cap = risk_valve_backtest(
  1270                              open_px=open_px,
  1271                              w=ds["w"].astype(float).reindex(open_px.index).fillna(0.0),
  1272                              cost=cost,
  1273                              benchmark_df=bench,
  1274                              mode="cap",
  1275                              cap_level=1.0,
  1276                          )
  1277                      except Exception as e:
  1278                          logger.warning(f"[{strat}] 無法導入 risk_valve_backtest: {e}")
  1279                          result_cap = None
  1280
  1281                      if result_cap:
  1282                          # === 安全覆寫：清掉舊鍵並補齊新鍵 ===
  1283                          logger.info(f"[UI_CHECK] 即將覆寫：new_trades={len(result_cap.get('trade_ledger_valve', pd.DataF
rame()))} rows, new_ds={len(result_cap.get('daily_state_valve', pd.DataFrame()))} rows")
  1284
  1285                          # 1) 覆寫結果 —— 一律用 pack_df/pack_series
  1286                          if 'trade_ledger_valve' in result_cap:
  1287                              result['trades'] = pack_df(result_cap['trade_ledger_valve'])
  1288                              result['trade_ledger'] = pack_df(result_cap['trade_ledger_valve'])
  1289                              result['trade_ledger_std'] = pack_df(result_cap['trade_ledger_valve'])
  1290                              result['trade_df'] = pack_df(result_cap['trade_ledger_valve'])
  1291
  1292                          if 'daily_state_valve' in result_cap:
  1293                              result['daily_state'] = pack_df(result_cap['daily_state_valve'])
  1294                              result['daily_state_std'] = pack_df(result_cap['daily_state_valve'])
  1295
  1296                          if 'weights_valve' in result_cap:
  1297                              result['weight_curve'] = pack_series(result_cap['weights_valve'])
  1298
  1299                          # 權益曲線：若是 Series
  1300                          if 'daily_state_valve' in result_cap and 'equity' in result_cap['daily_state_valve']:
  1301                              try:
  1302                                  result['equity_curve'] = pack_series(result_cap['daily_state_valve']['equity'])
  1303                              except Exception:
  1304                                  # 若你存的是 DataFrame
  1305                                  result['equity_curve'] = pack_df(result_cap['daily_state_valve']['equity'].to_frame('equ
ity'))
  1306
  1307                          # 2) **關鍵**：把 UI 可能拿來用的舊快取清掉，強迫 UI 走新資料
  1308                          for k in ['trades_ui', 'trade_df', 'trade_ledger_std', 'metrics']:
  1309                              if k in result:
  1310                                  result.pop(k, None)
  1311
  1312                          # 2025-08-20 重算指標以保留績效資訊 #app_dash.py
  1313                          ledger_valve = result_cap.get('trade_ledger_valve', pd.DataFrame())
  1314                          ds_valve = result_cap.get('daily_state_valve', pd.DataFrame())
  1315                          if not ledger_valve.empty and not ds_valve.empty and 'equity' in ds_valve:
  1316                              r = _sell_returns_pct_from_ledger(ledger_valve)
  1317                              eq = ds_valve['equity']
  1318                              total_ret = eq.iloc[-1] / eq.iloc[0] - 1
  1319                              years = max((eq.index[-1] - eq.index[0]).days / 365.25, 1)
  1320                              ann_ret = (1 + total_ret) ** (1 / years) - 1
root@a3bd66c837b3:/workspace/SSS096# nl -ba app_dash.py | sed -n '1320,1360p'
  1320                              ann_ret = (1 + total_ret) ** (1 / years) - 1
  1321                              mdd = _mdd_from_daily_equity(eq)
  1322                              dd = eq / eq.cummax() - 1
  1323                              blocks = (~(dd < 0)).cumsum()
  1324                              dd_dur = int((dd.groupby(blocks).cumcount() + 1).where(dd < 0).max() or 0)
  1325                              num_trades = len(r)
  1326                              win_rate = (r > 0).sum() / num_trades if num_trades > 0 else 0
  1327                              avg_win = r[r > 0].mean() if win_rate > 0 else np.nan
  1328                              avg_loss = r[r < 0].mean() if win_rate < 1 else np.nan
  1329                              payoff = abs(avg_win / avg_loss) if avg_loss != 0 and not np.isnan(avg_win) else np.nan
  1330                              daily_r = eq.pct_change().dropna()
  1331                              sharpe = (daily_r.mean() * np.sqrt(252)) / daily_r.std() if daily_r.std() != 0 else np.nan
  1332                              downside = daily_r[daily_r < 0]
  1333                              sortino = (daily_r.mean() * np.sqrt(252)) / downside.std() if downside.std() != 0 else np.na
n
  1334                              ann_vol = daily_r.std() * np.sqrt(252) if len(daily_r) > 0 else np.nan
  1335                              prof = r[r > 0].sum()
  1336                              loss = abs(r[r < 0].sum())
  1337                              pf = prof / loss if loss != 0 else np.nan
  1338                              win_flag = r > 0
  1339                              grp = (win_flag != win_flag.shift()).cumsum()
  1340                              consec = win_flag.groupby(grp).cumcount() + 1
  1341                              max_wins = int(consec[win_flag].max() if True in win_flag.values else 0)
  1342                              max_losses = int(consec[~win_flag].max() if False in win_flag.values else 0)
  1343                              result['metrics'] = {
  1344                                  'total_return': float(total_ret),
  1345                                  'annual_return': float(ann_ret),
  1346                                  'max_drawdown': float(mdd),
  1347                                  'max_drawdown_duration': dd_dur,
  1348                                  'calmar_ratio': float(ann_ret / abs(mdd)) if mdd < 0 else np.nan,
  1349                                  'num_trades': int(num_trades),
  1350                                  'win_rate': float(win_rate),
  1351                                  'avg_win': float(avg_win) if not np.isnan(avg_win) else np.nan,
  1352                                  'avg_loss': float(avg_loss) if not np.isnan(avg_loss) else np.nan,
  1353                                  'payoff_ratio': float(payoff) if not np.isnan(payoff) else np.nan,
  1354                                  'sharpe_ratio': float(sharpe) if not np.isnan(sharpe) else np.nan,
  1355                                  'sortino_ratio': float(sortino) if not np.isnan(sortino) else np.nan,
  1356                                  'max_consecutive_wins': max_wins,
  1357                                  'max_consecutive_losses': max_losses,
  1358                                  'annualized_volatility': float(ann_vol) if not np.isnan(ann_vol) else np.nan,
  1359                                  'profit_factor': float(pf) if not np.isnan(pf) else np.nan,
  1360                              }
I'll finalize the PR message describing the fix, testing, and references to logs.

I'll prepare the final message in Chinese, summarizing code changes and including necessary citations.

I'll summarize: metrics recalculated using ledger and equity; testing successful except powershell installation failure.