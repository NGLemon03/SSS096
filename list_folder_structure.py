#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ—å‡ºæ•´å€‹æ–‡ä»¶å¤¾çš„æ¶æ§‹å’Œæ–‡ä»¶
æ’é™¤ä»¥ . é–‹é ­çš„éš±è—æ–‡ä»¶å¤¾
"""

import os
from pathlib import Path
import json
from datetime import datetime
import logging

# è¨­ç½® logger
from analysis.logging_config import LOGGING_DICT
import logging.config
logging.config.dictConfig(LOGGING_DICT)
logger = logging.getLogger("SSS.ListFolder")

def get_file_size_str(size_bytes):
    """å°‡å­—ç¯€æ•¸è½‰æ›ç‚ºäººé¡å¯è®€çš„æ–‡ä»¶å¤§å°å­—ç¬¦ä¸²"""
    if size_bytes == 0:
        return "0 B"
    
    size_names = ["B", "KB", "MB", "GB", "TB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024.0
        i += 1
    
    if i == 0:
        return f"{size_bytes:.0f} {size_names[i]}"
    else:
        return f"{size_bytes:.1f} {size_names[i]}"

def scan_directory(root_path, max_depth=10, current_depth=0):
    """æƒæç›®éŒ„çµæ§‹"""
    if current_depth > max_depth:
        return None
    
    root_path = Path(root_path)
    if not root_path.exists():
        return None
    
    result = {
        "name": root_path.name,
        "path": str(root_path),
        "type": "directory",
        "size": 0,
        "items": [],
        "file_count": 0,
        "dir_count": 0
    }
    
    try:
        # ç²å–ç›®éŒ„å…§å®¹ï¼Œæ’é™¤éš±è—æ–‡ä»¶å¤¾
        items = [item for item in root_path.iterdir() 
                if not item.name.startswith('.')]
        
        # åˆ†åˆ¥è™•ç†æ–‡ä»¶å’Œæ–‡ä»¶å¤¾
        files = [item for item in items if item.is_file()]
        dirs = [item for item in items if item.is_dir()]
        
        # çµ±è¨ˆæ–‡ä»¶æ•¸é‡
        result["file_count"] = len(files)
        result["dir_count"] = len(dirs)
        
        # è™•ç†æ–‡ä»¶
        for file_path in sorted(files):
            try:
                file_stat = file_path.stat()
                file_info = {
                    "name": file_path.name,
                    "path": str(file_path),
                    "type": "file",
                    "size": file_stat.st_size,
                    "size_str": get_file_size_str(file_stat.st_size),
                    "modified": datetime.fromtimestamp(file_stat.st_mtime).strftime("%Y-%m-%d %H:%M:%S"),
                    "extension": file_path.suffix.lower()
                }
                result["items"].append(file_info)
                result["size"] += file_stat.st_size
            except (OSError, PermissionError):
                # è·³éç„¡æ³•è¨ªå•çš„æ–‡ä»¶
                continue
        
        # è™•ç†æ–‡ä»¶å¤¾ï¼ˆéæ­¸ï¼‰
        for dir_path in sorted(dirs):
            try:
                dir_info = scan_directory(dir_path, max_depth, current_depth + 1)
                if dir_info:
                    result["items"].append(dir_info)
                    result["size"] += dir_info["size"]
            except (OSError, PermissionError):
                # è·³éç„¡æ³•è¨ªå•çš„æ–‡ä»¶å¤¾
                continue
        
        # æ·»åŠ ç¸½å¤§å°å­—ç¬¦ä¸²
        result["size_str"] = get_file_size_str(result["size"])
        
    except (OSError, PermissionError):
        # ç„¡æ³•è¨ªå•ç›®éŒ„
        return None
    
    return result

def print_structure(data, indent=0, show_details=True):
    """æ‰“å°ç›®éŒ„çµæ§‹åˆ°æ§åˆ¶æ±"""
    if not data:
        return
    
    prefix = "  " * indent
    
    if data["type"] == "directory":
        logger.info(f"{prefix}ğŸ“ {data['name']}/")
        if show_details:
            logger.info(f"{prefix}   ğŸ“Š æ–‡ä»¶: {data['file_count']}, æ–‡ä»¶å¤¾: {data['dir_count']}, ç¸½å¤§å°: {data['size_str']}")
        
        # éæ­¸æ‰“å°å­é …ç›®
        for item in data["items"]:
            print_structure(item, indent + 1, show_details)
    
    elif data["type"] == "file":
        if show_details:
                    logger.info(f"{prefix}ğŸ“„ {data['name']} ({data['size_str']}, {data['modified']})")
    else:
        logger.info(f"{prefix}ğŸ“„ {data['name']}")

def print_structure_to_list(data, output_lines, indent=0, show_details=True):
    """å°‡ç›®éŒ„çµæ§‹è¼¸å‡ºåˆ°åˆ—è¡¨ä¸­"""
    if not data:
        return
    
    prefix = "  " * indent
    
    if data["type"] == "directory":
        output_lines.append(f"{prefix}ğŸ“ {data['name']}/")
        if show_details:
            output_lines.append(f"{prefix}   ğŸ“Š æ–‡ä»¶: {data['file_count']}, æ–‡ä»¶å¤¾: {data['dir_count']}, ç¸½å¤§å°: {data['size_str']}")
        
        # éæ­¸è™•ç†å­é …ç›®
        for item in data["items"]:
            print_structure_to_list(item, output_lines, indent + 1, show_details)
    
    elif data["type"] == "file":
        if show_details:
            output_lines.append(f"{prefix}ğŸ“„ {data['name']} ({data['size_str']}, {data['modified']})")
        else:
            output_lines.append(f"{prefix}ğŸ“„ {data['name']}")

def generate_summary(data):
    """ç”Ÿæˆçµ±è¨ˆæ‘˜è¦"""
    if not data:
        return {}
    
    summary = {
        "total_files": 0,
        "total_dirs": 0,
        "total_size": 0,
        "file_extensions": {},
        "largest_files": [],
        "largest_dirs": []
    }
    
    def collect_stats(item):
        if item["type"] == "file":
            summary["total_files"] += 1
            summary["total_size"] += item["size"]
            
            # çµ±è¨ˆæ–‡ä»¶æ“´å±•å
            ext = item["extension"]
            if ext:
                summary["file_extensions"][ext] = summary["file_extensions"].get(ext, 0) + 1
            
            # è¨˜éŒ„å¤§æ–‡ä»¶
            summary["largest_files"].append({
                "name": item["name"],
                "path": item["path"],
                "size": item["size"],
                "size_str": item["size_str"]
            })
        
        elif item["type"] == "directory":
            summary["total_dirs"] += 1
            summary["total_size"] += item["size"]
            
            # è¨˜éŒ„å¤§æ–‡ä»¶å¤¾
            summary["largest_dirs"].append({
                "name": item["name"],
                "path": item["path"],
                "size": item["size"],
                "size_str": item["size_str"]
            })
            
            # éæ­¸çµ±è¨ˆå­é …ç›®
            for sub_item in item["items"]:
                collect_stats(sub_item)
    
    collect_stats(data)
    
    # æ’åºå¤§æ–‡ä»¶å’Œå¤§æ–‡ä»¶å¤¾
    summary["largest_files"].sort(key=lambda x: x["size"], reverse=True)
    summary["largest_dirs"].sort(key=lambda x: x["size"], reverse=True)
    
    return summary

def main():
    """ä¸»å‡½æ•¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description='åˆ—å‡ºæ–‡ä»¶å¤¾çµæ§‹')
    parser.add_argument('path', nargs='?', default='.', help='è¦æƒæçš„è·¯å¾‘ï¼ˆé»˜èªç‚ºç•¶å‰ç›®éŒ„ï¼‰')
    parser.add_argument('--max-depth', type=int, default=10, help='æœ€å¤§æƒææ·±åº¦ï¼ˆé»˜èª10ï¼‰')
    parser.add_argument('--no-details', action='store_true', help='ä¸é¡¯ç¤ºè©³ç´°ä¿¡æ¯')
    parser.add_argument('--json', action='store_true', help='è¼¸å‡ºJSONæ ¼å¼')
    parser.add_argument('--summary', action='store_true', help='åªé¡¯ç¤ºçµ±è¨ˆæ‘˜è¦')
    parser.add_argument('--output', default='list.txt', help='è¼¸å‡ºæ–‡ä»¶åï¼ˆé»˜èªlist.txtï¼‰')
    
    args = parser.parse_args()
    
    # æº–å‚™è¼¸å‡ºå…§å®¹
    output_lines = []
    
    output_lines.append(f"ğŸ” æƒæç›®éŒ„: {os.path.abspath(args.path)}")
    output_lines.append(f"ğŸ“… æƒææ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    output_lines.append("=" * 80)
    
    # æƒæç›®éŒ„
    data = scan_directory(args.path, args.max_depth)
    
    if not data:
        output_lines.append("âŒ ç„¡æ³•è¨ªå•æŒ‡å®šç›®éŒ„")
        # ä¿å­˜åˆ°æ–‡ä»¶
        with open(args.output, 'w', encoding='utf-8') as f:
            f.write('\n'.join(output_lines))
        logger.error("âŒ ç„¡æ³•è¨ªå•æŒ‡å®šç›®éŒ„")
        return
    
    if args.json:
        # è¼¸å‡ºJSONæ ¼å¼
        json_output = json.dumps(data, indent=2, ensure_ascii=False)
        output_lines.append(json_output)
        logger.info(json_output)
    elif args.summary:
        # åªé¡¯ç¤ºçµ±è¨ˆæ‘˜è¦
        summary = generate_summary(data)
        output_lines.append("\nğŸ“Š çµ±è¨ˆæ‘˜è¦:")
        output_lines.append(f"ç¸½æ–‡ä»¶æ•¸: {summary['total_files']:,}")
        output_lines.append(f"ç¸½æ–‡ä»¶å¤¾æ•¸: {summary['total_dirs']:,}")
        output_lines.append(f"ç¸½å¤§å°: {get_file_size_str(summary['total_size'])}")
        
        if summary['file_extensions']:
            output_lines.append("\nğŸ“ æ–‡ä»¶é¡å‹åˆ†ä½ˆ:")
            for ext, count in sorted(summary['file_extensions'].items(), key=lambda x: x[1], reverse=True):
                output_lines.append(f"  {ext}: {count:,} å€‹æ–‡ä»¶")
        
        if summary['largest_files']:
            output_lines.append("\nğŸ“„ æœ€å¤§çš„10å€‹æ–‡ä»¶:")
            for i, file_info in enumerate(summary['largest_files'][:10], 1):
                output_lines.append(f"  {i:2d}. {file_info['name']} ({file_info['size_str']})")
        
        if summary['largest_dirs']:
            output_lines.append("\nğŸ“ æœ€å¤§çš„10å€‹æ–‡ä»¶å¤¾:")
            for i, dir_info in enumerate(summary['largest_dirs'][:10], 1):
                output_lines.append(f"  {i:2d}. {dir_info['name']}/ ({dir_info['size_str']})")
        
        # æ‰“å°åˆ°æ§åˆ¶æ±
        logger.info('\n'.join(output_lines))
    
    else:
        # é¡¯ç¤ºå®Œæ•´çµæ§‹
        structure_lines = []
        print_structure_to_list(data, structure_lines, show_details=not args.no_details)
        output_lines.extend(structure_lines)
        
        # é¡¯ç¤ºçµ±è¨ˆæ‘˜è¦
        summary = generate_summary(data)
        output_lines.append("\n" + "=" * 80)
        output_lines.append("ğŸ“Š çµ±è¨ˆæ‘˜è¦:")
        output_lines.append(f"ç¸½æ–‡ä»¶æ•¸: {summary['total_files']:,}")
        output_lines.append(f"ç¸½æ–‡ä»¶å¤¾æ•¸: {summary['total_dirs']:,}")
        output_lines.append(f"ç¸½å¤§å°: {get_file_size_str(summary['total_size'])}")
        
        if summary['file_extensions']:
            output_lines.append(f"æ–‡ä»¶é¡å‹æ•¸: {len(summary['file_extensions'])}")
        
        # æ‰“å°åˆ°æ§åˆ¶æ±
        logger.info('\n'.join(output_lines))
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    try:
        with open(args.output, 'w', encoding='utf-8') as f:
            f.write('\n'.join(output_lines))
        logger.info(f"ğŸ’¾ çµæœå·²ä¿å­˜åˆ°: {args.output}")
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜æ–‡ä»¶å¤±æ•—: {e}")

if __name__ == "__main__":
    main()
