import dash
from dash import dcc, html, dash_table, Input, Output, State, ctx, no_update
import dash_bootstrap_components as dbc
import pandas as pd
import plotly.graph_objects as go
import json
import io
from dash.dependencies import ALL
import shutil
import os
from datetime import datetime, timedelta
from pathlib import Path
import joblib
from analysis import config as cfg
import yfinance as yf
import logging
import numpy as np
from urllib.parse import quote as urlparse

# é…ç½® logger - ä½¿ç”¨çµ±ä¸€æ—¥èªŒç³»çµ±ï¼ˆæŒ‰éœ€åˆå§‹åŒ–ï¼‰
from analysis.logging_config import get_logger, init_logging
import os

# è¨­å®šç’°å¢ƒè®Šæ•¸ï¼ˆä½†ä¸ç«‹å³åˆå§‹åŒ–ï¼‰
os.environ["SSS_CREATE_LOGS"] = "1"

# ç²å–æ—¥èªŒå™¨ï¼ˆæ‡¶åŠ è¼‰ï¼‰
logger = get_logger("SSS.App")

def _initialize_app_logging():
    """åˆå§‹åŒ–æ‡‰ç”¨ç¨‹å¼æ—¥èªŒç³»çµ±"""
    # åªåœ¨å¯¦éš›éœ€è¦æ™‚æ‰åˆå§‹åŒ–æª”æ¡ˆæ—¥èªŒ
    init_logging(enable_file=True)
    logger.setLevel(logging.DEBUG)
    logger.info("=== App Dash å•Ÿå‹• - çµ±ä¸€æ—¥èªŒç³»çµ± ===")
    logger.info("å·²å•Ÿç”¨è©³ç´°èª¿è©¦æ¨¡å¼ - èª¿è©¦è³‡è¨Šå°‡å¯«å…¥æ—¥èªŒæª”æ¡ˆ")
    logger.info(f"æ—¥èªŒç›®éŒ„: {os.path.abspath('analysis/log')}")
    return logger

# ATR è¨ˆç®—å‡½æ•¸
def calculate_atr(df, window):
    """è¨ˆç®— ATR (Average True Range)"""
    try:
        # æ”¯æ´å¤šç¨®æ¬„ä½åç¨±æ ¼å¼
        high_col = None
        low_col = None
        close_col = None
        
        # æª¢æŸ¥è‹±æ–‡æ¬„ä½åç¨±
        if 'high' in df.columns and 'low' in df.columns and 'close' in df.columns:
            high_col = 'high'
            low_col = 'low'
            close_col = 'close'
        # æª¢æŸ¥ä¸­æ–‡æ¬„ä½åç¨±
        elif 'æœ€é«˜åƒ¹' in df.columns and 'æœ€ä½åƒ¹' in df.columns and 'æ”¶ç›¤åƒ¹' in df.columns:
            high_col = 'æœ€é«˜åƒ¹'
            low_col = 'æœ€ä½åƒ¹'
            close_col = 'æ”¶ç›¤åƒ¹'
        # æª¢æŸ¥å…¶ä»–å¯èƒ½çš„æ¬„ä½åç¨±
        elif 'open' in df.columns and 'close' in df.columns:
            # å¦‚æœæ²’æœ‰é«˜ä½åƒ¹ï¼Œç”¨é–‹ç›¤åƒ¹å’Œæ”¶ç›¤åƒ¹è¿‘ä¼¼
            high_col = 'open'
            low_col = 'close'
            close_col = 'close'
        
        if high_col and low_col and close_col:
            # æœ‰é«˜ä½åƒ¹æ™‚ï¼Œè¨ˆç®— True Range
            high = df[high_col]
            low = df[low_col]
            close = df[close_col]
            
            # ç¢ºä¿æ•¸æ“šç‚ºæ•¸å€¼å‹
            high = pd.to_numeric(high, errors='coerce')
            low = pd.to_numeric(low, errors='coerce')
            close = pd.to_numeric(close, errors='coerce')
            
            tr1 = high - low
            tr2 = abs(high - close.shift(1))
            tr3 = abs(low - close.shift(1))
            
            true_range = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
            atr = true_range.rolling(window=window).mean()
        else:
            # åªæœ‰æ”¶ç›¤åƒ¹æ™‚ï¼Œç”¨åƒ¹æ ¼è®ŠåŒ–è¿‘ä¼¼
            if close_col:
                close = pd.to_numeric(df[close_col], errors='coerce')
            elif 'close' in df.columns:
                close = pd.to_numeric(df['close'], errors='coerce')
            else:
                logger.warning("æ‰¾ä¸åˆ°å¯ç”¨çš„åƒ¹æ ¼æ¬„ä½ä¾†è¨ˆç®— ATR")
                return pd.Series(index=df.index, dtype=float)
            
            price_change = close.diff().abs()
            atr = price_change.rolling(window=window).mean()
        
        # æª¢æŸ¥è¨ˆç®—çµæœ
        if atr is None or atr.empty or atr.isna().all():
            logger.warning(f"ATR è¨ˆç®—çµæœç„¡æ•ˆï¼Œwindow={window}")
            return pd.Series(index=df.index, dtype=float)
        
        return atr
    except Exception as e:
        logger.warning(f"ATR è¨ˆç®—å¤±æ•—: {e}")
        return pd.Series(index=df.index, dtype=float)


def _build_benchmark_df(df_raw):
    """å»ºç«‹åŸºæº–è³‡æ–™ DataFrameï¼Œçµ±ä¸€è™•ç†æ¬„ä½åç¨±å’Œæ•¸æ“šè½‰æ›"""
    bench = pd.DataFrame(index=pd.to_datetime(df_raw.index))
    
    # æ”¶ç›¤åƒ¹æ¬„ä½ - å„ªå…ˆä½¿ç”¨è‹±æ–‡æ¬„ä½ï¼Œå›é€€åˆ°ä¸­æ–‡æ¬„ä½
    if 'close' in df_raw.columns:
        bench["æ”¶ç›¤åƒ¹"] = pd.to_numeric(df_raw["close"], errors="coerce")
    elif 'Close' in df_raw.columns:
        bench["æ”¶ç›¤åƒ¹"] = pd.to_numeric(df_raw["Close"], errors="coerce")
    elif 'æ”¶ç›¤åƒ¹' in df_raw.columns:
        bench["æ”¶ç›¤åƒ¹"] = pd.to_numeric(df_raw["æ”¶ç›¤åƒ¹"], errors="coerce")
    
    # æœ€é«˜åƒ¹å’Œæœ€ä½åƒ¹æ¬„ä½ - å„ªå…ˆä½¿ç”¨è‹±æ–‡æ¬„ä½ï¼Œå›é€€åˆ°ä¸­æ–‡æ¬„ä½
    if 'high' in df_raw.columns and 'low' in df_raw.columns:
        bench["æœ€é«˜åƒ¹"] = pd.to_numeric(df_raw["high"], errors="coerce")
        bench["æœ€ä½åƒ¹"] = pd.to_numeric(df_raw["low"], errors="coerce")
    elif 'High' in df_raw.columns and 'Low' in df_raw.columns:
        bench["æœ€é«˜åƒ¹"] = pd.to_numeric(df_raw["High"], errors="coerce")
        bench["æœ€ä½åƒ¹"] = pd.to_numeric(df_raw["Low"], errors="coerce")
    elif 'æœ€é«˜åƒ¹' in df_raw.columns and 'æœ€ä½åƒ¹' in df_raw.columns:
        bench["æœ€é«˜åƒ¹"] = pd.to_numeric(df_raw["æœ€é«˜åƒ¹"], errors="coerce")
        bench["æœ€ä½åƒ¹"] = pd.to_numeric(df_raw["æœ€ä½åƒ¹"], errors="coerce")
    
    return bench

def calculate_equity_curve(open_px, w, cap, atr_ratio):
    """è¨ˆç®—æ¬Šç›Šæ›²ç·š"""
    try:
        # ç°¡åŒ–çš„æ¬Šç›Šæ›²ç·šè¨ˆç®—
        # é€™è£¡ä½¿ç”¨é–‹ç›¤åƒ¹å’Œæ¬Šé‡çš„ä¹˜ç©ä¾†æ¨¡æ“¬æ¬Šç›Šè®ŠåŒ–
        equity = (open_px * w * cap).cumsum()
        return equity
    except Exception as e:
        logger.warning(f"æ¬Šç›Šæ›²ç·šè¨ˆç®—å¤±æ•—: {e}")
        return None

def calculate_trades_from_equity(equity_curve, open_px, w, cap, atr_ratio):
    """å¾æ¬Šç›Šæ›²ç·šè¨ˆç®—äº¤æ˜“è¨˜éŒ„"""
    try:
        if equity_curve is None or equity_curve.empty:
            return None
        
        # ç°¡åŒ–çš„äº¤æ˜“è¨˜éŒ„ç”Ÿæˆ
        # é€™è£¡æ ¹æ“šæ¬Šé‡è®ŠåŒ–ä¾†è­˜åˆ¥äº¤æ˜“
        weight_changes = w.diff().abs()
        trade_dates = weight_changes[weight_changes > 0.01].index
        
        trades = []
        for date in trade_dates:
            trades.append({
                'trade_date': date,
                'return': 0.0  # ç°¡åŒ–ï¼Œå¯¦éš›æ‡‰è©²è¨ˆç®—å ±é…¬ç‡
            })
        
        if trades:
            return pd.DataFrame(trades)
        else:
            return pd.DataFrame(columns=['trade_date', 'return'])
            
    except Exception as e:
        logger.warning(f"äº¤æ˜“è¨˜éŒ„è¨ˆç®—å¤±æ•—: {e}")
        return None

# è§£åŒ…å™¨å‡½æ•¸ï¼šæ”¯æ´ pack_df/pack_series å’Œå‚³çµ± JSON å­—ä¸²å…©ç¨®æ ¼å¼
def df_from_pack(data):
    """å¾ pack_df çµæœæˆ– JSON å­—ä¸²è§£åŒ… DataFrame"""
    import io, json
    import pandas as pd
    
    # å¦‚æœå·²ç¶“æ˜¯ DataFrameï¼Œç›´æ¥è¿”å›
    if isinstance(data, pd.DataFrame):
        return data
    
    # æª¢æŸ¥æ˜¯å¦ç‚º None æˆ–ç©ºå­—ä¸²
    if data is None:
        return pd.DataFrame()
    
    # å¦‚æœæ˜¯å­—ä¸²ï¼Œé€²è¡Œé¡å¤–æª¢æŸ¥
    if isinstance(data, str):
        if data == "" or data == "[]":
            return pd.DataFrame()
        # å…ˆå˜—è©¦ split â†’ å†é€€å›é è¨­
        for orient in ("split", None):
            try:
                kw = {"orient": orient} if orient else {}
                return pd.read_json(io.StringIO(data), **kw)
            except Exception:
                pass
        return pd.DataFrame()
    
    if isinstance(data, (list, dict)):
        try:
            return pd.DataFrame(data)
        except Exception:
            return pd.DataFrame()
    
    return pd.DataFrame()

def series_from_pack(data):
    """å¾ pack_series çµæœæˆ– JSON å­—ä¸²è§£åŒ… Series"""
    import io
    import pandas as pd
    
    # å¦‚æœå·²ç¶“æ˜¯ Seriesï¼Œç›´æ¥è¿”å›
    if isinstance(data, pd.Series):
        return data
    
    # æª¢æŸ¥æ˜¯å¦ç‚º None æˆ–ç©ºå­—ä¸²
    if data is None:
        return pd.Series(dtype=float)
    
    # å¦‚æœæ˜¯å­—ä¸²ï¼Œé€²è¡Œé¡å¤–æª¢æŸ¥
    if isinstance(data, str):
        if data == "" or data == "[]":
            return pd.Series(dtype=float)
        # Series ä¹Ÿå…ˆè©¦ split
        for orient in ("split", None):
            try:
                kw = {"orient": orient} if orient else {}
                return pd.read_json(io.StringIO(data), typ="series", **kw)
            except Exception:
                pass
        return pd.Series(dtype=float)
    
    if isinstance(data, (list, dict)):
        try:
            return pd.Series(data)
        except Exception:
            return pd.Series(dtype=float)
    
    return pd.Series(dtype=float)

from SSSv096 import (
    param_presets, load_data, compute_single, compute_dual, compute_RMA,
    compute_ssma_turn_combined, backtest_unified, plot_stock_price, plot_equity_cash, plot_weight_series, calculate_holding_periods
)

# å½ˆæ€§åŒ¯å…¥ pack_df/pack_series å‡½æ•¸
try:
    from sss_core.schemas import pack_df, pack_series
except Exception:
    from schemas import pack_df, pack_series

# åŒ¯å…¥æ¬Šé‡æ¬„ä½ç¢ºä¿å‡½å¼
try:
    from sss_core.normalize import _ensure_weight_columns
except Exception:
    # å¦‚æœç„¡æ³•åŒ¯å…¥ï¼Œå®šç¾©ä¸€å€‹ç©ºçš„å‡½å¼ä½œç‚º fallback
    def _ensure_weight_columns(df):
        return df

# å‡è¨­ä½ æœ‰ get_version_history_html
try:
    from version_history import get_version_history_html
except ImportError:
    def get_version_history_html() -> str:
        return "<b>ç„¡æ³•è¼‰å…¥ç‰ˆæœ¬æ­·å²è¨˜éŒ„</b>"

# --- ä¿è­‰æ”¾é€² Store çš„éƒ½æ˜¯ JSON-safe ---
def _pack_any(x):
    import pandas as pd
    if isinstance(x, pd.DataFrame):
        return pack_df(x)          # orient="split" + date_format="iso"
    if isinstance(x, pd.Series):
        return pack_series(x)      # orient="split" + date_format="iso"
    return x

def _pack_result_for_store(result: dict) -> dict:
    # çµ±ä¸€æŠŠæ‰€æœ‰ pandas ç‰©ä»¶è½‰æˆå­—ä¸²ï¼ˆJSONï¼‰
    keys = [
        'trade_df', 'trades_df', 'signals_df',
        'equity_curve', 'cash_curve', 'price_series',
        'daily_state', 'trade_ledger',
        'daily_state_std', 'trade_ledger_std',
        'weight_curve',
        # âŠ æ–°å¢ï¼šä¿å­˜æœªå¥—é–¥é–€ baseline
        'daily_state_base', 'trade_ledger_base', 'weight_curve_base'
    ]
    out = dict(result)
    for k in keys:
        if k in out:
            out[k] = _pack_any(out[k])
    # å¦å¤–æŠŠ datetime tuple çš„ trades è½‰å¯åºåˆ—åŒ–ï¼ˆä½ åŸæœ¬ä¹Ÿæœ‰åšï¼‰
    if 'trades' in out and isinstance(out['trades'], list):
        out['trades'] = [
            (str(t[0]), t[1], str(t[2])) if isinstance(t, tuple) and len(t) == 3 else t
            for t in out['trades']
        ]
    return out

default_tickers = ["00631L.TW", "2330.TW", "AAPL", "VOO"]
strategy_names = list(param_presets.keys())

theme_list = ['theme-dark', 'theme-light', 'theme-blue']

def get_theme_label(theme):
    if theme == 'theme-dark':
        return 'ğŸŒ‘ æ·±è‰²ä¸»é¡Œ'
    elif theme == 'theme-light':
        return 'ğŸŒ• æ·ºè‰²ä¸»é¡Œ'
    else:
        return 'ğŸ’™ è—é»ƒä¸»é¡Œ'

def get_column_display_name(column_name):
    """å°‡è‹±æ–‡æ¬„ä½åè½‰æ›ç‚ºä¸­æ–‡é¡¯ç¤ºåç¨±"""
    column_mapping = {
        'trade_date': 'äº¤æ˜“æ—¥æœŸ',
        'signal_date': 'ä¿¡è™Ÿæ—¥æœŸ',
        'type': 'äº¤æ˜“é¡å‹',
        'price': 'åƒ¹æ ¼',
        'weight_change': 'æ¬Šé‡è®ŠåŒ–',
        'w_before': 'äº¤æ˜“å‰æ¬Šé‡',
        'w_after': 'äº¤æ˜“å¾Œæ¬Šé‡',
        'delta_units': 'è‚¡æ•¸è®ŠåŒ–',
        'exec_notional': 'åŸ·è¡Œé‡‘é¡',
        'equity_after': 'äº¤æ˜“å¾Œæ¬Šç›Š',
        'cash_after': 'äº¤æ˜“å¾Œç¾é‡‘',
        'equity_pct': 'æ¬Šç›Š%',
        'cash_pct': 'ç¾é‡‘%',
        'invested_pct': 'æŠ•è³‡æ¯”ä¾‹',
        'position_value': 'éƒ¨ä½åƒ¹å€¼',
        'return': 'å ±é…¬ç‡',
        'comment': 'å‚™è¨»'
    }
    return column_mapping.get(column_name, column_name)

# é¡¯ç¤ºå±¤æ¬„åå°æ‡‰ï¼ˆâ†’ ä¸­æ–‡ï¼‰
DISPLAY_NAME = {
    'trade_date': 'äº¤æ˜“æ—¥æœŸ',
    'signal_date': 'è¨Šè™Ÿæ—¥æœŸ',
    'type': 'äº¤æ˜“é¡å‹',
    'price': 'åƒ¹æ ¼',
    'weight_change': 'æ¬Šé‡è®ŠåŒ–',
    'w_before': 'äº¤æ˜“å‰æ¬Šé‡',
    'w_after': 'äº¤æ˜“å¾Œæ¬Šé‡',
    'delta_units': 'è‚¡æ•¸è®ŠåŒ–',
    'exec_notional': 'åŸ·è¡Œé‡‘é¡',
    'equity_after': 'äº¤æ˜“å¾Œæ¬Šç›Š',
    'cash_after': 'äº¤æ˜“å¾Œç¾é‡‘',
    'equity_pct': 'æ¬Šç›Š%',
    'cash_pct': 'ç¾é‡‘%',
    'invested_pct': 'æŠ•è³‡æ¯”ä¾‹',
    'position_value': 'éƒ¨ä½å¸‚å€¼',
    'return': 'å ±é…¬',
    'comment': 'å‚™è¨»',
}

# é¡¯ç¤ºå±¤ã€Œéš±è—ã€æ¬„ä½ï¼ˆè¨ˆç®—ä¿ç•™ã€UI ä¸é¡¯ç¤ºï¼‰
HIDE_COLS = {
    'shares_before', 'shares_after', 'fee_buy', 'fee_sell', 'sell_tax', 'tax',
    'date', 'open', 'equity_open_after_trade'  # â† ä½ æåˆ°çš„é›œæ¬„ï¼Œçµ±ä¸€éš±è—
}

# é¡¯ç¤ºå±¤æ¬„ä½é †åºï¼ˆå­˜åœ¨æ‰æ’ï¼Œä¸å­˜åœ¨å°±è·³éï¼‰
PREFER_ORDER = [
    'trade_date','signal_date','type','price',
    'weight_change','w_before','w_after',
    'delta_units','exec_notional',
    'equity_after','cash_after','equity_pct','cash_pct',
    'invested_pct','position_value','return','comment'
]

def format_trade_like_df_for_display(df):
    """é¡¯ç¤ºå±¤ï¼šéš±è—é›œæ¬„ â†’ è£œç™¾åˆ†æ¯” â†’ æ ¼å¼åŒ– â†’ ä¸­æ–‡æ¬„å â†’ å®‰å…¨æ’åº"""
    import pandas as pd
    if df is None or len(df)==0:
        return df

    d = df.copy()

    # 1) éš±è—é›œæ¬„
    hide = [c for c in HIDE_COLS if c in d.columns]
    if hide:
        d = d.drop(columns=hide, errors='ignore')

    # 2) å¿…è¦æ¬„ä½è£œé½Šç™¾åˆ†æ¯”ï¼ˆè‹¥å·²å­˜åœ¨å°±ç•¥éï¼‰
    if {'equity_after','cash_after'}.issubset(d.columns):
        tot = d['equity_after'] + d['cash_after']
        if 'equity_pct' not in d.columns:
            d['equity_pct'] = d.apply(
                lambda r: "" if pd.isna(r['equity_after']) or pd.isna(tot.loc[r.name]) or tot.loc[r.name] <= 0
                          else f"{(r['equity_after']/tot.loc[r.name]):.2%}", axis=1)
        if 'cash_pct' not in d.columns:
            d['cash_pct'] = d.apply(
                lambda r: "" if pd.isna(r['cash_after']) or pd.isna(tot.loc[r.name]) or tot.loc[r.name] <= 0
                          else f"{(r['cash_after']/tot.loc[r.name]):.2%}", axis=1)

    # 3) æ ¼å¼åŒ–
    def _fmt_date_col(s):
        dt = pd.to_datetime(s, errors='coerce')
        return dt.dt.strftime('%Y-%m-%d').fillna("")

    for col in ['trade_date','signal_date']:
        if col in d.columns:
            d[col] = _fmt_date_col(d[col])

    if 'price' in d.columns:
        d['price'] = d['price'].apply(lambda x: f"{x:,.2f}" if pd.notnull(x) else "")
    if 'weight_change' in d.columns:
        d['weight_change'] = d['weight_change'].apply(lambda x: f"{x:.2%}" if pd.notnull(x) else "")
    for col in ['w_before','w_after']:
        if col in d.columns:
            d[col] = d[col].apply(lambda x: f"{x:,.4f}" if pd.notnull(x) else "")
    for col in ['exec_notional','equity_after','cash_after','position_value']:
        if col in d.columns:
            d[col] = d[col].apply(lambda x: f"{int(round(x)):,}" if pd.notnull(x) else "")
    if 'delta_units' in d.columns:
        d['delta_units'] = d['delta_units'].apply(lambda x: f"{int(round(x)):,}" if pd.notnull(x) else "")
    if 'return' in d.columns:
        d['return'] = d['return'].apply(lambda x: "-" if pd.isna(x) else f"{x:.2%}")

    # 4) å®‰å…¨æ’åºï¼ˆåªæ’å­˜åœ¨çš„æ¬„ä½ï¼‰
    exist = [c for c in PREFER_ORDER if c in d.columns]
    others = [c for c in d.columns if c not in exist]
    d = d[exist + others]

    # 5) ä¸­æ–‡æ¬„å
    d = d.rename(columns={k: DISPLAY_NAME.get(k, k) for k in d.columns})
    return d

app = dash.Dash(__name__, external_stylesheets=[dbc.themes.DARKLY], suppress_callback_exceptions=True)

# --------- Dash Layout ---------
app.layout = html.Div([
    dcc.Store(id='theme-store', data='theme-dark'),
    dcc.Store(id='sidebar-collapsed', data=False),
    html.Div([
        html.Button(id='theme-toggle', n_clicks=0, children='ğŸŒ‘ æ·±è‰²ä¸»é¡Œ', className='btn btn-secondary main-header-bar'),
        html.Button(id='sidebar-toggle', n_clicks=0, children='ğŸ“‹ éš±è—å´é‚Šæ¬„', className='btn btn-secondary main-header-bar ms-2'),
        html.Button(id='history-btn', n_clicks=0, children='ğŸ“š ç‰ˆæœ¬æ²¿é©', className='btn btn-secondary main-header-bar ms-2'),
    ], className='header-controls'),
    
    # ç‰ˆæœ¬æ²¿é©æ¨¡æ…‹æ¡†
    dbc.Modal([
        dbc.ModalHeader(dbc.ModalTitle("å„ç‰ˆæœ¬æ²¿é©ç´€éŒ„")),
        dbc.ModalBody([
            dcc.Markdown(get_version_history_html(), dangerously_allow_html=True)
        ], className='version-history-modal-body'),
        dbc.ModalFooter(
            dbc.Button("é—œé–‰", id="history-close", className="ms-auto", n_clicks=0)
        ),
    ], id="history-modal", size="lg", is_open=False),
    
    dbc.Container([
        dbc.Row([
            dbc.Col([
                html.Div([
                    html.H4("åƒæ•¸è¨­å®š"),
                    dbc.Checkbox(id='auto-run', value=True, label="è‡ªå‹•é‹ç®—ï¼ˆåƒæ•¸è®Šå‹•å³å›æ¸¬ï¼‰", className="mb-2"),
                    html.Label("è‚¡ç¥¨ä»£è™Ÿ"),
                    dcc.Dropdown(
                        id='ticker-dropdown',
                        options=[{'label': t, 'value': t} for t in default_tickers],
                        value=default_tickers[0]
                    ),
                    html.Label("æ•¸æ“šèµ·å§‹æ—¥æœŸ"),
                    dcc.Input(id='start-date', type='text', value='2010-01-01'),
                    html.Label("æ•¸æ“šçµæŸæ—¥æœŸ"),
                    dcc.Input(id='end-date', type='text', value=''),
                    html.Label("åˆ¸å•†æŠ˜æ•¸(0.7=7æŠ˜, 0.1=1æŠ˜)"),
                    dcc.Slider(id='discount-slider', min=0.1, max=0.7, step=0.01, value=0.3, marks={0.1:'0.1',0.3:'0.3',0.5:'0.5',0.7:'0.7'}),
                    html.Label("å†·å»æœŸ (bars)"),
                    dcc.Input(id='cooldown-bars', type='number', min=0, max=20, value=3),
                    dbc.Checkbox(id='bad-holding', value=False, label="è³£å‡ºå ±é…¬ç‡<-20%,ç­‰å¾…ä¸‹æ¬¡è³£é»"),
                    html.Br(),
                    
                    # === å…¨å±€é–‹é—œå¥—ç”¨å€å¡Š ===
                    html.H6("ğŸ”§ å…¨å±€é–‹é—œå¥—ç”¨", style={"marginTop":"16px","marginBottom":"8px","color":"#28a745"}),
                    dbc.Checkbox(id='global-apply-switch', value=False, label="å•Ÿç”¨å…¨å±€åƒæ•¸å¥—ç”¨", style={"marginBottom":"8px"}),
                    html.Div([
                        html.Label("é¢¨éšªé–¥é–€ CAP", style={"fontSize":"12px","color":"#888"}),
                        dcc.Input(id='risk-cap-input', type='number', min=0.1, max=1.0, step=0.1, value=0.3, 
                                 style={"width":"80px","marginBottom":"8px"})
                    ], style={"marginBottom":"8px"}),
                    html.Div([
                        html.Label("ATR(20)/ATR(60) æ¯”å€¼é–€æª»", style={"fontSize":"12px","color":"#888"}),
                        dcc.Input(id='atr-ratio-threshold', type='number', min=0.5, max=2.0, step=0.1, value=1.0, 
                                 style={"width":"80px","marginBottom":"8px"})
                    ], style={"marginBottom":"8px"}),
                    html.Div([
                        dbc.Checkbox(id='force-valve-trigger', value=False, label="å¼·åˆ¶è§¸ç™¼é¢¨éšªé–¥é–€ï¼ˆæ¸¬è©¦ç”¨ï¼‰", style={"fontSize":"11px","color":"#dc3545"}),
                        html.Small("ğŸ’¡ å‹¾é¸å¾Œå°‡å¼·åˆ¶è§¸ç™¼é¢¨éšªé–¥é–€ï¼Œç”¨æ–¼æ¸¬è©¦åŠŸèƒ½", style={"color":"#dc3545","fontSize":"10px"})
                    ], style={"marginBottom":"8px"}),
                    html.Small("ğŸ’¡ å•Ÿç”¨å¾Œï¼Œé€™äº›åƒæ•¸å°‡å¥—ç”¨åˆ°æ‰€æœ‰ç­–ç•¥ä¸­ï¼Œä¸¦é‡æ–°è¨ˆç®—ç­–ç•¥ä¿¡è™Ÿ", style={"color":"#666","fontSize":"11px"}),
                    
                    # === é¢¨éšªé–¥é–€ç‹€æ…‹é¡¯ç¤ºå€åŸŸ ===
                    html.Div(id='risk-valve-status', style={"marginTop":"8px","padding":"8px","backgroundColor":"#f8f9fa","borderRadius":"4px","border":"1px solid #dee2e6"}),
                    
                    html.Div([
                        html.Small("ğŸ”’ é¢¨éšªé–¥é–€èªªæ˜:", style={"color":"#28a745","fontWeight":"bold","fontSize":"11px"}),
                        html.Small("â€¢ CAP: æ§åˆ¶æœ€å¤§é¢¨éšªæš´éœ² (0.1=10%, 0.3=30%)", style={"color":"#666","fontSize":"10px"}),
                        html.Small("â€¢ ATRæ¯”å€¼: ç•¶çŸ­æœŸæ³¢å‹•>é•·æœŸæ³¢å‹•æ™‚ï¼Œè‡ªå‹•é™ä½é¢¨éšª", style={"color":"#666","fontSize":"10px"}),
                        html.Small("â€¢ é©ç”¨æ–¼: SSMAç­–ç•¥çš„delta_capã€Ensembleç­–ç•¥çš„floor/delta_cap", style={"color":"#666","fontSize":"10px"})
                    ], style={"marginTop":"4px","padding":"8px","backgroundColor":"#f8f9fa","borderRadius":"4px"}),
                    html.Br(),
                    
                    html.Label("ç­–ç•¥é¸æ“‡"),
                    dcc.Dropdown(
                        id='strategy-dropdown',
                        options=[{'label': s, 'value': s} for s in strategy_names],
                        value=strategy_names[0]
                    ),
                    html.Div(id='strategy-param-area'),  # å‹•æ…‹ç­–ç•¥åƒæ•¸
                    html.Br(),
                    html.Button("ğŸš€ ä¸€éµåŸ·è¡Œæ‰€æœ‰å›æ¸¬", id='run-btn', n_clicks=0, className="btn btn-primary mb-2"),
                    dcc.Loading(dcc.Store(id='backtest-store'), type="circle"),
                ], id='sidebar-content')
            ], width=3, className='sidebar-panel', id='sidebar-col'),
            dbc.Col([
                dcc.Tabs(
                    id='main-tabs',
                    value='backtest',
                    children=[
                        dcc.Tab(label="ç­–ç•¥å›æ¸¬", value="backtest"),
                        dcc.Tab(label="æ‰€æœ‰ç­–ç•¥è²·è³£é»æ¯”è¼ƒ", value="compare"),
                        dcc.Tab(label="ğŸ” å¢å¼·åˆ†æ", value="enhanced")
                    ],
                    className='main-tabs-bar'
                ),
                html.Div(id='tab-content', className='main-content-panel')
            ], width=9, id='main-content-col')
        ])
    ], fluid=True)
], id='main-bg', className='theme-dark')

# --------- å´é‚Šæ¬„éš±è—/é¡¯ç¤ºåˆ‡æ› ---------
@app.callback(
    Output('sidebar-col', 'width'),
    Output('main-content-col', 'width'),
    Output('sidebar-content', 'style'),
    Output('sidebar-toggle', 'children'),
    Input('sidebar-toggle', 'n_clicks'),
    State('sidebar-collapsed', 'data')
)
def toggle_sidebar(n_clicks, collapsed):
    if n_clicks is None:
        return 3, 9, {}, 'ğŸ“‹ éš±è—å´é‚Šæ¬„'
    
    if collapsed:
        # é¡¯ç¤ºå´é‚Šæ¬„
        return 3, 9, {}, 'ğŸ“‹ éš±è—å´é‚Šæ¬„'
    else:
        # éš±è—å´é‚Šæ¬„
        return 0, 12, {'display': 'none'}, 'ğŸ“‹ é¡¯ç¤ºå´é‚Šæ¬„'

# --------- å´é‚Šæ¬„ç‹€æ…‹å­˜å„² ---------
@app.callback(
    Output('sidebar-collapsed', 'data'),
    Input('sidebar-toggle', 'n_clicks'),
    State('sidebar-collapsed', 'data')
)
def update_sidebar_state(n_clicks, collapsed):
    if n_clicks is None:
        return False
    return not collapsed

# --------- å‹•æ…‹é¡¯ç¤ºç­–ç•¥åƒæ•¸ ---------
@app.callback(
    Output('strategy-param-area', 'children'),
    Input('strategy-dropdown', 'value')
)
def update_strategy_params(strategy):
    params = param_presets[strategy]
    
    # ç‰¹æ®Šè™•ç† ensemble ç­–ç•¥ï¼Œé¡¯ç¤ºåƒæ•¸æ‘˜è¦è€Œä¸æ˜¯è¼¸å…¥æ¡†
    if params.get('strategy_type') == 'ensemble':
        p = params.get('params', {})
        c = params.get('trade_cost', {})
        return html.Div([
            html.Div(f"method: {params.get('method')}"),
            html.Div(f"floor: {p.get('floor')} | ema_span: {p.get('ema_span')} | "
                     f"delta_cap: {p.get('delta_cap')} | cooldown: {p.get('min_cooldown_days')} | "
                     f"min_trade_dw: {p.get('min_trade_dw')} | majority_k: {p.get('majority_k', '-') }"),
            html.Div(f"cost(bps): buy {c.get('buy_fee_bp')}, sell {c.get('sell_fee_bp')}, tax {c.get('sell_tax_bp')}"),
            html.Small("ï¼ˆEnsemble åƒæ•¸ç›®å‰å›ºå®šæ–¼ SSSv096.param_presetsï¼Œå¦‚éœ€èª¿æ•´å»ºè­°åœ¨ SSSv096 å…§æ”¹ï¼‰")
        ])
    
    # å…¶ä»–ç­–ç•¥ç…§èˆŠè™•ç†
    controls = []
    for k, v in params.items():
        if k in ['strategy_type', 'smaa_source']:
            continue
        if isinstance(v, (int, float)):
            controls.append(
                html.Div([
                    html.Label(f"{k}"),
                    dcc.Input(id={'type': 'param-input', 'param': k}, type='number', value=v)
                ])
            )
        else:
            controls.append(
                html.Div([
                    html.Label(f"{k}"),
                    dcc.Input(id={'type': 'param-input', 'param': k}, type='text', value=str(v))
                ])
            )
    return controls

# --------- é¢¨éšªé–¥é–€ç‹€æ…‹æ›´æ–° ---------
@app.callback(
    Output('risk-valve-status', 'children'),
    [
        Input('global-apply-switch', 'value'),
        Input('risk-cap-input', 'value'),
        Input('atr-ratio-threshold', 'value'),
        Input('force-valve-trigger', 'value'),
        Input('ticker-dropdown', 'value'),
        Input('start-date', 'value'),
        Input('end-date', 'value')
    ]
)
def update_risk_valve_status(global_apply, risk_cap, atr_ratio, force_trigger, ticker, start_date, end_date):
    """å‹•æ…‹æ›´æ–°é¢¨éšªé–¥é–€ç‹€æ…‹é¡¯ç¤º"""
    logger.info(f"=== é¢¨éšªé–¥é–€ç‹€æ…‹æ›´æ–° ===")
    logger.info(f"global_apply: {global_apply}")
    logger.info(f"risk_cap: {risk_cap}")
    logger.info(f"atr_ratio: {atr_ratio}")
    logger.info(f"force_trigger: {force_trigger}")
    logger.info(f"ticker: {ticker}")
    logger.info(f"start_date: {start_date}")
    logger.info(f"end_date: {end_date}")
    
    if not global_apply:
        logger.info("é¢¨éšªé–¥é–€æœªå•Ÿç”¨")
        return html.Div([
            html.Small("ğŸ”´ é¢¨éšªé–¥é–€æœªå•Ÿç”¨", style={"color":"#dc3545","fontWeight":"bold"}),
            html.Br(),
            html.Small("é»æ“Šä¸Šæ–¹è¤‡é¸æ¡†å•Ÿç”¨å…¨å±€é¢¨éšªæ§åˆ¶", style={"color":"#666","fontSize":"10px"})
        ])
    
    # å¦‚æœå•Ÿç”¨ï¼Œå˜—è©¦è¼‰å…¥æ•¸æ“šä¸¦è¨ˆç®— ATR æ¯”å€¼
    try:
        if ticker and start_date:
            logger.info(f"é–‹å§‹è¼‰å…¥æ•¸æ“š: ticker={ticker}, start_date={start_date}, end_date={end_date}")
            df_raw, _ = load_data(ticker, start_date, end_date if end_date else None, "Self")
            logger.info(f"æ•¸æ“šè¼‰å…¥çµæœ: ç©º={df_raw.empty}, å½¢ç‹€={df_raw.shape if not df_raw.empty else 'N/A'}")
            
            if not df_raw.empty:
                # è¨ˆç®— ATR æ¯”å€¼
                logger.info("é–‹å§‹è¨ˆç®— ATR æ¯”å€¼")
                atr_20 = calculate_atr(df_raw, 20)
                atr_60 = calculate_atr(df_raw, 60)
                logger.info(f"ATR è¨ˆç®—å®Œæˆ: atr_20={type(atr_20)}, atr_60={type(atr_60)}")
                
                # åŠ å…¥é™¤éŒ¯è³‡è¨Š
                debug_info = []
                debug_info.append(f"æ•¸æ“šæ¬„ä½: {list(df_raw.columns)}")
                debug_info.append(f"æ•¸æ“šè¡Œæ•¸: {len(df_raw)}")
                debug_info.append(f"ATR(20) é¡å‹: {type(atr_20)}")
                debug_info.append(f"ATR(60) é¡å‹: {type(atr_60)}")
                
                if atr_20 is not None:
                    debug_info.append(f"ATR(20) é•·åº¦: {len(atr_20) if hasattr(atr_20, '__len__') else 'N/A'}")
                    debug_info.append(f"ATR(20) éç©ºå€¼: {atr_20.notna().sum() if hasattr(atr_20, 'notna') else 'N/A'}")
                
                if atr_60 is not None:
                    debug_info.append(f"ATR(60) é•·åº¦: {len(atr_60) if hasattr(atr_60, '__len__') else 'N/A'}")
                    debug_info.append(f"ATR(60) éç©ºå€¼: {atr_60.notna().sum() if hasattr(atr_60, 'notna') else 'N/A'}")
                
                # ç¢ºä¿ ATR æ•¸æ“šæœ‰æ•ˆ
                if (atr_20 is not None and atr_60 is not None and 
                    hasattr(atr_20, 'empty') and hasattr(atr_60, 'empty') and
                    not atr_20.empty and not atr_60.empty):
                    
                    # æª¢æŸ¥æ˜¯å¦æœ‰è¶³å¤ çš„éç©ºå€¼
                    atr_20_valid = atr_20.dropna()
                    atr_60_valid = atr_60.dropna()
                    
                    if len(atr_20_valid) > 0 and len(atr_60_valid) > 0:
                        # å–æœ€æ–°çš„ ATR å€¼é€²è¡Œæ¯”è¼ƒ
                        atr_20_latest = atr_20_valid.iloc[-1]
                        atr_60_latest = atr_60_valid.iloc[-1]
                        
                        debug_info.append(f"ATR(20) æœ€æ–°å€¼: {atr_20_latest:.6f}")
                        debug_info.append(f"ATR(60) æœ€æ–°å€¼: {atr_60_latest:.6f}")
                        
                        if atr_60_latest > 0:
                            atr_ratio_current = atr_20_latest / atr_60_latest
                            debug_info.append(f"ATR æ¯”å€¼: {atr_ratio_current:.4f}")
                            
                            # åˆ¤æ–·æ˜¯å¦éœ€è¦è§¸ç™¼é¢¨éšªé–¥é–€
                            valve_triggered = atr_ratio_current > atr_ratio
                            
                            # å¦‚æœå•Ÿç”¨å¼·åˆ¶è§¸ç™¼ï¼Œå‰‡å¼·åˆ¶è§¸ç™¼é¢¨éšªé–¥é–€
                            if force_trigger:
                                valve_triggered = True
                                logger.info(f"å¼·åˆ¶è§¸ç™¼é¢¨éšªé–¥é–€å•Ÿç”¨")
                            
                            # è¨˜éŒ„é¢¨éšªé–¥é–€ç‹€æ…‹åˆ°æ—¥èªŒ
                            logger.info(f"ATR æ¯”å€¼è¨ˆç®—: {atr_20_latest:.6f} / {atr_60_latest:.6f} = {atr_ratio_current:.4f}")
                            logger.info(f"é¢¨éšªé–¥é–€é–€æª»: {atr_ratio}, ç•¶å‰æ¯”å€¼: {atr_ratio_current:.4f}")
                            logger.info(f"é¢¨éšªé–¥é–€è§¸ç™¼: {'æ˜¯' if valve_triggered else 'å¦'}")
                            logger.info(f"é¢¨éšªé–¥é–€ç‹€æ…‹: {'ğŸ”´ è§¸ç™¼' if valve_triggered else 'ğŸŸ¢ æ­£å¸¸'}")
                            
                            status_color = "#dc3545" if valve_triggered else "#28a745"
                            status_icon = "ğŸ”´" if valve_triggered else "ğŸŸ¢"
                            status_text = "è§¸ç™¼" if valve_triggered else "æ­£å¸¸"
                            
                            # åŠ å…¥å¼·åˆ¶è§¸ç™¼çš„ç‹€æ…‹é¡¯ç¤º
                            force_status = ""
                            if force_trigger:
                                force_status = html.Br() + html.Small("ğŸ”´ å¼·åˆ¶è§¸ç™¼å·²å•Ÿç”¨", style={"color":"#dc3545","fontWeight":"bold","fontSize":"10px"})
                            
                            return html.Div([
                                html.Div([
                                    html.Small(f"{status_icon} é¢¨éšªé–¥é–€ç‹€æ…‹: {status_text}", 
                                              style={"color":status_color,"fontWeight":"bold","fontSize":"12px"}),
                                    force_status,
                                    html.Br(),
                                    html.Small(f"ATR(20)/ATR(60) = {atr_ratio_current:.2f}", style={"color":"#666","fontSize":"11px"}),
                                    html.Br(),
                                    html.Small(f"é–€æª»å€¼: {atr_ratio}", style={"color":"#666","fontSize":"11px"}),
                                    html.Br(),
                                    html.Small(f"é¢¨éšªCAP: {risk_cap*100:.0f}%", style={"color":"#666","fontSize":"11px"}),
                                    html.Br(),
                                    html.Small(f"ç¾é‡‘ä¿ç•™ä¸‹é™: {(1-risk_cap)*100:.0f}%", style={"color":"#666","fontSize":"11px"}),
                                    html.Br(),
                                    html.Small("--- é™¤éŒ¯è³‡è¨Š ---", style={"color":"#999","fontSize":"10px","fontStyle":"italic"}),
                                    html.Small([html.Div(info) for info in debug_info], style={"color":"#999","fontSize":"9px"})
                                ])
                            ])
                        else:
                            logger.warning(f"ATR(60) å€¼ç‚º 0ï¼Œç„¡æ³•è¨ˆç®—æ¯”å€¼: {atr_60_latest:.6f}")
                            return html.Div([
                                html.Small("ğŸŸ¡ ATR è¨ˆç®—ç•°å¸¸", style={"color":"#ffc107","fontWeight":"bold"}),
                                html.Br(),
                                html.Small(f"ATR(60) å€¼ç‚º {atr_60_latest:.6f}ï¼Œç„¡æ³•è¨ˆç®—æ¯”å€¼", style={"color":"#666","fontSize":"10px"}),
                                html.Br(),
                                html.Small("--- é™¤éŒ¯è³‡è¨Š ---", style={"color":"#999","fontSize":"10px","fontStyle":"italic"}),
                                html.Small([html.Div(info) for info in debug_info], style={"color":"#999","fontSize":"9px"})
                            ])
                    else:
                        logger.warning(f"ATR æ•¸æ“šä¸è¶³: ATR(20) æœ‰æ•ˆå€¼={len(atr_20_valid)}, ATR(60) æœ‰æ•ˆå€¼={len(atr_60_valid)}")
                        return html.Div([
                            html.Small("ğŸŸ¡ ATR æ•¸æ“šä¸è¶³", style={"color":"#ffc107","fontWeight":"bold"}),
                            html.Br(),
                            html.Small(f"ATR(20) æœ‰æ•ˆå€¼: {len(atr_20_valid)}, ATR(60) æœ‰æ•ˆå€¼: {len(atr_60_valid)}", style={"color":"#666","fontSize":"10px"}),
                            html.Br(),
                            html.Small("--- é™¤éŒ¯è³‡è¨Š ---", style={"color":"#999","fontSize":"10px","fontStyle":"italic"}),
                            html.Small([html.Div(info) for info in debug_info], style={"color":"#999","fontSize":"9px"})
                        ])
                else:
                    logger.warning("ATR æ•¸æ“šç„¡æ•ˆï¼Œç„¡æ³•è¨ˆç®—æ¯”å€¼")
                    return html.Div([
                        html.Small("ğŸŸ¡ ATR æ•¸æ“šç„¡æ•ˆ", style={"color":"#ffc107","fontWeight":"bold"}),
                        html.Br(),
                        html.Small("ç„¡æ³•è¨ˆç®— ATR æ¯”å€¼", style={"color":"#666","fontSize":"10px"}),
                        html.Br(),
                        html.Small("--- é™¤éŒ¯è³‡è¨Š ---", style={"color":"#999","fontSize":"10px","fontStyle":"italic"}),
                        html.Small([html.Div(info) for info in debug_info], style={"color":"#666","fontSize":"9px"})
                    ])

            else:
                logger.warning(f"ç„¡æ³•è¼‰å…¥æ•¸æ“š: ticker={ticker}, start_date={start_date}")
                return html.Div([
                    html.Small("ğŸŸ¡ ç„¡æ³•è¼‰å…¥æ•¸æ“š", style={"color":"#ffc107","fontWeight":"bold"}),
                    html.Br(),
                    html.Small("è«‹å…ˆé¸æ“‡è‚¡ç¥¨ä»£è™Ÿå’Œæ—¥æœŸ", style={"color":"#666","fontSize":"10px"})
                ])
        else:
            logger.info("ç­‰å¾…æ•¸æ“šè¼‰å…¥ï¼šæœªé¸æ“‡è‚¡ç¥¨ä»£è™Ÿæˆ–æ—¥æœŸ")
            return html.Div([
                html.Small("ğŸŸ¡ ç­‰å¾…æ•¸æ“šè¼‰å…¥", style={"color":"#ffc107","fontWeight":"bold"}),
                html.Br(),
                html.Small("è«‹é¸æ“‡è‚¡ç¥¨ä»£è™Ÿå’Œæ—¥æœŸ", style={"color":"#666","fontSize":"10px"})
            ])
    except Exception as e:
        logger.error(f"é¢¨éšªé–¥é–€ç‹€æ…‹æ›´æ–°å¤±æ•—: {e}")
        return html.Div([
            html.Small("ğŸŸ¡ è¨ˆç®—ä¸­...", style={"color":"#ffc107","fontWeight":"bold"}),
            html.Br(),
            html.Small(f"éŒ¯èª¤: {str(e)}", style={"color":"#666","fontSize":"10px"})
        ])

# --------- åŸ·è¡Œå›æ¸¬ä¸¦å­˜åˆ° Store ---------
@app.callback(
    Output('backtest-store', 'data'),
    [
        Input('run-btn', 'n_clicks'),
        Input('auto-run', 'value'),
        Input('ticker-dropdown', 'value'),
        Input('start-date', 'value'),
        Input('end-date', 'value'),
        Input('discount-slider', 'value'),
        Input('cooldown-bars', 'value'),
        Input('bad-holding', 'value'),
        Input('global-apply-switch', 'value'),
        Input('risk-cap-input', 'value'),
        Input('atr-ratio-threshold', 'value'),
        Input('force-valve-trigger', 'value'),
        Input('strategy-dropdown', 'value'),
        Input({'type': 'param-input', 'param': ALL}, 'value'),
        Input({'type': 'param-input', 'param': ALL}, 'id'),
    ],
    State('backtest-store', 'data')
)
def run_backtest(n_clicks, auto_run, ticker, start_date, end_date, discount, cooldown, bad_holding, global_apply, risk_cap, atr_ratio, force_trigger, strategy, param_values, param_ids, stored_data):
    # === èª¿è©¦æ—¥èªŒï¼ˆåƒ…åœ¨ DEBUG ç´šåˆ¥æ™‚é¡¯ç¤ºï¼‰===
    logger.debug(f"run_backtest è¢«èª¿ç”¨ - n_clicks: {n_clicks}, auto_run: {auto_run}, trigger: {ctx.triggered_id}")
    
    # ç§»é™¤è‡ªå‹•å¿«å–æ¸…ç†ï¼Œé¿å…å¤šç”¨æˆ·è¡çª
    # è®“ joblib.Memory è‡ªå‹•ç®¡ç†å¿«å–ï¼Œåªåœ¨éœ€è¦æ™‚æ‰‹å‹•æ¸…ç†
    if n_clicks is None and not auto_run:
        logger.debug(f"æ—©æœŸè¿”å›ï¼šn_clicks={n_clicks}, auto_run={auto_run}")
        return stored_data
    
    # è¼‰å…¥æ•¸æ“š
    df_raw, df_factor = load_data(ticker, start_date, end_date, "Self")
    if df_raw.empty:
        logger.warning(f"ç„¡æ³•è¼‰å…¥ {ticker} çš„æ•¸æ“š")
        return {"error": f"ç„¡æ³•è¼‰å…¥ {ticker} çš„æ•¸æ“š"}
    
    ctx_trigger = ctx.triggered_id
    
    # åªåœ¨ auto-run ç‚º True æˆ–æŒ‰éˆ•è¢«é»æ“Šæ™‚é‹ç®—
    if not auto_run and ctx_trigger != 'run-btn':
        logger.debug(f"è·³éå›æ¸¬ï¼šauto_run={auto_run}, ctx_trigger={ctx_trigger}")
        return stored_data
    
    logger.info(f"é–‹å§‹åŸ·è¡Œå›æ¸¬ - ticker: {ticker}, ç­–ç•¥æ•¸: {len(strategy_names)}")
    results = {}
    
    # === æ–°å¢ï¼šå…¨å±€é¢¨éšªé–¥é–€è§¸ç™¼ç‹€æ…‹è¿½è¹¤ ===
    valve_triggered = False
    atr_ratio_current = None
    
    for strat in strategy_names:
        # åªä½¿ç”¨ param_presets ä¸­çš„åƒæ•¸
        strat_params = param_presets[strat].copy()
        strat_type = strat_params["strategy_type"]
        smaa_src = strat_params.get("smaa_source", "Self")
        
        # ç‚ºæ¯å€‹ç­–ç•¥è¼‰å…¥å°æ‡‰çš„æ•¸æ“š
        df_raw, df_factor = load_data(ticker, start_date, end_date if end_date else None, smaa_source=smaa_src)
        
        # æ‡‰ç”¨å…¨å±€é¢¨éšªé–¥é–€è¨­å®šï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
        logger.info(f"[{strat}] é¢¨éšªé–¥é–€é–‹é—œç‹€æ…‹: global_apply={global_apply}, é¡å‹={type(global_apply)}")
        if global_apply:
            logger.info(f"[{strat}] æ‡‰ç”¨å…¨å±€é¢¨éšªé–¥é–€: CAP={risk_cap}, ATRæ¯”å€¼é–€æª»={atr_ratio}")
            
            # è¨ˆç®— ATR æ¯”å€¼ï¼ˆä½¿ç”¨æœ€æ–°æ•¸æ“šï¼Œåƒ…ç”¨æ–¼æ—¥èªŒé¡¯ç¤ºï¼‰
            try:
                atr_20 = calculate_atr(df_raw, 20)
                atr_60 = calculate_atr(df_raw, 60)
                
                # ç¢ºä¿ ATR æ•¸æ“šæœ‰æ•ˆ
                if not atr_20.empty and not atr_60.empty:
                    atr_20_valid = atr_20.dropna()
                    atr_60_valid = atr_60.dropna()
                    
                    # æª¢æŸ¥æ¨£æœ¬æ•¸é‡æ˜¯å¦è¶³å¤ 
                    min_samples_20, min_samples_60 = 30, 60  # è‡³å°‘éœ€è¦ 30 å’Œ 60 å€‹æ¨£æœ¬
                    if len(atr_20_valid) < min_samples_20 or len(atr_60_valid) < min_samples_60:
                        logger.warning(f"[{strat}] ATR æ¨£æœ¬ä¸è¶³ï¼Œ20æœŸ:{len(atr_20_valid)}/{min_samples_20}, 60æœŸ:{len(atr_60_valid)}/{min_samples_60}")
                        continue
                    
                    atr_20_latest = atr_20_valid.iloc[-1]
                    atr_60_latest = atr_60_valid.iloc[-1]
                    
                    # æª¢æŸ¥ ATR å€¼æ˜¯å¦åˆç†
                    if atr_60_latest <= 0 or not np.isfinite(atr_60_latest):
                        logger.warning(f"[{strat}] ATR(60) å€¼ç•°å¸¸: {atr_60_latest}ï¼Œè·³éé¢¨éšªé–¥é–€")
                        continue
                    
                    if atr_20_latest <= 0 or not np.isfinite(atr_20_latest):
                        logger.warning(f"[{strat}] ATR(20) å€¼ç•°å¸¸: {atr_20_latest}ï¼Œè·³éé¢¨éšªé–¥é–€")
                        continue
                    
                    atr_ratio_current = atr_20_latest / atr_60_latest
                    logger.info(f"[{strat}] æœ€æ–°ATRæ¯”å€¼: {atr_ratio_current:.4f} (20æœŸ:{atr_20_latest:.4f}, 60æœŸ:{atr_60_latest:.4f})")
                else:
                    logger.warning(f"[{strat}] ATR è¨ˆç®—çµæœç‚ºç©º")
                    
                # å¼·åˆ¶è§¸ç™¼æ™‚è¨­ç½®æ¨™è¨˜
                if force_trigger:
                    valve_triggered = True
                    logger.info(f"[{strat}] ğŸ”´ å¼·åˆ¶è§¸ç™¼é¢¨éšªé–¥é–€å•Ÿç”¨")
                    
            except Exception as e:
                logger.warning(f"[{strat}] ATR è¨ˆç®—å¤±æ•—: {e}")
        else:
            logger.info(f"[{strat}] æœªå•Ÿç”¨å…¨å±€é¢¨éšªé–¥é–€")
        
        if strat_type == 'ssma_turn':
            calc_keys = ['linlen', 'factor', 'smaalen', 'prom_factor', 'min_dist', 'buy_shift', 'exit_shift', 'vol_window', 'signal_cooldown_days', 'quantile_win']
            ssma_params = {k: v for k, v in strat_params.items() if k in calc_keys}
            backtest_params = ssma_params.copy()
            backtest_params['stop_loss'] = strat_params.get('stop_loss', 0.0)
            
            # é‡æ–°è¨ˆç®—ç­–ç•¥ä¿¡è™Ÿï¼ˆå› ç‚ºåƒæ•¸å¯èƒ½å·²ç¶“è¢«é¢¨éšªé–¥é–€èª¿æ•´ï¼‰
            df_ind, buy_dates, sell_dates = compute_ssma_turn_combined(df_raw, df_factor, **ssma_params, smaa_source=smaa_src)
            if df_ind.empty:
                continue
            result = backtest_unified(df_ind, strat_type, backtest_params, buy_dates, sell_dates, discount=discount, trade_cooldown_bars=cooldown, bad_holding=bad_holding)
            
            # === åœ¨ ssma_turn ä¹Ÿå¥—ç”¨é¢¨éšªé–¥é–€ï¼ˆå’Œ Ensemble ä¸€è‡´çš„å¾Œç½®è¦†å¯«ï¼‰ ===
            if global_apply:
                # åˆ¤æ–·æ˜¯å¦è¦è§¸ç™¼ï¼ˆèˆ‡ä½ çš„ ATR æª¢æŸ¥æˆ–å¼·åˆ¶è§¸ç™¼ä¸€è‡´ï¼‰
                valve_triggered_local = False
                ratio_local = None
                try:
                    atr_20 = calculate_atr(df_raw, 20)
                    atr_60 = calculate_atr(df_raw, 60)
                    if not atr_20.empty and not atr_60.empty:
                        a20 = atr_20.dropna().iloc[-1]
                        a60 = atr_60.dropna().iloc[-1]
                        if a60 > 0:
                            ratio_local = float(a20 / a60)
                            valve_triggered_local = (ratio_local > atr_ratio)  # èˆ‡é€²éšåˆ†æä¸€è‡´ï¼šä½¿ç”¨ ">"
                except Exception:
                    pass

                if force_trigger:
                    valve_triggered_local = True
                    if ratio_local is None:
                        ratio_local = 1.5

                if valve_triggered_local:
                    from SSS_EnsembleTab import risk_valve_backtest, CostParams
                    # å–å¾— open åƒ¹ï¼›df_raw æ¬„ä½åç¨±æ˜¯å°å¯«
                    open_px = df_raw['open'] if 'open' in df_raw.columns else df_raw['close']
                    # å¾å›æ¸¬è¼¸å‡ºæŠ“ wï¼ˆå…ˆç”¨æ¨™æº–åŒ– daily_stateï¼Œå¦‚æœæ²’æœ‰å°±ç”¨åŸ daily_stateï¼‰
                    w_series = None
                    try:
                        ds_std = df_from_pack(result.get('daily_state_std'))
                        if ds_std is not None and not ds_std.empty and 'w' in ds_std.columns:
                            w_series = ds_std['w']
                    except Exception:
                        pass
                    if w_series is None:
                        ds = df_from_pack(result.get('daily_state'))
                        if ds is not None and not ds.empty and 'w' in ds.columns:
                            w_series = ds['w']

                    if w_series is not None:
                        # äº¤æ˜“æˆæœ¬ï¼ˆèˆ‡ Ensemble åˆ†æ”¯ä¸€è‡´ï¼‰
                        trade_cost = strat_params.get('trade_cost', {})
                        cost_params = CostParams(
                            buy_fee_bp=float(trade_cost.get("buy_fee_bp", 4.27)),
                            sell_fee_bp=float(trade_cost.get("sell_fee_bp", 4.27)),
                            sell_tax_bp=float(trade_cost.get("sell_tax_bp", 30.0))
                        )

                        # === å…¨å±€å¥—ç”¨é¢¨éšªé–¥é–€ï¼šç¢ºä¿åƒæ•¸ä¸€è‡´æ€§ (2025/08/20) ===
                        global_valve_params = {
                            "open_px": open_px,
                            "w": w_series,
                            "cost": cost_params,
                            "benchmark_df": df_raw,
                            "mode": "cap",
                            "cap_level": float(risk_cap),
                            "slope20_thresh": 0.0, 
                            "slope60_thresh": 0.0,
                            "atr_win": 20, 
                            "atr_ref_win": 60,
                            "atr_ratio_mult": float(ratio_local if ratio_local is not None else atr_ratio),   # è‹¥ä½ æœ‰ local ratioï¼Œå°±ç”¨ localï¼›å¦å‰‡å…¨å±€ atr_ratio
                            "use_slopes": True,
                            "slope_method": "polyfit",
                            "atr_cmp": "gt"
                        }
                        
                        # è¨˜éŒ„å…¨å±€é¢¨éšªé–¥é–€é…ç½®
                        logger.info(f"[Global] é¢¨éšªé–¥é–€é…ç½®: cap_level={global_valve_params['cap_level']}, atr_ratio_mult={global_valve_params['atr_ratio_mult']}")
                        
                        rv = risk_valve_backtest(**global_valve_params)

                        # è¦†å¯«çµæœï¼Œç¢ºä¿ UI èˆ‡è¼¸å‡ºä¸€è‡´ï¼ˆå’Œ Ensemble åˆ†æ”¯å°é½Šï¼‰
                        result['equity_curve']     = pack_series(rv["daily_state_valve"]["equity"])
                        result['daily_state']      = pack_df(rv["daily_state_valve"])
                        result['daily_state_std']  = pack_df(rv["daily_state_valve"])
                        result['trade_ledger']     = pack_df(rv["trade_ledger_valve"])
                        result['trade_ledger_std'] = pack_df(rv["trade_ledger_valve"])
                        result['weight_curve']     = pack_series(rv["weights_valve"])
                        # çµ¦ UI çš„æ¨™è¨˜ï¼ˆä¸‹å€‹å°ç¯€æœƒç”¨åˆ°ï¼‰
                        result['valve'] = {
                            "applied": True,
                            "cap": float(risk_cap),
                            "atr_ratio": ratio_local
                        }
                        
                        logger.info(f"[{strat}] SSMA é¢¨éšªé–¥é–€å·²å¥—ç”¨ï¼ˆcap={risk_cap}, ratio={ratio_local:.4f}ï¼‰")
                    else:
                        logger.warning(f"[{strat}] SSMA ç„¡æ³•å–å¾—æ¬Šé‡åºåˆ—ï¼Œè·³éé¢¨éšªé–¥é–€å¥—ç”¨")
                else:
                    logger.info(f"[{strat}] SSMA é¢¨éšªé–¥é–€æœªè§¸ç™¼ï¼Œä½¿ç”¨åŸå§‹çµæœ")
                    # çµ¦ UI çš„æ¨™è¨˜ï¼ˆæœªè§¸ç™¼ï¼‰
                    result['valve'] = {
                        "applied": False,
                        "cap": float(risk_cap),
                        "atr_ratio": ratio_local if ratio_local is not None else "N/A"
                    }
        elif strat_type == 'ensemble':
            # ä½¿ç”¨æ–°çš„ ensemble_runner é¿å…å¾ªç’°ä¾è³´
            try:
                from runners.ensemble_runner import run_ensemble_backtest
                from SSS_EnsembleTab import EnsembleParams, CostParams, RunConfig
                
                # æŠŠ SSSv096 çš„å·¢ç‹€åƒæ•¸æ”¤å¹³
                flat_params = {}
                flat_params.update(strat_params.get('params', {}))
                flat_params.update(strat_params.get('trade_cost', {}))
                flat_params['method'] = strat_params.get('method', 'majority')
                flat_params['ticker'] = ticker
                
                # ä½¿ç”¨æ¯”ä¾‹é–€æª»é¿å… N è®Šå‹•æ™‚å¤±çœŸ
                if 'majority_k' in flat_params and flat_params.get('method') == 'majority':
                    flat_params['majority_k_pct'] = 0.55
                    flat_params.pop('majority_k', None)
                    logger.info(f"[Ensemble] ä½¿ç”¨æ¯”ä¾‹é–€æª» majority_k_pct={flat_params['majority_k_pct']}")
                
                # å‰µå»ºé…ç½®
                ensemble_params = EnsembleParams(
                    floor=flat_params.get("floor", 0.2),
                    ema_span=flat_params.get("ema_span", 3),
                    delta_cap=flat_params.get("delta_cap", 0.3),
                    majority_k=flat_params.get("majority_k", 6),
                    min_cooldown_days=flat_params.get("min_cooldown_days", 1),
                    min_trade_dw=flat_params.get("min_trade_dw", 0.01)
                )
                
                # è¨»è§£æ‰åŸæœ¬çš„ç„¡æ¢ä»¶é¢¨éšªé–¥é–€èª¿æ•´ï¼ˆæœƒé€ æˆ floor æ–¹å‘éŒ¯èª¤ï¼‰
                # if global_apply:
                #     logger.info(f"[{strat}] Ensemble ç­–ç•¥æ‡‰ç”¨é¢¨éšªé–¥é–€: åŸå§‹ delta_cap={ensemble_params.delta_cap}, floor={ensemble_params.floor}")
                #     
                #     # èª¿æ•´ delta_capï¼ˆæœ€å¤§é¢¨éšªæš´éœ²ï¼‰
                #     if ensemble_params.delta_cap > risk_cap:
                #         ensemble_params.delta_cap = risk_cap
                #         logger.info(f"[{strat}] èª¿æ•´ delta_cap ç‚º {ensemble_params.delta_cap}")
                #     
                #     # èª¿æ•´ floorï¼ˆæœ€å°ç¾é‡‘ä¿ç•™ï¼‰
                #     min_floor = 1 - risk_cap
                #     if ensemble_params.floor < min_floor:
                #         ensemble_params.floor = min_floor
                #         logger.info(f"[{strat}] èª¿æ•´ floor ç‚º {ensemble_params.floor}")
                #     
                #     logger.info(f"[{strat}] Ensemble ç­–ç•¥æœ€çµ‚åƒæ•¸: delta_cap={ensemble_params.delta_cap}, floor={ensemble_params.floor}")
                
                cost_params = CostParams(
                    buy_fee_bp=flat_params.get("buy_fee_bp", 4.27),
                    sell_fee_bp=flat_params.get("sell_fee_bp", 4.27),
                    sell_tax_bp=flat_params.get("sell_tax_bp", 30.0)
                )
                
                cfg = RunConfig(
                    ticker=ticker,
                    method=flat_params.get("method", "majority"),
                    params=ensemble_params,
                    cost=cost_params
                )
                
                # å‚³éæ¯”ä¾‹é–€æª»åƒæ•¸
                if flat_params.get("majority_k_pct"):
                    cfg.majority_k_pct = flat_params.get("majority_k_pct")
                else:
                    cfg.majority_k_pct = 0.55
                    logger.info(f"[Ensemble] å¼·åˆ¶è¨­å®š majority_k_pct=0.55")
                
                logger.info(f"[Ensemble] åŸ·è¡Œé…ç½®: ticker={ticker}, method={flat_params.get('method')}, majority_k_pct={flat_params.get('majority_k_pct', 'N/A')}")
                
                # --- æ–°å¢ï¼šåªåœ¨ ATR è§¸ç™¼æ™‚å•Ÿç”¨é¢¨éšªé–¥é–€ ---
                valve_triggered = False
                ratio = None
                try:
                    atr_20 = calculate_atr(df_raw, 20)
                    atr_60 = calculate_atr(df_raw, 60)
                    
                    # å¢åŠ è©³ç´°çš„èª¿è©¦è³‡è¨Š
                    logger.info(f"[{strat}] Ensemble ATR è¨ˆç®—: atr_20={type(atr_20)}, atr_60={type(atr_60)}")
                    
                    if not atr_20.empty and not atr_60.empty:
                        atr_20_valid = atr_20.dropna()
                        atr_60_valid = atr_60.dropna()
                        
                        logger.info(f"[{strat}] Ensemble ATR æœ‰æ•ˆå€¼: atr_20={len(atr_20_valid)}, atr_60={len(atr_60_valid)}")
                        
                        if len(atr_20_valid) > 0 and len(atr_60_valid) > 0:
                            a20 = atr_20_valid.iloc[-1]
                            a60 = atr_60_valid.iloc[-1]
                            
                            logger.info(f"[{strat}] Ensemble ATR æœ€æ–°å€¼: a20={a20:.6f}, a60={a60:.6f}")
                            
                            if a60 > 0:
                                ratio = float(a20 / a60)
                                valve_triggered = (ratio > atr_ratio)  # èˆ‡é€²éšåˆ†æä¸€è‡´ï¼šä½¿ç”¨ ">"
                                logger.info(f"[{strat}] Ensemble ATR æ¯”å€¼: {ratio:.4f} (é–€æª»={atr_ratio}) -> è§¸ç™¼={valve_triggered}")
                                
                                # å¢åŠ é¢¨éšªé–¥é–€è§¸ç™¼çš„è©³ç´°è³‡è¨Š
                                if valve_triggered:
                                    logger.info(f"[{strat}] ğŸ”´ é¢¨éšªé–¥é–€è§¸ç™¼ï¼ATRæ¯”å€¼({ratio:.4f}) > é–€æª»({atr_ratio})")
                                else:
                                    logger.info(f"[{strat}] ğŸŸ¢ é¢¨éšªé–¥é–€æœªè§¸ç™¼ï¼ŒATRæ¯”å€¼({ratio:.4f}) <= é–€æª»({atr_ratio})")
                            else:
                                logger.warning(f"[{strat}] Ensemble ATR(60) å€¼ç‚º 0ï¼Œç„¡æ³•è¨ˆç®—æ¯”å€¼")
                        else:
                            logger.warning(f"[{strat}] Ensemble ATR æ•¸æ“šä¸è¶³")
                    else:
                        logger.warning(f"[{strat}] Ensemble ATR è¨ˆç®—çµæœç‚ºç©º")
                        
                except Exception as e:
                    logger.warning(f"[{strat}] ç„¡æ³•è¨ˆç®— Ensemble ATR æ¯”å€¼: {e}")
                    logger.warning(f"[{strat}] éŒ¯èª¤è©³æƒ…: {type(e).__name__}: {str(e)}")

                # å¦‚æœå•Ÿç”¨å¼·åˆ¶è§¸ç™¼ï¼Œå‰‡å¼·åˆ¶è§¸ç™¼é¢¨éšªé–¥é–€
                if force_trigger:
                    valve_triggered = True
                    logger.info(f"[{strat}] ğŸ”´ å¼·åˆ¶è§¸ç™¼é¢¨éšªé–¥é–€å•Ÿç”¨")
                    if ratio is None:
                        ratio = 1.5  # è¨­å®šä¸€å€‹é è¨­å€¼ç”¨æ–¼é¡¯ç¤º

                # ä½¿ç”¨æ–°çš„ ensemble_runner åŸ·è¡Œ
                backtest_result = run_ensemble_backtest(cfg)

                # è‹¥å…¨å±€é–‹é—œé–‹å•Ÿä¸”é”è§¸ç™¼æ¢ä»¶ï¼Œæ‰åœ¨æ¬Šé‡åºåˆ—ä¸Šå¥—ç”¨ CAP
                if global_apply and valve_triggered:
                    from SSS_EnsembleTab import risk_valve_backtest
                    bench = df_raw  # å·²å« open/high/low/close/volume
                    
                    logger.info(f"[{strat}] ğŸ”´ é–‹å§‹å¥—ç”¨é¢¨éšªé–¥é–€: cap={risk_cap}, ratio={ratio:.4f}")
                    
                    rv = risk_valve_backtest(
                        open_px=backtest_result.price_series,
                        w=backtest_result.weight_curve,
                        cost=cost_params,
                        benchmark_df=bench,
                        mode="cap",
                        cap_level=float(risk_cap),
                        slope20_thresh=0.0, slope60_thresh=0.0,
                        atr_win=20, atr_ref_win=60,
                        atr_ratio_mult=float(atr_ratio),   # â† UI çš„ ATR é–€æª»
                        use_slopes=True,                   # â† è·Ÿå¢å¼·åˆ†æä¸€è‡´
                        slope_method="polyfit",            # â† è·Ÿå¢å¼·åˆ†æä¸€è‡´
                        atr_cmp="gt"                       # â† è·Ÿå¢å¼·åˆ†æä¸€è‡´ï¼ˆç”¨ >ï¼‰
                    )
                    # è¦†å¯«çµæœï¼Œç¢ºä¿ UI èˆ‡è¼¸å‡ºä¸€è‡´
                    backtest_result.daily_state = rv["daily_state_valve"]
                    backtest_result.ledger = rv["trade_ledger_valve"]
                    backtest_result.weight_curve = rv["weights_valve"]
                    backtest_result.equity_curve = rv["daily_state_valve"]["equity"]
                    logger.info(f"[{strat}] é¢¨éšªé–¥é–€å·²å¥—ç”¨ï¼ˆcap={risk_cap}, ratio={ratio:.4f}ï¼‰")
                    
                    # å¢åŠ é¢¨éšªé–¥é–€æ•ˆæœçš„è©³ç´°è³‡è¨Š
                    if "metrics" in rv:
                        logger.info(f"[{strat}] é¢¨éšªé–¥é–€æ•ˆæœ: PFåŸå§‹={rv['metrics'].get('pf_orig', 'N/A'):.2f}, PFé–¥é–€={rv['metrics'].get('pf_valve', 'N/A'):.2f}")
                        logger.info(f"[{strat}] é¢¨éšªé–¥é–€æ•ˆæœ: MDDåŸå§‹={rv['metrics'].get('mdd_orig', 'N/A'):.2f}%, MDDé–¥é–€={rv['metrics'].get('mdd_valve', 'N/A'):.2f}%")
                    
                    # çµ¦ UI çš„æ¨™è¨˜ï¼ˆèˆ‡ SSMA åˆ†æ”¯å°é½Šï¼‰
                    result['valve'] = {
                        "applied": True,
                        "cap": float(risk_cap),
                        "atr_ratio": ratio
                    }
                    
                    # æ–°å¢ï¼šè®“å…¨å±€å€æ®µçŸ¥é“å·²å¥—ç”¨é
                    result['_risk_valve_applied'] = True
                else:
                    if global_apply:
                        logger.info(f"[{strat}] ğŸŸ¢ é¢¨éšªé–¥é–€æœªè§¸ç™¼ï¼Œä½¿ç”¨åŸå§‹åƒæ•¸")
                        # çµ¦ UI çš„æ¨™è¨˜ï¼ˆæœªè§¸ç™¼ï¼‰
                        result['valve'] = {
                            "applied": False,
                            "cap": float(risk_cap),
                            "atr_ratio": ratio if ratio is not None else "N/A"
                        }
                    else:
                        logger.info(f"[{strat}] âšª å…¨å±€é¢¨éšªé–¥é–€æœªå•Ÿç”¨")
                        # çµ¦ UI çš„æ¨™è¨˜ï¼ˆæœªå•Ÿç”¨ï¼‰
                        result['valve'] = {
                            "applied": False,
                            "cap": "N/A",
                            "atr_ratio": "N/A"
                        }
                
                # è½‰æ›ç‚ºèˆŠæ ¼å¼ä»¥ä¿æŒç›¸å®¹æ€§
                result = {
                    'trades': [],
                    'trade_df': pack_df(backtest_result.trades),
                    'trades_df': pack_df(backtest_result.trades),
                    'signals_df': pack_df(backtest_result.trades[['trade_date', 'type', 'price']].rename(columns={'type': 'action'}) if not backtest_result.trades.empty else pd.DataFrame(columns=['trade_date', 'action', 'price'])),
                    'metrics': backtest_result.stats,
                    'equity_curve': pack_series(backtest_result.equity_curve),
                    'cash_curve': pack_series(backtest_result.cash_curve) if backtest_result.cash_curve is not None else "",
                    'weight_curve': pack_series(backtest_result.weight_curve) if backtest_result.weight_curve is not None else pack_series(pd.Series(0.0, index=backtest_result.equity_curve.index)),
                    'price_series': pack_series(backtest_result.price_series) if backtest_result.price_series is not None else pack_series(pd.Series(1.0, index=backtest_result.equity_curve.index)),
                    'daily_state': pack_df(backtest_result.daily_state),
                    'trade_ledger': pack_df(backtest_result.ledger),
                    'daily_state_std': pack_df(backtest_result.daily_state),
                    'trade_ledger_std': pack_df(backtest_result.ledger)
                }
                
                logger.info(f"[Ensemble] åŸ·è¡ŒæˆåŠŸ: æ¬Šç›Šæ›²ç·šé•·åº¦={len(backtest_result.equity_curve)}, äº¤æ˜“æ•¸={len(backtest_result.ledger) if backtest_result.ledger is not None and not backtest_result.ledger.empty else 0}")
                
            except Exception as e:
                logger.error(f"Ensemble ç­–ç•¥åŸ·è¡Œå¤±æ•—: {e}")
                # å‰µå»ºç©ºçš„çµæœ
                result = {
                    'trades': [],
                    'trade_df': pd.DataFrame(),
                    'trades_df': pd.DataFrame(),
                    'signals_df': pd.DataFrame(),
                    'metrics': {'total_return': 0.0, 'annual_return': 0.0, 'max_drawdown': 0.0, 'sharpe_ratio': 0.0, 'calmar_ratio': 0.0, 'num_trades': 0},
                    'equity_curve': pd.Series(1.0, index=df_raw.index)
                }
            
            # === ä¿®å¾© 3ï¼šæ·»åŠ èª¿è©¦æ—¥èªŒï¼Œæ ¸å°å­ç­–ç•¥é›†åˆæ˜¯å¦ä¸€è‡´ ===
            logger.info(f"[Ensemble] åŸ·è¡Œå®Œæˆï¼Œticker={ticker}, method={flat_params.get('method')}")
            if 'equity_curve' in result and hasattr(result['equity_curve'], 'shape'):
                logger.info(f"[Ensemble] æ¬Šç›Šæ›²ç·šé•·åº¦: {len(result['equity_curve'])}")
            if 'trade_df' in result and hasattr(result['trade_df'], 'shape'):
                logger.info(f"[Ensemble] äº¤æ˜“è¨˜éŒ„æ•¸é‡: {len(result['trade_df'])}")
        else:
            if strat_type == 'single':
                df_ind = compute_single(df_raw, df_factor, strat_params["linlen"], strat_params["factor"], strat_params["smaalen"], strat_params["devwin"], smaa_source=smaa_src)
            elif strat_type == 'dual':
                df_ind = compute_dual(df_raw, df_factor, strat_params["linlen"], strat_params["factor"], strat_params["smaalen"], strat_params["short_win"], strat_params["long_win"], smaa_source=smaa_src)
            elif strat_type == 'RMA':
                df_ind = compute_RMA(df_raw, df_factor, strat_params["linlen"], strat_params["factor"], strat_params["smaalen"], strat_params["rma_len"], strat_params["dev_len"], smaa_source=smaa_src)
            if df_ind.empty:
                continue
            result = backtest_unified(df_ind, strat_type, strat_params, discount=discount, trade_cooldown_bars=cooldown, bad_holding=bad_holding)
            
            # ç‚ºå…¶ä»–ç­–ç•¥é¡å‹æ·»åŠ  valve æ¨™è¨˜
            if global_apply:
                result['valve'] = {
                    "applied": False,  # å…¶ä»–ç­–ç•¥é¡å‹æš«æ™‚ä¸æ”¯æ´é¢¨éšªé–¥é–€
                    "cap": float(risk_cap),
                    "atr_ratio": "N/A"
                }
            else:
                result['valve'] = {
                    "applied": False,
                    "cap": "N/A",
                    "atr_ratio": "N/A"
                }
        # çµ±ä¸€ä½¿ç”¨ orient="split" æ‰“åŒ…ï¼Œé¿å…é‡è¤‡åºåˆ—åŒ–
        # æ³¨æ„ï¼šEnsemble ç­–ç•¥å·²ç¶“åœ¨ pack_df/pack_series ä¸­è™•ç†éï¼Œé€™è£¡åªè™•ç†å–®ç­–ç•¥
        if strat_type != 'ensemble':
            if hasattr(result.get('trade_df'), 'to_json'):
                result['trade_df'] = result['trade_df'].to_json(date_format='iso', orient='split')
            if 'signals_df' in result and hasattr(result['signals_df'], 'to_json'):
                result['signals_df'] = result['signals_df'].to_json(date_format='iso', orient='split')
            if 'trades_df' in result and hasattr(result['trades_df'], 'to_json'):
                result['trades_df'] = result['trades_df'].to_json(date_format='iso', orient='split')
            if 'equity_curve' in result and hasattr(result['equity_curve'], 'to_json'):
                result['equity_curve'] = result['equity_curve'].to_json(date_format='iso', orient='split')
        if 'trades' in result and isinstance(result['trades'], list):
            result['trades'] = [
                (str(t[0]), t[1], str(t[2])) if isinstance(t, tuple) and len(t) == 3 else t
                for t in result['trades']
            ]
        
        # << æ–°å¢ï¼šä¸€å¾‹åšæœ€å¾Œä¿éšªæ‰“åŒ…ï¼Œè£œä¸Š daily_state / weight_curve ç­‰ >>
        result = _pack_result_for_store(result)
        
        # === å…¨å±€é¢¨éšªé–¥é–€ï¼šé€æ—¥å‹•æ…‹å¥—ç”¨ï¼ˆèˆ‡å¢å¼·åˆ†æä¸€è‡´ï¼‰ ===
        if global_apply:
            # æ–°å¢ï¼šè‹¥ç­–ç•¥åˆ†æ”¯å·²ç¶“å¥—ç”¨ï¼Œå°±ä¸è¦å†ä¾†ä¸€æ¬¡
            if result.get('_risk_valve_applied'):
                logger.info(f"[{strat}] å·²ç”±ç­–ç•¥åˆ†æ”¯å¥—ç”¨é¢¨éšªé–¥é–€ï¼Œè·³éå…¨å±€å†æ¬¡å¥—ç”¨")
            else:
                # åŸæœ¬å€å¡Šå¾é€™è£¡é–‹å§‹
                # 1) å– dsï¼ˆdaily_stateï¼‰ï¼Œä¸¦è§£åŒ…
                ds_raw = result.get("daily_state_std") or result.get("daily_state")
                ds = df_from_pack(ds_raw)
                if ds is None or ds.empty or "w" not in ds.columns:
                    logger.warning(f"[{strat}] daily_state ä¸å« 'w'ï¼Œè·³éå…¨å±€é¢¨éšªé–¥é–€")
                else:
                    # 2) ä½¿ç”¨èˆ‡é€²éšåˆ†æä¸€è‡´çš„é¢¨éšªé–¥é–€åˆ¤æ–·é‚è¼¯
                    try:
                        from SSS_EnsembleTab import compute_risk_valve_signals
                        
                        # å»ºç«‹åŸºæº–è³‡æ–™ï¼ˆæœ‰é«˜ä½åƒ¹å°±å¸¶ä¸Šï¼‰
                        bench = _build_benchmark_df(df_raw)
                        # æ”¶ç›¤åƒ¹æ¬„ä½ - å„ªå…ˆä½¿ç”¨è‹±æ–‡æ¬„ä½ï¼Œå›é€€åˆ°ä¸­æ–‡æ¬„ä½
                        if 'close' in df_raw.columns:
                            bench["æ”¶ç›¤åƒ¹"] = pd.to_numeric(df_raw["close"], errors="coerce")
                        elif 'Close' in df_raw.columns:
                            bench["æ”¶ç›¤åƒ¹"] = pd.to_numeric(df_raw["Close"], errors="coerce")
                        elif 'æ”¶ç›¤åƒ¹' in df_raw.columns:
                            bench["æ”¶ç›¤åƒ¹"] = pd.to_numeric(df_raw["æ”¶ç›¤åƒ¹"], errors="coerce")
                        
                        # æœ€é«˜åƒ¹å’Œæœ€ä½åƒ¹æ¬„ä½ - å„ªå…ˆä½¿ç”¨è‹±æ–‡æ¬„ä½ï¼Œå›é€€åˆ°ä¸­æ–‡æ¬„ä½
                        if 'high' in df_raw.columns and 'low' in df_raw.columns:
                            bench["æœ€é«˜åƒ¹"] = pd.to_numeric(df_raw["high"], errors="coerce")
                            bench["æœ€ä½åƒ¹"] = pd.to_numeric(df_raw["low"], errors="coerce")
                        elif 'High' in df_raw.columns and 'Low' in df_raw.columns:
                            bench["æœ€é«˜åƒ¹"] = pd.to_numeric(df_raw["High"], errors="coerce")
                            bench["æœ€ä½åƒ¹"] = pd.to_numeric(df_raw["Low"], errors="coerce")
                        elif 'æœ€é«˜åƒ¹' in df_raw.columns and 'æœ€ä½åƒ¹' in df_raw.columns:
                            bench["æœ€é«˜åƒ¹"] = pd.to_numeric(df_raw["æœ€é«˜åƒ¹"], errors="coerce")
                            bench["æœ€ä½åƒ¹"] = pd.to_numeric(df_raw["æœ€ä½åƒ¹"], errors="coerce")
                        
                        # ä½¿ç”¨é€²éšåˆ†æçš„é è¨­åƒæ•¸ï¼šæ–œç‡é–€æª»=0ï¼ŒATRæ¯”å€¼=1.5ï¼Œæ¯”è¼ƒç¬¦è™Ÿ=">"
                        risk_signals = compute_risk_valve_signals(
                            benchmark_df=bench,
                            slope20_thresh=0.0,      # 20æ—¥æ–œç‡é–€æª»
                            slope60_thresh=0.0,      # 60æ—¥æ–œç‡é–€æª»
                            atr_win=20,              # ATRè¨ˆç®—çª—å£
                            atr_ref_win=60,          # ATRåƒè€ƒçª—å£
                            atr_ratio_mult=float(atr_ratio),  # ATRæ¯”å€¼é–€æª»
                            use_slopes=True,         # å•Ÿç”¨æ–œç‡æ¢ä»¶
                            slope_method="polyfit",   # ä½¿ç”¨å¤šé …å¼æ“¬åˆæ–œç‡
                            atr_cmp="gt"             # ä½¿ç”¨ ">" æ¯”è¼ƒç¬¦è™Ÿ
                        )
                        
                        mask = risk_signals["risk_trigger"].reindex(ds.index).fillna(False)
                        logger.info(f"[{strat}] é€²éšåˆ†æé¢¨éšªé–¥é–€ï¼šæ–œç‡æ¢ä»¶å•Ÿç”¨ï¼ŒATRæ¯”å€¼é–€æª»={atr_ratio}")
                        
                    except Exception as e:
                        logger.warning(f"[{strat}] ç„¡æ³•ä½¿ç”¨é€²éšåˆ†æé¢¨éšªé–¥é–€ï¼Œå›é€€åˆ° ATR-only: {e}")
                        # å›é€€åˆ°åŸæœ¬çš„ ATR-only é‚è¼¯
                        atr20 = calculate_atr(df_raw, 20)
                        atr60 = calculate_atr(df_raw, 60)
                        if atr20 is None or atr60 is None:
                            logger.warning(f"[{strat}] ç„¡æ³•è¨ˆç®— ATR20/60ï¼Œè·³éå…¨å±€é¢¨éšªé–¥é–€")
                            continue
                        ratio = (atr20 / atr60).replace([np.inf, -np.inf], np.nan)
                        mask = (ratio > float(atr_ratio))  # èˆ‡é€²éšåˆ†æä¸€è‡´ï¼šä½¿ç”¨ ">" æ¯”è¼ƒ
                    
                    if force_trigger:
                        mask[:] = True  # å¼·åˆ¶å…¨éƒ¨æ—¥å­å¥— CAP

                    # åœ¨å…¨å±€å£“ w ä¹‹å‰åŠ ï¼šä¿å­˜æœªå¥—é–¥é–€çš„ baseline
                    if "daily_state_base" not in result and ds_raw is not None:
                        result["daily_state_base"] = ds_raw  # ä¿å­˜æœªå¥—é–¥é–€çš„ baseline
                    
                    # â‹ è¿½åŠ ä»¥ä¸‹å…©è¡Œï¼ˆæ”¾åœ¨åŒä¸€æ®µã€è¦†å¯« w ä¹‹å‰ï¼‰
                    if "trade_ledger_base" not in result and result.get("trade_ledger") is not None:
                        result["trade_ledger_base"] = result["trade_ledger"]
                    if "weight_curve_base" not in result and result.get("weight_curve") is not None:
                        result["weight_curve_base"] = result["weight_curve"]
                    
                    # 3) å°é½Šåˆ° ds.indexï¼Œé€æ—¥å£“ w è‡³ CAP
                    mask_aligned = mask.reindex(ds.index).fillna(False).to_numpy()
                    w = ds["w"].astype(float).to_numpy()
                    w_new = w.copy()
                    w_new[mask_aligned] = np.minimum(w_new[mask_aligned], float(risk_cap))
                    ds["w"] = w_new

                    # 4) å›å¯« dsï¼Œä¸¦é‡ç®—äº¤æ˜“/æ¬Šç›Š
                    result["daily_state_std"] = pack_df(ds)

                    # open åƒ¹ï¼ˆæ²’æœ‰ open å°±é€€è€Œæ±‚å…¶æ¬¡ç”¨æ”¶ç›¤åƒ¹ï¼‰
                    open_px = (df_raw["open"] if "open" in df_raw.columns else df_raw.get("æ”¶ç›¤åƒ¹")).astype(float)
                    open_px = open_px.reindex(ds.index).dropna()

                    # è‹¥ä½ æ²¿ç”¨ç¾æœ‰çš„ risk_valve_backtestï¼Œçµ¦ cap_level=1.0 è¡¨ç¤ºã€Œw å·²ç¶“æ˜¯ç›®æ¨™åºåˆ—ã€
                    try:
                        from SSS_EnsembleTab import (
                            risk_valve_backtest,
                            CostParams,
                            _mdd_from_daily_equity,
                            _sell_returns_pct_from_ledger,
                        )
                        
                        # æˆæœ¬åƒæ•¸
                        trade_cost = (strat_params.get("trade_cost", {}) 
                                      if isinstance(strat_params, dict) else {})
                        cost = CostParams(
                            buy_fee_bp=float(trade_cost.get("buy_fee_bp", 4.27)),
                            sell_fee_bp=float(trade_cost.get("sell_fee_bp", 4.27)),
                            sell_tax_bp=float(trade_cost.get("sell_tax_bp", 30.0)),
                        )
                        
                        # åŸºæº–ï¼ˆæœ‰é«˜ä½åƒ¹å°±å¸¶ä¸Šï¼‰
                        bench = _build_benchmark_df(df_raw)
                        
                        # === é¢¨éšªé–¥é–€å›æ¸¬ï¼šç¢ºä¿åƒæ•¸ä¸€è‡´æ€§ (2025/08/20) ===
                        valve_params = {
                            "open_px": open_px,
                            "w": ds["w"].astype(float).reindex(open_px.index).fillna(0.0),
                            "cost": cost,
                            "benchmark_df": bench,
                            "mode": "cap",
                            "cap_level": float(risk_cap),  # ä½¿ç”¨å¯¦éš›çš„é¢¨éšªä¸Šé™å€¼
                            "slope20_thresh": 0.0,         # ğŸ‘ˆ èˆ‡é€²éšåˆ†æä¸€è‡´ï¼š20æ—¥æ–œç‡é–€æª»
                            "slope60_thresh": 0.0,         # ğŸ‘ˆ èˆ‡é€²éšåˆ†æä¸€è‡´ï¼š60æ—¥æ–œç‡é–€æª»
                            "atr_win": 20, 
                            "atr_ref_win": 60,
                            "atr_ratio_mult": float(atr_ratio),   # ğŸ‘ˆ èˆ‡å…¨å±€ä¸€è‡´
                            "use_slopes": True,            # ğŸ‘ˆ èˆ‡é€²éšåˆ†æä¸€è‡´ï¼šå•Ÿç”¨æ–œç‡æ¢ä»¶
                            "slope_method": "polyfit",     # ğŸ‘ˆ èˆ‡é€²éšåˆ†æä¸€è‡´ï¼šä½¿ç”¨å¤šé …å¼æ“¬åˆ
                            "atr_cmp": "gt"               # ğŸ‘ˆ èˆ‡é€²éšåˆ†æä¸€è‡´ï¼šä½¿ç”¨ ">" æ¯”è¼ƒç¬¦è™Ÿ
                        }
                        
                        # è¨˜éŒ„é¢¨éšªé–¥é–€é…ç½®ç”¨æ–¼è¨ºæ–·
                        logger.info(f"[{strat}] é¢¨éšªé–¥é–€é…ç½®: cap_level={valve_params['cap_level']}, atr_ratio_mult={valve_params['atr_ratio_mult']}")
                        
                        result_cap = risk_valve_backtest(**valve_params)
                    except Exception as e:
                        logger.warning(f"[{strat}] ç„¡æ³•å°å…¥ risk_valve_backtest: {e}")
                        result_cap = None

                    if result_cap:
                        # === å®‰å…¨è¦†å¯«ï¼šæ¸…æ‰èˆŠéµä¸¦è£œé½Šæ–°éµ ===
                        logger.info(f"[UI_CHECK] å³å°‡è¦†å¯«ï¼šnew_trades={len(result_cap.get('trade_ledger_valve', pd.DataFrame()))} rows, new_ds={len(result_cap.get('daily_state_valve', pd.DataFrame()))} rows")
                        
                        # 1) è¦†å¯«çµæœ â€”â€” ä¸€å¾‹ç”¨ pack_df/pack_series
                        if 'trade_ledger_valve' in result_cap:
                            result['trades'] = pack_df(result_cap['trade_ledger_valve'])
                            result['trade_ledger'] = pack_df(result_cap['trade_ledger_valve'])
                            result['trade_ledger_std'] = pack_df(result_cap['trade_ledger_valve'])
                        
                        if 'daily_state_valve' in result_cap:
                            result['daily_state'] = pack_df(result_cap['daily_state_valve'])
                            result['daily_state_std'] = pack_df(result_cap['daily_state_valve'])
                        
                        if 'weights_valve' in result_cap:
                            result['weight_curve'] = pack_series(result_cap['weights_valve'])
                        
                        # æ¬Šç›Šæ›²ç·šï¼šè‹¥æ˜¯ Series
                        if 'daily_state_valve' in result_cap and 'equity' in result_cap['daily_state_valve']:
                            try:
                                result['equity_curve'] = pack_series(result_cap['daily_state_valve']['equity'])
                            except Exception:
                                # è‹¥ä½ å­˜çš„æ˜¯ DataFrame
                                result['equity_curve'] = pack_df(result_cap['daily_state_valve']['equity'].to_frame('equity'))
                        
                        # 2) **é—œéµ**ï¼šæŠŠ UI å¯èƒ½æ‹¿ä¾†ç”¨çš„èˆŠå¿«å–æ¸…æ‰ï¼Œå¼·è¿« UI èµ°æ–°è³‡æ–™
                        for k in ['trades_ui', 'trade_df', 'trade_ledger_std', 'metrics']:
                            if k in result:
                                result.pop(k, None)
                        

                        
                        # æ–°å¢ï¼šæ¨™è¨˜ valve ç‹€æ…‹ä¾›å¾ŒçºŒå¿«å–åˆ¤æ–·
                        result['valve'] = {
                            'applied': True,
                            'cap': float(risk_cap),
                            'atr_ratio_mult': float(atr_ratio),
                        }
                        
                        # æ–°å¢ï¼šå­˜å…¥ ensemble åƒæ•¸ï¼ˆè‹¥å¯å–å¾—ï¼‰
                        # åœ¨å…¨å±€é¢¨éšªé–¥é–€å€å¡Šä¸­ï¼Œæˆ‘å€‘æ²’æœ‰ cfg ç‰©ä»¶ï¼Œç›´æ¥ä½¿ç”¨é è¨­å€¼
                        result["ensemble_params"] = {"majority_k_pct": 0.55}  # é è¨­å€¼

                        # 2025-08-20 é‡ç®—æŒ‡æ¨™ä»¥ä¿ç•™ç¸¾æ•ˆè³‡è¨Š #app_dash.py
                        ledger_valve = result_cap.get('trade_ledger_valve', pd.DataFrame())
                        ds_valve = result_cap.get('daily_state_valve', pd.DataFrame())
                        if not ledger_valve.empty and not ds_valve.empty and 'equity' in ds_valve:
                            r = _sell_returns_pct_from_ledger(ledger_valve)
                            eq = ds_valve['equity']
                            total_ret = eq.iloc[-1] / eq.iloc[0] - 1
                            years = max((eq.index[-1] - eq.index[0]).days / 365.25, 1)
                            ann_ret = (1 + total_ret) ** (1 / years) - 1
                            mdd = _mdd_from_daily_equity(eq)
                            dd = eq / eq.cummax() - 1
                            blocks = (~(dd < 0)).cumsum()
                            dd_dur = int((dd.groupby(blocks).cumcount() + 1).where(dd < 0).max() or 0)
                            num_trades = len(r)
                            win_rate = (r > 0).sum() / num_trades if num_trades > 0 else 0
                            avg_win = r[r > 0].mean() if win_rate > 0 else np.nan
                            avg_loss = r[r < 0].mean() if win_rate < 1 else np.nan
                            payoff = abs(avg_win / avg_loss) if avg_loss != 0 and not np.isnan(avg_win) else np.nan
                            daily_r = eq.pct_change().dropna()
                            sharpe = (daily_r.mean() * np.sqrt(252)) / daily_r.std() if daily_r.std() != 0 else np.nan
                            downside = daily_r[daily_r < 0]
                            sortino = (daily_r.mean() * np.sqrt(252)) / downside.std() if downside.std() != 0 else np.nan
                            ann_vol = daily_r.std() * np.sqrt(252) if len(daily_r) > 0 else np.nan
                            prof = r[r > 0].sum()
                            loss = abs(r[r < 0].sum())
                            pf = prof / loss if loss != 0 else np.nan
                            win_flag = r > 0
                            grp = (win_flag != win_flag.shift()).cumsum()
                            consec = win_flag.groupby(grp).cumcount() + 1
                            max_wins = int(consec[win_flag].max() if True in win_flag.values else 0)
                            max_losses = int(consec[~win_flag].max() if False in win_flag.values else 0)
                            result['metrics'] = {
                                'total_return': float(total_ret),
                                'annual_return': float(ann_ret),
                                'max_drawdown': float(mdd),
                                'max_drawdown_duration': dd_dur,
                                'calmar_ratio': float(ann_ret / abs(mdd)) if mdd < 0 else np.nan,
                                'num_trades': int(num_trades),
                                'win_rate': float(win_rate),
                                'avg_win': float(avg_win) if not np.isnan(avg_win) else np.nan,
                                'avg_loss': float(avg_loss) if not np.isnan(avg_loss) else np.nan,
                                'payoff_ratio': float(payoff) if not np.isnan(payoff) else np.nan,
                                'sharpe_ratio': float(sharpe) if not np.isnan(sharpe) else np.nan,
                                'sortino_ratio': float(sortino) if not np.isnan(sortino) else np.nan,
                                'max_consecutive_wins': max_wins,
                                'max_consecutive_losses': max_losses,
                                'annualized_volatility': float(ann_vol) if not np.isnan(ann_vol) else np.nan,
                                'profit_factor': float(pf) if not np.isnan(pf) else np.nan,
                            }
                        
                        # 3) çµ¦ UI ä¸€å€‹æ——æ¨™èˆ‡åƒæ•¸ï¼Œä¾¿æ–¼é¡¯ç¤ºã€Œå·²å¥—ç”¨ã€
                        result['_risk_valve_applied'] = True
                        result['_risk_valve_params'] = {
                            'cap': float(risk_cap),
                            'atr_ratio': float(atr_ratio),
                            'atr20_last': float(atr_20_valid.iloc[-1]) if len(atr_20_valid) > 0 else None,
                            'atr60_last': float(atr_60_valid.iloc[-1]) if len(atr_60_valid) > 0 else None,
                        }
                        
                        true_days = int(mask_aligned.sum())
                        logger.info(f"[{strat}] å…¨å±€é¢¨éšªé–¥é–€å·²å¥—ç”¨ï¼ˆé€æ—¥ï¼‰ï¼Œé¢¨éšªå¤©æ•¸={true_days}, CAP={risk_cap:.2f}")
                    else:
                        logger.warning(f"[{strat}] é¢¨éšªé–¥é–€é‡ç®—æ²’æœ‰è¿”å›çµæœ")

        
        results[strat] = result
    
    # ä½¿ç”¨ç¬¬ä¸€å€‹ç­–ç•¥çš„æ•¸æ“šä½œç‚ºä¸»è¦é¡¯ç¤ºæ•¸æ“š
    first_strat = list(results.keys())[0] if results else strategy_names[0]
    first_smaa_src = param_presets[first_strat].get("smaa_source", "Self")
    df_raw_main, _ = load_data(ticker, start_date, end_date if end_date else None, smaa_source=first_smaa_src)
    
    # çµ±ä¸€ä½¿ç”¨ orient="split" åºåˆ—åŒ–ï¼Œç¢ºä¿ä¸€è‡´æ€§
    payload = {
        'results': results, 
        'df_raw': df_raw_main.to_json(date_format='iso', orient='split'), 
        'ticker': ticker
    }
    
    # é˜²å®ˆæ€§æª¢æŸ¥ï¼šå¦‚é‚„æœ‰æ¼ç¶²çš„éåºåˆ—åŒ–ç‰©ä»¶å°±èƒ½ææ—©çœ‹å‡º
    try:
        json.dumps(payload)
    except Exception as e:
        logger.exception("[BUG] backtest-store payload ä»å«ä¸å¯åºåˆ—åŒ–ç‰©ä»¶ï¼š%s", e)
        # å¦‚æœè¦å¼·åˆ¶ä¸å™´ï¼Œå¯åš fallbackï¼šjson.dumps(..., default=str) ä½†é€šå¸¸ä¸å»ºè­°åæ‰
    
    # === å›æ¸¬å®Œæˆæ—¥èªŒ ===
    logger.info(f"å›æ¸¬å®Œæˆ - ç­–ç•¥æ•¸: {len(results)}, ticker: {ticker}, æ•¸æ“šè¡Œæ•¸: {len(df_raw_main)}")
    logger.debug(f"ç­–ç•¥åˆ—è¡¨: {list(results.keys())}")
    
    return payload

# --------- ä¸»é ç±¤å…§å®¹é¡¯ç¤º ---------
@app.callback(
    Output('tab-content', 'children'),
    Input('backtest-store', 'data'),
    Input('main-tabs', 'value'),
    State('strategy-dropdown', 'value'),
    Input('theme-store', 'data')
)
def update_tab(data, tab, selected_strategy, theme):
    # === èª¿è©¦æ—¥èªŒï¼ˆåƒ…åœ¨ DEBUG ç´šåˆ¥æ™‚é¡¯ç¤ºï¼‰===
    logger.debug(f"update_tab è¢«èª¿ç”¨ - tab: {tab}, strategy: {selected_strategy}")
    
    if not data:
        logger.warning("æ²’æœ‰å›æ¸¬æ•¸æ“šï¼Œé¡¯ç¤ºæç¤ºè¨Šæ¯")
        return html.Div("è«‹å…ˆåŸ·è¡Œå›æ¸¬")
    
    # data ç¾åœ¨å·²ç¶“æ˜¯ dictï¼Œä¸éœ€è¦ json.loads
    results = data['results']
    df_raw = df_from_pack(data['df_raw'])  # ä½¿ç”¨ df_from_pack çµ±ä¸€è§£åŒ…
    ticker = data['ticker']
    strategy_names = list(results.keys())
    
    logger.debug(f"æ•¸æ“šè§£æå®Œæˆ - ç­–ç•¥æ•¸: {len(strategy_names)}, ticker: {ticker}, æ•¸æ“šè¡Œæ•¸: {len(df_raw) if df_raw is not None else 0}")
    # æ ¹æ“šä¸»é¡Œæ±ºå®š plotly template èˆ‡é¡è‰²
    if theme == 'theme-dark':
        plotly_template = 'plotly_dark'
        font_color = '#fff'
        bg_color = '#181818'
        legend_font_color = '#fff'
        legend_bgcolor = '#232323'
        legend_bordercolor = '#fff'
    elif theme == 'theme-light':
        plotly_template = 'plotly_white'
        font_color = '#111'
        bg_color = '#fff'
        legend_font_color = '#111'
        legend_bgcolor = '#fff'
        legend_bordercolor = '#111'
    else:  # theme-blue
        plotly_template = 'plotly_white'
        font_color = '#ffe066'
        bg_color = '#003366'
        legend_font_color = '#ffe066'
        legend_bgcolor = '#002244'
        legend_bordercolor = '#ffe066'
    
    if tab == "backtest":
        # å‰µå»ºç­–ç•¥å›æ¸¬çš„å­é ç±¤
        strategy_tabs = []
        for strategy in strategy_names:
            result = results.get(strategy)
            if not result:
                continue
            
            # === çµ±ä¸€å…¥å£ï¼šè®€å–äº¤æ˜“è¡¨ã€æ—¥ç‹€æ…‹ã€æ¬Šç›Šæ›²ç·š ===
            # è®€äº¤æ˜“è¡¨çš„çµ±ä¸€å…¥å£ï¼šå…ˆç”¨æ¨™æº–éµï¼Œå† fallback
            trade_df = None
            candidates = [
                result.get('trades'),      # å…¨å±€è¦†å¯«å¾Œæ¨™æº–éµ
                result.get('trades_ui'),   # èˆŠæ ¼å¼ï¼ˆè‹¥é‚„å­˜åœ¨ï¼‰
                result.get('trade_df'),    # æŸäº›ç­–ç•¥è‡ªå¸¶
            ]
            
            for cand in candidates:
                if cand is None:
                    continue
                # cand å¯èƒ½å·²æ˜¯ DataFrame æˆ–æ‰“åŒ…å­—ä¸²
                df = df_from_pack(cand) if isinstance(cand, str) else cand
                if df is not None and getattr(df, 'empty', True) is False:
                    trade_df = df.copy()
                    break
            
            if trade_df is None:
                # å»ºç«‹ç©ºè¡¨é¿å…å¾ŒçºŒå´©
                trade_df = pd.DataFrame(columns=['trade_date','type','price','shares','return'])
            
            # æ—¥ç‹€æ…‹èˆ‡æ¬Šç›Šæ›²ç·šä¹Ÿé¡ä¼¼è™•ç†
            daily_state_std = df_from_pack(result.get('daily_state_std'))
            if daily_state_std is None or daily_state_std.empty:
                daily_state_std = df_from_pack(result.get('daily_state'))
            if daily_state_std is None:
                daily_state_std = pd.DataFrame()
            
            trade_ledger_std = df_from_pack(result.get('trade_ledger_std'))
            if trade_ledger_std is None or trade_ledger_std.empty:
                trade_ledger_std = df_from_pack(result.get('trade_ledger'))
            if trade_ledger_std is None:
                trade_ledger_std = pd.DataFrame()
            
            # è¨˜éŒ„ä¾†æºé¸æ“‡çµæœ
            logger.info(f"[UI] {strategy} trades ä¾†æºå„ªå…ˆåºï¼štrades -> trades_ui -> trade_dfï¼›å¯¦éš›ä½¿ç”¨={'trades' if 'trades' in result else ('trades_ui' if 'trades_ui' in result else 'trade_df')}")
            logger.info(f"[UI] {strategy} è®€å–å¾Œå‰ 3 åˆ— w: {daily_state_std['w'].head(3).tolist() if 'w' in daily_state_std.columns else 'N/A'}")
            
            # æ¨™æº–åŒ–äº¤æ˜“è³‡æ–™ï¼Œç¢ºä¿æœ‰çµ±ä¸€çš„ trade_date/type/price æ¬„ä½
            try:
                from sss_core.normalize import normalize_trades_for_ui as norm
                trade_df = norm(trade_df)
                logger.info(f"æ¨™æº–åŒ–å¾Œ trades_ui æ¬„ä½: {list(trade_df.columns)}")
            except Exception as e:
                logger.warning(f"ç„¡æ³•ä½¿ç”¨ sss_core æ¨™æº–åŒ–ï¼Œä½¿ç”¨å¾Œå‚™æ–¹æ¡ˆ: {e}")
                # å¾Œå‚™æ¨™æº–åŒ–æ–¹æ¡ˆ
                if trade_df is not None and len(trade_df) > 0:
                    trade_df = trade_df.copy()
                    trade_df.columns = [str(c).lower() for c in trade_df.columns]
                    
                    # ç¢ºä¿æœ‰ trade_date æ¬„
                    if "trade_date" not in trade_df.columns:
                        if "date" in trade_df.columns:
                            trade_df["trade_date"] = pd.to_datetime(trade_df["date"], errors="coerce")
                        elif isinstance(trade_df.index, pd.DatetimeIndex):
                            trade_df = trade_df.reset_index().rename(columns={"index": "trade_date"})
                        else:
                            trade_df["trade_date"] = pd.NaT
                    else:
                        trade_df["trade_date"] = pd.to_datetime(trade_df["trade_date"], errors="coerce")
                    
                    # ç¢ºä¿æœ‰ type æ¬„
                    if "type" not in trade_df.columns:
                        if "action" in trade_df.columns:
                            trade_df["type"] = trade_df["action"].astype(str).str.lower()
                        elif "side" in trade_df.columns:
                            trade_df["type"] = trade_df["side"].astype(str).str.lower()
                        else:
                            trade_df["type"] = "hold"
                    
                    # ç¢ºä¿æœ‰ price æ¬„
                    if "price" not in trade_df.columns:
                        for c in ["open", "price_open", "exec_price", "px", "close"]:
                            if c in trade_df.columns:
                                trade_df["price"] = trade_df[c]
                                break
                        if "price" not in trade_df.columns:
                            trade_df["price"] = 0.0
            
            # å‹åˆ¥å°é½Šï¼šä¿è­‰ trade_date ç‚º Timestampï¼Œprice/shares ç‚º float
            if 'trade_date' in trade_df.columns:
                trade_df['trade_date'] = pd.to_datetime(trade_df['trade_date'])
            if 'signal_date' in trade_df.columns:
                trade_df['signal_date'] = pd.to_datetime(trade_df['signal_date'])
            if 'price' in trade_df.columns:
                trade_df['price'] = pd.to_numeric(trade_df['price'], errors='coerce')
            if 'shares' in trade_df.columns:
                trade_df['shares'] = pd.to_numeric(trade_df['shares'], errors='coerce')
            
            # === æ–°ï¼šè‹¥æœ‰ trade_ledgerï¼Œå„ªå…ˆé¡¯ç¤ºæ›´å®Œæ•´çš„æ¬„ä½ ===
            ledger_df = df_from_pack(result.get('trade_ledger'))
            try:
                from sss_core.normalize import normalize_trades_for_ui as norm
                ledger_ui = norm(ledger_df) if ledger_df is not None and len(ledger_df)>0 else pd.DataFrame()
            except Exception:
                ledger_ui = ledger_df if ledger_df is not None else pd.DataFrame()
            
            # === ä¿®æ­£ï¼šå„ªå…ˆä½¿ç”¨æ¨™æº–åŒ–å¾Œçš„ trade_ledger_std ===
            # ä½¿ç”¨ utils_payload æ¨™æº–åŒ–å¾Œçš„çµæœï¼Œç¢ºä¿æ¬„ä½é½Šå…¨
            if trade_ledger_std is not None and not trade_ledger_std.empty:
                base_df = trade_ledger_std
                if 'trade_date' in base_df.columns:
                    base_df['trade_date'] = pd.to_datetime(base_df['trade_date'], errors='coerce')
                if 'signal_date' in base_df.columns:
                    base_df['signal_date'] = pd.to_datetime(base_df['signal_date'], errors='coerce')
            elif ledger_ui is not None and not ledger_ui.empty:
                base_df = ledger_ui
                if 'trade_date' in base_df.columns:
                    base_df['trade_date'] = pd.to_datetime(base_df['trade_date'], errors='coerce')
                if 'signal_date' in base_df.columns:
                    base_df['signal_date'] = pd.to_datetime(base_df['signal_date'], errors='coerce')
            else:
                base_df = trade_df
            
            # è¨˜éŒ„åŸå§‹æ¬„ä½ï¼ˆåµéŒ¯ç”¨ï¼‰
            logger.info("[UI] trade_df åŸå§‹æ¬„ä½ï¼š%s", list(base_df.columns) if base_df is not None else None)
            logger.info("[UI] trade_ledger_std åŸå§‹æ¬„ä½ï¼š%s", list(trade_ledger_std.columns) if trade_ledger_std is not None else None)

            # ç‚ºäº† 100% ä¿è­‰ weight_change å‡ºç¾ï¼Œå…ˆç¢ºä¿æ¬Šé‡æ¬„ä½
            base_df = _ensure_weight_columns(base_df)
            # ä½¿ç”¨æ–°çš„çµ±ä¸€æ ¼å¼åŒ–å‡½å¼
            display_df = format_trade_like_df_for_display(base_df)

            # === äº¤æ˜“æµæ°´å¸³(ledger)è¡¨æ ¼ï¼šå…ˆæº–å‚™é¡¯ç¤ºç‰ˆ ===
            ledger_src = trade_ledger_std if (trade_ledger_std is not None and not trade_ledger_std.empty) else \
                         (ledger_ui if (ledger_ui is not None and not ledger_ui.empty) else pd.DataFrame())

            if ledger_src is not None and not ledger_src.empty:
                # ç‚ºäº† 100% ä¿è­‰ weight_change å‡ºç¾ï¼Œå…ˆç¢ºä¿æ¬Šé‡æ¬„ä½
                ledger_src = _ensure_weight_columns(ledger_src)
                # ä½¿ç”¨æ–°çš„çµ±ä¸€æ ¼å¼åŒ–å‡½å¼
                ledger_display = format_trade_like_df_for_display(ledger_src)
                ledger_columns = [{"name": i, "id": i} for i in ledger_display.columns]
                ledger_data = ledger_display.to_dict('records')
            else:
                ledger_columns = []
                ledger_data = []
            
            metrics = result.get('metrics', {})
            tooltip = f"{strategy} ç­–ç•¥èª¬æ˜"
            param_display = {k: v for k, v in param_presets[strategy].items() if k != "strategy_type"}
            param_str = ", ".join(f"{k}: {v}" for k, v in param_display.items())
            avg_holding = calculate_holding_periods(trade_df)
            metrics['avg_holding_period'] = avg_holding
            
            label_map = {
                "total_return": "ç¸½å›å ±ç‡",
                "annual_return": "å¹´åŒ–å›å ±ç‡",
                "win_rate": "å‹ç‡",
                "max_drawdown": "æœ€å¤§å›æ’¤",
                "max_drawdown_duration": "å›æ’¤æŒçºŒ",
                "calmar_ratio": "å¡ç‘ªæ¯”ç‡",
                "sharpe_ratio": "å¤æ™®æ¯”ç‡",
                "sortino_ratio": "ç´¢æè«¾æ¯”ç‡",
                "payoff_ratio": "ç›ˆè™§æ¯”",
                "profit_factor": "ç›ˆè™§å› å­",
                "num_trades": "äº¤æ˜“æ¬¡æ•¸",
                "avg_holding_period": "å¹³å‡æŒå€‰å¤©æ•¸",
                "annualized_volatility": "å¹´åŒ–æ³¢å‹•ç‡",
                "max_consecutive_wins": "æœ€å¤§é€£çºŒç›ˆåˆ©",
                "max_consecutive_losses": "æœ€å¤§é€£çºŒè™§æ",
                "avg_win": "å¹³å‡ç›ˆåˆ©",
                "avg_loss": "å¹³å‡è™§æ",
            }
            
            metric_cards = []
            for k, v in metrics.items():
                if k in ["total_return", "annual_return", "win_rate", "max_drawdown", "annualized_volatility", "avg_win", "avg_loss"]:
                    txt = f"{v:.2%}" if pd.notna(v) else ""
                elif k in ["calmar_ratio", "sharpe_ratio", "sortino_ratio", "payoff_ratio", "profit_factor"]:
                    txt = f"{v:.2f}" if pd.notna(v) else ""
                elif k in ["max_drawdown_duration", "avg_holding_period"]:
                    txt = f"{v:.2f} å¤©" if pd.notna(v) else ""
                elif k in ["num_trades", "max_consecutive_wins", "max_consecutive_losses"]:
                    txt = f"{v:.0f}" if pd.notna(v) else ""
                else:
                    txt = f"{v:.2f}" if isinstance(v, (float, int)) and pd.notna(v) else f"{v}"
                metric_cards.append(
                    dbc.Col([
                        dbc.Card([
                            dbc.CardBody([
                                html.Div(label_map.get(k, k), className="card-title-label"),
                                html.Div(txt, style={"font-weight": "bold", "font-size": "20px"})
                            ])
                        ], style={"background": "#1a1a1a", "border": "1px solid #444", "border-radius": "8px", "margin-bottom": "6px"})
                    ], xs=12, sm=6, md=4, lg=2, xl=2, style={"minWidth": "100px", "margin-bottom": "6px", "maxWidth": "12.5%"})
                )
            
            fig1 = plot_stock_price(df_raw, trade_df, ticker)
            fig1.update_layout(
                template=plotly_template, font_color=font_color, plot_bgcolor=bg_color, paper_bgcolor=bg_color,
                legend_font_color=legend_font_color,
                legend=dict(bgcolor=legend_bgcolor, bordercolor=legend_bordercolor, font=dict(color=legend_font_color))
            )
            # æª¢æŸ¥æ˜¯å¦æœ‰ daily_state å¯ç”¨ï¼ˆensemble ç­–ç•¥ï¼‰
            daily_state = df_from_pack(result.get('daily_state'))
            
            # å„ªå…ˆä½¿ç”¨æ¨™æº–åŒ–å¾Œçš„è³‡æ–™ï¼Œç¢ºä¿æ¬„ä½å®Œæ•´
            if daily_state_std is not None and not daily_state_std.empty:
                daily_state_display = daily_state_std
                logger.info(f"[UI] ä½¿ç”¨æ¨™æº–åŒ–å¾Œçš„ daily_state_stdï¼Œæ¬„ä½: {list(daily_state_std.columns)}")
            else:
                daily_state_display = daily_state
                logger.info(f"[UI] ä½¿ç”¨åŸå§‹ daily_stateï¼Œæ¬„ä½: {list(daily_state.columns) if daily_state is not None else None}")
            
            # æª¢æŸ¥é»ï¼ˆå¿«é€Ÿè‡ªæŸ¥ï¼‰
            logger.info(f"[UI] daily_state_display cols={list(daily_state_display.columns) if daily_state_display is not None else None}")
            if daily_state_display is not None:
                logger.info(f"[UI] daily_state_display head=\n{daily_state_display[['equity','cash']].head(3) if 'equity' in daily_state_display.columns and 'cash' in daily_state_display.columns else 'Missing equity/cash columns'}")
            logger.info(f"[UI] trade_df cols={list(trade_df.columns)} head=\n{trade_df.head(3)}")
            
            # === ä¿®æ­£ï¼šå¯¦ç¾ fallback é‚è¼¯ï¼Œè®“å–®ä¸€ç­–ç•¥ä¹Ÿèƒ½é¡¯ç¤ºæ¬Šç›Š/ç¾é‡‘ ===
            if daily_state_display is not None and not daily_state_display.empty and {'equity','cash'}.issubset(daily_state_display.columns):
                # æ­£å¸¸ï¼šæœ‰ daily_state
                fig2 = plot_equity_cash(daily_state_display, df_raw)
                
                # === æ–°å¢ï¼šæŒæœ‰æ¬Šé‡è®ŠåŒ–åœ–ï¼ˆçµ±ä¸€èƒŒæ™¯è‰²ï¼‰ ===
                fig_w = plot_weight_series(daily_state_display, trade_df)
                # çµ±ä¸€èƒŒæ™¯è‰²ç‚ºä¸»é¡Œä¸€è‡´
                fig_w.update_layout(
                    template=plotly_template,
                    font_color=font_color,
                    plot_bgcolor=bg_color,
                    paper_bgcolor=bg_color,
                    legend=dict(bgcolor=legend_bgcolor, bordercolor=legend_bordercolor, font=dict(color=legend_font_color))
                )
                
                # === æ–°å¢ï¼šè³‡é‡‘æ¬Šé‡è¡¨æ ¼ ===
                # ä½¿ç”¨æ¨™æº–åŒ–å¾Œçš„ daily_state_displayï¼ˆå·²ç¶“æ¨™æº–åŒ–éäº†ï¼‰
                # æº–å‚™è³‡é‡‘æ¬Šé‡è¡¨æ ¼æ•¸æ“š
                if not daily_state_display.empty:
                    # é¸æ“‡è¦é¡¯ç¤ºçš„æ¬„ä½ï¼ˆèˆ‡ Streamlit ä¸€è‡´ï¼‰
                    display_cols = ['equity', 'cash', 'invested_pct', 'cash_pct', 'w', 'position_value']
                    available_cols = [col for col in display_cols if col in daily_state_display.columns]
                    
                    if available_cols:
                        # æ ¼å¼åŒ–æ•¸æ“šç”¨æ–¼é¡¯ç¤º
                        display_daily_state = daily_state_display[available_cols].copy()
                        display_daily_state.index = display_daily_state.index.strftime('%Y-%m-%d')
                        
                        # æ ¼å¼åŒ–æ•¸å€¼
                        for col in ['equity', 'cash', 'position_value']:
                            if col in display_daily_state.columns:
                                display_daily_state[col] = display_daily_state[col].apply(lambda x: f"{int(x):,}" if pd.notnull(x) and not pd.isna(x) else "")
                        
                        for col in ['invested_pct', 'cash_pct']:
                            if col in display_daily_state.columns:
                                display_daily_state[col] = display_daily_state[col].apply(lambda x: f"{x:.2%}" if pd.notnull(x) else "")
                        
                        for col in ['w']:
                            if col in display_daily_state.columns:
                                display_daily_state[col] = display_daily_state[col].apply(lambda x: f"{x:.4f}" if pd.notnull(x) else "")
                        
                        # å‰µå»ºè³‡é‡‘æ¬Šé‡è¡¨æ ¼
                        daily_state_table = html.Div([
                            html.H5("è³‡é‡‘æ¬Šé‡", style={"marginTop": "16px"}),
                            html.Div("æ¯æ—¥è³‡ç”¢é…ç½®ç‹€æ…‹ï¼ŒåŒ…å«æ¬Šç›Šã€ç¾é‡‘ã€æŠ•è³‡æ¯”ä¾‹ç­‰", 
                                     style={"fontSize": "14px", "color": "#666", "marginBottom": "8px"}),
                            dash_table.DataTable(
                                columns=[{"name": i, "id": i} for i in display_daily_state.columns],
                                data=display_daily_state.head(20).to_dict('records'),  # åªé¡¯ç¤ºå‰20ç­†
                                style_table={'overflowX': 'auto', 'backgroundColor': '#1a1a1a'},
                                style_cell={'textAlign': 'center', 'backgroundColor': '#1a1a1a', 'color': '#fff', 'border': '1px solid #444'},
                                style_header={'backgroundColor': '#2a2a2a', 'color': '#fff', 'border': '1px solid #444'},
                                id={'type': 'daily-state-table', 'strategy': strategy}
                            ),
                            html.Div(f"é¡¯ç¤ºå‰20ç­†è¨˜éŒ„ï¼Œå…±{len(display_daily_state)}ç­†", 
                                     style={"fontSize": "12px", "color": "#888", "textAlign": "center", "marginTop": "8px"})
                        ])
                    else:
                        daily_state_table = html.Div("è³‡é‡‘æ¬Šé‡è³‡æ–™ä¸è¶³", style={"color": "#888", "fontStyle": "italic"})
                else:
                    daily_state_table = html.Div("è³‡é‡‘æ¬Šé‡è³‡æ–™ç‚ºç©º", style={"color": "#888", "fontStyle": "italic"})
            else:
                # å›é€€ï¼šæ²’æœ‰ daily_stateï¼Œå°±ç”¨äº¤æ˜“è¡¨é‡å»ºï¼ˆå–®ä¸€ç­–ç•¥æœƒå›ä¾†ï¼‰
                logger.info("[UI] ä½¿ç”¨ fallbackï¼šå¾äº¤æ˜“è¡¨é‡å»ºæ¬Šç›Š/ç¾é‡‘æ›²ç·š")
                fig2 = plot_equity_cash(trade_df, df_raw)  # ä½¿ç”¨ SSSv096 çš„ fallback é‚è¼¯
                
                # æ¬Šé‡åœ–ï¼šè‹¥ DS æœ‰ w å°±ç•«ï¼Œå¦å‰‡å…ˆçµ¦ç©ºåœ–
                if daily_state_display is not None and not daily_state_display.empty and 'w' in daily_state_display.columns:
                    fig_w = plot_weight_series(daily_state_display['w'], title="æŒæœ‰æ¬Šé‡è®ŠåŒ–")
                    fig_w.update_layout(
                        template=plotly_template,
                        font_color=font_color,
                        plot_bgcolor=bg_color,
                        paper_bgcolor=bg_color,
                        legend=dict(bgcolor=legend_bgcolor, bordercolor=legend_bordercolor, font=dict(color=legend_font_color))
                    )
                else:
                    fig_w = go.Figure()  # å…ˆçµ¦ç©ºåœ–
                
                daily_state_table = html.Div("ä½¿ç”¨äº¤æ˜“è¡¨é‡å»ºçš„æ¬Šç›Š/ç¾é‡‘æ›²ç·š", style={"color": "#888", "fontStyle": "italic"})
            
            fig2.update_layout(
                template=plotly_template, font_color=font_color, plot_bgcolor=bg_color, paper_bgcolor=bg_color,
                legend_font_color=legend_font_color,
                legend=dict(bgcolor=legend_bgcolor, bordercolor=legend_bordercolor, font=dict(color=legend_font_color))
            )
            
            # === è¨ˆç®—é¢¨éšªé–¥é–€å¾½ç« å…§å®¹ ===
            valve = results.get(strategy, {}).get('valve', {}) or {}
            valve_badge_text = ("å·²å¥—ç”¨" if valve.get("applied") else "æœªå¥—ç”¨")
            valve_badge_extra = []
            if isinstance(valve.get("cap"), (int, float)):
                valve_badge_extra.append(f"CAP={valve['cap']:.2f}")
            if isinstance(valve.get("atr_ratio"), (int, float)):
                valve_badge_extra.append(f"ATRæ¯”å€¼={valve['atr_ratio']:.2f}")
            elif valve.get("atr_ratio") == "forced":
                valve_badge_extra.append("å¼·åˆ¶è§¸ç™¼")
            
            valve_badge = html.Span(
                "ğŸ›¡ï¸ é¢¨éšªé–¥é–€ï¼š" + valve_badge_text + ((" | " + " | ".join(valve_badge_extra)) if valve_badge_extra else ""),
                style={
                    "marginLeft": "8px",
                    "color": ("#dc3545" if valve.get("applied") else "#6c757d"),
                    "fontWeight": "bold"
                }
            ) if valve else html.Span("")

            strategy_content = html.Div([
                html.H4([
                    f"å›æ¸¬ç­–ç•¥: {strategy} ",
                    html.Span("â“˜", title=tooltip, style={"cursor": "help", "color": "#888"}),
                    valve_badge
                ]),
                html.Div(f"åƒæ•¸è¨­å®š: {param_str}"),
                html.Br(),
                dbc.Row(metric_cards, style={"flex-wrap": "wrap"}, className='metrics-cards-row'),
                html.Br(),
                dcc.Graph(figure=fig1, config={'displayModeBar': True}, className='main-metrics-graph'),
                dcc.Graph(figure=fig2, config={'displayModeBar': True}, className='main-cash-graph'),
                # === æ–°å¢ï¼šæŒæœ‰æ¬Šé‡è®ŠåŒ–åœ– ===
                dcc.Graph(figure=fig_w, config={'displayModeBar': True}, className='main-weight-graph'),
                # å°‡äº¤æ˜“æ˜ç´°æ¨™é¡Œèˆ‡èª¬æ˜åˆä½µç‚ºåŒä¸€è¡Œ
                html.Div([
                    html.H5("äº¤æ˜“æ˜ç´°", style={"marginBottom": 0, "marginRight": "12px"}),
                    html.Div("å¯¦éš›ä¸‹å–®æ—¥ç‚ºä¿¡è™Ÿæ—¥çš„éš”å¤©ï¼ˆS+1ï¼‰ï¼Œä¿®æ”¹ä»£ç¢¼æœƒå½±éŸ¿å¾ˆå¤šå±¤é¢ï¼Œæš«ä¸ä¿®æ”¹", 
                             style={"fontWeight": "bold", "fontSize": "16px"})
                ], style={"display": "flex", "alignItems": "center", "marginTop": "16px"}),
                
                dash_table.DataTable(
                    columns=[{"name": get_column_display_name(i), "id": i} for i in display_df.columns],
                    data=display_df.to_dict('records'),
                    style_table={'overflowX': 'auto', 'backgroundColor': '#1a1a1a'},
                    style_cell={'textAlign': 'center', 'backgroundColor': '#1a1a1a', 'color': '#fff', 'border': '1px solid #444'},
                    style_header={'backgroundColor': '#2a2a2a', 'color': '#fff', 'border': '1px solid #444'},
                    id={'type': 'strategy-table', 'strategy': strategy}
                ),
                
                # === æ–°å¢ï¼šäº¤æ˜“æ˜ç´° CSV ä¸‹è¼‰æŒ‰éˆ• ===
                html.Div([
                    html.Button(
                        "ğŸ“¥ ä¸‹è¼‰äº¤æ˜“æ˜ç´° CSV",
                        id={'type': 'download-trade-details-csv', 'strategy': strategy},
                        style={
                            'backgroundColor': '#28a745',
                            'color': 'white',
                            'border': 'none',
                            'padding': '8px 16px',
                            'borderRadius': '4px',
                            'cursor': 'pointer',
                            'marginTop': '8px',
                            'fontSize': '14px'
                        }
                    ),
                    dcc.Download(id={'type': 'download-trade-details-data', 'strategy': strategy})
                ], style={'textAlign': 'center', 'marginTop': '8px'}),
                

            ])
            
            strategy_tabs.append(dcc.Tab(label=strategy, value=f"strategy_{strategy}", children=strategy_content))
        
        # å‰µå»ºç­–ç•¥å›æ¸¬çš„å­é ç±¤å®¹å™¨
        return html.Div([
            dcc.Tabs(
                id='strategy-tabs',
                value=f"strategy_{strategy_names[0]}" if strategy_names else "no_strategy",
                children=strategy_tabs,
                className='strategy-tabs-bar'
            )
        ])
        
    elif tab == "compare":
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=df_raw.index, y=df_raw['close'], name='Close Price', line=dict(color='dodgerblue')))
        colors = ['green', 'limegreen', 'red', 'orange', 'purple', 'blue', 'pink', 'cyan']
        
        # å®šç¾©ç­–ç•¥åˆ°é¡è‰²çš„æ˜ å°„
        strategy_colors = {strategy: colors[i % len(colors)] for i, strategy in enumerate(strategy_names)}
        
        # ç‚ºåœ–è¡¨æ·»åŠ è²·è³£é»
        for i, strategy in enumerate(strategy_names):
            result = results.get(strategy)
            if not result:
                continue
            # ä½¿ç”¨è§£åŒ…å™¨å‡½æ•¸ï¼Œæ”¯æ´ pack_df å’Œå‚³çµ± JSON å­—ä¸²å…©ç¨®æ ¼å¼
            trade_df = df_from_pack(result.get('trade_df'))
            
            # æ¨™æº–åŒ–äº¤æ˜“è³‡æ–™
            try:
                from sss_core.normalize import normalize_trades_for_ui as norm
                trade_df = norm(trade_df)
            except Exception:
                # å¾Œå‚™æ¨™æº–åŒ–æ–¹æ¡ˆ
                if trade_df is not None and len(trade_df) > 0:
                    trade_df = trade_df.copy()
                    trade_df.columns = [str(c).lower() for c in trade_df.columns]
                    if "trade_date" not in trade_df.columns and "date" in trade_df.columns:
                        trade_df["trade_date"] = pd.to_datetime(trade_df["date"], errors="coerce")
                    if "type" not in trade_df.columns and "action" in trade_df.columns:
                        trade_df["type"] = trade_df["action"].astype(str).str.lower()
                    if "price" not in trade_df.columns:
                        for c in ["open", "price_open", "exec_price", "px", "close"]:
                            if c in trade_df.columns:
                                trade_df["price"] = trade_df[c]
                                break
            
            if 'trade_date' in trade_df.columns:
                trade_df['trade_date'] = pd.to_datetime(trade_df['trade_date'])
            if trade_df.empty:
                continue
            buys = trade_df[trade_df['type'] == 'buy']
            sells = trade_df[trade_df['type'] == 'sell']
            fig.add_trace(go.Scatter(x=buys['trade_date'], y=buys['price'], mode='markers', name=f'{strategy} Buy',
                                     marker=dict(symbol='cross', size=8, color=colors[i % len(colors)])))
            fig.add_trace(go.Scatter(x=sells['trade_date'], y=sells['price'], mode='markers', name=f'{strategy} Sell',
                                     marker=dict(symbol='x', size=8, color=colors[i % len(colors)])))
        
        # æ›´æ–°åœ–è¡¨ä½ˆå±€
        fig.update_layout(
            title=f'{ticker} æ‰€æœ‰ç­–ç•¥è²·è³£é»æ¯”è¼ƒ',
            xaxis_title='Date', yaxis_title='è‚¡åƒ¹', template=plotly_template,
            font_color=font_color, plot_bgcolor=bg_color, paper_bgcolor=bg_color, legend_font_color=legend_font_color,
            legend=dict(
                x=1.05, y=1, xanchor='left', yanchor='top',
                bordercolor=legend_bordercolor, borderwidth=1, bgcolor=legend_bgcolor,
                itemsizing='constant', orientation='v', font=dict(color=legend_font_color)
            )
        )
        
        # æº–å‚™æ¯”è¼ƒè¡¨æ ¼æ•¸æ“š
        comparison_data = []
        for strategy in strategy_names:
            result = results.get(strategy)
            if not result:
                continue
            
            # è®€å–äº¤æ˜“æ•¸æ“š
            trade_df = df_from_pack(result.get('trade_df'))
            
            # æ¨™æº–åŒ–äº¤æ˜“è³‡æ–™
            try:
                from sss_core.normalize import normalize_trades_for_ui as norm
                trade_df = norm(trade_df)
            except Exception:
                # å¾Œå‚™æ¨™æº–åŒ–æ–¹æ¡ˆ
                if trade_df is not None and len(trade_df) > 0:
                    trade_df = trade_df.copy()
                    trade_df.columns = [str(c).lower() for c in trade_df.columns]
                    if "trade_date" not in trade_df.columns and "date" in trade_df.columns:
                        trade_df["trade_date"] = pd.to_datetime(trade_df["date"], errors="coerce")
                    if "type" not in trade_df.columns and "action" in trade_df.columns:
                        trade_df["type"] = trade_df["action"].astype(str).str.lower()
                    if "price" not in trade_df.columns:
                        for c in ["open", "price_open", "exec_price", "px", "close"]:
                            if c in trade_df.columns:
                                trade_df["price"] = trade_df[c]
                                break
            
            if 'trade_date' in trade_df.columns:
                trade_df['trade_date'] = pd.to_datetime(trade_df['trade_date'])
            
            # è¨ˆç®—è©³ç´°çµ±è¨ˆä¿¡æ¯
            detailed_stats = calculate_strategy_detailed_stats(trade_df, df_raw)
            
            metrics = result['metrics']
            comparison_data.append({
                'ç­–ç•¥': strategy,
                'ç¸½å›å ±ç‡': f"{metrics.get('total_return', 0):.2%}",
                'å¹´åŒ–å›å ±ç‡': f"{metrics.get('annual_return', 0):.2%}",
                'æœ€å¤§å›æ’¤': f"{metrics.get('max_drawdown', 0):.2%}",
                'å¡ç‘ªæ¯”ç‡': f"{metrics.get('calmar_ratio', 0):.2f}",
                'äº¤æ˜“æ¬¡æ•¸': metrics.get('num_trades', 0),
                'å‹ç‡': f"{metrics.get('win_rate', 0):.2%}",
                'ç›ˆè™§æ¯”': f"{metrics.get('payoff_ratio', 0):.2f}",
                'å¹³å‡æŒæœ‰å¤©æ•¸': f"{detailed_stats['avg_holding_days']:.1f}",
                'è³£å¾Œè²·å¹³å‡å¤©æ•¸': f"{detailed_stats['avg_sell_to_buy_days']:.1f}",
                'ç›®å‰ç‹€æ…‹': detailed_stats['current_status'],
                'è·é›¢ä¸Šæ¬¡æ“ä½œå¤©æ•¸': f"{detailed_stats['days_since_last_action']}"
            })
        
        # å®šç¾©é¡è‰²èª¿æ•´å‡½æ•¸
        def adjust_color_for_theme(color, theme):
            # é å®šç¾©é¡è‰²åˆ° RGB çš„æ˜ å°„
            color_to_rgb = {
                'green': '0, 128, 0',
                'limegreen': '50, 205, 50', 
                'red': '255, 0, 0',
                'orange': '255, 165, 0',
                'purple': '128, 0, 128',
                'blue': '0, 0, 255',
                'pink': '255, 192, 203',
                'cyan': '0, 255, 255'
            }
            
            rgb = color_to_rgb.get(color, '128, 128, 128')  # é»˜èªç°è‰²
            
            if theme == 'theme-dark':
                return f'rgba({rgb}, 0.2)'  # é€æ˜åº¦ 0.2
            elif theme == 'theme-light':
                return f'rgba({rgb}, 1)'    # é€æ˜åº¦ 1
            else:  # theme-blue
                return f'rgba({rgb}, 0.5)'  # é€æ˜åº¦ 0.5
        
        # å‰µå»ºæ¯”è¼ƒè¡¨æ ¼ä¸¦æ‡‰ç”¨æ¢ä»¶æ¨£å¼
        compare_table = dash_table.DataTable(
            columns=[{"name": i, "id": i} for i in comparison_data[0].keys()] if comparison_data else [],
            data=comparison_data,
            style_table={'overflowX': 'auto', 'backgroundColor': '#1a1a1a'},
            style_cell={'textAlign': 'center', 'backgroundColor': '#1a1a1a', 'color': '#fff', 'border': '1px solid #444'},
            style_header={'backgroundColor': '#2a2a2a', 'color': '#fff', 'border': '1px solid #444'},
            style_data_conditional=[
                {
                    'if': {'row_index': i},
                    'backgroundColor': adjust_color_for_theme(strategy_colors[row['ç­–ç•¥']], theme),
                    'border': f'1px solid {strategy_colors[row['ç­–ç•¥']]}'
                } for i, row in enumerate(comparison_data)
            ],
            id='compare-table'
        )
        
        return html.Div([
            dcc.Graph(figure=fig, config={'displayModeBar': True}, className='compare-graph'),
            html.Hr(),
            compare_table
        ])
        
    elif tab == "enhanced":
        # === å¢å¼·åˆ†æé é¢ ===
        enhanced_controls = html.Div([
            html.H4("ğŸ” å¢å¼·åˆ†æ"),
            
            # === æ–°å¢ï¼šå…¨å±€åƒæ•¸å¥—ç”¨ç‹€æ…‹æç¤º ===
            html.Div([
                html.Div(id="enhanced-global-status", style={
                    "padding": "12px",
                    "marginBottom": "16px",
                    "borderRadius": "8px",
                    "border": "1px solid #dee2e6",
                    "backgroundColor": "#f8f9fa"
                })
            ]),
            
            # === æ–°å¢ï¼šå¾å›æ¸¬çµæœè¼‰å…¥å€å¡Š ===
            html.Details([
                html.Summary("ğŸ§  å¾å›æ¸¬çµæœè¼‰å…¥"),
                html.Div([
                    html.Div("é¸æ“‡ç­–ç•¥ï¼ˆè‡ªå‹•è©•åˆ†ï¼šledger_std > ledger > trade_dfï¼‰", 
                             style={"marginBottom":"8px","fontSize":"14px","color":"#666"}),
                    dcc.Dropdown(
                        id="enhanced-strategy-selector",
                        placeholder="è«‹å…ˆåŸ·è¡Œå›æ¸¬...",
                        style={"width":"100%","marginBottom":"8px"}
                    ),
                    html.Button("è¼‰å…¥é¸å®šç­–ç•¥", id="load-enhanced-strategy", n_clicks=0, 
                               style={"width":"100%","marginBottom":"8px"}),
                    html.Div(id="enhanced-load-status", style={"fontSize":"12px","color":"#888"}),
                    html.Div("ğŸ’¡ å›æ¸¬å®Œæˆå¾Œæœƒè‡ªå‹•å¿«å–æœ€ä½³ç­–ç•¥", 
                             style={"fontSize":"11px","color":"#666","fontStyle":"italic","marginTop":"4px"})
                ])
            ], style={"marginBottom":"16px"}),
            
            # === éš±è—çš„ cache store ===
            dcc.Store(id="enhanced-trades-cache"),
            
            html.Details([
                html.Summary("é¢¨éšªé–¥é–€å›æ¸¬"),
                html.Div([
                    dcc.Dropdown(
                        id="rv-mode", options=[
                            {"label":"é™ä½ä¸Šé™ (cap)","value":"cap"},
                            {"label":"ç¦æ­¢åŠ ç¢¼ (ban_add)","value":"ban_add"},
                        ], value="cap", clearable=False, style={"width":"240px"}
                    ),
                    dcc.Slider(id="rv-cap", min=0.1, max=1.0, step=0.05, value=0.5,
                               tooltip={"placement":"bottom","always_visible":True}),
                    html.Div("ATR(20)/ATR(60) æ¯”å€¼é–€æª»", style={"marginTop":"8px"}),
                    dcc.Slider(id="rv-atr-mult", min=1.0, max=2.0, step=0.05, value=1.3,
                               tooltip={"placement":"bottom","always_visible":True}),
                    html.Button("åŸ·è¡Œé¢¨éšªé–¥é–€å›æ¸¬", id="run-rv", n_clicks=0, style={"marginTop":"8px"})
                ])
            ]),
            
            html.Div(id="rv-summary", style={"marginTop":"12px"}),
            dcc.Graph(id="rv-equity-chart"),
            dcc.Graph(id="rv-dd-chart"),
            
            # === æ–°å¢ï¼šæ•¸æ“šæ¯”å°åŠŸèƒ½ ===
            html.Details([
                html.Summary("ğŸ” æ•¸æ“šæ¯”å°èˆ‡è¨ºæ–·"),
                html.Div([
                    html.Div("ç›´æ¥è¼¸å‡ºå¯¦éš›æ•¸æ“šé€²è¡Œæ¯”å°ï¼Œè¨ºæ–·å…¨å±€å¥—ç”¨èˆ‡å¼·åŒ–åˆ†æçµæœä¸åŒçš„å•é¡Œ", 
                             style={"marginBottom":"8px","fontSize":"14px","color":"#666"}),
                    html.Button("è¼¸å‡ºæ•¸æ“šæ¯”å°å ±å‘Š", id="export-data-comparison", n_clicks=0, 
                               style={"width":"100%","marginBottom":"8px","backgroundColor":"#17a2b8","color":"white"}),
                    html.Div(id="data-comparison-output", style={"fontSize":"12px","color":"#666","marginTop":"8px"}),
                    dcc.Download(id="data-comparison-csv")
                ])
            ], style={"border":"1px solid #17a2b8","borderRadius":"8px","padding":"12px","marginTop":"12px"}),
            
            # === æ–°å¢ï¼šé¢¨éšª-å ±é…¬åœ°åœ–ï¼ˆPareto Mapï¼‰å€å¡Š ===
            html.Details([
                html.Summary("ğŸ“Š é¢¨éšª-å ±é…¬åœ°åœ–ï¼ˆPareto Mapï¼‰"),
                html.Div([
                    html.Div("ç”Ÿæˆç­–ç•¥çš„é¢¨éšª-å ±é…¬åˆ†æåœ–è¡¨", 
                             style={"marginBottom":"8px","fontSize":"14px","color":"#666"}),
                    html.Button("ç”Ÿæˆ Pareto Map", id="generate-pareto-map", n_clicks=0, 
                               style={"width":"100%","marginBottom":"8px"}),
                    html.Div(id="pareto-map-status", style={"fontSize":"12px","color":"#888","marginBottom":"8px"}),
                    dcc.Graph(id="pareto-map-graph", style={"height":"600px"}),
                    html.Div([
                        html.Button("ğŸ“¥ ä¸‹è¼‰ Pareto Map æ•¸æ“š (CSV)", id="download-pareto-csv", n_clicks=0,
                                   style={"width":"100%","marginBottom":"8px"}),
                        dcc.Download(id="pareto-csv-download"),
                        html.H6("åœ–è¡¨èªªæ˜ï¼š", style={"marginTop":"16px","marginBottom":"8px"}),
                        html.Ul([
                            html.Li("æ©«è»¸ï¼šæœ€å¤§å›æ’¤ï¼ˆæ„ˆå·¦æ„ˆå¥½ï¼‰"),
                            html.Li("ç¸±è»¸ï¼šPF ç²åˆ©å› å­ï¼ˆæ„ˆä¸Šæ„ˆå¥½ï¼‰"),
                            html.Li("é¡è‰²ï¼šå³å°¾èª¿æ•´å¹…åº¦ï¼ˆç´…è‰²=å‰Šæ¸›å³å°¾ï¼Œè—è‰²=æ”¾å¤§å³å°¾ï¼Œ0ç‚ºä¸­ç·šï¼‰"),
                            html.Li("é»å¤§å°ï¼šé¢¨éšªè§¸ç™¼å¤©æ•¸ï¼ˆè¶Šå¤§ï¼ç®¡å¾—è¶Šå‹¤ï¼‰"),
                            html.Li("ç†æƒ³å€åŸŸï¼šç¶ è‰²è™›ç·šæ¡†å…§ï¼ˆåˆä¸Šåˆå·¦ã€é¡è‰²æ¥è¿‘ä¸­ç·šã€é»ä¸è¦å¤§åˆ°èª‡å¼µï¼‰")
                        ], style={"fontSize":"12px","color":"#666"})
                    ])
                ])
            ], style={"border":"1px solid #333","borderRadius":"8px","padding":"12px","marginTop":"12px"}),
            # === äº¤æ˜“è²¢ç»æ‹†è§£å€å¡Š ===
            html.Details([
                html.Summary("ğŸ” äº¤æ˜“è²¢ç»æ‹†è§£"),
                html.Div([
                    html.Div("æ‹†è§£äº¤æ˜“è²¢ç»ï¼Œåˆ†æä¸åŒåŠ ç¢¼/æ¸›ç¢¼éšæ®µçš„ç¸¾æ•ˆè¡¨ç¾", 
                             style={"marginBottom":"8px","fontSize":"14px","color":"#666"}),
                    html.Div([
                        html.Div([
                            html.Label("æœ€å°é–“è· (å¤©)", style={"fontSize":"12px","color":"#888"}),
                            dcc.Input(id="phase-min-gap", type="number", value=5, min=0, max=30, step=1,
                                     style={"width":"80px","marginRight":"16px"})
                        ], style={"display":"inline-block","marginRight":"16px"}),
                                            html.Div([
                        html.Label("å†·å»æœŸ (å¤©)", style={"fontSize":"12px","color":"#888"}),
                        dcc.Input(id="phase-cooldown", type="number", value=10, min=0, max=30, step=1,
                                 style={"width":"80px"})
                    ], style={"display":"inline-block"})
                ], style={"marginBottom":"8px"}),
                html.Div([
                    html.Button("åŸ·è¡Œäº¤æ˜“è²¢ç»æ‹†è§£", id="run-phase", n_clicks=0, 
                               style={"width":"48%","marginBottom":"8px","marginRight":"2%"}),
                    html.Button("æ‰¹é‡æ¸¬è©¦åƒæ•¸ç¯„åœ", id="run-batch-phase", n_clicks=0,
                               style={"width":"48%","marginBottom":"8px","marginLeft":"2%","backgroundColor":"#28a745","color":"white"})
                ], style={"display":"flex","justifyContent":"space-between"}),
                    html.Div([
                        html.H6("åƒæ•¸èªªæ˜ï¼š", style={"marginTop":"16px","marginBottom":"8px"}),
                        html.Ul([
                            html.Li("æœ€å°é–“è·ï¼šå…©æ¬¡åŠ ç¢¼è‡³å°‘è¦é–“éš”å¹¾å¤©ï¼Œæ‰ç®—ç¨ç«‹è¨Šè™Ÿï¼ˆéæ¿¾çŸ­æœŸå™ªéŸ³ï¼‰"),
                            html.Li("å†·å»æœŸï¼šæ¯æ¬¡åŠ ç¢¼å¾Œï¼Œå¿…é ˆéå¤šä¹…æ‰å…è¨±ä¸‹ä¸€ç­†åŠ ç¢¼ï¼ˆé¿å…éåº¦æ›éšªï¼‰"),
                            html.Li("ç”¨é€”ï¼šè®“æ‹†è§£èšç„¦åœ¨æ¯”è¼ƒæœ‰æ„ç¾©çš„åŠ ç¢¼æ³¢æ®µï¼Œé¿å…è¢«çŸ­æœŸå°å–®ç¨€é‡‹")
                        ], style={"fontSize":"12px","color":"#666","marginBottom":"16px"}),
                        html.Div(id="phase-table"),
                        html.Div([
                            html.H6("æ‰¹é‡æ¸¬è©¦çµæœ", style={"marginTop":"16px","marginBottom":"8px","color":"#28a745"}),
                            html.Div(id="batch-phase-results", style={"fontSize":"12px"})
                        ])
                    ])
                ])
            ], style={"border":"1px solid #333","borderRadius":"8px","padding":"12px","marginTop":"12px"})
        ])
        
        return enhanced_controls

# --------- ç‰ˆæœ¬æ²¿é©æ¨¡æ…‹æ¡†æ§åˆ¶å’Œä¸»é¡Œåˆ‡æ› ---------
@app.callback(
    Output("history-modal", "is_open"),
    Output('main-bg', 'className'),
    Output('theme-toggle', 'children'),
    Output('theme-store', 'data'),
    [Input("history-btn", "n_clicks"), Input("history-close", "n_clicks"), Input('theme-toggle', 'n_clicks')],
    [State("history-modal", "is_open"), State('theme-store', 'data')],
    prevent_initial_call=True
)
def toggle_history_modal_and_theme(history_btn, history_close, theme_btn, is_open, current_theme):
    ctx_trigger = ctx.triggered_id
    
    if ctx_trigger == "history-btn":
        # é–‹å•Ÿç‰ˆæœ¬æ²¿é©æ¨¡æ…‹æ¡†ï¼Œå¼·åˆ¶åˆ‡æ›åˆ°æ·±è‰²ä¸»é¡Œ
        return True, 'theme-dark', 'ğŸŒ‘ æ·±è‰²ä¸»é¡Œ', 'theme-dark'
    elif ctx_trigger == "history-close":
        # é—œé–‰ç‰ˆæœ¬æ²¿é©æ¨¡æ…‹æ¡†ï¼Œæ¢å¾©åŸä¸»é¡Œ
        return False, current_theme, get_theme_label(current_theme), current_theme
    elif ctx_trigger == "theme-toggle":
        # æ­£å¸¸çš„ä¸»é¡Œåˆ‡æ›
        if current_theme is None:
            return is_open, 'theme-dark', 'ğŸŒ‘ æ·±è‰²ä¸»é¡Œ', 'theme-dark'
        themes = ['theme-dark', 'theme-light', 'theme-blue']
        current_index = themes.index(current_theme)
        next_theme = themes[(current_index + 1) % len(themes)]
        return is_open, next_theme, get_theme_label(next_theme), next_theme
    
    return is_open, current_theme, get_theme_label(current_theme), current_theme

# --------- ä¸‹è¼‰äº¤æ˜“ç´€éŒ„ ---------
@app.callback(
    Output({'type': 'download-trade', 'strategy': ALL}, 'data'),
    Input({'type': 'download-btn', 'strategy': ALL}, 'n_clicks'),
    State({'type': 'strategy-table', 'strategy': ALL}, 'data'),
    State('backtest-store', 'data'),
    prevent_initial_call=True
)
def download_trade(n_clicks, table_data, backtest_data):
    ctx_trigger = ctx.triggered_id
    if not ctx_trigger or not backtest_data:
        return [None] * len(n_clicks)
    
    # å¾è§¸ç™¼çš„æŒ‰éˆ•IDä¸­æå–ç­–ç•¥åç¨±
    strategy = ctx_trigger['strategy']
    
    # å¾backtest_dataä¸­ç²å–å°æ‡‰ç­–ç•¥çš„äº¤æ˜“æ•¸æ“š
    # backtest_data ç¾åœ¨å·²ç¶“æ˜¯ dictï¼Œä¸éœ€è¦ json.loads
    results = backtest_data['results']
    result = results.get(strategy)
    
    if not result:
        return [None] * len(n_clicks)
    
    # ä½¿ç”¨è§£åŒ…å™¨å‡½æ•¸ï¼Œæ”¯æ´ pack_df å’Œå‚³çµ± JSON å­—ä¸²å…©ç¨®æ ¼å¼
    trade_df = df_from_pack(result.get('trade_df'))
    
    # æ¨™æº–åŒ–äº¤æ˜“è³‡æ–™
    try:
        from sss_core.normalize import normalize_trades_for_ui as norm
        trade_df = norm(trade_df)
    except Exception:
        # å¾Œå‚™æ¨™æº–åŒ–æ–¹æ¡ˆ
        if trade_df is not None and len(trade_df) > 0:
            trade_df = trade_df.copy()
            trade_df.columns = [str(c).lower() for c in trade_df.columns]
            if "trade_date" not in trade_df.columns and "date" in trade_df.columns:
                trade_df["trade_date"] = pd.to_datetime(trade_df["date"], errors="coerce")
            if "type" not in trade_df.columns and "action" in trade_df.columns:
                trade_df["type"] = trade_df["action"].astype(str).str.lower()
            if "price" not in trade_df.columns:
                for c in ["open", "price_open", "exec_price", "px", "close"]:
                    if c in trade_df.columns:
                        trade_df["price"] = trade_df[c]
                        break
    
    # å‰µå»ºä¸‹è¼‰æ•¸æ“š
    def to_xlsx(bytes_io):
        with pd.ExcelWriter(bytes_io, engine='openpyxl') as writer:
            trade_df.to_excel(writer, sheet_name='äº¤æ˜“ç´€éŒ„', index=False)
    
    return [dcc.send_bytes(to_xlsx, f"{strategy}_äº¤æ˜“ç´€éŒ„.xlsx") if i and i > 0 else None for i in n_clicks]

# --------- ä¸‹è¼‰äº¤æ˜“æ˜ç´° CSV ---------
@app.callback(
    Output({'type': 'download-trade-details-data', 'strategy': ALL}, 'data'),
    Input({'type': 'download-trade-details-csv', 'strategy': ALL}, 'n_clicks'),
    State({'type': 'strategy-table', 'strategy': ALL}, 'data'),
    State('backtest-store', 'data'),
    prevent_initial_call=True
)
def download_trade_details_csv(n_clicks, table_data, backtest_data):
    """ä¸‹è¼‰äº¤æ˜“æ˜ç´°ç‚º CSV æ ¼å¼"""
    ctx_trigger = ctx.triggered_id
    if not ctx_trigger or not backtest_data:
        return [None] * len(n_clicks)
    
    # å¾è§¸ç™¼çš„æŒ‰éˆ•IDä¸­æå–ç­–ç•¥åç¨±
    strategy = ctx_trigger['strategy']
    
    # å¾backtest_dataä¸­ç²å–å°æ‡‰ç­–ç•¥çš„äº¤æ˜“æ•¸æ“š
    results = backtest_data['results']
    result = results.get(strategy)
    
    if not result:
        return [None] * len(n_clicks)
    
    # ä½¿ç”¨è§£åŒ…å™¨å‡½æ•¸ï¼Œæ”¯æ´ pack_df å’Œå‚³çµ± JSON å­—ä¸²å…©ç¨®æ ¼å¼
    trade_df = df_from_pack(result.get('trade_df'))
    
    # æ¨™æº–åŒ–äº¤æ˜“è³‡æ–™
    try:
        from sss_core.normalize import normalize_trades_for_ui as norm
        trade_df = norm(trade_df)
    except Exception:
        # å¾Œå‚™æ¨™æº–åŒ–æ–¹æ¡ˆ
        if trade_df is not None and len(trade_df) > 0:
            trade_df = trade_df.copy()
            trade_df.columns = [str(c).lower() for c in trade_df.columns]
            if "trade_date" not in trade_df.columns and "date" in trade_df.columns:
                trade_df["trade_date"] = pd.to_datetime(trade_df["date"], errors="coerce")
            if "type" not in trade_df.columns and "action" in trade_df.columns:
                trade_df["type"] = trade_df["action"].astype(str).str.lower()
            if "price" not in trade_df.columns:
                for c in ["open", "price_open", "exec_price", "px", "close"]:
                    if c in trade_df.columns:
                        trade_df["price"] = trade_df[c]
                        break
    
    # å‰µå»º CSV ä¸‹è¼‰æ•¸æ“š
    def to_csv(bytes_io):
        # ä½¿ç”¨ UTF-8 BOM ç¢ºä¿ Excel èƒ½æ­£ç¢ºé¡¯ç¤ºä¸­æ–‡
        bytes_io.write('\ufeff'.encode('utf-8'))
        trade_df.to_csv(bytes_io, index=False, encoding='utf-8-sig')
    
    return [dcc.send_bytes(to_csv, f"{strategy}_äº¤æ˜“æ˜ç´°.csv") if i and i > 0 else None for i in n_clicks]

def calculate_strategy_detailed_stats(trade_df, df_raw):
    """è¨ˆç®—ç­–ç•¥çš„è©³ç´°çµ±è¨ˆä¿¡æ¯"""
    if trade_df.empty:
        return {
            'avg_holding_days': 0,
            'avg_sell_to_buy_days': 0,
            'current_status': 'æœªæŒæœ‰',
            'days_since_last_action': 0
        }
    
    # ç¢ºä¿æ—¥æœŸåˆ—æ˜¯ datetime é¡å‹
    if 'trade_date' in trade_df.columns:
        trade_df['trade_date'] = pd.to_datetime(trade_df['trade_date'])
    
    # æŒ‰æ—¥æœŸæ’åºç¢ºä¿é †åºæ­£ç¢º
    trade_df = trade_df.sort_values('trade_date').reset_index(drop=True)
    
    # è¨ˆç®—å¹³å‡æŒæœ‰å¤©æ•¸ï¼ˆè²·å…¥åˆ°è³£å‡ºçš„å¤©æ•¸ï¼‰
    holding_periods = []
    for i in range(len(trade_df) - 1):
        current_type = trade_df.iloc[i]['type']
        next_type = trade_df.iloc[i+1]['type']
        if current_type == 'buy' and next_type in ['sell', 'sell_forced']:
            buy_date = trade_df.iloc[i]['trade_date']
            sell_date = trade_df.iloc[i+1]['trade_date']
            holding_days = (sell_date - buy_date).days
            holding_periods.append(holding_days)
    avg_holding_days = sum(holding_periods) / len(holding_periods) if holding_periods else 0
    
    # è¨ˆç®—è³£å¾Œè²·å¹³å‡å¤©æ•¸ï¼ˆè³£å‡ºåˆ°ä¸‹æ¬¡è²·å…¥çš„å¤©æ•¸ï¼‰
    sell_to_buy_periods = []
    for i in range(len(trade_df) - 1):
        current_type = trade_df.iloc[i]['type']
        next_type = trade_df.iloc[i+1]['type']
        if current_type in ['sell', 'sell_forced'] and next_type == 'buy':
            sell_date = trade_df.iloc[i]['trade_date']
            buy_date = trade_df.iloc[i+1]['trade_date']
            days_between = (buy_date - sell_date).days
            sell_to_buy_periods.append(days_between)
    avg_sell_to_buy_days = sum(sell_to_buy_periods) / len(sell_to_buy_periods) if sell_to_buy_periods else 0
    
    # å–å¾—æœ€å¾Œä¸€ç­†æ“ä½œ
    last_trade = trade_df.iloc[-1] if not trade_df.empty else None
    if not df_raw.empty:
        current_date = df_raw.index[-1]
        if isinstance(current_date, str):
            current_date = pd.to_datetime(current_date)
    else:
        current_date = datetime.now()
    
    if last_trade is not None:
        last_type = last_trade['type']
        last_date = last_trade['trade_date']
        if last_type == 'buy':
            current_status = 'æŒæœ‰'
            days_since_last_action = (current_date - last_date).days
        elif last_type == 'sell':
            current_status = 'æœªæŒæœ‰'
            days_since_last_action = (current_date - last_date).days
        elif last_type == 'sell_forced':
            # ç‹€æ…‹ç‚ºæŒæœ‰ï¼Œå¤©æ•¸ç‚ºç›®å‰æ—¥æœŸæ¸›å»æœ€è¿‘ä¸€ç­† buy æ—¥æœŸ
            current_status = 'æŒæœ‰'
            # å¾€å‰æ‰¾æœ€è¿‘ä¸€ç­† buy
            last_buy = trade_df[trade_df['type'] == 'buy']
            if not last_buy.empty:
                last_buy_date = last_buy.iloc[-1]['trade_date']
                days_since_last_action = (current_date - last_buy_date).days
            else:
                days_since_last_action = 0
        else:
            current_status = 'æœªæŒæœ‰'
            days_since_last_action = (current_date - last_date).days
    else:
        current_status = 'æœªæŒæœ‰'
        days_since_last_action = 0
    
    return {
        'avg_holding_days': round(avg_holding_days, 1),
        'avg_sell_to_buy_days': round(avg_sell_to_buy_days, 1),
        'current_status': current_status,
        'days_since_last_action': days_since_last_action
    }

def is_price_data_up_to_date(csv_path):
    if not os.path.exists(csv_path):
        return False
    try:
        df = pd.read_csv(csv_path)
        if 'date' in df.columns:
            last_date = pd.to_datetime(df['date'].iloc[-1])
        else:
            last_date = pd.to_datetime(df.iloc[-1, 0])
        
        # ç²å–å°åŒ—æ™‚é–“çš„ä»Šå¤©
        today = pd.Timestamp.now(tz='Asia/Taipei').normalize()
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºå·¥ä½œæ—¥ï¼ˆé€±ä¸€åˆ°é€±äº”ï¼‰
        if today.weekday() >= 5:  # é€±å…­(5)æˆ–é€±æ—¥(6)
            # å¦‚æœæ˜¯é€±æœ«ï¼Œæª¢æŸ¥æœ€å¾Œæ•¸æ“šæ˜¯å¦ç‚ºä¸Šå€‹å·¥ä½œæ—¥
            last_weekday = today - pd.Timedelta(days=today.weekday() - 4)  # ä¸Šå€‹é€±äº”
            return last_date >= last_weekday
        else:
            # å¦‚æœæ˜¯å·¥ä½œæ—¥ï¼Œæª¢æŸ¥æ˜¯å¦ç‚ºä»Šå¤©æˆ–æ˜¨å¤©ï¼ˆè€ƒæ…®æ•¸æ“šå»¶é²ï¼‰
            yesterday = today - pd.Timedelta(days=1)
            return last_date >= yesterday
    except Exception:
        return False

def fetch_yf_data(ticker: str, filename: Path, start_date: str = "2000-01-01", end_date: str | None = None):
    now_taipei = pd.Timestamp.now(tz='Asia/Taipei')
    try:
        end_date_str = end_date if end_date is not None else now_taipei.strftime('%Y-%m-%d')
        df = yf.download(ticker, start=start_date, end=end_date_str, auto_adjust=True)
        if df is None or df.empty:
            raise ValueError("ä¸‹è¼‰çš„æ•¸æ“šç‚ºç©º")
        df.to_csv(filename)
        print(f"æˆåŠŸä¸‹è¼‰ '{ticker}' æ•¸æ“šåˆ° '{filename}'.")
    except Exception as e:
        print(f"è­¦å‘Š: '{ticker}' ä¸‹è¼‰å¤±æ•—: {e}")

def ensure_all_price_data_up_to_date(ticker_list, data_dir):
    """æ™ºèƒ½æª¢æŸ¥ä¸¦æ›´æ–°è‚¡åƒ¹æ•¸æ“šï¼Œåªåœ¨å¿…è¦æ™‚ä¸‹è¼‰"""
    for ticker in ticker_list:
        filename = Path(data_dir) / f"{ticker.replace(':','_')}_data_raw.csv"
        if not is_price_data_up_to_date(filename):
            print(f"{ticker} è‚¡åƒ¹è³‡æ–™éœ€è¦æ›´æ–°ï¼Œé–‹å§‹ä¸‹è¼‰...")
            fetch_yf_data(ticker, filename)
        else:
            print(f"{ticker} è‚¡åƒ¹è³‡æ–™å·²æ˜¯æœ€æ–°ï¼Œè·³éä¸‹è¼‰ã€‚")

# ç°¡åŒ–çš„è‚¡åƒ¹æ•¸æ“šä¸‹è¼‰å‰è»Šæ©Ÿåˆ¶
def should_download_price_data():
    """æª¢æŸ¥æ˜¯å¦éœ€è¦ä¸‹è¼‰è‚¡åƒ¹æ•¸æ“šçš„å‰è»Šæ©Ÿåˆ¶"""
    try:
        # æª¢æŸ¥æ˜¯å¦ç‚ºäº¤æ˜“æ™‚é–“ï¼ˆé¿å…åœ¨äº¤æ˜“æ™‚é–“é »ç¹ä¸‹è¼‰ï¼‰
        now = pd.Timestamp.now(tz='Asia/Taipei')
        if now.weekday() < 5:  # å·¥ä½œæ—¥
            hour = now.hour
            if 9 <= hour <= 13:  # äº¤æ˜“æ™‚é–“
                print("ç•¶å‰ç‚ºäº¤æ˜“æ™‚é–“ï¼Œè·³éè‚¡åƒ¹æ•¸æ“šä¸‹è¼‰ä»¥é¿å…å¹¹æ“¾")
                return False
        
        # æª¢æŸ¥æ•¸æ“šæ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”è¼ƒæ–°ï¼ˆé¿å…é‡è¤‡ä¸‹è¼‰ï¼‰
        data_files_exist = all(
            os.path.exists(Path(DATA_DIR) / f"{ticker.replace(':','_')}_data_raw.csv")
            for ticker in TICKER_LIST
        )
        
        if data_files_exist:
            print("è‚¡åƒ¹æ•¸æ“šæ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³éåˆå§‹ä¸‹è¼‰")
            return False
        
        return True
    except Exception as e:
        print(f"å‰è»Šæ©Ÿåˆ¶æª¢æŸ¥å¤±æ•—: {e}ï¼Œå…è¨±ä¸‹è¼‰")
        return True

# åœ¨ app å•Ÿå‹•æ™‚å‘¼å«ï¼ˆæ·»åŠ å‰è»Šæ©Ÿåˆ¶ï¼‰
TICKER_LIST = ['2330.TW', '2412.TW', '2414.TW', '^TWII']  # ä¾å¯¦éš›éœ€æ±‚èª¿æ•´
DATA_DIR = 'data'  # ä¾å¯¦éš›è·¯å¾‘èª¿æ•´

# å®‰å…¨çš„å•Ÿå‹•æ©Ÿåˆ¶
def safe_startup():
    """å®‰å…¨çš„å•Ÿå‹•å‡½æ•¸ï¼Œé¿å…ç·šç¨‹è¡çª"""
    try:
        # åªæœ‰åœ¨å‰è»Šæ©Ÿåˆ¶å…è¨±æ™‚æ‰ä¸‹è¼‰
        if should_download_price_data():
            ensure_all_price_data_up_to_date(TICKER_LIST, DATA_DIR)
        else:
            print("è‚¡åƒ¹æ•¸æ“šä¸‹è¼‰å·²ç”±å‰è»Šæ©Ÿåˆ¶é˜»æ­¢")
    except Exception as e:
        print(f"å•Ÿå‹•æ™‚æ•¸æ“šä¸‹è¼‰å¤±æ•—: {e}ï¼Œç¹¼çºŒå•Ÿå‹•æ‡‰ç”¨")

# --------- å¢å¼·åˆ†æ Callbackï¼šå…¨å±€åƒæ•¸ç‹€æ…‹æ›´æ–° ---------
@app.callback(
    Output("enhanced-global-status", "children"),
    [
        Input("global-apply-switch", "value"),
        Input("risk-cap-input", "value"),
        Input("atr-ratio-threshold", "value"),
        Input("force-valve-trigger", "value")
    ]
)
def update_enhanced_global_status(global_apply, risk_cap, atr_ratio, force_trigger):
    """æ›´æ–°å¢å¼·åˆ†æé é¢çš„å…¨å±€åƒæ•¸å¥—ç”¨ç‹€æ…‹"""
    if not global_apply:
        return html.Div([
            html.Small("ğŸ”´ å…¨å±€åƒæ•¸å¥—ç”¨æœªå•Ÿç”¨", style={"color":"#dc3545","fontWeight":"bold","fontSize":"14px"}),
            html.Br(),
            html.Small("å¢å¼·åˆ†æå°‡ä½¿ç”¨é é¢å…§å»ºçš„åƒæ•¸è¨­å®š", style={"color":"#666","fontSize":"12px"}),
            html.Br(),
            html.Small("ğŸ’¡ å¦‚éœ€ä½¿ç”¨å…¨å±€è¨­å®šï¼Œè«‹åœ¨å´é‚Šæ¬„å•Ÿç”¨ã€Œå•Ÿç”¨å…¨å±€åƒæ•¸å¥—ç”¨ã€", style={"color":"#666","fontSize":"11px","fontStyle":"italic"})
        ])
    
    # å¦‚æœå•Ÿç”¨å…¨å±€åƒæ•¸å¥—ç”¨
    status_color = "#28a745" if not force_trigger else "#dc3545"
    status_icon = "ğŸŸ¢" if not force_trigger else "ğŸ”´"
    status_text = "æ­£å¸¸" if not force_trigger else "å¼·åˆ¶è§¸ç™¼"
    
    return html.Div([
        html.Small(f"{status_icon} å…¨å±€åƒæ•¸å¥—ç”¨å·²å•Ÿç”¨", style={"color":status_color,"fontWeight":"bold","fontSize":"14px"}),
        html.Br(),
        html.Small(f"é¢¨éšªé–¥é–€ CAP: {risk_cap}", style={"color":"#666","fontSize":"12px"}),
        html.Br(),
        html.Small(f"ATRæ¯”å€¼é–€æª»: {atr_ratio}", style={"color":"#666","fontSize":"12px"}),
        html.Br(),
        html.Small(f"ç‹€æ…‹: {status_text}", style={"color":status_color,"fontSize":"12px"}),
        html.Br(),
        html.Small("ğŸ’¡ å¢å¼·åˆ†æçš„é¢¨éšªé–¥é–€å›æ¸¬å°‡å„ªå…ˆä½¿ç”¨é€™äº›å…¨å±€è¨­å®š", style={"color":"#28a745","fontSize":"11px","fontStyle":"italic"})
    ])

# --------- å¢å¼·åˆ†æ Callbackï¼šé¢¨éšªé–¥é–€å›æ¸¬ï¼ˆæ•´åˆç‰ˆï¼‰ ---------
@app.callback(
    Output("rv-summary","children"),
    Output("rv-equity-chart","figure"),
    Output("rv-dd-chart","figure"),
    Input("run-rv","n_clicks"),
    State("rv-mode","value"),
    State("rv-cap","value"),
    State("rv-atr-mult","value"),
    State("enhanced-trades-cache","data"),
    # === æ–°å¢ï¼šè®€å–å…¨å±€åƒæ•¸è¨­å®š ===
    State("global-apply-switch","value"),
    State("risk-cap-input","value"),
    State("atr-ratio-threshold","value"),
    # === æ–°å¢ï¼šè®€å–å…¨å±€å¥—ç”¨æ•¸æ“šæº ===
    State("backtest-store","data"),
    prevent_initial_call=True
)
def _run_rv(n_clicks, mode, cap_level, atr_mult, cache, global_apply, global_risk_cap, global_atr_ratio, backtest_data=None):
    if not n_clicks or not cache:
        return "è«‹å…ˆè¼‰å…¥ç­–ç•¥è³‡æ–™", no_update, no_update

    # === ä¿®æ­£ï¼šå„ªå…ˆä½¿ç”¨å…¨å±€åƒæ•¸è¨­å®š ===
    if global_apply:
        # å¦‚æœå•Ÿç”¨å…¨å±€åƒæ•¸å¥—ç”¨ï¼Œå„ªå…ˆä½¿ç”¨å…¨å±€è¨­å®š
        effective_cap = global_risk_cap if global_risk_cap is not None else cap_level
        effective_atr_ratio = global_atr_ratio if global_atr_ratio is not None else atr_mult
        logger.info(f"å¢å¼·åˆ†æä½¿ç”¨å…¨å±€åƒæ•¸ï¼šCAP={effective_cap}, ATRæ¯”å€¼é–€æª»={effective_atr_ratio}")
        
        # === æ–°å¢ï¼šè©³ç´°çš„åƒæ•¸å°æ¯”æ—¥èªŒ ===
        logger.info(f"=== å¢å¼·åˆ†æåƒæ•¸å°æ¯” ===")
        logger.info(f"å…¨å±€è¨­å®šï¼šCAP={global_risk_cap}, ATRæ¯”å€¼é–€æª»={global_atr_ratio}")
        logger.info(f"é é¢è¨­å®šï¼šCAP={cap_level}, ATRæ¯”å€¼é–€æª»={atr_mult}")
        logger.info(f"æœ€çµ‚ä½¿ç”¨ï¼šCAP={effective_cap}, ATRæ¯”å€¼é–€æª»={effective_atr_ratio}")
        
    else:
        # å¦å‰‡ä½¿ç”¨å¢å¼·åˆ†æé é¢çš„è¨­å®š
        effective_cap = cap_level
        effective_atr_ratio = atr_mult
        logger.info(f"å¢å¼·åˆ†æä½¿ç”¨é é¢åƒæ•¸ï¼šCAP={effective_cap}, ATRæ¯”å€¼é–€æª»={effective_atr_ratio}")
    
    # === æ•´åˆï¼šä½¿ç”¨èˆ‡å…¨å±€å¥—ç”¨ç›¸åŒçš„æ•¸æ“šæº ===
    logger.info(f"=== æ•¸æ“šé©—è­‰ ===")
    
    # å„ªå…ˆä½¿ç”¨å…¨å±€å¥—ç”¨çš„æ•¸æ“šæºï¼Œç¢ºä¿ä¸€è‡´æ€§
    if global_apply and backtest_data:
        # å¾ backtest-store ç²å–æ•¸æ“šï¼Œèˆ‡å…¨å±€å¥—ç”¨ä¿æŒä¸€è‡´
        results = backtest_data.get("results", {})
        if results:
            # æ‰¾åˆ°å°æ‡‰çš„ç­–ç•¥çµæœ
            strategy_name = cache.get("strategy") if cache else None
            if strategy_name and strategy_name in results:
                result = results[strategy_name]
                df_raw = df_from_pack(backtest_data.get("df_raw"))
                daily_state = df_from_pack(result.get("daily_state_std") or result.get("daily_state"))
                logger.info(f"ä½¿ç”¨å…¨å±€å¥—ç”¨æ•¸æ“šæº: {strategy_name}")
            else:
                # å›é€€åˆ°å¿«å–æ•¸æ“š
                df_raw = df_from_pack(cache.get("df_raw"))
                daily_state = df_from_pack(cache.get("daily_state"))
                logger.info("å›é€€åˆ°å¿«å–æ•¸æ“šæº")
        else:
            # å›é€€åˆ°å¿«å–æ•¸æ“š
            df_raw = df_from_pack(cache.get("df_raw"))
            daily_state = df_from_pack(cache.get("daily_state"))
            logger.info("å›é€€åˆ°å¿«å–æ•¸æ“šæº")
    else:
        # ä½¿ç”¨å¿«å–æ•¸æ“š
        df_raw = df_from_pack(cache.get("df_raw"))
        daily_state = df_from_pack(cache.get("daily_state"))
        logger.info("ä½¿ç”¨å¿«å–æ•¸æ“šæº")
    
    # === æ–°å¢ï¼šæ•¸æ“šä¸€è‡´æ€§æª¢æŸ¥ ===
    if global_apply and backtest_data:
        logger.info("=== æ•¸æ“šä¸€è‡´æ€§æª¢æŸ¥ ===")
        # æª¢æŸ¥èˆ‡å…¨å±€å¥—ç”¨æ•¸æ“šçš„ä¸€è‡´æ€§
        global_df_raw = df_from_pack(backtest_data.get("df_raw"))
        if global_df_raw is not None and df_raw is not None:
            if len(global_df_raw) == len(df_raw):
                logger.info(f"âœ… æ•¸æ“šé•·åº¦ä¸€è‡´: {len(df_raw)}")
            else:
                logger.warning(f"âš ï¸  æ•¸æ“šé•·åº¦ä¸ä¸€è‡´: å…¨å±€={len(global_df_raw)}, å¢å¼·åˆ†æ={len(df_raw)}")
        
        if daily_state is not None:
            logger.info(f"âœ… daily_state è¼‰å…¥æˆåŠŸ: {len(daily_state)} è¡Œ")
        else:
            logger.warning("âš ï¸  daily_state è¼‰å…¥å¤±æ•—")
    
    # === åŸæœ‰æ•¸æ“šé©—è­‰æ—¥èªŒ ===
    logger.info(f"df_raw å½¢ç‹€: {df_raw.shape if df_raw is not None else 'None'}")
    logger.info(f"daily_state å½¢ç‹€: {daily_state.shape if daily_state is not None else 'None'}")
    if daily_state is not None:
        logger.info(f"daily_state æ¬„ä½: {list(daily_state.columns)}")
        logger.info(f"daily_state ç´¢å¼•ç¯„åœ: {daily_state.index.min()} åˆ° {daily_state.index.max()}")
        if "w" in daily_state.columns:
            logger.info(f"æ¬Šé‡æ¬„ä½çµ±è¨ˆ: æœ€å°å€¼={daily_state['w'].min():.4f}, æœ€å¤§å€¼={daily_state['w'].max():.4f}, å¹³å‡å€¼={daily_state['w'].mean():.4f}")
    
    if df_raw is None or df_raw.empty:
        return "æ‰¾ä¸åˆ°è‚¡åƒ¹è³‡æ–™", no_update, no_update
    
    if daily_state is None or daily_state.empty:
        return "æ‰¾ä¸åˆ° daily_stateï¼ˆæ¯æ—¥è³‡ç”¢/æ¬Šé‡ï¼‰", no_update, no_update

    # æ¬„åå°é½Š
    c_open = "open" if "open" in df_raw.columns else _first_col(df_raw, ["Open","é–‹ç›¤åƒ¹"])
    c_close = "close" if "close" in df_raw.columns else _first_col(df_raw, ["Close","æ”¶ç›¤åƒ¹"])
    c_high  = "high" if "high" in df_raw.columns else _first_col(df_raw, ["High","æœ€é«˜åƒ¹"])
    c_low   = "low"  if "low"  in df_raw.columns else _first_col(df_raw, ["Low","æœ€ä½åƒ¹"])

    if c_open is None or c_close is None:
        return "è‚¡åƒ¹è³‡æ–™ç¼ºå°‘ open/close æ¬„ä½", no_update, no_update

    open_px = pd.to_numeric(df_raw[c_open], errors="coerce").dropna()
    open_px.index = pd.to_datetime(df_raw.index)

    # æ¬Šé‡å–è‡ª daily_state
    if "w" not in daily_state.columns:
        return "daily_state ç¼ºå°‘æ¬Šé‡æ¬„ä½ 'w'", no_update, no_update
    
    w = daily_state["w"].astype(float).reindex(open_px.index).ffill().fillna(0.0)

    # æˆæœ¬åƒæ•¸ï¼ˆä½¿ç”¨ SSS_EnsembleTab é è¨­ï¼‰
    cost = None

    # åŸºæº–ï¼šç”¨ df_raw ç•¶åŸºæº–ï¼ˆå³å¯ï¼‰ï¼Œå‡½å¼èƒ½åœ¨ç„¡é«˜ä½åƒ¹æ™‚å›é€€
    bench = pd.DataFrame({
        "æ”¶ç›¤åƒ¹": pd.to_numeric(df_raw[c_close], errors="coerce"),
    }, index=pd.to_datetime(df_raw.index))
    if c_high and c_low:
        bench["æœ€é«˜åƒ¹"] = pd.to_numeric(df_raw[c_high], errors="coerce")
        bench["æœ€ä½åƒ¹"] = pd.to_numeric(df_raw[c_low], errors="coerce")

    # éœ€è¦ç”¨åˆ° SSS_EnsembleTab å…§æ–°åŠ çš„å‡½å¼
    try:
        from SSS_EnsembleTab import risk_valve_backtest
        # === å¢å¼·åˆ†æé¢¨éšªé–¥é–€ï¼šç¢ºä¿åƒæ•¸ä¸€è‡´æ€§ (2025/08/20) ===
        enhanced_valve_params = {
            "open_px": open_px, 
            "w": w, 
            "cost": cost, 
            "benchmark_df": bench,
            "mode": mode, 
            "cap_level": float(effective_cap),  # === ä¿®æ­£ï¼šä½¿ç”¨æœ‰æ•ˆåƒæ•¸ ===
            "slope20_thresh": 0.0, 
            "slope60_thresh": 0.0,
            "atr_win": 20, 
            "atr_ref_win": 60, 
            "atr_ratio_mult": float(effective_atr_ratio),  # === ä¿®æ­£ï¼šä½¿ç”¨æœ‰æ•ˆåƒæ•¸ ===
            "use_slopes": True, 
            "slope_method": "polyfit", 
            "atr_cmp": "gt"
        }
        
        # è¨˜éŒ„å¢å¼·åˆ†æé¢¨éšªé–¥é–€é…ç½®
        logger.info(f"[Enhanced] é¢¨éšªé–¥é–€é…ç½®: cap_level={enhanced_valve_params['cap_level']}, atr_ratio_mult={enhanced_valve_params['atr_ratio_mult']}")
        
        out = risk_valve_backtest(**enhanced_valve_params)
    except Exception as e:
        return f"é¢¨éšªé–¥é–€å›æ¸¬åŸ·è¡Œå¤±æ•—: {e}", no_update, no_update

    m = out["metrics"]
    
    # è¨ˆç®—é¢¨éšªè§¸ç™¼å¤©æ•¸
    sig = out["signals"]["risk_trigger"]
    trigger_days = int(sig.fillna(False).sum())
    
    # === ä¿®æ­£ï¼šé¡¯ç¤ºå¯¦éš›ä½¿ç”¨çš„åƒæ•¸ ===
    summary = html.Div([
        html.Code(f"PF: åŸå§‹ {m['pf_orig']:.2f} â†’ é–¥é–€ {m['pf_valve']:.2f}"), html.Br(),
        html.Code(f"MDD: åŸå§‹ {m['mdd_orig']:.2%} â†’ é–¥é–€ {m['mdd_valve']:.2%}"), html.Br(),
        html.Code(f"å³å°¾ç¸½å’Œ(>P90 æ­£å ±é…¬): åŸå§‹ {m['right_tail_sum_orig']:.2f} â†’ é–¥é–€ {m['right_tail_sum_valve']:.2f} (â†“{m['right_tail_reduction']:.2f})"), html.Br(),
        html.Code(f"é¢¨éšªè§¸ç™¼å¤©æ•¸ï¼š{trigger_days} å¤©"), html.Br(),
        html.Code(f"ä½¿ç”¨åƒæ•¸ï¼šCAP={effective_cap}, ATRæ¯”å€¼é–€æª»={effective_atr_ratio}"), html.Br(),
        html.Code(f"åƒæ•¸ä¾†æºï¼š{'å…¨å±€è¨­å®š' if global_apply else 'é é¢è¨­å®š'}", style={"color": "#28a745" if global_apply else "#ffc107"})
    ])

    # ç¹ªåœ–ï¼šå…©ç‰ˆæ¬Šç›Šèˆ‡å›æ’¤
    import plotly.graph_objects as go
    eq1 = out["daily_state_orig"]["equity"]
    eq2 = out["daily_state_valve"]["equity"]
    dd1 = eq1/eq1.cummax()-1
    dd2 = eq2/eq2.cummax()-1

    palette = {
        "orig":  {"color": "#1f77b4", "dash": "solid"},
        "valve": {"color": "#ff7f0e", "dash": "dot"},
    }

    fig_eq = go.Figure()
    fig_eq.add_trace(go.Scatter(
        x=eq1.index, y=eq1, name="åŸå§‹",
        mode="lines", line=dict(color=palette["orig"]["color"], width=2, dash=palette["orig"]["dash"]),
        legendgroup="equity"
    ))
    fig_eq.add_trace(go.Scatter(
        x=eq2.index, y=eq2, name="é–¥é–€",
        mode="lines", line=dict(color=palette["valve"]["color"], width=2, dash=palette["valve"]["dash"]),
        legendgroup="equity"
    ))
    fig_eq.update_layout(title="æ¬Šç›Šæ›²ç·šï¼ˆOpenâ†’Openï¼‰", legend_orientation="h")

    fig_dd = go.Figure()
    fig_dd.add_trace(go.Scatter(
        x=dd1.index, y=dd1, name="åŸå§‹",
        mode="lines", line=dict(color=palette["orig"]["color"], width=2, dash=palette["orig"]["dash"]),
        legendgroup="dd"
    ))
    fig_dd.add_trace(go.Scatter(
        x=dd2.index, y=dd2, name="é–¥é–€",
        mode="lines", line=dict(color=palette["valve"]["color"], width=2, dash=palette["valve"]["dash"]),
        legendgroup="dd"
    ))
    fig_dd.update_layout(title="å›æ’¤æ›²ç·š", legend_orientation="h", yaxis_tickformat=".0%")

    return summary, fig_eq, fig_dd

# --------- å¢å¼·åˆ†æ Callbackï¼šæ•¸æ“šæ¯”å°å ±å‘Š ---------
@app.callback(
    Output("data-comparison-output", "children"),
    Output("data-comparison-csv", "data"),
    Input("export-data-comparison", "n_clicks"),
    State("enhanced-trades-cache", "data"),
    State("backtest-store", "data"),
    State("global-apply-switch", "value"),
    State("risk-cap-input", "value"),
    State("atr-ratio-threshold", "value"),
    State("rv-cap", "value"),
    State("rv-atr-mult", "value"),
    prevent_initial_call=True
)
def generate_data_comparison_report(n_clicks, cache, backtest_data, global_apply, global_cap, global_atr, page_cap, page_atr):
    """ç”Ÿæˆæ•¸æ“šæ¯”å°å ±å‘Šï¼Œè¨ºæ–·å…¨å±€å¥—ç”¨èˆ‡å¼·åŒ–åˆ†æçµæœä¸åŒçš„å•é¡Œ - å¢å¼·ç‰ˆ (2025/08/20)"""
    if not n_clicks:
        return "è«‹é»æ“ŠæŒ‰éˆ•ç”Ÿæˆå ±å‘Š", no_update
    
    logger.info(f"=== ç”Ÿæˆå¢å¼·æ•¸æ“šæ¯”å°å ±å‘Š ===")
    
    # æ”¶é›†åƒæ•¸è³‡è¨Š
    param_info = {
        "å…¨å±€åƒæ•¸å¥—ç”¨": "å•Ÿç”¨" if global_apply else "æœªå•Ÿç”¨",
        "å…¨å±€é¢¨éšªé–¥é–€CAP": global_cap,
        "å…¨å±€ATRæ¯”å€¼é–€æª»": global_atr,
        "é é¢é¢¨éšªé–¥é–€CAP": page_cap,
        "é é¢ATRæ¯”å€¼é–€æª»": page_atr,
        "æœ€çµ‚ä½¿ç”¨CAP": global_cap if global_apply else page_cap,
        "æœ€çµ‚ä½¿ç”¨ATRæ¯”å€¼é–€æª»": global_atr if global_apply else page_atr,
        "åƒæ•¸å·®ç•°åˆ†æ": "CAPå·®ç•°={}, ATRå·®ç•°={}".format(
            abs((global_cap or 0) - (page_cap or 0)), 
            abs((global_atr or 0) - (page_atr or 0))
        )
    }
    
    # æ”¶é›†æ•¸æ“šè³‡è¨Š
    data_info = {}
    
    if cache:
        df_raw = df_from_pack(cache.get("df_raw"))
        daily_state = df_from_pack(cache.get("daily_state"))
        trade_data = df_from_pack(cache.get("trade_data"))
        weight_curve = df_from_pack(cache.get("weight_curve"))
        
        data_info["enhanced_cache"] = {
            "df_raw_shape": df_raw.shape if df_raw is not None else None,
            "daily_state_shape": daily_state.shape if daily_state is not None else None,
            "trade_data_shape": trade_data.shape if trade_data is not None else None,
            "weight_curve_shape": weight_curve.shape if weight_curve is not None else None,
            "daily_state_columns": list(daily_state.columns) if daily_state is not None else None,
            "daily_state_index_range": f"{daily_state.index.min()} åˆ° {daily_state.index.max()}" if daily_state is not None and not daily_state.empty else None
        }
        
        if daily_state is not None and "w" in daily_state.columns:
            data_info["enhanced_cache"]["weight_stats"] = {
                "min": float(daily_state["w"].min()),
                "max": float(daily_state["w"].max()),
                "mean": float(daily_state["w"].mean()),
                "std": float(daily_state["w"].std())
            }
    
    if backtest_data and backtest_data.get("results"):
        results = backtest_data["results"]
        data_info["backtest_store"] = {
            "available_strategies": list(results.keys()),
            "results_count": len(results)
        }
        
        # é¸æ“‡ç¬¬ä¸€å€‹ç­–ç•¥é€²è¡Œè©³ç´°åˆ†æ
        if results:
            first_strategy = list(results.keys())[0]
            result = results[first_strategy]
            
            data_info["backtest_store"]["first_strategy"] = {
                "name": first_strategy,
                "has_daily_state": result.get("daily_state") is not None,
                "has_daily_state_std": result.get("daily_state_std") is not None,
                "has_weight_curve": result.get("weight_curve") is not None,
                "valve_info": result.get("valve", {})
            }
    
    # ç”Ÿæˆå ±å‘Š
    report_lines = []
    report_lines.append("=== æ•¸æ“šæ¯”å°å ±å‘Š ===")
    report_lines.append("")
    
    # åƒæ•¸éƒ¨åˆ†
    report_lines.append("ğŸ“Š åƒæ•¸è¨­å®š:")
    for key, value in param_info.items():
        report_lines.append(f"  {key}: {value}")
    report_lines.append("")
    
    # æ•¸æ“šéƒ¨åˆ†
    report_lines.append("ğŸ“ˆ æ•¸æ“šç‹€æ…‹:")
    if "enhanced_cache" in data_info:
        report_lines.append("  Enhanced Cache:")
        for key, value in data_info["enhanced_cache"].items():
            report_lines.append(f"    {key}: {value}")
        report_lines.append("")
    
    if "backtest_store" in data_info:
        report_lines.append("  Backtest Store:")
        for key, value in data_info["backtest_store"].items():
            report_lines.append(f"    {key}: {value}")
        report_lines.append("")
    
    # å¢å¼·è¨ºæ–·å»ºè­° (2025/08/20)
    report_lines.append("ğŸ” è©³ç´°è¨ºæ–·å»ºè­°:")
    
    # åƒæ•¸ä¸€è‡´æ€§æª¢æŸ¥
    if global_apply:
        cap_diff = abs((global_cap or 0) - (page_cap or 0))
        atr_diff = abs((global_atr or 0) - (page_atr or 0))
        if cap_diff > 0.001 or atr_diff > 0.001:
            report_lines.append(f"  âš ï¸  å…¨å±€èˆ‡é é¢åƒæ•¸å·®ç•°: CAPå·®ç•°={cap_diff:.4f}, ATRå·®ç•°={atr_diff:.4f}")
            report_lines.append("      â†’ å»ºè­°æª¢æŸ¥ UI ä»‹é¢çš„åƒæ•¸åŒæ­¥æ©Ÿåˆ¶")
        else:
            report_lines.append("  âœ… å…¨å±€åƒæ•¸èˆ‡é é¢åƒæ•¸ä¸€è‡´")
    else:
        report_lines.append("  â„¹ï¸  æœªå•Ÿç”¨å…¨å±€åƒæ•¸å¥—ç”¨ï¼Œä½¿ç”¨é é¢åƒæ•¸")
        report_lines.append("      â†’ ç¢ºèªæ˜¯å¦éœ€è¦å•Ÿç”¨å…¨å±€å¥—ç”¨ä»¥ä¿æŒä¸€è‡´æ€§")
    
    # æ•¸æ“šå®Œæ•´æ€§æª¢æŸ¥
    enhanced_has_data = "enhanced_cache" in data_info and data_info["enhanced_cache"]["daily_state_shape"]
    backtest_has_data = "backtest_store" in data_info and data_info["backtest_store"]["results_count"] > 0
    
    if enhanced_has_data:
        report_lines.append("  âœ… Enhanced Cache æœ‰æ•¸æ“š")
        if "weight_stats" in data_info["enhanced_cache"]:
            ws = data_info["enhanced_cache"]["weight_stats"]
            report_lines.append(f"      æ¬Šé‡ç¯„åœ: {ws['min']:.4f} ~ {ws['max']:.4f}, å‡å€¼: {ws['mean']:.4f}")
    else:
        report_lines.append("  âŒ Enhanced Cache ç„¡æ•¸æ“š")
        report_lines.append("      â†’ å¯èƒ½éœ€è¦é‡æ–°åŸ·è¡Œå¢å¼·åˆ†æ")
    
    if backtest_has_data:
        report_lines.append("  âœ… Backtest Store æœ‰çµæœ")
    else:
        report_lines.append("  âŒ Backtest Store ç„¡çµæœ")
        report_lines.append("      â†’ å¯èƒ½éœ€è¦é‡æ–°åŸ·è¡Œå›æ¸¬åˆ†æ")
    
    # é¢¨éšªé–¥é–€é‚è¼¯æª¢æŸ¥
    effective_cap = global_cap if global_apply else page_cap
    effective_atr = global_atr if global_apply else page_atr
    
    report_lines.append("  ğŸ”§ é¢¨éšªé–¥é–€é…ç½®:")
    report_lines.append(f"      æœ‰æ•ˆCAPå€¼: {effective_cap}")
    report_lines.append(f"      æœ‰æ•ˆATRé–€æª»: {effective_atr}")
    
    if effective_cap and effective_cap < 0.1:
        report_lines.append("      âš ï¸  CAPå€¼éä½ï¼Œå¯èƒ½é€ æˆéåº¦ä¿å®ˆ")
    if effective_atr and effective_atr > 3.0:
        report_lines.append("      âš ï¸  ATRé–€æª»éé«˜ï¼Œå¯èƒ½å¾ˆå°‘è§¸ç™¼")
    
    # ä¸€è‡´æ€§æª¢æŸ¥ç¸½çµ
    consistency_issues = []
    if global_apply and (cap_diff > 0.001 or atr_diff > 0.001):
        consistency_issues.append("åƒæ•¸ä¸ä¸€è‡´")
    if not enhanced_has_data:
        consistency_issues.append("Enhanced Cacheç¼ºå¤±")
    if not backtest_has_data:
        consistency_issues.append("Backtest Storeç¼ºå¤±")
    
    if consistency_issues:
        report_lines.append(f"  ğŸš¨ ç™¼ç¾ä¸€è‡´æ€§å•é¡Œ: {', '.join(consistency_issues)}")
        report_lines.append("      å»ºè­°å„ªå…ˆè§£æ±ºé€™äº›å•é¡Œä»¥ç¢ºä¿åˆ†æçµæœä¸€è‡´æ€§")
    else:
        report_lines.append("  âœ… æœªç™¼ç¾æ˜é¡¯ä¸€è‡´æ€§å•é¡Œ")
    
    # ç”Ÿæˆ CSV æ•¸æ“š
    csv_data = []
    for key, value in param_info.items():
        csv_data.append({"é …ç›®": key, "æ•¸å€¼": str(value)})
    
    csv_data.append({"é …ç›®": "", "æ•¸å€¼": ""})
    csv_data.append({"é …ç›®": "=== æ•¸æ“šç‹€æ…‹ ===", "æ•¸å€¼": ""})
    
    if "enhanced_cache" in data_info:
        for key, value in data_info["enhanced_cache"].items():
            csv_data.append({"é …ç›®": f"Enhanced_{key}", "æ•¸å€¼": str(value)})
    
    if "backtest_store" in data_info:
        for key, value in data_info["backtest_store"].items():
            csv_data.append({"é …ç›®": f"Backtest_{key}", "æ•¸å€¼": str(value)})
    
    # è¿”å›å ±å‘Šå’Œ CSV ä¸‹è¼‰
    report_text = "\n".join(report_lines)
    csv_df = pd.DataFrame(csv_data)
    
    return report_text, dcc.send_data_frame(csv_df.to_csv, "data_comparison_report.csv", index=False)

def _first_col(df, names):
    low = {c.lower(): c for c in df.columns}
    for n in names:
        if n.lower() in low: return low[n.lower()]
    return None

# --------- å¢å¼·åˆ†æ Callbackï¼šäº¤æ˜“è²¢ç»æ‹†è§£ï¼ˆä¿®æ­£ç‰ˆï¼‰ ---------
@app.callback(
    Output("phase-table", "children"),
    Input("run-phase", "n_clicks"),
    State("phase-min-gap", "value"),
    State("phase-cooldown", "value"),
    State("enhanced-trades-cache", "data"),
    State("theme-store", "data"),   # è‹¥æ²’æœ‰ theme-storeï¼Œé€™è¡Œèˆ‡ä¸‹æ–¹ theme ç›¸é—œå¯ç§»é™¤
    prevent_initial_call=True
)
def _run_phase(n_clicks, min_gap, cooldown, cache, theme):
    import numpy as np
    from urllib.parse import quote as urlparse
    if not n_clicks:
        raise dash.exceptions.PreventUpdate
    if not cache:
        return html.Div("å°šæœªè¼‰å…¥å›æ¸¬çµæœ", style={"color": "#ffb703"})

    # å¾å¿«å–é‚„åŸè³‡æ–™
    trade_df = df_from_pack(cache.get("trade_data"))
    daily_state = df_from_pack(cache.get("daily_state"))
    
    if trade_df is None or trade_df.empty:
        return "æ‰¾ä¸åˆ°äº¤æ˜“è³‡æ–™"
    
    if daily_state is None or daily_state.empty:
        return "æ‰¾ä¸åˆ° daily_stateï¼ˆæ¯æ—¥è³‡ç”¢/æ¬Šé‡ï¼‰"
    
    if "equity" not in daily_state.columns:
        return "daily_state ç¼ºå°‘æ¬Šç›Šæ¬„ä½ 'equity'"

    equity = daily_state["equity"]

    # å‘¼å«ä½ å·²å¯«å¥½çš„åˆ†æå‡½æ•¸
    try:
        from SSS_EnsembleTab import trade_contribution_by_phase
        table = trade_contribution_by_phase(trade_df, equity, min_gap, cooldown).copy()
    except Exception as e:
        return f"äº¤æ˜“è²¢ç»æ‹†è§£åŸ·è¡Œå¤±æ•—: {e}"

    if table.empty:
        return "ç„¡è³‡æ–™"

    # æ•¸å­—æ¬„ä½è½‰å‹
    num_cols = ["äº¤æ˜“ç­†æ•¸","è³£å‡ºå ±é…¬ç¸½å’Œ(%)","éšæ®µå…§MDD(%)","éšæ®µæ·¨è²¢ç»(%)"]
    for c in num_cols:
        if c in table.columns:
            table[c] = pd.to_numeric(table[c], errors="coerce")

    # ====== ç¸½é«” KPI ======
    avg_net = table["éšæ®µæ·¨è²¢ç»(%)"].mean() if "éšæ®µæ·¨è²¢ç»(%)" in table else np.nan
    avg_mdd = table["éšæ®µå…§MDD(%)"].mean() if "éšæ®µå…§MDD(%)" in table else np.nan
    succ_all = (table["éšæ®µæ·¨è²¢ç»(%)"] > 0).mean() if "éšæ®µæ·¨è²¢ç»(%)" in table else np.nan
    succ_acc = np.nan
    if "éšæ®µ" in table.columns and "éšæ®µæ·¨è²¢ç»(%)" in table.columns:
        mask_acc = table["éšæ®µ"].astype(str).str.contains("åŠ ç¢¼", na=False)
        if mask_acc.any():
            succ_acc = (table.loc[mask_acc, "éšæ®µæ·¨è²¢ç»(%)"] > 0).mean()
    risk_eff = np.nan
    if pd.notna(avg_net) and pd.notna(avg_mdd) and avg_mdd != 0:
        risk_eff = avg_net / abs(avg_mdd)

    # ====== CSV æ–‡å­—ï¼ˆçµ¦è¤‡è£½ç”¨ï¼›DataTable å¦æœ‰å…§å»ºä¸‹è¼‰ï¼‰======
    csv_text = table.to_csv(index=False)
    csv_data_url = "data:text/csv;charset=utf-8," + urlparse(csv_text)

    # ====== ä¸»é¡Œæ¨£å¼ï¼ˆé¿å…ç™½åº•ç™½å­—ï¼‰======
    theme = theme or "theme-dark"
    if theme == "theme-dark":
        table_bg = "#1a1a1a"; cell_color = "#ffffff"
        header_bg = "#2a2a2a"; header_color = "#ffffff"; border = "#444444"
        accent_bg = "#243447"; accent_color = "#ffffff"
    elif theme == "theme-light":
        table_bg = "#ffffff"; cell_color = "#111111"
        header_bg = "#f2f2f2"; header_color = "#111111"; border = "#cccccc"
        accent_bg = "#eef2ff"; accent_color = "#111111"
    else:  # theme-blue
        table_bg = "#0b1e3a"; cell_color = "#ffe066"
        header_bg = "#12345b"; header_color = "#ffe066"; border = "#335577"
        accent_bg = "#12345b"; accent_color = "#ffe066"

    style_table = {
        "overflowX": "auto",
        "overflowY": "auto",
        "maxHeight": "70vh",
        "fontSize": "12px",
        "fontFamily": "Arial, sans-serif",
        "backgroundColor": table_bg,
        "border": f"1px solid {border}",
        # å…è¨±é¸å–â†’å¯è¤‡è£½
        "userSelect": "text", "-webkit-user-select": "text",
        "-moz-user-select": "text", "-ms-user-select": "text",
    }
    style_cell = {
        "textAlign": "center",
        "padding": "8px",
        "minWidth": "80px",
        "backgroundColor": table_bg,
        "color": cell_color,
        "border": f"1px solid {border}",
        "whiteSpace": "normal",
        "height": "auto",
    }
    style_header = {
        "backgroundColor": header_bg,
        "color": header_color,
        "fontWeight": "bold",
        "textAlign": "center",
        "borderBottom": f"2px solid {border}",
    }

    # ====== å®Œæ•´è¡¨æ ¼ ======
    # æ³¨æ„ï¼šfull_table å°‡åœ¨ ordered è®Šæ•¸å®šç¾©å¾Œé‡æ–°å®šç¾©

    # ====== æ˜“è®€ç‰ˆï¼ˆKPI + Top3 / Worst3ï¼‰======
    def kpi(label, value):
        return html.Div([
            html.Div(label, style={"fontSize": "12px", "opacity": 0.8}),
            html.Div(value, style={"fontSize": "18px", "fontWeight": "bold"})
        ], style={
            "backgroundColor": accent_bg, "color": accent_color,
            "padding": "10px 14px", "borderRadius": "12px", "minWidth": "160px"
        })

    kpi_bar = html.Div([
        kpi("å¹³å‡æ¯æ®µæ·¨è²¢ç»(%)", f"{avg_net:.2f}" if pd.notna(avg_net) else "â€”"),
        kpi("å¹³å‡æ¯æ®µ MDD(%)", f"{avg_mdd:.2f}" if pd.notna(avg_mdd) else "â€”"),
        kpi("æˆåŠŸç‡(å…¨éƒ¨)", f"{succ_all*100:.1f}%" if pd.notna(succ_all) else "â€”"),
        kpi("æˆåŠŸç‡(åŠ ç¢¼)", f"{succ_acc*100:.1f}%" if pd.notna(succ_acc) else "â€”"),
        kpi("é¢¨éšªæ•ˆç‡", f"{risk_eff:.3f}" if pd.notna(risk_eff) else "â€”"),
    ], style={"display":"flex","gap":"12px","flexWrap":"wrap","marginBottom":"10px"})

    # ====== åˆ†çµ„ KPIï¼šåŠ ç¢¼ vs æ¸›ç¢¼ ======
    def _group_metrics(mask):
        if {"éšæ®µæ·¨è²¢ç»(%)","éšæ®µå…§MDD(%)"}.issubset(table.columns):
            sub = table.loc[mask]
            if sub.empty:
                return None
            a_net = sub["éšæ®µæ·¨è²¢ç»(%)"].mean()
            a_mdd = sub["éšæ®µå…§MDD(%)"].mean()
            succ  = (sub["éšæ®µæ·¨è²¢ç»(%)"] > 0).mean()
            eff   = (a_net / abs(a_mdd)) if pd.notna(a_net) and pd.notna(a_mdd) and a_mdd != 0 else np.nan
            return {"count": int(len(sub)), "avg_net": a_net, "avg_mdd": a_mdd, "succ": succ, "eff": eff}
        return None

    def _fmt(val, pct=False, dec=2):
        if val is None or (isinstance(val, float) and (np.isnan(val) or np.isinf(val))):
            return "â€”"
        return f"{val*100:.1f}%" if pct else f"{val:.{dec}f}"

    def group_row(title, m):
        return html.Div([
            html.Div(title, style={"fontWeight":"bold","marginRight":"12px","minWidth":"72px","alignSelf":"center"}),
            kpi("æ®µæ•¸", f"{m['count']}" if m else "â€”"),
            kpi("å¹³å‡æ·¨è²¢ç»(%)", _fmt(m['avg_net']) if m else "â€”"),
            kpi("å¹³å‡MDD(%)",   _fmt(m['avg_mdd']) if m else "â€”"),
            kpi("æˆåŠŸç‡",        _fmt(m['succ'], pct=True) if m else "â€”"),
            kpi("é¢¨éšªæ•ˆç‡",      _fmt(m['eff'],  dec=3) if m else "â€”"),
        ], style={"display":"flex","gap":"10px","flexWrap":"wrap","marginBottom":"8px"})

    acc_metrics = dis_metrics = None
    if "éšæ®µ" in table.columns:
        mask_acc = table["éšæ®µ"].astype(str).str.contains("åŠ ç¢¼", na=False)
        mask_dis = table["éšæ®µ"].astype(str).str.contains("æ¸›ç¢¼", na=False)
        acc_metrics = _group_metrics(mask_acc)
        dis_metrics = _group_metrics(mask_dis)

    group_section = html.Div([
        html.H6("åˆ†çµ„ KPIï¼ˆåŠ ç¢¼ vs æ¸›ç¢¼ï¼‰", style={"margin":"8px 0 6px 0"}),
        group_row("åŠ ç¢¼æ®µ", acc_metrics),
        group_row("æ¸›ç¢¼æ®µ", dis_metrics),
    ], style={"marginTop":"4px"})

    # ====== Top/Worst ä¾†æºåˆ‡æ›ï¼ˆå…¨éƒ¨ / åªåŠ ç¢¼ / åªæ¸›ç¢¼ï¼‰ ======
    source_selector = html.Div([
        html.Div("Top/Worst ä¾†æº", style={"marginRight":"8px", "alignSelf":"center"}),
        dcc.RadioItems(
            id="phase-source",
            options=[
                {"label": "å…¨éƒ¨",   "value": "all"},
                {"label": "åŠ ç¢¼æ®µ", "value": "acc"},
                {"label": "æ¸›ç¢¼æ®µ", "value": "dis"},
            ],
            value="all",
            inline=True,
            inputStyle={"marginRight":"4px"},
            labelStyle={"marginRight":"12px"}
        )
    ], style={"display":"flex","gap":"6px","alignItems":"center","margin":"6px 0 8px 0"})

    # æ¬„ä½é †åºï¼ˆå®Œæ•´è¡¨ & Top/Worst å…±ç”¨ï¼‰
    ordered = [c for c in ["éšæ®µ","é–‹å§‹æ—¥æœŸ","çµæŸæ—¥æœŸ","äº¤æ˜“ç­†æ•¸",
                           "éšæ®µæ·¨è²¢ç»(%)","è³£å‡ºå ±é…¬ç¸½å’Œ(%)","éšæ®µå…§MDD(%)","æ˜¯å¦æˆåŠŸ"] if c in table.columns]
    basis_col = "éšæ®µæ·¨è²¢ç»(%)" if "éšæ®µæ·¨è²¢ç»(%)" in table.columns else "è³£å‡ºå ±é…¬ç¸½å’Œ(%)"

    # ====== å®Œæ•´è¡¨æ ¼ ======
    full_table = dash_table.DataTable(
        id="phase-datatable",
        columns=[{"name": c, "id": c, "type": ("numeric" if c in num_cols else "text")} for c in ordered],
        data=table[ordered].to_dict("records"),
        # åˆ†é 
        page_action="native",
        page_current=0,
        page_size=100,            # é è¨­æ¯é  100ï¼Œè‹¥è¦æ”¹å¯åœ¨é€™è£¡
        # äº’å‹•
        sort_action="native",
        filter_action="native",
        # ä¸‹è¼‰
        export_format="csv",
        export_headers="display",
        # è¤‡è£½
        cell_selectable=True,
        virtualization=False,     # é—œé–‰è™›æ“¬åŒ–ï¼Œé¿å…è¤‡è£½æ™‚åªè¤‡åˆ°å¯è¦–å€
        fixed_rows={"headers": True},
        style_table=style_table,
        style_cell=style_cell,
        style_header=style_header,
        css=[{
            "selector": ".dash-table-container .dash-spreadsheet-container .dash-spreadsheet-inner *",
            "rule": "user-select: text; -webkit-user-select: text; -moz-user-select: text; -ms-user-select: text;"
        }],
    )

    # ====== dcc.Storeï¼šæä¾› Top/Worst å‹•æ…‹ callback ä½¿ç”¨ ======
    store = dcc.Store(id="phase-table-store", data={
        "records": table[ordered].to_dict("records"),
        "ordered": ordered,
        "basis": basis_col,
        "has_stage": "éšæ®µ" in table.columns
    })

    # é è¨­ï¼ˆå…¨éƒ¨ä¾†æºï¼‰å…ˆç®—ä¸€æ¬¡ï¼Œé¿å…ç©ºç•«é¢
    def _subset(src):
        df = table
        if "éšæ®µ" not in df.columns:
            return df
        if src == "acc":
            return df[df["éšæ®µ"].astype(str).str.contains("åŠ ç¢¼", na=False)]
        if src == "dis":
            return df[df["éšæ®µ"].astype(str).str.contains("æ¸›ç¢¼", na=False)]
        return df
    base = _subset("all")
    top3   = base.nlargest(3, basis_col) if basis_col in base else base.head(3)
    worst3 = base.nsmallest(3, basis_col) if basis_col in base else base.tail(3)

    def simple_table(df, tbl_id):
        return dash_table.DataTable(
            id=tbl_id,
            columns=[{"name": c, "id": c} for c in ordered],
            data=df[ordered].to_dict("records"),
            page_action="none",
            style_table=style_table, style_cell=style_cell, style_header=style_header
        )

    top3_table = simple_table(top3, "phase-top-table")
    worst3_table = simple_table(worst3, "phase-worst-table")

    # ====== Copy / Download å·¥å…·åˆ— ======
    tools = html.Div([
        html.Button("è¤‡è£½å…¨éƒ¨ï¼ˆCSVï¼‰", id="phase-copy-btn",
                    style={"padding": "6px 10px", "borderRadius": "8px", "cursor": "pointer"}),
        dcc.Clipboard(target_id="phase-csv-text", title="Copy", style={"marginLeft": "6px"}),
        html.A("ä¸‹è¼‰ CSV", href=csv_data_url, download="trade_contribution.csv",
               style={"marginLeft": "12px", "textDecoration": "none"})
    ], style={"display": "flex", "alignItems": "center", "gap": "4px", "marginBottom": "8px"})

    # éš±è—çš„ CSV æ–‡å­—ä¾†æºï¼ˆçµ¦ Clipboard ç”¨ï¼‰
    csv_hidden = html.Pre(id="phase-csv-text", children=csv_text, style={"display": "none"})

    # ====== Tabsï¼šæ˜“è®€ç‰ˆ / å®Œæ•´è¡¨æ ¼ ======
    tabs = dcc.Tabs(id="phase-tabs", value="summary", children=[
        dcc.Tab(label="æ˜“è®€ç‰ˆ", value="summary", children=[
            kpi_bar,
            group_section,
            source_selector,
            html.H6("æœ€è³ºçš„ 3 æ®µï¼ˆä¾ä¾†æºèˆ‡æ’åºæ¬„ï¼‰", style={"marginTop":"8px"}),
            top3_table,
            html.H6("æœ€è™§çš„ 3 æ®µï¼ˆä¾ä¾†æºèˆ‡æ’åºæ¬„ï¼‰", style={"marginTop":"16px"}),
            worst3_table
        ]),
        dcc.Tab(label="å®Œæ•´è¡¨æ ¼", value="full", children=[full_table]),
    ])

    return html.Div([tools, csv_hidden, store, tabs], style={"marginTop": "8px"})

# --------- æ‰¹é‡æ¸¬è©¦åƒæ•¸ç¯„åœ Callback ---------
@app.callback(
    Output("batch-phase-results", "children"),
    Input("run-batch-phase", "n_clicks"),
    State("enhanced-trades-cache", "data"),
    prevent_initial_call=True
)
def _run_batch_phase_test(n_clicks, cache):
    """æ‰¹é‡æ¸¬è©¦1-24ç¯„åœçš„æœ€å°é–“è·å’Œå†·å»æœŸåƒæ•¸"""
    if not n_clicks:
        raise dash.exceptions.PreventUpdate
    if not cache:
        return html.Div("å°šæœªè¼‰å…¥å›æ¸¬çµæœ", style={"color": "#ffb703"})

    # å¾å¿«å–é‚„åŸè³‡æ–™
    trade_df = df_from_pack(cache.get("trade_data"))
    daily_state = df_from_pack(cache.get("daily_state"))
    
    if trade_df is None or trade_df.empty:
        return "æ‰¾ä¸åˆ°äº¤æ˜“è³‡æ–™"
    
    if daily_state is None or daily_state.empty:
        return "æ‰¾ä¸åˆ° daily_stateï¼ˆæ¯æ—¥è³‡ç”¢/æ¬Šé‡ï¼‰"
    
    if "equity" not in daily_state.columns:
        return "daily_state ç¼ºå°‘æ¬Šç›Šæ¬„ä½ 'equity'"

    equity = daily_state["equity"]
    
    # æª¢æŸ¥ä¸¦æº–å‚™äº¤æ˜“è³‡æ–™æ ¼å¼
    debug_info = []
    debug_info.append(f"åŸå§‹äº¤æ˜“è³‡æ–™æ¬„ä½: {list(trade_df.columns)}")
    debug_info.append(f"äº¤æ˜“è³‡æ–™è¡Œæ•¸: {len(trade_df)}")
    debug_info.append(f"æ¬Šç›Šè³‡æ–™è¡Œæ•¸: {len(equity)}")
    
    # æª¢æŸ¥å¿…è¦æ¬„ä½ä¸¦é€²è¡Œè½‰æ›
    required_mappings = {
        "date": ["date", "trade_date", "äº¤æ˜“æ—¥æœŸ", "Date"],
        "type": ["type", "äº¤æ˜“é¡å‹", "action", "side", "Type"],
        "w_before": ["w_before", "äº¤æ˜“å‰æ¬Šé‡", "weight_before", "weight_prev"],
        "w_after": ["w_after", "äº¤æ˜“å¾Œæ¬Šé‡", "weight_after", "weight_next"]
    }
    
    # å°‹æ‰¾å°æ‡‰çš„æ¬„ä½
    found_columns = {}
    for target, possible_names in required_mappings.items():
        for name in possible_names:
            if name in trade_df.columns:
                found_columns[target] = name
                break
    
    debug_info.append(f"æ‰¾åˆ°çš„æ¬„ä½å°æ‡‰: {found_columns}")
    
    # å¦‚æœç¼ºå°‘å¿…è¦æ¬„ä½ï¼Œå˜—è©¦å‰µå»º
    if len(found_columns) < 4:
        debug_info.append("ç¼ºå°‘å¿…è¦æ¬„ä½ï¼Œå˜—è©¦å‰µå»º...")
        
        # å˜—è©¦å¾ç¾æœ‰æ¬„ä½æ¨å°
        if "weight_change" in trade_df.columns and "w_before" not in found_columns:
            # å¦‚æœæœ‰æ¬Šé‡è®ŠåŒ–ï¼Œå˜—è©¦é‡å»ºå‰å¾Œæ¬Šé‡
            trade_df = trade_df.copy()
            trade_df["w_before"] = 0.0
            trade_df["w_after"] = trade_df["weight_change"]
            found_columns["w_before"] = "w_before"
            found_columns["w_after"] = "w_after"
            debug_info.append("å¾ weight_change å‰µå»º w_before å’Œ w_after")
        
        if "price" in trade_df.columns and "type" not in found_columns:
            # å¦‚æœæœ‰åƒ¹æ ¼ï¼Œå‡è¨­ç‚ºè²·å…¥
            trade_df["type"] = "buy"
            found_columns["type"] = "type"
            debug_info.append("å‰µå»º type æ¬„ä½ï¼Œé è¨­ç‚º buy")
    
    # æ‰¹é‡æ¸¬è©¦åƒæ•¸ç¯„åœ 1-24
    results = []
    total_combinations = 24 * 24  # 576ç¨®çµ„åˆ
    
    try:
        from SSS_EnsembleTab import trade_contribution_by_phase
        
        # é€²åº¦é¡¯ç¤º
        progress_div = html.Div([
            html.H6("æ­£åœ¨åŸ·è¡Œæ‰¹é‡æ¸¬è©¦...", style={"color": "#28a745"}),
            html.Div(f"æ¸¬è©¦ç¯„åœï¼šæœ€å°é–“è· 1-24 å¤©ï¼Œå†·å»æœŸ 1-24 å¤©", style={"fontSize": "12px", "color": "#666"}),
            html.Div(f"ç¸½çµ„åˆæ•¸ï¼š{total_combinations}", style={"fontSize": "12px", "color": "#666"}),
            html.Div(id="batch-progress", children="é–‹å§‹æ¸¬è©¦...")
        ])
        
        # åŸ·è¡Œæ‰¹é‡æ¸¬è©¦
        batch_results = []
        debug_info = []
        
        # å…ˆæ¸¬è©¦ä¸€å€‹ç°¡å–®çš„æ¡ˆä¾‹
        test_min_gap, test_cooldown = 1, 1
        try:
            debug_info.append(f"é–‹å§‹æ¸¬è©¦å–®ä¸€æ¡ˆä¾‹: min_gap={test_min_gap}, cooldown={test_cooldown}")
            
            # æª¢æŸ¥äº¤æ˜“è³‡æ–™çš„æ¬Šé‡æ¬„ä½
            if "weight_change" in trade_df.columns:
                debug_info.append(f"æ‰¾åˆ° weight_change æ¬„ä½ï¼Œç¯„åœ: {trade_df['weight_change'].min():.4f} ~ {trade_df['weight_change'].max():.4f}")
            
            # æª¢æŸ¥æ¬Šç›Šè³‡æ–™
            if len(equity) > 0:
                debug_info.append(f"æ¬Šç›Šè³‡æ–™ç¯„åœ: {equity.min():.2f} ~ {equity.max():.2f}")
            
            table = trade_contribution_by_phase(trade_df, equity, test_min_gap, test_cooldown)
            debug_info.append(f"å‡½æ•¸åŸ·è¡ŒæˆåŠŸï¼Œè¿”å›è¡¨æ ¼å¤§å°: {table.shape}")
            debug_info.append(f"è¡¨æ ¼æ¬„ä½: {list(table.columns)}")
            
            if not table.empty:
                debug_info.append(f"ç¬¬ä¸€è¡Œè³‡æ–™: {table.iloc[0].to_dict()}")
                
                # æª¢æŸ¥æ˜¯å¦æœ‰éšæ®µæ·¨è²¢ç»æ¬„ä½
                if "éšæ®µæ·¨è²¢ç»(%)" in table.columns:
                    debug_info.append(f"éšæ®µæ·¨è²¢ç»æ¬„ä½å­˜åœ¨ï¼Œéç©ºå€¼æ•¸é‡: {table['éšæ®µæ·¨è²¢ç»(%)'].notna().sum()}")
                    debug_info.append(f"éšæ®µæ·¨è²¢ç»ç¯„åœ: {table['éšæ®µæ·¨è²¢ç»(%)'].min():.2f} ~ {table['éšæ®µæ·¨è²¢ç»(%)'].max():.2f}")
                else:
                    debug_info.append("ç¼ºå°‘éšæ®µæ·¨è²¢ç»æ¬„ä½")
                
                if "éšæ®µå…§MDD(%)" in table.columns:
                    debug_info.append(f"éšæ®µå…§MDDæ¬„ä½å­˜åœ¨ï¼Œéç©ºå€¼æ•¸é‡: {table['éšæ®µå…§MDD(%)'].notna().sum()}")
                    debug_info.append(f"éšæ®µå…§MDDç¯„åœ: {table['éšæ®µå…§MDD(%)'].min():.2f} ~ {table['éšæ®µå…§MDD(%)'].max():.2f}")
                else:
                    debug_info.append("ç¼ºå°‘éšæ®µå…§MDDæ¬„ä½")
            else:
                debug_info.append("å‡½æ•¸è¿”å›ç©ºè¡¨æ ¼")
                
        except Exception as e:
            import traceback
            debug_info.append(f"å‡½æ•¸åŸ·è¡ŒéŒ¯èª¤: {str(e)}")
            debug_info.append(f"éŒ¯èª¤è©³æƒ…: {traceback.format_exc()}")
        
        # å¦‚æœå–®ä¸€æ¸¬è©¦æˆåŠŸï¼Œç¹¼çºŒæ‰¹é‡æ¸¬è©¦
        if not table.empty and "éšæ®µæ·¨è²¢ç»(%)" in table.columns and "éšæ®µå…§MDD(%)" in table.columns:
            debug_info.append("å–®ä¸€æ¸¬è©¦æˆåŠŸï¼Œé–‹å§‹æ‰¹é‡æ¸¬è©¦...")
            
            for min_gap in range(1, 25):
                for cooldown in range(1, 25):
                    try:
                        table = trade_contribution_by_phase(trade_df, equity, min_gap, cooldown)
                        
                        if not table.empty:
                            # éæ¿¾æ‰æ‘˜è¦è¡Œï¼ˆé€šå¸¸åŒ…å«"çµ±è¨ˆæ‘˜è¦"å­—æ¨£ï¼‰
                            data_rows = table[~table["éšæ®µ"].astype(str).str.contains("çµ±è¨ˆæ‘˜è¦", na=False)]
                            
                            if len(data_rows) == 0:
                                continue
                            
                            # è¨ˆç®—é—œéµæŒ‡æ¨™
                            avg_net = data_rows["éšæ®µæ·¨è²¢ç»(%)"].mean()
                            avg_mdd = data_rows["éšæ®µå…§MDD(%)"].mean()
                            succ_rate = (data_rows["éšæ®µæ·¨è²¢ç»(%)"] > 0).mean()
                            risk_eff = avg_net / abs(avg_mdd) if avg_mdd != 0 else 0
                            
                            batch_results.append({
                                "æœ€å°é–“è·": min_gap,
                                "å†·å»æœŸ": cooldown,
                                "å¹³å‡æ·¨è²¢ç»(%)": round(avg_net, 2),
                                "å¹³å‡MDD(%)": round(avg_mdd, 2),
                                "æˆåŠŸç‡(%)": round(succ_rate * 100, 1),
                                "é¢¨éšªæ•ˆç‡": round(risk_eff, 3),
                                "éšæ®µæ•¸": len(data_rows)
                            })
                    except Exception as e:
                        # è¨˜éŒ„éŒ¯èª¤ä½†ç¹¼çºŒåŸ·è¡Œ
                        continue
        else:
            debug_info.append("å–®ä¸€æ¸¬è©¦å¤±æ•—ï¼Œè·³éæ‰¹é‡æ¸¬è©¦")
        
        if not batch_results:
            # é¡¯ç¤ºé™¤éŒ¯è³‡è¨Š
            debug_html = html.Div([
                html.H6("é™¤éŒ¯è³‡è¨Š", style={"color": "#dc3545", "marginTop": "16px"}),
                html.Div([html.Pre(info) for info in debug_info], style={"backgroundColor": "#f8f9fa", "padding": "10px", "borderRadius": "4px", "fontSize": "11px"})
            ])
            
            return html.Div([
                html.Div("æ‰¹é‡æ¸¬è©¦å®Œæˆï¼Œä½†ç„¡æœ‰æ•ˆçµæœ", style={"color": "#ffb703"}),
                html.Div("å¯èƒ½åŸå› ï¼š", style={"marginTop": "8px", "color": "#666"}),
                html.Ul([
                    html.Li("äº¤æ˜“è³‡æ–™æ ¼å¼ä¸æ­£ç¢º"),
                    html.Li("ç¼ºå°‘å¿…è¦çš„æ¬„ä½ï¼ˆéšæ®µæ·¨è²¢ç»(%)ã€éšæ®µå…§MDD(%)ï¼‰"),
                    html.Li("æ‰€æœ‰åƒæ•¸çµ„åˆéƒ½ç„¡æ³•ç”¢ç”Ÿæœ‰æ•ˆéšæ®µ"),
                    html.Li("å‡½æ•¸åŸ·è¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤")
                ], style={"fontSize": "12px", "color": "#666"}),
                debug_html
            ])
        
        # è½‰æ›ç‚ºDataFrameä¸¦æ’åº
        results_df = pd.DataFrame(batch_results)
        
        # æŒ‰é¢¨éšªæ•ˆç‡æ’åºï¼ˆé™åºï¼‰
        results_df = results_df.sort_values("é¢¨éšªæ•ˆç‡", ascending=False)
        
        # ç”ŸæˆCSVä¸‹è¼‰é€£çµ
        csv_text = results_df.to_csv(index=False)
        csv_data_url = "data:text/csv;charset=utf-8," + urlparse(csv_text)
        
        # é¡¯ç¤ºå‰10åçµæœ
        top10 = results_df.head(10)
        
        # ç”Ÿæˆçµæœè¡¨æ ¼
        results_table = dash_table.DataTable(
            id="batch-results-table",
            columns=[{"name": c, "id": c} for c in results_df.columns],
            data=top10.to_dict("records"),
            page_action="none",
            style_table={"overflowX": "auto", "fontSize": "11px"},
            style_cell={"textAlign": "center", "padding": "4px", "minWidth": "60px"},
            style_header={"backgroundColor": "#28a745", "color": "white", "fontWeight": "bold"}
        )
        
        # çµ±è¨ˆæ‘˜è¦
        summary_stats = html.Div([
            html.H6("æ‰¹é‡æ¸¬è©¦æ‘˜è¦", style={"marginTop": "16px", "marginBottom": "8px", "color": "#28a745"}),
            html.Div(f"æœ‰æ•ˆçµ„åˆæ•¸ï¼š{len(results_df)} / {total_combinations}", style={"fontSize": "12px"}),
            html.Div(f"æœ€ä½³é¢¨éšªæ•ˆç‡ï¼š{results_df['é¢¨éšªæ•ˆç‡'].max():.3f}", style={"fontSize": "12px"}),
            html.Div(f"æœ€ä½³å¹³å‡æ·¨è²¢ç»ï¼š{results_df['å¹³å‡æ·¨è²¢ç»(%)'].max():.2f}%", style={"fontSize": "12px"}),
            html.Div(f"æœ€ä½³æˆåŠŸç‡ï¼š{results_df['æˆåŠŸç‡(%)'].max():.1f}%", style={"fontSize": "12px"}),
            html.Div([
                html.Button("ä¸‹è¼‰å®Œæ•´çµæœCSV", id="download-batch-csv", 
                           style={"backgroundColor": "#28a745", "color": "white", "border": "none", "padding": "8px 16px", "borderRadius": "4px", "cursor": "pointer"}),
                html.A("ç›´æ¥ä¸‹è¼‰", href=csv_data_url, download="batch_phase_test_results.csv",
                       style={"marginLeft": "12px", "textDecoration": "none", "color": "#28a745"})
            ], style={"marginTop": "8px"})
        ])
        
        return html.Div([
            summary_stats,
            html.H6("å‰10åæœ€ä½³åƒæ•¸çµ„åˆï¼ˆæŒ‰é¢¨éšªæ•ˆç‡æ’åºï¼‰", style={"marginTop": "16px", "marginBottom": "8px"}),
            results_table
        ])
        
    except Exception as e:
        return html.Div(f"æ‰¹é‡æ¸¬è©¦åŸ·è¡Œå¤±æ•—: {str(e)}", style={"color": "#dc3545"})

# --- Gate analysis buttons until cache is ready ---
@app.callback(
    Output("run-rv", "disabled"),
    Output("run-phase", "disabled"),
    Output("run-batch-phase", "disabled"),
    Input("enhanced-trades-cache", "data"),
    prevent_initial_call=False
)
def _gate_analyze_buttons(cache):
    ready = bool(cache) and (
        (cache.get("trade_data") or cache.get("trade_df") or cache.get("trade_ledger") or cache.get("trade_ledger_std"))
        and (cache.get("daily_state") or cache.get("daily_state_std"))
    )
    disabled = not ready
    return disabled, disabled, disabled

# --------- å¢å¼·åˆ†æ Callback Aï¼šä¾ backtest-store å¡«æ»¿ç­–ç•¥é¸å–® ---------
@app.callback(
    Output("enhanced-strategy-selector", "options"),
    Output("enhanced-strategy-selector", "value"),
    Input("backtest-store", "data"),
    prevent_initial_call=False
)
def _populate_enhanced_strategy_selector(bstore):
    """ä¾ backtest-store å¡«æ»¿ç­–ç•¥é¸å–®ï¼Œä¸¦è‡ªå‹•é¸æ“‡æœ€ä½³ç­–ç•¥"""
    if not bstore:
        return [], None
    
    results = bstore.get("results", {})
    if not results:
        return [], None
    
    # ç­–ç•¥è©•åˆ†ï¼šledger_std > ledger > trade_df
    strategy_scores = []
    for strategy_name, result in results.items():
        score = 0
        if result.get("trade_ledger_std"):
            score += 100  # æœ€é«˜åˆ†ï¼šæ¨™æº–åŒ–äº¤æ˜“æµæ°´å¸³
        elif result.get("trade_ledger"):
            score += 50   # ä¸­åˆ†ï¼šåŸå§‹äº¤æ˜“æµæ°´å¸³
        elif result.get("trade_df"):
            score += 10   # ä½åˆ†ï¼šäº¤æ˜“æ˜ç´°
        
        # é¡å¤–åŠ åˆ†ï¼šæœ‰ daily_state
        if result.get("daily_state") or result.get("daily_state_std"):
            score += 20
        
        strategy_scores.append((strategy_name, score))
    
    # æŒ‰åˆ†æ•¸æ’åº
    strategy_scores.sort(key=lambda x: x[1], reverse=True)
    
    # ç”Ÿæˆé¸å–®é¸é …
    options = [{"label": f"{name} (åˆ†æ•¸: {score})", "value": name} 
               for name, score in strategy_scores]
    
    # è‡ªå‹•é¸æ“‡æœ€é«˜åˆ†ç­–ç•¥
    auto_select = strategy_scores[0][0] if strategy_scores else None
    
    return options, auto_select

# --------- å¢å¼·åˆ†æ Callback Bï¼šè¼‰å…¥é¸å®šç­–ç•¥åˆ° enhanced-trades-cache ---------
@app.callback(
    Output("enhanced-trades-cache", "data"),
    Output("enhanced-load-status", "children"),
    Input("load-enhanced-strategy", "n_clicks"),
    State("enhanced-strategy-selector", "value"),
    State("backtest-store", "data"),
    prevent_initial_call=True
)
def _load_enhanced_strategy_to_cache(n_clicks, selected_strategy, bstore):
    """è¼‰å…¥é¸å®šç­–ç•¥çš„å›æ¸¬çµæœåˆ° enhanced-trades-cache"""
    if not n_clicks or not selected_strategy or not bstore:
        return no_update, "è«‹é¸æ“‡ç­–ç•¥ä¸¦é»æ“Šè¼‰å…¥"
    
    results = bstore.get("results", {})
    if selected_strategy not in results:
        return no_update, f"æ‰¾ä¸åˆ°ç­–ç•¥ï¼š{selected_strategy}"
    
    result = results[selected_strategy]
    
    # å„ªå…ˆé †åºï¼šledger_std > ledger > trade_df
    trade_data = None
    data_source = ""
    
    if result.get("trade_ledger_std"):
        trade_data = df_from_pack(result["trade_ledger_std"])
        data_source = "trade_ledger_std (æ¨™æº–åŒ–)"
    elif result.get("trade_ledger"):
        trade_data = df_from_pack(result["trade_ledger"])
        data_source = "trade_ledger (åŸå§‹)"
    elif result.get("trade_df"):
        trade_data = df_from_pack(result["trade_df"])
        data_source = "trade_df (äº¤æ˜“æ˜ç´°)"
    else:
        return no_update, "è©²ç­–ç•¥ç„¡äº¤æ˜“è³‡æ–™"
    
    # æ¨™æº–åŒ–äº¤æ˜“è³‡æ–™
    try:
        from sss_core.normalize import normalize_trades_for_ui as norm
        trade_data = norm(trade_data)
    except Exception:
        # å¾Œå‚™æ¨™æº–åŒ–æ–¹æ¡ˆ
        if trade_data is not None and len(trade_data) > 0:
            trade_data = trade_data.copy()
            trade_data.columns = [str(c).lower() for c in trade_data.columns]
            
            # ç¢ºä¿æœ‰ trade_date æ¬„
            if "trade_date" not in trade_data.columns:
                if "date" in trade_data.columns:
                    trade_data["trade_date"] = pd.to_datetime(trade_data["date"], errors="coerce")
                elif isinstance(trade_data.index, pd.DatetimeIndex):
                    trade_data = trade_data.reset_index().rename(columns={"index": "trade_date"})
                else:
                    trade_data["trade_date"] = pd.to_datetime(trade_data["date"], errors="coerce")
            
            # ç¢ºä¿æœ‰ type æ¬„
            if "type" not in trade_data.columns:
                if "action" in trade_data.columns:
                    trade_data["type"] = trade_data["action"].astype(str).str.lower()
                elif "side" in trade_data.columns:
                    trade_data["type"] = trade_data["side"].astype(str).str.lower()
                else:
                    trade_data["type"] = "hold"
            
            # ç¢ºä¿æœ‰ price æ¬„
            if "price" not in trade_data.columns:
                for c in ["open", "price_open", "exec_price", "px", "close"]:
                    if c in trade_data.columns:
                        trade_data["price"] = trade_data[c]
                        break
                if "price" not in trade_data.columns:
                    trade_data["price"] = 0.0
    
    # æº–å‚™ daily_state - è‹¥å·²å¥—ç”¨é–¥é–€å‰‡å„ªå…ˆä½¿ç”¨èª¿æ•´å¾Œè³‡æ–™
    daily_state = None
    valve_info = result.get("valve", {})
    valve_on = bool(valve_info.get("applied", False))
    
    # å…ˆç”¨é–¥é–€å¾Œçš„æ—¥ç·šï¼ˆè‹¥æœ‰ï¼‰
    if valve_on and result.get("daily_state"):
        daily_state = df_from_pack(result["daily_state"])
    elif result.get("daily_state_std"):
        daily_state = df_from_pack(result["daily_state_std"])
    elif result.get("daily_state"):
        daily_state = df_from_pack(result["daily_state"])
    elif result.get("daily_state_base"):
        daily_state = df_from_pack(result["daily_state_base"])
    else:
        daily_state = None
    
    # æº–å‚™ weight_curve å’Œé–¥é–€è³‡è¨Š
    weight_curve = None
    if result.get("weight_curve"):
        weight_curve = df_from_pack(result["weight_curve"])
    
    # ç²å–é–¥é–€ç‹€æ…‹è³‡è¨Š
    valve_info = result.get("valve", {})  # {"applied": bool, "cap": float, "atr_ratio": float or "N/A"}
    valve_on = bool(valve_info.get("applied", False))
    
    # è‹¥é–¥é–€ç”Ÿæ•ˆï¼Œä¿è­‰åˆ†æç«¯è¦†å¯« w_series
    if valve_on and weight_curve is not None and daily_state is not None:
        ds = daily_state.copy()
        wc = weight_curve.copy()
        # å°é½Šæ™‚é–“ç´¢å¼•ï¼›è‹¥ ds æœ‰ 'trade_date' æ¬„å°± mergeï¼Œå¦å‰‡ä»¥ç´¢å¼•å°é½Š
        if "trade_date" in ds.columns:
            ds["trade_date"] = pd.to_datetime(ds["trade_date"])
            wc = wc.rename("w").to_frame().reset_index().rename(columns={"index": "trade_date"})
            ds = ds.merge(wc, on="trade_date", how="left")
        else:
            # ä»¥ç´¢å¼•å°é½Š
            ds.index = pd.to_datetime(ds.index)
            wc.index = pd.to_datetime(wc.index)
            # ä¿®æ­£ï¼šç¢ºä¿ wc æ˜¯ Series ä¸¦ä¸”æ­£ç¢ºå°é½Š
            if isinstance(wc, pd.DataFrame):
                if "w" in wc.columns:
                    wc_series = wc["w"]
                else:
                    wc_series = wc.iloc[:, 0]  # å–ç¬¬ä¸€åˆ—
            else:
                wc_series = wc
            ds["w"] = wc_series.reindex(ds.index).ffill().bfill()
        daily_state = ds
    
    # æº–å‚™ df_raw
    df_raw = None
    if bstore.get("df_raw"):
        try:
            df_raw = pd.read_json(bstore["df_raw"], orient="split")
        except Exception:
            df_raw = pd.DataFrame()
    
    # ---- pack valve flags into cache ----
    cache_data = {
        "strategy": selected_strategy,
        "trade_data": pack_df(trade_data) if trade_data is not None else None,
        "daily_state": pack_df(daily_state) if daily_state is not None else None,
        "weight_curve": pack_df(weight_curve) if weight_curve is not None else None,
        "df_raw": pack_df(df_raw) if df_raw is not None else None,
        "valve": valve_info,
        "valve_applied": valve_on,
        "ensemble_params": result.get("ensemble_params", {}),
        "data_source": data_source,
        "timestamp": datetime.now().isoformat(),
        # âŒ æ–°å¢ï¼šbaseline ç‰ˆæœ¬ä¸€ä½µæ”¾é€²å¿«å–
        "daily_state_base": result.get("daily_state_base"),
        "weight_curve_base": result.get("weight_curve_base"),
        "trade_ledger_base": result.get("trade_ledger_base"),
    }
    
    status_msg = f"âœ… å·²è¼‰å…¥ {selected_strategy} ({data_source})"
    if daily_state is not None:
        status_msg += f"ï¼ŒåŒ…å« {len(daily_state)} ç­†æ—¥ç·šè³‡æ–™"
    if trade_data is not None:
        status_msg += f"ï¼ŒåŒ…å« {len(trade_data)} ç­†äº¤æ˜“"
    
    return cache_data, status_msg

# --------- å¢å¼·åˆ†æ Callback Cï¼šè‡ªå‹•å¿«å–æœ€ä½³ç­–ç•¥ ---------
@app.callback(
    Output("enhanced-trades-cache", "data", allow_duplicate=True),
    Output("enhanced-load-status", "children", allow_duplicate=True),
    Input("backtest-store", "data"),
    State("enhanced-strategy-selector", "value"),
    prevent_initial_call='initial_duplicate'
)
def _auto_cache_best_strategy(bstore, current_selection):
    """å›æ¸¬å®Œæˆå¾Œè‡ªå‹•å¿«å–æœ€ä½³ç­–ç•¥"""
    if not bstore:
        return no_update, no_update
    
    results = bstore.get("results", {})
    if not results:
        return no_update, no_update
    
    # å¦‚æœå·²ç¶“æœ‰æ‰‹å‹•é¸æ“‡ï¼Œä¸è¦†è“‹
    if current_selection:
        return no_update, no_update
    
    # ç­–ç•¥è©•åˆ†ï¼šledger_std > ledger > trade_df
    strategy_scores = []
    for strategy_name, result in results.items():
        score = 0
        if result.get("trade_ledger_std"):
            score += 100  # æœ€é«˜åˆ†ï¼šæ¨™æº–åŒ–äº¤æ˜“æµæ°´å¸³
        elif result.get("trade_ledger"):
            score += 50   # ä¸­åˆ†ï¼šåŸå§‹äº¤æ˜“æµæ°´å¸³
        elif result.get("trade_df"):
            score += 10   # ä½åˆ†ï¼šäº¤æ˜“æ˜ç´°
        
        # é¡å¤–åŠ åˆ†ï¼šæœ‰ daily_state
        if result.get("daily_state") or result.get("daily_state_std"):
            score += 20
        
        strategy_scores.append((strategy_name, score))
    
    # æŒ‰åˆ†æ•¸æ’åºï¼Œé¸æ“‡æœ€ä½³ç­–ç•¥
    if not strategy_scores:
        return no_update, no_update
    
    strategy_scores.sort(key=lambda x: x[1], reverse=True)
    best_strategy = strategy_scores[0][0]
    best_result = results[best_strategy]
    
    # æº–å‚™äº¤æ˜“è³‡æ–™ï¼ˆå„ªå…ˆé †åºï¼šledger_std > ledger > trade_dfï¼‰
    trade_data = None
    data_source = ""
    
    if best_result.get("trade_ledger_std"):
        trade_data = df_from_pack(best_result["trade_ledger_std"])
        data_source = "trade_ledger_std (æ¨™æº–åŒ–)"
    elif best_result.get("trade_ledger"):
        trade_data = df_from_pack(best_result["trade_ledger"])
        data_source = "trade_ledger (åŸå§‹)"
    elif best_result.get("trade_df"):
        trade_data = df_from_pack(best_result["trade_df"])
        data_source = "trade_df (äº¤æ˜“æ˜ç´°)"
    else:
        return no_update, no_update
    
    # æ¨™æº–åŒ–äº¤æ˜“è³‡æ–™
    try:
        from sss_core.normalize import normalize_trades_for_ui as norm
        trade_data = norm(trade_data)
    except Exception:
        # å¾Œå‚™æ¨™æº–åŒ–æ–¹æ¡ˆ
        if trade_data is not None and len(trade_data) > 0:
            trade_data = trade_data.copy()
            trade_data.columns = [str(c).lower() for c in trade_data.columns]
            
            # ç¢ºä¿æœ‰ trade_date æ¬„
            if "trade_date" not in trade_data.columns:
                if "date" in trade_data.columns:
                    trade_data["trade_date"] = pd.to_datetime(trade_data["date"], errors="coerce")
                elif isinstance(trade_data.index, pd.DatetimeIndex):
                    trade_data = trade_data.reset_index().rename(columns={"index": "trade_date"})
                else:
                    trade_data["trade_date"] = pd.to_datetime(trade_data["date"], errors="coerce")
            
            # ç¢ºä¿æœ‰ type æ¬„
            if "type" not in trade_data.columns:
                if "action" in trade_data.columns:
                    trade_data["type"] = trade_data["action"].astype(str).str.lower()
                elif "side" in trade_data.columns:
                    trade_data["type"] = trade_data["side"].astype(str).str.lower()
                else:
                    trade_data["type"] = "hold"
            
            # ç¢ºä¿æœ‰ price æ¬„
            if "price" not in trade_data.columns:
                for c in ["open", "price_open", "exec_price", "px", "close"]:
                    if c in trade_data.columns:
                        trade_data["price"] = trade_data[c]
                        break
                if "price" not in trade_data.columns:
                    trade_data["price"] = 0.0
    
    # ---- choose daily_state consistently ----
    valve_info = best_result.get("valve", {}) or {}
    valve_on = bool(valve_info.get("applied", False))
    
    daily_state = None
    if valve_on and best_result.get("daily_state"):                 # adjusted first if valve is on
        daily_state = df_from_pack(best_result["daily_state"])
    elif best_result.get("daily_state_std"):
        daily_state = df_from_pack(best_result["daily_state_std"])
    elif best_result.get("daily_state"):
        daily_state = df_from_pack(best_result["daily_state"])
    elif best_result.get("daily_state_base"):
        daily_state = df_from_pack(best_result["daily_state_base"])
    
    # æº–å‚™ weight_curve å’Œé–¥é–€è³‡è¨Š
    weight_curve = None
    if best_result.get("weight_curve"):
        weight_curve = df_from_pack(best_result["weight_curve"])
    
    # è‹¥é–¥é–€ç”Ÿæ•ˆï¼Œä¿è­‰åˆ†æç«¯è¦†å¯« w_series
    if valve_on and weight_curve is not None and daily_state is not None:
        ds = daily_state.copy()
        wc = weight_curve.copy()
        # å°é½Šæ™‚é–“ç´¢å¼•ï¼›è‹¥ ds æœ‰ 'trade_date' æ¬„å°± mergeï¼Œå¦å‰‡ä»¥ç´¢å¼•å°é½Š
        if "trade_date" in ds.columns:
            ds["trade_date"] = pd.to_datetime(ds["trade_date"])
            wc = wc.rename("w").to_frame().reset_index().rename(columns={"index": "trade_date"})
            ds = ds.merge(wc, on="trade_date", how="left")
        else:
            # ä»¥ç´¢å¼•å°é½Š
            ds.index = pd.to_datetime(ds.index)
            wc.index = pd.to_datetime(wc.index)
            # ä¿®æ­£ï¼šç¢ºä¿ wc æ˜¯ Series ä¸¦ä¸”æ­£ç¢ºå°é½Š
            if isinstance(wc, pd.DataFrame):
                if "w" in wc.columns:
                    wc_series = wc["w"]
                else:
                    wc_series = wc.iloc[:, 0]  # å–ç¬¬ä¸€åˆ—
            else:
                wc_series = wc
            ds["w"] = wc_series.reindex(ds.index).ffill().bfill()
        daily_state = ds
    
    # æº–å‚™ df_raw
    df_raw = None
    if bstore.get("df_raw"):
        try:
            df_raw = pd.read_json(bstore["df_raw"], orient="split")
        except Exception:
            df_raw = pd.DataFrame()
    
    # ---- pack valve flags into cache ----
    cache_data = {
        "strategy": best_strategy,
        "trade_data": pack_df(trade_data) if trade_data is not None else None,
        "daily_state": pack_df(daily_state) if daily_state is not None else None,
        "weight_curve": pack_df(weight_curve) if weight_curve is not None else None,
        "df_raw": pack_df(df_raw) if df_raw is not None else None,
        "valve": valve_info,
        "valve_applied": valve_on,
        "ensemble_params": best_result.get("ensemble_params", {}),
        "data_source": data_source,
        "timestamp": datetime.now().isoformat(),
        "auto_cached": True,
        # âŒ æ–°å¢ï¼šbaseline ç‰ˆæœ¬ä¸€ä½µæ”¾é€²å¿«å–
        "daily_state_base": best_result.get("daily_state_base"),
        "weight_curve_base": best_result.get("weight_curve_base"),
        "trade_ledger_base": best_result.get("trade_ledger_base"),
    }
    
    status_msg = f"ğŸ”„ è‡ªå‹•å¿«å–æœ€ä½³ç­–ç•¥ï¼š{best_strategy} ({data_source})"
    if daily_state is not None:
        status_msg += f"ï¼ŒåŒ…å« {len(daily_state)} ç­†æ—¥ç·šè³‡æ–™"
    if trade_data is not None:
        status_msg += f"ï¼ŒåŒ…å« {len(trade_data)} ç­†äº¤æ˜“"
    
    return cache_data, status_msg

# --------- æ–°å¢ï¼šé¢¨éšª-å ±é…¬åœ°åœ–ï¼ˆPareto Mapï¼‰Callback ---------
@app.callback(
    Output("pareto-map-graph", "figure"),
    Output("pareto-map-status", "children"),
    Input("generate-pareto-map", "n_clicks"),
    State("enhanced-trades-cache", "data"),
    State("backtest-store", "data"),
    State("rv-mode", "value"),
    State("risk-cap-input", "value"),
    State("atr-ratio-threshold", "value"),
    prevent_initial_call=True
)
def generate_pareto_map(n_clicks, cache, backtest_data, rv_mode, risk_cap_value, atr_ratio_value):
    """ç”Ÿæˆé¢¨éšª-å ±é…¬åœ°åœ–ï¼ˆPareto Mapï¼‰ï¼šæƒæ cap èˆ‡ ATR(20)/ATR(60) æ¯”å€¼å…¨çµ„åˆ"""
    logger.info(f"=== Pareto Map ç”Ÿæˆé–‹å§‹ ===")
    logger.info(f"n_clicks: {n_clicks}")
    logger.info(f"cache å­˜åœ¨: {cache is not None}")
    logger.info(f"backtest_data å­˜åœ¨: {backtest_data is not None}")
    
    if not n_clicks:
        logger.warning("æ²’æœ‰é»æ“Šäº‹ä»¶")
        return go.Figure(), "âŒ è«‹é»æ“Šç”ŸæˆæŒ‰éˆ•"
    
    # å„ªå…ˆä½¿ç”¨ enhanced-trades-cacheï¼Œå¦‚æœæ²’æœ‰å‰‡å˜—è©¦å¾ backtest-store ç”Ÿæˆ
    if cache:
        logger.info("ä½¿ç”¨ enhanced-trades-cache è³‡æ–™")
        df_raw = df_from_pack(cache.get("df_raw"))
        daily_state = df_from_pack(cache.get("daily_state"))
        data_source = "enhanced-trades-cache"
        logger.info(f"df_raw å½¢ç‹€: {df_raw.shape if df_raw is not None else 'None'}")
        logger.info(f"daily_state å½¢ç‹€: {daily_state.shape if daily_state is not None else 'None'}")
    elif backtest_data and backtest_data.get("results"):
        logger.info("ä½¿ç”¨ backtest-store è³‡æ–™")
        results = backtest_data["results"]
        logger.info(f"å¯ç”¨ç­–ç•¥: {list(results.keys())}")
        
        # å¾ backtest-store é¸æ“‡ç¬¬ä¸€å€‹æœ‰ daily_state çš„ç­–ç•¥
        selected_strategy = None
        for strategy_name, result in results.items():
            logger.info(f"æª¢æŸ¥ç­–ç•¥ {strategy_name}: daily_state={result.get('daily_state') is not None}, daily_state_std={result.get('daily_state_std') is not None}")
            if result.get("daily_state") or result.get("daily_state_std"):
                selected_strategy = strategy_name
                logger.info(f"é¸æ“‡ç­–ç•¥: {selected_strategy}")
                break
        
        if not selected_strategy:
            logger.error("æ²’æœ‰æ‰¾åˆ°åŒ…å« daily_state çš„ç­–ç•¥")
            return go.Figure(), "âŒ å›æ¸¬çµæœä¸­æ²’æœ‰æ‰¾åˆ°åŒ…å« daily_state çš„ç­–ç•¥"
        
        result = results[selected_strategy]
        daily_state = df_from_pack(result.get("daily_state") or result.get("daily_state_std"))
        df_raw = df_from_pack(backtest_data.get("df_raw"))
        data_source = f"backtest-store ({selected_strategy})"
        logger.info(f"df_raw å½¢ç‹€: {df_raw.shape if df_raw is not None else 'None'}")
        logger.info(f"daily_state å½¢ç‹€: {daily_state.shape if daily_state is not None else 'None'}")
    else:
        logger.error("æ²’æœ‰å¯ç”¨çš„è³‡æ–™ä¾†æº")
        return go.Figure(), "âŒ è«‹å…ˆåŸ·è¡Œå›æ¸¬ï¼Œæˆ–æ–¼ã€ğŸ§  å¾å›æ¸¬çµæœè¼‰å…¥ã€è¼‰å…¥ç­–ç•¥"

    # è³‡æ–™é©—è­‰
    logger.info("=== è³‡æ–™é©—è­‰ ===")
    if df_raw is None or df_raw.empty:
        logger.error("df_raw ç‚ºç©º")
        return go.Figure(), "âŒ æ‰¾ä¸åˆ°è‚¡åƒ¹è³‡æ–™ (df_raw)"
    if daily_state is None or daily_state.empty:
        logger.error("daily_state ç‚ºç©º")
        return go.Figure(), "âŒ æ‰¾ä¸åˆ° daily_stateï¼ˆæ¯æ—¥è³‡ç”¢/æ¬Šé‡ï¼‰"
    
    # è³‡æ–™ä¸è¶³æ™‚çš„è¡Œç‚ºå°é½Š
    if len(daily_state) < 60:
        logger.warning("è³‡æ–™ä¸è¶³ï¼ˆ<60å¤©ï¼‰ï¼Œå·²ç•¥éæƒæ")
        return go.Figure(), "âš ï¸ è³‡æ–™ä¸è¶³ï¼ˆ<60å¤©ï¼‰ï¼Œå·²ç•¥éæƒæ"
    
    logger.info(f"df_raw æ¬„ä½: {list(df_raw.columns)}")
    logger.info(f"daily_state æ¬„ä½: {list(daily_state.columns)}")

    # æ¬„åå°é½Š
    c_open = "open" if "open" in df_raw.columns else _first_col(df_raw, ["Open","é–‹ç›¤åƒ¹"])
    c_close = "close" if "close" in df_raw.columns else _first_col(df_raw, ["Close","æ”¶ç›¤åƒ¹"])
    c_high  = "high" if "high" in df_raw.columns else _first_col(df_raw, ["High","æœ€é«˜åƒ¹"])
    c_low   = "low"  if "low"  in df_raw.columns else _first_col(df_raw, ["Low","æœ€ä½åƒ¹"])
    
    logger.info(f"æ¬„åå°é½Šçµæœ: open={c_open}, close={c_close}, high={c_high}, low={c_low}")
    
    if c_open is None or c_close is None:
        logger.error("ç¼ºå°‘å¿…è¦çš„åƒ¹æ ¼æ¬„ä½")
        return go.Figure(), "âŒ è‚¡åƒ¹è³‡æ–™ç¼ºå°‘ open/close æ¬„ä½"

    # æº–å‚™è¼¸å…¥åºåˆ—
    open_px = pd.to_numeric(df_raw[c_open], errors="coerce").dropna()
    open_px.index = pd.to_datetime(df_raw.index)
    
    # å– open_px å¾Œï¼Œæº–å‚™ wï¼ˆbaseline å„ªå…ˆï¼‰
    ds_base = df_from_pack(cache.get("daily_state_base")) if cache else None
    wc_base = series_from_pack(cache.get("weight_curve_base")) if cache else None
    
    # å¾ backtest-store ä¾†çš„æƒ…æ³
    if ds_base is None and (not cache) and backtest_data and "results" in backtest_data:
        ds_base = df_from_pack(result.get("daily_state_base"))
        # æ³¨æ„ï¼šweight_curve_base ä¹Ÿå¯èƒ½å­˜åœ¨æ–¼ result
        try:
            wc_base = series_from_pack(result.get("weight_curve_base"))
        except Exception:
            wc_base = None
    
    # ä»¥ baseline w ç‚ºå„ªå…ˆï¼›æ²’æœ‰å†é€€å›ç¾è¡Œ daily_state['w']
    if ds_base is not None and (not ds_base.empty) and ("w" in ds_base.columns):
        w = pd.to_numeric(ds_base["w"], errors="coerce").reindex(open_px.index).ffill().fillna(0.0)
    elif wc_base is not None and (not wc_base.empty):
        w = pd.to_numeric(wc_base, errors="coerce").reindex(open_px.index).ffill().fillna(0.0)
    else:
        # å¾Œå‚™ï¼šæ²¿ç”¨ç¾è¡Œ daily_stateï¼ˆå¯èƒ½å·²è¢«é–¥é–€å£“éï¼‰
        if "w" not in daily_state.columns:
            return go.Figure(), "âŒ daily_state ç¼ºå°‘æ¬Šé‡æ¬„ä½ 'w'"
        w = pd.to_numeric(daily_state["w"], errors="coerce").reindex(open_px.index).ffill().fillna(0.0)

    bench = pd.DataFrame({
        "æ”¶ç›¤åƒ¹": pd.to_numeric(df_raw[c_close], errors="coerce"),
    }, index=pd.to_datetime(df_raw.index))
    if c_high and c_low:
        bench["æœ€é«˜åƒ¹"] = pd.to_numeric(df_raw[c_high], errors="coerce")
        bench["æœ€ä½åƒ¹"] = pd.to_numeric(df_raw[c_low], errors="coerce")

    # ATR æ¨£æœ¬æª¢æŸ¥ï¼ˆèˆ‡ç‹€æ…‹é¢æ¿ä¸€è‡´ï¼‰
    logger.info("=== ATR æ¨£æœ¬æª¢æŸ¥ ===")
    a20, a60 = calculate_atr(df_raw, 20), calculate_atr(df_raw, 60)
    if a20 is None or a60 is None or a20.dropna().size < 60 or a60.dropna().size < 60:
        logger.warning("ATR æ¨£æœ¬ä¸è¶³ï¼Œå›å‚³è­¦ç¤º")
        return go.Figure(), "ğŸŸ¡ ATR æ¨£æœ¬ä¸è¶³ï¼ˆè«‹æ‹‰é•·æœŸé–“æˆ–æ”¹ç”¨æ›´é•·è³‡æ–™ï¼‰"
    
    # æƒæåƒæ•¸æ ¼é» - æŠŠå…¨å±€é–€æª»ç½®å…¥æ ¼é»
    logger.info("=== é–‹å§‹æƒæåƒæ•¸æ ¼é» ===")
    import numpy as np
    
    # è®€å–ç•¶å‰è¨­å®š
    cap_now = float(risk_cap_value) if risk_cap_value else 0.8
    atr_now = float(atr_ratio_value) if atr_ratio_value else 1.2
    
    # åŸºæœ¬æ ¼é»
    caps = np.round(np.linspace(0.10, 1.00, 19), 2)
    atr_mults = np.round(np.linspace(1.00, 2.00, 21), 2)
    
    # å°‡å…¨å±€è¨­å®šæ¤å…¥æ ¼é»ï¼ˆé¿å…è¢«å…§æ’å¿½ç•¥ï¼‰
    if risk_cap_value is not None:
        caps = np.unique(np.r_[caps, float(risk_cap_value)])
    if atr_ratio_value is not None:
        atr_mults = np.unique(np.r_[atr_mults, float(atr_ratio_value)])
    
    logger.info(f"ç•¶å‰è¨­å®š: cap={cap_now:.2f}, atr={atr_now:.2f}")
    logger.info(f"cap ç¯„åœ: {len(caps)} å€‹å€¼ï¼Œå¾ {caps[0]} åˆ° {caps[-1]}")
    logger.info(f"ATR æ¯”å€¼ç¯„åœ: {len(atr_mults)} å€‹å€¼ï¼Œå¾ {atr_mults[0]} åˆ° {atr_mults[-1]}")
    logger.info(f"ç¸½çµ„åˆæ•¸: {len(caps) * len(atr_mults)}")

    pareto_rows = []
    tried = 0
    succeeded = 0
    
    # æª¢æŸ¥æ˜¯å¦å¯ä»¥åŒ¯å…¥ risk_valve_backtest
    try:
        from SSS_EnsembleTab import risk_valve_backtest
        logger.info("æˆåŠŸåŒ¯å…¥ risk_valve_backtest")
    except Exception as e:
        logger.error(f"åŒ¯å…¥ risk_valve_backtest å¤±æ•—: {e}")
        return go.Figure(), f"âŒ ç„¡æ³•åŒ¯å…¥ risk_valve_backtest: {e}"
    
    logger.info("é–‹å§‹åŸ·è¡Œåƒæ•¸æƒæ...")
    for cap_level in caps:
        for atr_mult in atr_mults:
            tried += 1
            if tried % 50 == 0:  # æ¯50æ¬¡è¨˜éŒ„ä¸€æ¬¡é€²åº¦
                logger.info(f"é€²åº¦: {tried}/{len(caps) * len(atr_mults)} (cap={cap_level:.2f}, atr={atr_mult:.2f})")
            
            try:
                out = risk_valve_backtest(
                    open_px=open_px, w=w, cost=None, benchmark_df=bench,
                    mode=(rv_mode or "cap"), cap_level=float(cap_level),
                    slope20_thresh=0.0, slope60_thresh=0.0,
                    atr_win=20, atr_ref_win=60, atr_ratio_mult=float(atr_mult),
                    use_slopes=True, slope_method="polyfit", atr_cmp="gt"
                )
                
                if not isinstance(out, dict) or "metrics" not in out:
                    logger.warning(f"cap={cap_level:.2f}, atr={atr_mult:.2f}: å›å‚³æ ¼å¼ç•°å¸¸")
                    continue
                
                m = out["metrics"]
                sig = out["signals"]["risk_trigger"]
                trigger_days = int(sig.fillna(False).sum())

                # å–ç”¨ã€é–¥é–€ã€ç‰ˆæœ¬ä½œç‚ºæ­¤çµ„åˆçš„é»ä½
                pf = float(m.get("pf_valve", np.nan))
                mdd = float(m.get("mdd_valve", np.nan))
                rt_sum_valve = float(m.get("right_tail_sum_valve", np.nan))
                rt_sum_orig = float(m.get("right_tail_sum_orig", np.nan)) if m.get("right_tail_sum_orig") is not None else np.nan
                rt_reduction = float(m.get("right_tail_reduction", np.nan)) if m.get("right_tail_reduction") is not None else (rt_sum_orig - rt_sum_valve if np.isfinite(rt_sum_orig) and np.isfinite(rt_sum_valve) else np.nan)

                # æ”¶é›†ä¸€ç­†é»è³‡æ–™
                pareto_rows.append({
                    "cap": cap_level,
                    "atr": atr_mult,
                    "pf": pf,
                    "max_drawdown": abs(mdd) if pd.notna(mdd) else np.nan,
                    "right_tail_sum_valve": rt_sum_valve,
                    "right_tail_sum_orig": rt_sum_orig,
                    "right_tail_reduction": rt_reduction,
                    "risk_trigger_days": trigger_days,
                    "label": f"cap={cap_level:.2f}, atr={atr_mult:.2f}"
                })
                succeeded += 1
                
                if succeeded % 20 == 0:  # æ¯20æ¬¡æˆåŠŸè¨˜éŒ„ä¸€æ¬¡
                    logger.info(f"æˆåŠŸ: {succeeded} çµ„ (cap={cap_level:.2f}, atr={atr_mult:.2f})")
                    
            except Exception as e:
                logger.warning(f"cap={cap_level:.2f}, atr={atr_mult:.2f} åŸ·è¡Œå¤±æ•—: {e}")
                continue

    logger.info(f"=== æƒæå®Œæˆ ===")
    logger.info(f"å˜—è©¦: {tried} çµ„ï¼ŒæˆåŠŸ: {succeeded} çµ„")
    
    if not pareto_rows:
        logger.error("æ²’æœ‰æˆåŠŸç”Ÿæˆä»»ä½•è³‡æ–™é»")
        return go.Figure(), "âŒ ç„¡æ³•å¾é¢¨éšªé–¥é–€å›æ¸¬çš„åƒæ•¸çµ„åˆä¸­å–å¾—è³‡æ–™"

    # ç”¨ reduction ç•¶é¡è‰²ï¼ˆè¶Šå¤§=å‰Šè¶Šå¤šå³å°¾â†’è¶Šç´…ï¼‰ï¼Œç¬¦åˆã€é¡è‰²è¶Šç´…ï¼å‰Šå¤ªå¤šå³å°¾ã€
    logger.info("é–‹å§‹è™•ç†çµæœè³‡æ–™...")
    dfp = pd.DataFrame(pareto_rows).dropna(subset=["pf","max_drawdown","right_tail_reduction"]).reset_index(drop=True)
    logger.info(f"è™•ç†å¾Œè³‡æ–™é»æ•¸: {len(dfp)}")
    logger.info(f"dfp æ¬„ä½: {list(dfp.columns)}")
    
    if dfp.empty:
        logger.error("è™•ç†å¾Œè³‡æ–™ç‚ºç©º")
        return go.Figure(), "âŒ è³‡æ–™è™•ç†å¾Œç‚ºç©ºï¼Œè«‹æª¢æŸ¥åŸå§‹è³‡æ–™"
    
    logger.info("é–‹å§‹ç¹ªè£½åœ–è¡¨...")
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=dfp['max_drawdown'],
        y=dfp['pf'],
        mode='markers',
        marker=dict(
            size=np.clip(dfp['risk_trigger_days'] / 5.0, 6, 30),
            color=dfp['right_tail_reduction'],
            colorscale='Reds',
            showscale=True,
            colorbar=dict(title="å³å°¾å‰Šæ¸›å¹…åº¦")
        ),
        text=dfp['label'],
        hovertemplate=(
            "<b>%{text}</b><br>" +
            "MDD: %{x:.2%}<br>" +
            "PF: %{y:.2f}<br>" +
            "å³å°¾ç¸½å’Œ(é–¥é–€): %{customdata[0]:.2f}<br>" +
            "å³å°¾ç¸½å’Œ(åŸå§‹): %{customdata[1]:.2f}<br>" +
            "å³å°¾å‰Šæ¸›: %{marker.color:.2f}<br>" +
            "é¢¨éšªè§¸ç™¼å¤©æ•¸: %{marker.size:.0f} å¤©<br>" +
            "<extra></extra>"
        ),
        customdata=dfp[["right_tail_sum_valve","right_tail_sum_orig"]].values,
        name="cap-atr grid"
    ))
    
    # åŠ å…¥ã€ŒCurrentã€æ¨™è¨˜é»ï¼ˆç•¶å‰å…¨å±€è¨­å®šï¼‰
    if cap_now in caps and atr_now in atr_mults:
        # æ‰¾åˆ°ç•¶å‰è¨­å®šå°æ‡‰çš„é»ä½
        current_point = dfp[(dfp['cap'] == cap_now) & (dfp['atr'] == atr_now)]
        if not current_point.empty:
            fig.add_trace(go.Scatter(
                x=current_point['max_drawdown'],
                y=current_point['pf'],
                mode='markers',
                marker=dict(
                    size=20,
                    symbol='star',
                    color='gold',
                    line=dict(color='black', width=2)
                ),
                text=f"Current: cap={cap_now:.2f}, atr={atr_now:.2f}",
                hovertemplate=(
                    "<b>%{text}</b><br>" +
                    "MDD: %{x:.2%}<br>" +
                    "PF: %{y:.2f}<br>" +
                    "<extra></extra>"
                ),
                name="Current Settings"
            ))
    
    # åŠ å…¥ã€ŒGlobalã€æ¨™è¨˜é»ï¼ˆå…¨å±€é–€æª»è¨­å®šï¼‰
    if risk_cap_value is not None and atr_ratio_value is not None:
        # å˜—è©¦æ‰¾åˆ°å°æ‡‰çš„æƒæçµæœé»ä½
        global_cap = float(risk_cap_value)
        global_atr = float(atr_ratio_value)
        global_point = dfp[(dfp['cap'] == global_cap) & (dfp['atr'] == global_atr)]
        
        if not global_point.empty:
            fig.add_trace(go.Scatter(
                x=global_point['max_drawdown'],
                y=global_point['pf'],
                mode='markers',
                marker=dict(
                    size=25,
                    symbol='diamond',
                    color='blue',
                    line=dict(color='white', width=2)
                ),
                text=f"Global: cap={global_cap:.2f}, atr={global_atr:.2f}",
                hovertemplate=(
                    "<b>%{text}</b><br>" +
                    "MDD: %{x:.2%}<br>" +
                    "PF: %{y:.2f}<br>" +
                    "<extra></extra>"
                ),
                name="Global Setting"
            ))

    fig.update_layout(
        title={
            'text': f'é¢¨éšª-å ±é…¬åœ°åœ–ï¼ˆPareto Mapï¼‰- {succeeded}/{tried} çµ„',
            'x': 0.5,
            'xanchor': 'center',
            'font': {'size': 20}
        },
        xaxis_title="æœ€å¤§å›æ’¤ï¼ˆæ„ˆå·¦æ„ˆå¥½ï¼‰",
        yaxis_title="PF ç²åˆ©å› å­ï¼ˆæ„ˆä¸Šæ„ˆå¥½ï¼‰",
        xaxis=dict(tickformat=".1%", gridcolor="rgba(128,128,128,0.2)"),
        yaxis=dict(gridcolor="rgba(128,128,128,0.2)"),
        plot_bgcolor="rgba(0,0,0,0)",
        paper_bgcolor="rgba(0,0,0,0)",
        margin=dict(r=120)
    )

    status_msg = f"âœ… æˆåŠŸç”Ÿæˆï¼šæƒæ capÃ—ATR æ¯”å€¼ {succeeded}/{tried} çµ„ã€‚é¡è‰²=å³å°¾èª¿æ•´å¹…åº¦ï¼ˆç´…=å‰Šæ¸›ï¼Œè—=æ”¾å¤§ï¼‰ï¼Œå¤§å°=é¢¨éšªè§¸ç™¼å¤©æ•¸ã€‚ç›®å‰å…¨å±€è¨­å®šï¼šcap={cap_now:.2f}, atr={atr_now:.2f}ã€‚è³‡æ–™ä¾†æºï¼š{data_source}"
    return fig, status_msg

def calculate_pareto_metrics(equity_curve, trade_df):
    """è¨ˆç®— Pareto Map æ‰€éœ€çš„æŒ‡æ¨™"""
    try:
        # åˆå§‹åŒ–æŒ‡æ¨™
        max_drawdown = 0.0
        pf = 1.0
        right_tail_loss = 0.0  # é è¨­ï¼šç„¡èª¿æ•´
        risk_trigger_days = 50
        
        # è™•ç†æ¬Šç›Šæ›²ç·šæ•¸æ“š
        if equity_curve is not None and not equity_curve.empty:
            # ç¢ºä¿æ¬Šç›Šæ›²ç·šæ˜¯ Series
            if isinstance(equity_curve, pd.DataFrame):
                if len(equity_curve.columns) == 1:
                    equity_curve = equity_curve.iloc[:, 0]
                else:
                    # å¦‚æœæœ‰å¤šåˆ—ï¼Œä½¿ç”¨ç¬¬ä¸€åˆ—
                    equity_curve = equity_curve.iloc[:, 0]
            
            # è¨ˆç®—æ—¥å ±é…¬ç‡
            daily_returns = equity_curve.pct_change().dropna()
            
            if len(daily_returns) > 0:
                # 1. æœ€å¤§å›æ’¤ï¼ˆæ„ˆå·¦æ„ˆå¥½ï¼‰
                peak = equity_curve.expanding().max()
                drawdown = (equity_curve - peak) / peak
                max_drawdown = abs(drawdown.min()) if not drawdown.empty else 0.0
                
                # 2. PFï¼ˆç²åˆ©å› å­ï¼Œæ„ˆä¸Šæ„ˆå¥½ï¼‰
                if trade_df is not None and not trade_df.empty and 'return' in trade_df.columns:
                    profits = trade_df[trade_df['return'] > 0]['return'].sum()
                    losses = abs(trade_df[trade_df['return'] < 0]['return'].sum())
                    pf = profits / losses if losses > 0 else (profits if profits > 0 else 1.0)
                else:
                    # å¦‚æœæ²’æœ‰äº¤æ˜“æ•¸æ“šï¼Œç”¨å¹´åŒ–å ±é…¬ç‡ä»£æ›¿
                    total_return = (equity_curve.iloc[-1] / equity_curve.iloc[0] - 1)
                    annual_return = total_return * (252 / len(daily_returns))
                    pf = 1 + annual_return  # è½‰æ›ç‚º PF æ ¼å¼
                
                # 3. å³å°¾èª¿æ•´å¹…åº¦ï¼ˆæ­£å€¼=å‰Šæ¸›å³å°¾ï¼Œè² å€¼=æ”¾å¤§å³å°¾ï¼Œ0=ç„¡èª¿æ•´ï¼‰
                # è¨ˆç®—å³å°¾é¢¨éšªï¼šä½¿ç”¨ååº¦å’Œå³°åº¦ä¾†è¡¡é‡
                positive_returns = daily_returns[daily_returns > 0]
                if len(positive_returns) > 0:
                    # è¨ˆç®—å³å°¾çš„èª¿æ•´ç¨‹åº¦
                    if len(positive_returns) >= 10:
                        # è¨ˆç®—ååº¦
                        mean_ret = positive_returns.mean()
                        std_ret = positive_returns.std()
                        if std_ret > 0:
                            skewness = ((positive_returns - mean_ret) / std_ret) ** 3
                            skewness_mean = skewness.mean()
                            
                            # å°‡ååº¦è½‰æ›ç‚º -1 åˆ° 1 çš„ç¯„åœ
                            # æ­£ååº¦ï¼ˆå³å°¾è¼ƒé•·ï¼‰= è² å€¼ï¼ˆæ”¾å¤§å³å°¾ï¼‰
                            # è² ååº¦ï¼ˆå·¦å°¾è¼ƒé•·ï¼‰= æ­£å€¼ï¼ˆå‰Šæ¸›å³å°¾ï¼‰
                            if skewness_mean > 0:
                                # æ­£ååº¦ï¼šå³å°¾è¼ƒé•·ï¼Œè¡¨ç¤ºæ”¾å¤§å³å°¾
                                right_tail_loss = -min(1.0, skewness_mean / 2)  # è½‰æ›ç‚º -1 åˆ° 0
                            else:
                                # è² ååº¦ï¼šå·¦å°¾è¼ƒé•·ï¼Œè¡¨ç¤ºå‰Šæ¸›å³å°¾
                                right_tail_loss = min(1.0, abs(skewness_mean) / 2)  # è½‰æ›ç‚º 0 åˆ° 1
                        else:
                            right_tail_loss = 0.0  # ç„¡æ³¢å‹•ï¼Œç„¡èª¿æ•´
                    else:
                        right_tail_loss = 0.0  # æ•¸æ“šä¸è¶³ï¼Œç„¡èª¿æ•´
                else:
                    right_tail_loss = 1.0  # æ²’æœ‰æ­£å ±é…¬ï¼Œå®Œå…¨å‰Šæ¸›å³å°¾
                
                # 4. é¢¨éšªè§¸ç™¼å¤©æ•¸ï¼ˆé»å¤§å°ï¼Œè¶Šå¤§ï¼ç®¡å¾—è¶Šå‹¤ï¼‰
                if trade_df is not None and not trade_df.empty and 'trade_date' in trade_df.columns:
                    trade_df['trade_date'] = pd.to_datetime(trade_df['trade_date'])
                    # è¨ˆç®—æœ‰äº¤æ˜“çš„å¤©æ•¸
                    risk_trigger_days = len(trade_df['trade_date'].dt.date.unique())
                else:
                    # å¦‚æœæ²’æœ‰äº¤æ˜“æ•¸æ“šï¼Œç”¨æ¬Šç›Šæ›²ç·šçš„æ³¢å‹•ç‡ä¾†ä¼°è¨ˆ
                    volatility = daily_returns.std()
                    risk_trigger_days = min(100, int(volatility * 1000))  # è½‰æ›ç‚ºåˆç†ç¯„åœ
        else:
            # å¦‚æœæ²’æœ‰æ¬Šç›Šæ›²ç·šï¼Œå˜—è©¦å¾äº¤æ˜“æ•¸æ“šè¨ˆç®—åŸºæœ¬æŒ‡æ¨™
            if trade_df is not None and not trade_df.empty:
                # å¾äº¤æ˜“æ•¸æ“šè¨ˆç®—åŸºæœ¬æŒ‡æ¨™
                if 'return' in trade_df.columns:
                    profits = trade_df[trade_df['return'] > 0]['return'].sum()
                    losses = abs(trade_df[trade_df['return'] < 0]['return'].sum())
                    pf = profits / losses if losses > 0 else (profits if profits > 0 else 1.0)
                
                # ä¼°ç®—é¢¨éšªè§¸ç™¼å¤©æ•¸
                if 'trade_date' in trade_df.columns:
                    trade_df['trade_date'] = pd.to_datetime(trade_df['trade_date'])
                    risk_trigger_days = len(trade_df['trade_date'].dt.date.unique())
                else:
                    risk_trigger_days = len(trade_df)
                
                # å¦‚æœæ²’æœ‰æ¬Šç›Šæ›²ç·šï¼Œç„¡æ³•è¨ˆç®—æœ€å¤§å›æ’¤å’Œå³å°¾æå¤±ï¼Œä½¿ç”¨é è¨­å€¼
                max_drawdown = 0.1  # é è¨­ 10% å›æ’¤
                right_tail_loss = 0.0  # é è¨­ï¼šç„¡èª¿æ•´
        
        return {
            'max_drawdown': max_drawdown,
            'pf': pf,
            'right_tail_loss': right_tail_loss,
            'risk_trigger_days': risk_trigger_days
        }
        
    except Exception as e:
        logger.exception(f"è¨ˆç®— Pareto æŒ‡æ¨™å¤±æ•—ï¼š{e}")
        return None

def create_pareto_map(pareto_data):
    """å‰µå»ºé¢¨éšª-å ±é…¬åœ°åœ–ï¼ˆPareto Mapï¼‰"""
    df = pd.DataFrame(pareto_data)
    
    # å‰µå»ºæ•£é»åœ–
    fig = go.Figure()
    
    # æ·»åŠ æ•£é»åœ–
    fig.add_trace(go.Scatter(
        x=df['max_drawdown'],
        y=df['pf'],
        mode='markers',
        marker=dict(
            size=df['risk_trigger_days'] / 10,  # é»å¤§å°ï¼šé¢¨éšªè§¸ç™¼å¤©æ•¸
            color=df['right_tail_loss'],  # é¡è‰²ï¼šå³å°¾èª¿æ•´å¹…åº¦
            colorscale='RdBu',  # ç´…è—è‰²éšï¼šç´…è‰²=å‰Šæ¸›å³å°¾ï¼ˆæ­£å€¼ï¼‰ï¼Œè—è‰²=æ”¾å¤§å³å°¾ï¼ˆè² å€¼ï¼‰
            cmin=-1,  # æœ€å°å€¼ï¼š-1ï¼ˆæœ€å¤§æ”¾å¤§å³å°¾ï¼‰
            cmax=1,   # æœ€å¤§å€¼ï¼š1ï¼ˆæœ€å¤§å‰Šæ¸›å³å°¾ï¼‰
            mid=0,    # ä¸­ç·šï¼š0ï¼ˆç„¡èª¿æ•´ï¼‰
            colorbar=dict(
                title="å³å°¾èª¿æ•´å¹…åº¦<br>ï¼ˆç´…=å‰Šæ¸›ï¼Œè—=æ”¾å¤§ï¼‰",
                titleside="right",
                tickformat=".2f",
                tickmode="array",
                tickvals=[-1, -0.5, 0, 0.5, 1],
                ticktext=["æ”¾å¤§å³å°¾", "è¼•å¾®æ”¾å¤§", "ç„¡èª¿æ•´", "è¼•å¾®å‰Šæ¸›", "å‰Šæ¸›å³å°¾"]
            ),
            showscale=True
        ),
        text=df['strategy'],
        hovertemplate=(
            "<b>%{text}</b><br>" +
            "æœ€å¤§å›æ’¤: %{x:.2%}<br>" +
            "PF: %{y:.2f}<br>" +
            "å³å°¾èª¿æ•´: %{marker.color:.2f}<br>" +
            "é¢¨éšªè§¸ç™¼å¤©æ•¸: %{marker.size:.0f}<br>" +
            "<extra></extra>"
        ),
        name="ç­–ç•¥"
    ))
    
    # æ·»åŠ  Pareto é‚Šç•Œç·šï¼ˆç†æƒ³å€åŸŸï¼‰
    # æ‰¾åˆ°æœ€ä½³é»ï¼ˆæœ€å°å›æ’¤ï¼Œæœ€å¤§PFï¼‰
    best_idx = df['max_drawdown'].idxmin()
    best_dd = df.loc[best_idx, 'max_drawdown']
    best_pf = df.loc[best_idx, 'pf']
    
    # æ·»åŠ ç†æƒ³å€åŸŸçš„åƒè€ƒç·š
    fig.add_shape(
        type="rect",
        x0=0, y0=best_pf,
        x1=best_dd, y1=df['pf'].max() * 1.1,
        fillcolor="rgba(0,255,0,0.1)",
        line=dict(color="green", width=2, dash="dash"),
        name="ç†æƒ³å€åŸŸ"
    )
    
    # æ·»åŠ æ–‡å­—æ¨™è¨»
    fig.add_annotation(
        x=best_dd/2, y=best_pf + (df['pf'].max() - best_pf)/2,
        text="ç†æƒ³å€åŸŸ<br>ï¼ˆä½å›æ’¤ï¼Œé«˜PFï¼‰",
        showarrow=True,
        arrowhead=2,
        arrowsize=1,
        arrowwidth=2,
        arrowcolor="green",
        font=dict(size=12, color="green")
    )
    
    # æ›´æ–°ä½ˆå±€
    fig.update_layout(
        title={
            'text': 'é¢¨éšª-å ±é…¬åœ°åœ–ï¼ˆPareto Mapï¼‰',
            'x': 0.5,
            'xanchor': 'center',
            'font': {'size': 20}
        },
        xaxis_title="æœ€å¤§å›æ’¤ï¼ˆæ„ˆå·¦æ„ˆå¥½ï¼‰",
        yaxis_title="PF ç²åˆ©å› å­ï¼ˆæ„ˆä¸Šæ„ˆå¥½ï¼‰",
        xaxis=dict(
            tickformat=".1%",
            gridcolor="rgba(128,128,128,0.2)"
        ),
        yaxis=dict(
            gridcolor="rgba(128,128,128,0.2)"
        ),
        plot_bgcolor="rgba(0,0,0,0)",
        paper_bgcolor="rgba(0,0,0,0)",
        font=dict(size=12),
        legend=dict(
            x=1.02,
            y=1,
            xanchor="left",
            yanchor="top"
        ),
        margin=dict(r=150)  # ç‚ºé¡è‰²æ¢ç•™å‡ºç©ºé–“
    )
    
    # æ·»åŠ ç¶²æ ¼
    fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor="rgba(128,128,128,0.2)")
    fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor="rgba(128,128,128,0.2)")
    
    return fig

# --------- æ–°å¢ï¼šPareto Map CSV ä¸‹è¼‰ Callback ---------
@app.callback(
    Output("pareto-csv-download", "data"),
    Input("download-pareto-csv", "n_clicks"),
    State("enhanced-trades-cache", "data"),
    State("backtest-store", "data"),
    State("rv-mode", "value"),
    prevent_initial_call=True
)
def download_pareto_csv(n_clicks, cache, backtest_data, rv_mode):
    """ä¸‹è¼‰ Pareto Map æ•¸æ“šç‚º CSV æª”æ¡ˆ"""
    if not n_clicks:
        return None
    
    try:
        # å„ªå…ˆä½¿ç”¨ enhanced-trades-cacheï¼Œå¦‚æœæ²’æœ‰å‰‡å˜—è©¦å¾ backtest-store ç”Ÿæˆ
        if cache:
            df_raw = df_from_pack(cache.get("df_raw"))
            daily_state = df_from_pack(cache.get("daily_state"))
            data_source = "enhanced-trades-cache"
        elif backtest_data and backtest_data.get("results"):
            results = backtest_data["results"]
            selected_strategy = None
            for strategy_name, result in results.items():
                if result.get("daily_state") or result.get("daily_state_std"):
                    selected_strategy = strategy_name
                    break
            
            if not selected_strategy:
                return None
            
            result = results[selected_strategy]
            daily_state = df_from_pack(result.get("daily_state") or result.get("daily_state_std"))
            df_raw = df_from_pack(backtest_data.get("df_raw"))
            data_source = f"backtest-store ({selected_strategy})"
        else:
            return None
        
        # è³‡æ–™é©—è­‰
        if df_raw is None or df_raw.empty or daily_state is None or daily_state.empty:
            return None
        
        # æ¬„åå°é½Š
        c_open = "open" if "open" in df_raw.columns else _first_col(df_raw, ["Open","é–‹ç›¤åƒ¹"])
        c_close = "close" if "close" in df_raw.columns else _first_col(df_raw, ["Close","æ”¶ç›¤åƒ¹"])
        c_high  = "high" if "high" in df_raw.columns else _first_col(df_raw, ["High","æœ€é«˜åƒ¹"])
        c_low   = "low"  if "low"  in df_raw.columns else _first_col(df_raw, ["Low","æœ€ä½åƒ¹"])
        
        if c_open is None or c_close is None:
            return None
        
        # æº–å‚™è¼¸å…¥åºåˆ—
        open_px = pd.to_numeric(df_raw[c_open], errors="coerce").dropna()
        open_px.index = pd.to_datetime(df_raw.index)
        
        # å– open_px å¾Œï¼Œæº–å‚™ wï¼ˆbaseline å„ªå…ˆï¼‰
        ds_base = df_from_pack(cache.get("daily_state_base")) if cache else None
        wc_base = series_from_pack(cache.get("weight_curve_base")) if cache else None
        
        # å¾ backtest-store ä¾†çš„æƒ…æ³
        if ds_base is None and (not cache) and backtest_data and "results" in backtest_data:
            ds_base = df_from_pack(result.get("daily_state_base"))
            # æ³¨æ„ï¼šweight_curve_base ä¹Ÿå¯èƒ½å­˜åœ¨æ–¼ result
            try:
                wc_base = series_from_pack(result.get("weight_curve_base"))
            except Exception:
                wc_base = None
        
        # ä»¥ baseline w ç‚ºå„ªå…ˆï¼›æ²’æœ‰å†é€€å›ç¾è¡Œ daily_state['w']
        if ds_base is not None and (not ds_base.empty) and ("w" in ds_base.columns):
            w = pd.to_numeric(ds_base["w"], errors="coerce").reindex(open_px.index).ffill().fillna(0.0)
        elif wc_base is not None and (not wc_base.empty):
            w = pd.to_numeric(wc_base, errors="coerce").reindex(open_px.index).ffill().fillna(0.0)
        else:
            # å¾Œå‚™ï¼šæ²¿ç”¨ç¾è¡Œ daily_stateï¼ˆå¯èƒ½å·²è¢«é–¥é–€å£“éï¼‰
            if "w" not in daily_state.columns:
                return None
            w = pd.to_numeric(daily_state["w"], errors="coerce").reindex(open_px.index).ffill().fillna(0.0)
        
        bench = pd.DataFrame({
            "æ”¶ç›¤åƒ¹": pd.to_numeric(df_raw[c_close], errors="coerce"),
        }, index=pd.to_datetime(df_raw.index))
        if c_high and c_low:
            bench["æœ€é«˜åƒ¹"] = pd.to_numeric(df_raw[c_high], errors="coerce")
            bench["æœ€ä½åƒ¹"] = pd.to_numeric(df_raw[c_low], errors="coerce")
        
        # ä½¿ç”¨èˆ‡ generate_pareto_map ç›¸åŒçš„åƒæ•¸ç¯„åœå’Œé‚è¼¯
        logger.info("=== é–‹å§‹ç”Ÿæˆ Pareto Map æ•¸æ“šç”¨æ–¼ CSV ä¸‹è¼‰ ===")
        caps = np.round(np.arange(0.10, 1.00 + 1e-9, 0.05), 2)
        atr_mults = np.round(np.arange(1.00, 2.00 + 1e-9, 0.05), 2)
        logger.info(f"cap ç¯„åœ: {len(caps)} å€‹å€¼ï¼Œå¾ {caps[0]} åˆ° {caps[-1]}")
        logger.info(f"ATR æ¯”å€¼ç¯„åœ: {len(atr_mults)} å€‹å€¼ï¼Œå¾ {atr_mults[0]} åˆ° {atr_mults[-1]}")
        logger.info(f"ç¸½çµ„åˆæ•¸: {len(caps) * len(atr_mults)}")
        
        pareto_data = []
        tried = 0
        succeeded = 0
        
        # æª¢æŸ¥æ˜¯å¦å¯ä»¥åŒ¯å…¥ risk_valve_backtest
        try:
            from SSS_EnsembleTab import risk_valve_backtest
            logger.info("æˆåŠŸåŒ¯å…¥ risk_valve_backtest")
        except Exception as e:
            logger.error(f"åŒ¯å…¥ risk_valve_backtest å¤±æ•—: {e}")
            return None
        
        logger.info("é–‹å§‹åŸ·è¡Œåƒæ•¸æƒæ...")
        for cap_level in caps:
            for atr_mult in atr_mults:
                tried += 1
                if tried % 50 == 0:  # æ¯50æ¬¡è¨˜éŒ„ä¸€æ¬¡é€²åº¦
                    logger.info(f"é€²åº¦: {tried}/{len(caps) * len(atr_mults)} (cap={cap_level:.2f}, atr={atr_mult:.2f})")
                
                try:
                    out = risk_valve_backtest(
                        open_px=open_px, w=w, cost=None, benchmark_df=bench,
                        mode=(rv_mode or "cap"), cap_level=float(cap_level),
                        slope20_thresh=0.0, slope60_thresh=0.0,
                        atr_win=20, atr_ref_win=60, atr_ratio_mult=float(atr_mult),
                        use_slopes=True, slope_method="polyfit", atr_cmp="gt"
                    )
                    
                    if out and "metrics" in out:
                        m = out["metrics"]
                        
                        # è¨ˆç®— Pareto æŒ‡æ¨™
                        equity_curve = out.get("daily_state_valve", {}).get("equity")
                        trade_df = None  # risk_valve_backtest ä¸ç›´æ¥æä¾›äº¤æ˜“è¨˜éŒ„
                        
                        metrics = calculate_pareto_metrics(equity_curve, trade_df)
                        if metrics:
                            pareto_data.append({
                                'strategy': f'cap_{cap_level:.2f}_atr_{atr_mult:.2f}',
                                'cap': cap_level,
                                'atr_ratio': atr_mult,
                                'max_drawdown': metrics['max_drawdown'],
                                'pf': metrics['pf'],
                                'right_tail_loss': metrics['right_tail_loss'],
                                'risk_trigger_days': metrics['risk_trigger_days'],
                                'pf_orig': m.get('pf_orig', 0.0),
                                'pf_valve': m.get('pf_valve', 0.0),
                                'mdd_orig': m.get('mdd_orig', 0.0),
                                'mdd_valve': m.get('mdd_valve', 0.0),
                                'right_tail_reduction': m.get('right_tail_reduction', 0.0)
                            })
                            succeeded += 1
                            
                except Exception as e:
                    logger.debug(f"åƒæ•¸çµ„åˆ cap={cap_level}, atr={atr_mult} è¨ˆç®—å¤±æ•—: {e}")
                    continue
        
        if not pareto_data:
            logger.warning("æ²’æœ‰ç”Ÿæˆä»»ä½• Pareto æ•¸æ“š")
            return None
        
        logger.info(f"æˆåŠŸç”Ÿæˆ {succeeded} çµ„ Pareto æ•¸æ“š")
        
        # è½‰æ›ç‚º DataFrame ä¸¦æº–å‚™ä¸‹è¼‰
        df_pareto = pd.DataFrame(pareto_data)
        
        # æ·»åŠ æ™‚é–“æˆ³è¨˜
        timestamp = pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")
        filename = f"pareto_map_data_{timestamp}.csv"
        
        # è¿”å› CSV ä¸‹è¼‰æ•¸æ“š
        return dcc.send_data_frame(
            df_pareto.to_csv,
            filename,
            index=False,
            encoding='utf-8-sig'  # æ”¯æ´ä¸­æ–‡
        )
        
    except Exception as e:
        logger.exception(f"ä¸‹è¼‰ Pareto Map CSV å¤±æ•—ï¼š{e}")
        return None

# --------- æ–°å¢ï¼šå‹•æ…‹åˆ‡æ› Top/Worst çš„ callback ---------
@app.callback(
    [dash.Output("phase-top-table", "data"),
     dash.Output("phase-worst-table", "data")],
    [dash.Input("phase-source", "value"),
     dash.Input("phase-table-store", "data")]
)
def _update_top_worst(src, store):
    if not store:
        raise dash.exceptions.PreventUpdate
    import pandas as pd
    records = store.get("records", [])
    ordered = store.get("ordered", [])
    basis   = store.get("basis", None)
    has_stage = store.get("has_stage", False)

    df = pd.DataFrame(records)
    # ä¾†æºéæ¿¾
    if has_stage and "éšæ®µ" in df.columns:
        if src == "acc":
            df = df[df["éšæ®µ"].astype(str).str.contains("åŠ ç¢¼", na=False)]
        elif src == "dis":
            df = df[df["éšæ®µ"].astype(str).str.contains("æ¸›ç¢¼", na=False)]

    if basis and basis in df.columns and not df.empty:
        top3   = df.nlargest(3, basis)
        worst3 = df.nsmallest(3, basis)
    else:
        top3   = df.head(3)
        worst3 = df.tail(3)

    return top3[ordered].to_dict("records"), worst3[ordered].to_dict("records")

if __name__ == '__main__':
    # åˆå§‹åŒ–æ—¥èªŒç³»çµ±ï¼ˆåªåœ¨å¯¦éš›é‹è¡Œ app æ™‚ï¼‰
    _initialize_app_logging()
    
    # åœ¨ä¸»ç·šç¨‹ä¸­åŸ·è¡Œå•Ÿå‹•ä»»å‹™
    safe_startup()
    
    # è¨­ç½®æ›´å®‰å…¨çš„æœå‹™å™¨é…ç½®
    app.run_server(
        debug=True, 
        host='127.0.0.2', 
        port=8051,
        threaded=True,
        use_reloader=False  # é¿å…é‡è¼‰å™¨é€ æˆçš„ç·šç¨‹å•é¡Œ
    ) 